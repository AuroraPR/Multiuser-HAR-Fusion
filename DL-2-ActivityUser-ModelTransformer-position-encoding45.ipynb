{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934b764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2024-07-05': ['0001', '3d57', 'ed9c'], '2024-07-06': ['0001', '3d57', 'ed9c'], '2024-07-07': ['0001', '3d57', 'ed9c'], '2024-07-18': ['16fe', 'f02e', 'ed9c'], '2024-07-19': ['16fe', 'f02e', 'ed9c'], '2024-07-20': ['16fe', 'f02e', 'ed9c'], '2024-07-24': ['16fe', '5b66', 'ed9c'], '2024-07-25': ['16fe', '5b66', 'ed9c'], '2024-07-26': ['16fe', '5b66', 'ed9c'], '2024-07-27': ['16fe', '5b66', 'ed9c'], '2024-07-28': ['16fe', '5b66', 'ed9c'], '2024-07-29': ['16fe', '5b66', 'ed9c'], '2024-07-30': ['16fe', '5b66', 'ed9c'], '2024-07-31': ['16fe', '5b66', 'ed9c']}\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('agg-config.txt')\n",
    "\n",
    "\n",
    "time_step = int(config.get('Configuration', 'time_step'))\n",
    "time_step2 = int(config.get('Configuration', 'time_step2'))\n",
    "\n",
    "window_size = int(config.get('Configuration', 'window_size'))\n",
    "processed_data_folder = config.get('Configuration', 'processed_data_folder')\n",
    "raw_data_folder = config.get('Configuration', 'raw_data_folder')\n",
    "\n",
    "ini_date = config.get('Configuration', 'ini_date')\n",
    "end_date = config.get('Configuration', 'end_date')\n",
    "\n",
    "\n",
    "activities=config.get('Configuration', 'learn_activities')\n",
    "activities = [(item.strip()) for item in activities.split(',')]\n",
    "\n",
    "cross_days=config.get('Configuration', 'cross_days')\n",
    "cross_days = [(item.strip()) for item in cross_days.split(',')]\n",
    "\n",
    "sensors=config.get('Configuration', 'sensors')\n",
    "sensors = [(item.strip()) for item in sensors.split(',')]\n",
    "\n",
    "w = int(config.get('Configuration', 'w'))\n",
    "h = int(config.get('Configuration', 'h'))\n",
    "\n",
    "users_day={}\n",
    "for cross_day in cross_days:\n",
    "    users_day[cross_day]=config.get('Configuration', cross_day)\n",
    "    users_day[cross_day] = [(item.strip()) for item in users_day[cross_day].split(',')]\n",
    "print(users_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ea50ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv    \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "off_zone=60*60*2\n",
    "\n",
    "def day_time(t0,tN,ti):\n",
    "    return int((int)((ti+off_zone)/(60*60*24)))\n",
    "\n",
    "\n",
    "def time2str(t0,tN,tt):\n",
    "    return datetime.fromtimestamp(tt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def day_time0(t0,tN,ti):\n",
    "    return day_time(ti)-day_time(t0)+1\n",
    "\n",
    "def relT(t0,tN,ti):\n",
    "    return (int)((ti-t0)/time_step2)\n",
    "\n",
    "def sizeT(t0,tN):\n",
    "    return relT(t0,tN,tN)+1\n",
    "\n",
    "\n",
    "def initTime(ini_date,end_date):\n",
    "    tN = (int)(datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "\n",
    "    t0 = (int)(datetime.strptime(ini_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    print (ini_date,\"Init date is\", t0, \"day:\",day_time(t0,tN,t0), time2str(t0,tN,t0))\n",
    "    print (end_date,\"End date is\", tN, \"day:\",day_time(t0,tN,tN), time2str(t0,tN,tN))\n",
    "\n",
    "    day=list(range(day_time(t0,tN,t0),day_time(t0,tN,tN)+1))[0]\n",
    "    return day,t0,tN\n",
    "    \n",
    "initTime(ini_date,end_date)\n",
    "\n",
    "\n",
    "def getStrDatefrom(day_number):\n",
    "    # Reference date (1970-01-01)\n",
    "    reference_date = datetime(1970, 1, 1)\n",
    "    \n",
    "    # Compute the date corresponding to the day number\n",
    "    resulting_date = reference_date + timedelta(days=day_number)\n",
    "    \n",
    "    return resulting_date.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeeab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ed8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-05\n",
      "New ini_date: 2024-07-05 02:00:00\n",
      "New end_date: 2024-07-06 01:59:59\n",
      "2024-07-05 02:00:00 Init date is 1720137600 day: 19909 2024-07-05 02:00:00\n",
      "2024-07-06 01:59:59 End date is 1720223999 day: 19910 2024-07-06 01:59:59\n",
      "2024-07-06\n",
      "New ini_date: 2024-07-06 02:00:00\n",
      "New end_date: 2024-07-07 01:59:59\n",
      "2024-07-06 02:00:00 Init date is 1720224000 day: 19910 2024-07-06 02:00:00\n",
      "2024-07-07 01:59:59 End date is 1720310399 day: 19911 2024-07-07 01:59:59\n",
      "2024-07-07\n",
      "New ini_date: 2024-07-07 02:00:00\n",
      "New end_date: 2024-07-08 01:59:59\n",
      "2024-07-07 02:00:00 Init date is 1720310400 day: 19911 2024-07-07 02:00:00\n",
      "2024-07-08 01:59:59 End date is 1720396799 day: 19912 2024-07-08 01:59:59\n",
      "2024-07-18\n",
      "New ini_date: 2024-07-18 02:00:00\n",
      "New end_date: 2024-07-19 01:59:59\n",
      "2024-07-18 02:00:00 Init date is 1721260800 day: 19922 2024-07-18 02:00:00\n",
      "2024-07-19 01:59:59 End date is 1721347199 day: 19923 2024-07-19 01:59:59\n",
      "2024-07-19\n",
      "New ini_date: 2024-07-19 02:00:00\n",
      "New end_date: 2024-07-20 01:59:59\n",
      "2024-07-19 02:00:00 Init date is 1721347200 day: 19923 2024-07-19 02:00:00\n",
      "2024-07-20 01:59:59 End date is 1721433599 day: 19924 2024-07-20 01:59:59\n",
      "2024-07-20\n",
      "New ini_date: 2024-07-20 02:00:00\n",
      "New end_date: 2024-07-21 01:59:59\n",
      "2024-07-20 02:00:00 Init date is 1721433600 day: 19924 2024-07-20 02:00:00\n",
      "2024-07-21 01:59:59 End date is 1721519999 day: 19925 2024-07-21 01:59:59\n",
      "2024-07-24\n",
      "New ini_date: 2024-07-24 02:00:00\n",
      "New end_date: 2024-07-25 01:59:59\n",
      "2024-07-24 02:00:00 Init date is 1721779200 day: 19928 2024-07-24 02:00:00\n",
      "2024-07-25 01:59:59 End date is 1721865599 day: 19929 2024-07-25 01:59:59\n",
      "2024-07-25\n",
      "New ini_date: 2024-07-25 02:00:00\n",
      "New end_date: 2024-07-26 01:59:59\n",
      "2024-07-25 02:00:00 Init date is 1721865600 day: 19929 2024-07-25 02:00:00\n",
      "2024-07-26 01:59:59 End date is 1721951999 day: 19930 2024-07-26 01:59:59\n",
      "2024-07-26\n",
      "New ini_date: 2024-07-26 02:00:00\n",
      "New end_date: 2024-07-27 01:59:59\n",
      "2024-07-26 02:00:00 Init date is 1721952000 day: 19930 2024-07-26 02:00:00\n",
      "2024-07-27 01:59:59 End date is 1722038399 day: 19931 2024-07-27 01:59:59\n",
      "2024-07-27\n",
      "New ini_date: 2024-07-27 02:00:00\n",
      "New end_date: 2024-07-28 01:59:59\n",
      "2024-07-27 02:00:00 Init date is 1722038400 day: 19931 2024-07-27 02:00:00\n",
      "2024-07-28 01:59:59 End date is 1722124799 day: 19932 2024-07-28 01:59:59\n",
      "2024-07-28\n",
      "New ini_date: 2024-07-28 02:00:00\n",
      "New end_date: 2024-07-29 01:59:59\n",
      "2024-07-28 02:00:00 Init date is 1722124800 day: 19932 2024-07-28 02:00:00\n",
      "2024-07-29 01:59:59 End date is 1722211199 day: 19933 2024-07-29 01:59:59\n",
      "2024-07-29\n",
      "New ini_date: 2024-07-29 02:00:00\n",
      "New end_date: 2024-07-30 01:59:59\n",
      "2024-07-29 02:00:00 Init date is 1722211200 day: 19933 2024-07-29 02:00:00\n",
      "2024-07-30 01:59:59 End date is 1722297599 day: 19934 2024-07-30 01:59:59\n",
      "2024-07-30\n",
      "New ini_date: 2024-07-30 02:00:00\n",
      "New end_date: 2024-07-31 01:59:59\n",
      "2024-07-30 02:00:00 Init date is 1722297600 day: 19934 2024-07-30 02:00:00\n",
      "2024-07-31 01:59:59 End date is 1722383999 day: 19935 2024-07-31 01:59:59\n",
      "2024-07-31\n",
      "New ini_date: 2024-07-31 02:00:00\n",
      "New end_date: 2024-08-01 01:59:59\n",
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n",
      "[19909, 19910, 19911, 19922, 19923, 19924, 19928, 19929, 19930, 19931, 19932, 19933, 19934, 19935]\n",
      "{19909: (1720137600, 1720223999), 19910: (1720224000, 1720310399), 19911: (1720310400, 1720396799), 19922: (1721260800, 1721347199), 19923: (1721347200, 1721433599), 19924: (1721433600, 1721519999), 19928: (1721779200, 1721865599), 19929: (1721865600, 1721951999), 19930: (1721952000, 1722038399), 19931: (1722038400, 1722124799), 19932: (1722124800, 1722211199), 19933: (1722211200, 1722297599), 19934: (1722297600, 1722383999), 19935: (1722384000, 1722470399)}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "days=[]\n",
    "t0N_days={}\n",
    "\n",
    "for cross_day in cross_days:\n",
    "    print(cross_day)\n",
    "    # Convertir las fechas a objetos datetime\n",
    "    ini_date_dt = datetime.strptime(ini_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    cross_day_dt = datetime.strptime(cross_day, \"%Y-%m-%d\")\n",
    "\n",
    "    # Reemplazar el día manteniendo la hora original\n",
    "    new_ini_date = cross_day_dt.replace(hour=ini_date_dt.hour, minute=ini_date_dt.minute, second=ini_date_dt.second)\n",
    "    new_end_date = cross_day_dt.replace(hour=end_date_dt.hour, minute=end_date_dt.minute, second=end_date_dt.second) + timedelta(days=1)\n",
    "\n",
    "    # Convertir las fechas de nuevo a cadena si es necesario\n",
    "    new_ini_date_str = new_ini_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    new_end_date_str = new_end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    print(f\"New ini_date: {new_ini_date_str}\")\n",
    "    print(f\"New end_date: {new_end_date_str}\")\n",
    "    day,t0,tN=initTime(new_ini_date_str,new_end_date_str)\n",
    "    days.append(day)\n",
    "    t0N_days[day]=(t0,tN)\n",
    "    \n",
    "\n",
    "print(days)\n",
    "print(t0N_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 14, 1440)\n",
      "\t toileting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.toileting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.toileting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.toileting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.toileting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.toileting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.toileting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.toileting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.toileting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.toileting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.toileting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.toileting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.toileting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.toileting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.toileting.tsv\n",
      "19935 (1440,)\n",
      "\t resting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.resting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.resting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.resting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.resting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.resting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.resting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.resting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.resting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.resting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.resting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.resting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.resting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.resting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.resting.tsv\n",
      "19935 (1440,)\n",
      "\t exit\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.exit.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.exit.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.exit.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.exit.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.exit.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.exit.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.exit.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.exit.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.exit.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.exit.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.exit.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.exit.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.exit.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.exit.tsv\n",
      "19935 (1440,)\n",
      "\t cooking\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.cooking.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.cooking.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.cooking.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.cooking.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.cooking.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.cooking.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.cooking.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.cooking.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.cooking.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.cooking.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.cooking.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.cooking.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.cooking.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.cooking.tsv\n",
      "19935 (1440,)\n",
      "\t shower\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.shower.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.shower.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.shower.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.shower.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.shower.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.shower.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.shower.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.shower.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.shower.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.shower.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.shower.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.shower.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.shower.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.shower.tsv\n",
      "19935 (1440,)\n",
      "\t pc\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.pc.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.pc.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.pc.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.pc.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.pc.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.pc.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.pc.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.pc.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.pc.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.pc.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.pc.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.pc.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.pc.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.pc.tsv\n",
      "19935 (1440,)\n",
      "\t sleep\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.sleep.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.sleep.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.sleep.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.sleep.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.sleep.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.sleep.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.sleep.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.sleep.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.sleep.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.sleep.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.sleep.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.sleep.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.sleep.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.sleep.tsv\n",
      "19935 (1440,)\n",
      "\t kitchen\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.kitchen.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.kitchen.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.kitchen.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.kitchen.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.kitchen.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.kitchen.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.kitchen.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.kitchen.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.kitchen.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.kitchen.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.kitchen.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.kitchen.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.kitchen.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.kitchen.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "len_users=3\n",
    "loc_user=np.zeros((len(activities),len_users,len(days),sizeT(t0,tN)))\n",
    "print(loc_user.shape)\n",
    "for ax,activity in enumerate(activities):\n",
    "    print(\"\\t\",activity)\n",
    "    for dx,day in enumerate(days):\n",
    "        day_str=getStrDatefrom(day)\n",
    "        users=users_day[day_str]\n",
    "        print(day,users)\n",
    "        for ux,user in enumerate(users):\n",
    "            print(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\")\n",
    "            series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"loc\"])\n",
    "            series=series[\"loc\"].values\n",
    "            print(day,series.shape)\n",
    "            loc_user[ax][ux][dx]=series\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9631e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 14, 1440)\n",
      "\t fridge_13\n",
      "./data-har//DAY_19909/object_sensor/fridge_13.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/fridge_13.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/fridge_13.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/fridge_13.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/fridge_13.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/fridge_13.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/fridge_13.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/fridge_13.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/fridge_13.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/fridge_13.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/fridge_13.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/fridge_13.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/fridge_13.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/fridge_13.tsv\n",
      "19935 (1440,)\n",
      "\t tap_22\n",
      "./data-har//DAY_19909/object_sensor/tap_22.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/tap_22.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/tap_22.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/tap_22.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/tap_22.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/tap_22.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/tap_22.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/tap_22.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/tap_22.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/tap_22.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/tap_22.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/tap_22.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/tap_22.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/tap_22.tsv\n",
      "19935 (1440,)\n",
      "\t micro_5\n",
      "./data-har//DAY_19909/object_sensor/micro_5.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/micro_5.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/micro_5.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/micro_5.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/micro_5.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/micro_5.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/micro_5.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/micro_5.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/micro_5.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/micro_5.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/micro_5.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/micro_5.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/micro_5.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/micro_5.tsv\n",
      "19935 (1440,)\n",
      "\t pans_8\n",
      "./data-har//DAY_19909/object_sensor/pans_8.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pans_8.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pans_8.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pans_8.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pans_8.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pans_8.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pans_8.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pans_8.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pans_8.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pans_8.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pans_8.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pans_8.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pans_8.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pans_8.tsv\n",
      "19935 (1440,)\n",
      "\t dishes_9\n",
      "./data-har//DAY_19909/object_sensor/dishes_9.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/dishes_9.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/dishes_9.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/dishes_9.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/dishes_9.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/dishes_9.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/dishes_9.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/dishes_9.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/dishes_9.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/dishes_9.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/dishes_9.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/dishes_9.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/dishes_9.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/dishes_9.tsv\n",
      "19935 (1440,)\n",
      "\t shower_24_apertura\n",
      "./data-har//DAY_19909/object_sensor/shower_24_apertura.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_24_apertura.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_24_apertura.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_24_apertura.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_24_apertura.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_24_apertura.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_24_apertura.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_24_apertura.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_24_apertura.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_24_apertura.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_24_apertura.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_24_apertura.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_24_apertura.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_24_apertura.tsv\n",
      "19935 (1440,)\n",
      "\t hum_shower_25\n",
      "./data-har//DAY_19909/object_sensor/hum_shower_25.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/hum_shower_25.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/hum_shower_25.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/hum_shower_25.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/hum_shower_25.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/hum_shower_25.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/hum_shower_25.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/hum_shower_25.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/hum_shower_25.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/hum_shower_25.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/hum_shower_25.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/hum_shower_25.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/hum_shower_25.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/hum_shower_25.tsv\n",
      "19935 (1440,)\n",
      "\t shower_31\n",
      "./data-har//DAY_19909/object_sensor/shower_31.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_31.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_31.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_31.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_31.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_31.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_31.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_31.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_31.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_31.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_31.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_31.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_31.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_31.tsv\n",
      "19935 (1440,)\n",
      "\t wc_17\n",
      "./data-har//DAY_19909/object_sensor/wc_17.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/wc_17.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/wc_17.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/wc_17.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/wc_17.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/wc_17.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/wc_17.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/wc_17.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/wc_17.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/wc_17.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/wc_17.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/wc_17.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/wc_17.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/wc_17.tsv\n",
      "19935 (1440,)\n",
      "\t sink_21\n",
      "./data-har//DAY_19909/object_sensor/sink_21.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/sink_21.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/sink_21.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/sink_21.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/sink_21.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/sink_21.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/sink_21.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/sink_21.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/sink_21.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/sink_21.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/sink_21.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/sink_21.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/sink_21.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/sink_21.tsv\n",
      "19935 (1440,)\n",
      "\t pc_1_current_consumption\n",
      "./data-har//DAY_19909/object_sensor/pc_1_current_consumption.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pc_1_current_consumption.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pc_1_current_consumption.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pc_1_current_consumption.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pc_1_current_consumption.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pc_1_current_consumption.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pc_1_current_consumption.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pc_1_current_consumption.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pc_1_current_consumption.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pc_1_current_consumption.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pc_1_current_consumption.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pc_1_current_consumption.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pc_1_current_consumption.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pc_1_current_consumption.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "act_sensors=np.zeros((len(sensors),len(days),sizeT(t0,tN)))\n",
    "print(act_sensors.shape)\n",
    "for sx,sensor in enumerate(sensors):\n",
    "    print(\"\\t\",sensor)\n",
    "    for dx,day in enumerate(days):\n",
    "        print(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\")\n",
    "        series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"status\"])\n",
    "        series=series[\"status\"].values\n",
    "        print(day,series.shape)\n",
    "        act_sensors[sx][dx]=series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n"
     ]
    }
   ],
   "source": [
    "user_activity=np.zeros((len(activities),len(users),len(days),sizeT(t0,tN)))\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            df_total=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/INTERVAL.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"ix\",\"d0\",\"dN\"])\n",
    "            #print(df_total)\n",
    "            #print(pd.to_datetime(df_total['d0']))\n",
    "            df_total['d0'] = pd.to_datetime(df_total['d0'])\n",
    "            df_total['dN'] = pd.to_datetime(df_total['dN'])\n",
    "            #print(df_total)\n",
    "\n",
    "            for tx,tt in enumerate(ts):\n",
    "                ttt=pd.to_datetime(time2str(t0,tN,tt))\n",
    "#                print(ttt)\n",
    "                row = df_total[(df_total['d0'] <= ttt) & (df_total['dN'] >= ttt)]\n",
    "#                print(\"df_in#tervalo\",row)\n",
    "                if(row.size>0):\n",
    "                    user_activity[ax][ux][dx][tx]=1\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "            \n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/LABEL3.\"+user+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                for tx,tt in enumerate(ts):\n",
    "                    file.write(time2str(t0,tN,tt)+\"\\t\"+str(user_activity[ax][ux][dx][tx])+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b92a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 09:22:12.193791: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 09:22:13.202686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 09:22:15.672737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 8, 45)       0           ['input_1[0][0]']                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 09:22:15.944715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 09:22:15.944771: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 09:22:15.947739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 09:22:15.947787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 09:22:15.947821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 09:22:16.201830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 09:22:16.201891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 09:22:16.201901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-12-11 09:22:16.201937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 09:22:16.201962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:26:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 8, 45)       0           ['input_2[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 11, 45)      0           ['input_3[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 8, 45)       65925       ['tf.__operators__.add[0][0]',   \n",
      " dAttention)                                                      'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_2[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 8, 45)       90          ['multi_head_attention[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8, 45)        0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 8, 45)        0           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 11, 45)       0           ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 45)          0           ['dropout[0][0]']                \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 45)          0           ['dropout_1[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 45)          0           ['dropout_2[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 135)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'global_average_pooling1d_1[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 135)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          17408       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, MultiHeadAttention, LayerNormalization, Dropout, Concatenate, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "N1 = len(activities)\n",
    "N2 = len(activities)\n",
    "N3 = len(sensors)\n",
    "\n",
    "TWA = 45\n",
    "TWB = 0\n",
    "T = TWA + TWB\n",
    "\n",
    "print(N1,N2,N3)\n",
    "\n",
    "# Positional Encoding function\n",
    "def getPositionEncoding(seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Computes positional encoding for a given sequence length and embedding dimension.\n",
    "    \"\"\"\n",
    "    position = np.arange(seq_len)[:, np.newaxis]  # (seq_len, 1)\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "\n",
    "    pos_enc = np.zeros((seq_len, d_model))  # Inicializar matriz de codificación posicional\n",
    "\n",
    "    # Llenar columnas pares con seno\n",
    "    pos_enc[:, 0::2] = np.sin(position * div_term)\n",
    "\n",
    "    # Llenar columnas impares con coseno\n",
    "    pos_enc[:, 1::2] = np.cos(position * div_term[:len(pos_enc[0, 1::2])])\n",
    "\n",
    "    # Expandir dimensiones para coincidir con batch size\n",
    "    pos_enc = np.expand_dims(pos_enc, axis=0)  # (1, seq_len, d_model)\n",
    "\n",
    "    return tf.cast(pos_enc, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modelo con Positional Encoding\n",
    "def getModelHAR():\n",
    "    # Define inputs\n",
    "    input1 = Input(shape=(8, 45))  # Forma de L1: (batch_size, 8, 45)\n",
    "    input2 = Input(shape=(8, 45))  # Forma de L2: (batch_size, 8, 45)\n",
    "    input3 = Input(shape=(11, 45))  # Forma de S: (batch_size, 11, 45)\n",
    "\n",
    "    # Codificación posicional\n",
    "    pos_enc1 = getPositionEncoding(8, 45)\n",
    "    pos_enc2 = getPositionEncoding(8, 45)\n",
    "    pos_enc3 = getPositionEncoding(11, 45)\n",
    "\n",
    "    # Añadir Positional Encoding a las entradas\n",
    "    encoded1 = input1 + pos_enc1\n",
    "    encoded2 = input2 + pos_enc2\n",
    "    encoded3 = input3 + pos_enc3\n",
    "\n",
    "    # Encoder para la primera secuencia\n",
    "    encoder1 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded1, encoded1)\n",
    "    encoder1 = LayerNormalization()(encoder1)\n",
    "    encoder1 = Dropout(0.5)(encoder1)\n",
    "\n",
    "    # Encoder para la segunda secuencia\n",
    "    encoder2 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded2, encoded2)\n",
    "    encoder2 = LayerNormalization()(encoder2)\n",
    "    encoder2 = Dropout(0.5)(encoder2)\n",
    "\n",
    "    # Encoder para la tercera secuencia\n",
    "    encoder3 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded3, encoded3)\n",
    "    encoder3 = LayerNormalization()(encoder3)\n",
    "    encoder3 = Dropout(0.5)(encoder3)\n",
    "\n",
    "    # Reducir las dimensiones de las secuencias\n",
    "    reduced1 = GlobalAveragePooling1D()(encoder1)\n",
    "    reduced2 = GlobalAveragePooling1D()(encoder2)\n",
    "    reduced3 = GlobalAveragePooling1D()(encoder3)\n",
    "\n",
    "    # Concatenar las secuencias reducidas\n",
    "    merged_encoded = Concatenate(axis=-1)([reduced1, reduced2, reduced3])\n",
    "\n",
    "    # Capa Bottleneck\n",
    "    bottleneck = Dropout(0.5)(merged_encoded)\n",
    "\n",
    "    # Capas densas para clasificación\n",
    "    dense = Dense(128, activation='relu')(bottleneck)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = Model(inputs=[input1, input2, input3], outputs=output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = getModelHAR()\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "386cb41e-bb1e-4043-b002-ea2c550f5dbd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a216fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 19909\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 8, 45)       0           ['input_4[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 8, 45)       0           ['input_5[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 11, 45)      0           ['input_6[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_4[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 8, 45)        0           ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 8, 45)        0           ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 11, 45)       0           ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 45)          0           ['dropout_5[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 45)          0           ['dropout_6[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 45)          0           ['dropout_7[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_3[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_4[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 135)          0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          17408       ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            129         ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 09:23:31.707907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-12-11 09:23:31.814400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-12-11 09:23:31.937163: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f91f8154b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-11 09:23:31.937202: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "2024-12-11 09:23:31.987002: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-11 09:23:32.252000: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-12-11 09:23:32.252028: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-12-11 09:23:32.252081: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:344] Couldn't read CUDA driver version.\n",
      "2024-12-11 09:23:32.293526: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 20s 17ms/step - loss: 0.4459 - accuracy: 0.7858 - val_loss: 0.2326 - val_accuracy: 0.9202\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2889 - accuracy: 0.8907 - val_loss: 0.1890 - val_accuracy: 0.9180\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2558 - accuracy: 0.9030 - val_loss: 0.2325 - val_accuracy: 0.9121\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2365 - accuracy: 0.9119 - val_loss: 0.1808 - val_accuracy: 0.9264\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2189 - accuracy: 0.9171 - val_loss: 0.1545 - val_accuracy: 0.9398\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.2123 - accuracy: 0.9192 - val_loss: 0.1243 - val_accuracy: 0.9431\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2066 - accuracy: 0.9243 - val_loss: 0.1164 - val_accuracy: 0.9508\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1903 - accuracy: 0.9285 - val_loss: 0.1495 - val_accuracy: 0.9467\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1865 - accuracy: 0.9293 - val_loss: 0.1816 - val_accuracy: 0.9317\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1744 - accuracy: 0.9355 - val_loss: 0.2651 - val_accuracy: 0.9142\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 8, 45)       0           ['input_7[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 8, 45)       0           ['input_8[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 11, 45)      0           ['input_9[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_6[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_7[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_8[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_7[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_8[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 8, 45)        0           ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 8, 45)        0           ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 11, 45)       0           ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 45)          0           ['dropout_10[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 45)          0           ['dropout_11[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 45)          0           ['dropout_12[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_7[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 135)          0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          17408       ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            129         ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 17ms/step - loss: 0.3306 - accuracy: 0.8381 - val_loss: 0.2743 - val_accuracy: 0.8633\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1430 - accuracy: 0.9453 - val_loss: 0.3183 - val_accuracy: 0.8769\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1240 - accuracy: 0.9549 - val_loss: 0.3291 - val_accuracy: 0.8796\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1181 - accuracy: 0.9567 - val_loss: 0.3318 - val_accuracy: 0.8767\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1088 - accuracy: 0.9610 - val_loss: 0.2334 - val_accuracy: 0.8748\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1015 - accuracy: 0.9637 - val_loss: 0.4724 - val_accuracy: 0.8827\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0939 - accuracy: 0.9661 - val_loss: 0.4472 - val_accuracy: 0.8753\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0902 - accuracy: 0.9685 - val_loss: 0.2709 - val_accuracy: 0.8898\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0859 - accuracy: 0.9699 - val_loss: 0.2752 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0833 - accuracy: 0.9715 - val_loss: 0.3416 - val_accuracy: 0.8953\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 8, 45)       0           ['input_10[0][0]']               \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 8, 45)       0           ['input_11[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 11, 45)      0           ['input_12[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_9[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_10[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_11[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_9[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 8, 45)       90          ['multi_head_attention_10[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 11, 45)      90          ['multi_head_attention_11[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 8, 45)        0           ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 8, 45)        0           ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 11, 45)       0           ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 45)          0           ['dropout_15[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 45)          0           ['dropout_16[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_11 (G  (None, 45)          0           ['dropout_17[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_9[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_10[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 135)          0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          17408       ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 128)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            129         ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 17ms/step - loss: 0.2466 - accuracy: 0.9120 - val_loss: 0.0775 - val_accuracy: 0.9885\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1417 - accuracy: 0.9687 - val_loss: 0.0760 - val_accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1335 - accuracy: 0.9689 - val_loss: 0.0642 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1243 - accuracy: 0.9694 - val_loss: 0.0595 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1245 - accuracy: 0.9687 - val_loss: 0.0665 - val_accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1179 - accuracy: 0.9697 - val_loss: 0.0719 - val_accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1123 - accuracy: 0.9699 - val_loss: 0.0725 - val_accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1067 - accuracy: 0.9705 - val_loss: 0.0742 - val_accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1015 - accuracy: 0.9699 - val_loss: 0.0808 - val_accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0957 - accuracy: 0.9702 - val_loss: 0.0635 - val_accuracy: 0.9835\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 8, 45)       0           ['input_13[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 8, 45)       0           ['input_14[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 11, 45)      0           ['input_15[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_12[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_13[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_14[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 8, 45)       90          ['multi_head_attention_12[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 8, 45)       90          ['multi_head_attention_13[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 11, 45)      90          ['multi_head_attention_14[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 8, 45)        0           ['layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 8, 45)        0           ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 11, 45)       0           ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_12 (G  (None, 45)          0           ['dropout_20[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_13 (G  (None, 45)          0           ['dropout_21[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_14 (G  (None, 45)          0           ['dropout_22[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_12[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_13[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_14[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 135)          0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          17408       ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 17ms/step - loss: 0.3668 - accuracy: 0.8437 - val_loss: 0.2367 - val_accuracy: 0.9348\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2557 - accuracy: 0.9086 - val_loss: 0.1852 - val_accuracy: 0.9374\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2326 - accuracy: 0.9127 - val_loss: 0.1897 - val_accuracy: 0.9443\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2164 - accuracy: 0.9201 - val_loss: 0.1847 - val_accuracy: 0.9357\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1987 - accuracy: 0.9252 - val_loss: 0.1427 - val_accuracy: 0.9481\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1861 - accuracy: 0.9312 - val_loss: 0.1455 - val_accuracy: 0.9458\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1784 - accuracy: 0.9328 - val_loss: 0.1683 - val_accuracy: 0.9441\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1646 - accuracy: 0.9380 - val_loss: 0.1965 - val_accuracy: 0.9329\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1602 - accuracy: 0.9401 - val_loss: 0.1837 - val_accuracy: 0.9367\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1533 - accuracy: 0.9437 - val_loss: 0.1870 - val_accuracy: 0.9360\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_17 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 8, 45)       0           ['input_16[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 8, 45)       0           ['input_17[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 11, 45)      0           ['input_18[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_15[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_16[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_17[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 8, 45)       90          ['multi_head_attention_15[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 8, 45)       90          ['multi_head_attention_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 11, 45)      90          ['multi_head_attention_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 8, 45)        0           ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 8, 45)        0           ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 11, 45)       0           ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 45)          0           ['dropout_25[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_16 (G  (None, 45)          0           ['dropout_26[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_17 (G  (None, 45)          0           ['dropout_27[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_15[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_16[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 135)          0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          17408       ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 128)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            129         ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.1307 - accuracy: 0.9506 - val_loss: 0.0230 - val_accuracy: 0.9902\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0417 - accuracy: 0.9890 - val_loss: 0.0405 - val_accuracy: 0.9854\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0295 - accuracy: 0.9927 - val_loss: 0.0194 - val_accuracy: 0.9924\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.0283 - val_accuracy: 0.9895\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0185 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.0136 - val_accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0255 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.0352 - val_accuracy: 0.9902\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.0126 - val_accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0131 - val_accuracy: 0.9969\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 8, 45)       0           ['input_19[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 8, 45)       0           ['input_20[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 11, 45)      0           ['input_21[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_18[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_19[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_20[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 8, 45)       90          ['multi_head_attention_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 8, 45)       90          ['multi_head_attention_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 11, 45)      90          ['multi_head_attention_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 8, 45)        0           ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 8, 45)        0           ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 11, 45)       0           ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_18 (G  (None, 45)          0           ['dropout_30[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_19 (G  (None, 45)          0           ['dropout_31[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_20 (G  (None, 45)          0           ['dropout_32[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_18[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_19[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_20[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 135)          0           ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          17408       ['dropout_33[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 128)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            129         ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 17ms/step - loss: 0.1613 - accuracy: 0.9334 - val_loss: 0.0209 - val_accuracy: 0.9943\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.0231 - val_accuracy: 0.9945\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0244 - accuracy: 0.9943 - val_loss: 0.0166 - val_accuracy: 0.9964\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0202 - accuracy: 0.9958 - val_loss: 0.0220 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.0381 - val_accuracy: 0.9907\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0146 - accuracy: 0.9969 - val_loss: 0.0191 - val_accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.0171 - val_accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.0295 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.0164 - val_accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0321 - val_accuracy: 0.9897\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 8, 45)       0           ['input_22[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 8, 45)       0           ['input_23[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 11, 45)      0           ['input_24[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_21[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_22[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_23[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_23[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 8, 45)       90          ['multi_head_attention_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 8, 45)       90          ['multi_head_attention_22[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 11, 45)      90          ['multi_head_attention_23[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 8, 45)        0           ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 8, 45)        0           ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 11, 45)       0           ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_21 (G  (None, 45)          0           ['dropout_35[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_22 (G  (None, 45)          0           ['dropout_36[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_23 (G  (None, 45)          0           ['dropout_37[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_21[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_22[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_23[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 135)          0           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          17408       ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 128)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            129         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 17ms/step - loss: 0.1908 - accuracy: 0.9313 - val_loss: 0.0426 - val_accuracy: 0.9912\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1151 - accuracy: 0.9706 - val_loss: 0.0443 - val_accuracy: 0.9895\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1083 - accuracy: 0.9715 - val_loss: 0.0455 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1031 - accuracy: 0.9731 - val_loss: 0.0373 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0990 - accuracy: 0.9743 - val_loss: 0.0439 - val_accuracy: 0.9902\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0970 - accuracy: 0.9743 - val_loss: 0.0384 - val_accuracy: 0.9909\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0948 - accuracy: 0.9747 - val_loss: 0.0447 - val_accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0929 - accuracy: 0.9749 - val_loss: 0.0565 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0906 - accuracy: 0.9760 - val_loss: 0.0416 - val_accuracy: 0.9921\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0900 - accuracy: 0.9758 - val_loss: 0.0411 - val_accuracy: 0.9890\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 8, 45)       0           ['input_25[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 8, 45)       0           ['input_26[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 11, 45)      0           ['input_27[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_24[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_25[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_26[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 8, 45)       90          ['multi_head_attention_24[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 8, 45)       90          ['multi_head_attention_25[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 11, 45)      90          ['multi_head_attention_26[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 8, 45)        0           ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 8, 45)        0           ['layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 11, 45)       0           ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_24 (G  (None, 45)          0           ['dropout_40[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_25 (G  (None, 45)          0           ['dropout_41[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_26 (G  (None, 45)          0           ['dropout_42[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_24[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_25[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_26[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 135)          0           ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          17408       ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            129         ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 17ms/step - loss: 0.3042 - accuracy: 0.8751 - val_loss: 0.1875 - val_accuracy: 0.9047\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1977 - accuracy: 0.9277 - val_loss: 0.1464 - val_accuracy: 0.9257\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1740 - accuracy: 0.9353 - val_loss: 0.1282 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1620 - accuracy: 0.9381 - val_loss: 0.1968 - val_accuracy: 0.9197\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1514 - accuracy: 0.9419 - val_loss: 0.1528 - val_accuracy: 0.9345\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1433 - accuracy: 0.9453 - val_loss: 0.1510 - val_accuracy: 0.9250\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1406 - accuracy: 0.9449 - val_loss: 0.1584 - val_accuracy: 0.9312\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1329 - accuracy: 0.9484 - val_loss: 0.1191 - val_accuracy: 0.9462\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.1317 - accuracy: 0.9480 - val_loss: 0.1468 - val_accuracy: 0.9243\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1224 - accuracy: 0.9524 - val_loss: 0.1635 - val_accuracy: 0.9384\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 1 19910\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 8, 45)       0           ['input_28[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 8, 45)       0           ['input_29[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 11, 45)      0           ['input_30[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_27[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_28[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_29[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 8, 45)       90          ['multi_head_attention_27[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 8, 45)       90          ['multi_head_attention_28[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 11, 45)      90          ['multi_head_attention_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 8, 45)        0           ['layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 8, 45)        0           ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 11, 45)       0           ['layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_27 (G  (None, 45)          0           ['dropout_45[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_28 (G  (None, 45)          0           ['dropout_46[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_29 (G  (None, 45)          0           ['dropout_47[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 135)          0           ['global_average_pooling1d_27[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_28[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_29[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 135)          0           ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          17408       ['dropout_48[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 128)          0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            129         ['dropout_49[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.4624 - accuracy: 0.7769 - val_loss: 0.3628 - val_accuracy: 0.9137\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2807 - accuracy: 0.8964 - val_loss: 0.0975 - val_accuracy: 0.9615\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.2543 - accuracy: 0.9048 - val_loss: 0.1111 - val_accuracy: 0.9603\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2299 - accuracy: 0.9165 - val_loss: 0.0973 - val_accuracy: 0.9658\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2180 - accuracy: 0.9200 - val_loss: 0.1272 - val_accuracy: 0.9579\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2066 - accuracy: 0.9242 - val_loss: 0.1255 - val_accuracy: 0.9556\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1991 - accuracy: 0.9298 - val_loss: 0.1681 - val_accuracy: 0.9484\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1915 - accuracy: 0.9324 - val_loss: 0.1252 - val_accuracy: 0.9613\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1880 - accuracy: 0.9327 - val_loss: 0.0857 - val_accuracy: 0.9661\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1818 - accuracy: 0.9366 - val_loss: 0.1494 - val_accuracy: 0.9510\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 8, 45)       0           ['input_31[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 8, 45)       0           ['input_32[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 11, 45)      0           ['input_33[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_30[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_31 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_31[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_31[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_32 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_32[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 8, 45)       90          ['multi_head_attention_30[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 8, 45)       90          ['multi_head_attention_31[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 11, 45)      90          ['multi_head_attention_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 8, 45)        0           ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 8, 45)        0           ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 11, 45)       0           ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_30 (G  (None, 45)          0           ['dropout_50[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_31 (G  (None, 45)          0           ['dropout_51[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_32 (G  (None, 45)          0           ['dropout_52[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_30[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_31[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_32[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 135)          0           ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          17408       ['dropout_53[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 128)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            129         ['dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.3398 - accuracy: 0.8355 - val_loss: 0.0777 - val_accuracy: 0.9601\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1707 - accuracy: 0.9307 - val_loss: 0.0342 - val_accuracy: 0.9897\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1557 - accuracy: 0.9356 - val_loss: 0.0361 - val_accuracy: 0.9919\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1430 - accuracy: 0.9419 - val_loss: 0.0409 - val_accuracy: 0.9924\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1334 - accuracy: 0.9481 - val_loss: 0.0448 - val_accuracy: 0.9892\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1224 - accuracy: 0.9523 - val_loss: 0.0314 - val_accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1177 - accuracy: 0.9531 - val_loss: 0.0324 - val_accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1146 - accuracy: 0.9562 - val_loss: 0.0405 - val_accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1112 - accuracy: 0.9592 - val_loss: 0.0339 - val_accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1039 - accuracy: 0.9596 - val_loss: 0.0514 - val_accuracy: 0.9835\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_34 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 8, 45)       0           ['input_34[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 8, 45)       0           ['input_35[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 11, 45)      0           ['input_36[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_33 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_33[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_34 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_34[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_35 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_35[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 8, 45)       90          ['multi_head_attention_33[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 8, 45)       90          ['multi_head_attention_34[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 11, 45)      90          ['multi_head_attention_35[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 8, 45)        0           ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 8, 45)        0           ['layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 11, 45)       0           ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_33 (G  (None, 45)          0           ['dropout_55[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_34 (G  (None, 45)          0           ['dropout_56[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_35 (G  (None, 45)          0           ['dropout_57[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_33[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_34[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_35[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 135)          0           ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 128)          17408       ['dropout_58[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 128)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            129         ['dropout_59[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.2232 - accuracy: 0.9184 - val_loss: 0.3980 - val_accuracy: 0.8769\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1230 - accuracy: 0.9743 - val_loss: 0.5155 - val_accuracy: 0.8726\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1128 - accuracy: 0.9752 - val_loss: 0.4299 - val_accuracy: 0.8769\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1053 - accuracy: 0.9758 - val_loss: 0.4497 - val_accuracy: 0.8781\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1038 - accuracy: 0.9763 - val_loss: 0.4205 - val_accuracy: 0.8784\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1009 - accuracy: 0.9763 - val_loss: 0.3391 - val_accuracy: 0.8707\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0966 - accuracy: 0.9762 - val_loss: 0.3785 - val_accuracy: 0.8793\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0913 - accuracy: 0.9771 - val_loss: 0.2973 - val_accuracy: 0.8786\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0863 - accuracy: 0.9775 - val_loss: 0.3803 - val_accuracy: 0.8791\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0816 - accuracy: 0.9772 - val_loss: 0.1958 - val_accuracy: 0.8729\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_38 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_39 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (TFOpL  (None, 8, 45)       0           ['input_37[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (TFOpL  (None, 8, 45)       0           ['input_38[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (TFOpL  (None, 11, 45)      0           ['input_39[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_36 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_36[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_36[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_37 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_37[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_37[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_38 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_38[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_38[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 8, 45)       90          ['multi_head_attention_36[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 8, 45)       90          ['multi_head_attention_37[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 11, 45)      90          ['multi_head_attention_38[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 8, 45)        0           ['layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 8, 45)        0           ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 11, 45)       0           ['layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_36 (G  (None, 45)          0           ['dropout_60[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_37 (G  (None, 45)          0           ['dropout_61[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_38 (G  (None, 45)          0           ['dropout_62[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_36[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_37[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_38[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 135)          0           ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 128)          17408       ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 128)          0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1)            129         ['dropout_64[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 17ms/step - loss: 0.3789 - accuracy: 0.8371 - val_loss: 0.1718 - val_accuracy: 0.9651\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2590 - accuracy: 0.9057 - val_loss: 0.1407 - val_accuracy: 0.9656\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2372 - accuracy: 0.9102 - val_loss: 0.1769 - val_accuracy: 0.9594\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2219 - accuracy: 0.9166 - val_loss: 0.1390 - val_accuracy: 0.9611\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2103 - accuracy: 0.9198 - val_loss: 0.0739 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1962 - accuracy: 0.9265 - val_loss: 0.1225 - val_accuracy: 0.9582\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1893 - accuracy: 0.9281 - val_loss: 0.1221 - val_accuracy: 0.9594\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1778 - accuracy: 0.9342 - val_loss: 0.1915 - val_accuracy: 0.9446\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1659 - accuracy: 0.9364 - val_loss: 0.0979 - val_accuracy: 0.9673\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1642 - accuracy: 0.9379 - val_loss: 0.1023 - val_accuracy: 0.9687\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_40 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_41 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_42 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (TFOpL  (None, 8, 45)       0           ['input_40[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (TFOpL  (None, 8, 45)       0           ['input_41[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (TFOpL  (None, 11, 45)      0           ['input_42[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_39 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_39[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_39[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_40 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_40[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_40[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_41 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_41[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_41[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 8, 45)       90          ['multi_head_attention_39[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 8, 45)       90          ['multi_head_attention_40[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 11, 45)      90          ['multi_head_attention_41[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)           (None, 8, 45)        0           ['layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 8, 45)        0           ['layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 11, 45)       0           ['layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_39 (G  (None, 45)          0           ['dropout_65[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_40 (G  (None, 45)          0           ['dropout_66[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_41 (G  (None, 45)          0           ['dropout_67[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_39[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_40[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_41[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_68 (Dropout)           (None, 135)          0           ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          17408       ['dropout_68[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 128)          0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1)            129         ['dropout_69[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.1343 - accuracy: 0.9456 - val_loss: 0.0244 - val_accuracy: 0.9890\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0406 - accuracy: 0.9893 - val_loss: 0.0151 - val_accuracy: 0.9914\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0276 - accuracy: 0.9932 - val_loss: 0.0311 - val_accuracy: 0.9876\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.0117 - val_accuracy: 0.9957\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0129 - accuracy: 0.9971 - val_loss: 0.0220 - val_accuracy: 0.9931\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 0.0106 - val_accuracy: 0.9952\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0082 - val_accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0069 - val_accuracy: 0.9983\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0076 - val_accuracy: 0.9983\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_43 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_44 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_45 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (TFOpL  (None, 8, 45)       0           ['input_43[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (TFOpL  (None, 8, 45)       0           ['input_44[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  (None, 11, 45)      0           ['input_45[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_42 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_42[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_42[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_43 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_43[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_43[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_44 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_44[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 8, 45)       90          ['multi_head_attention_42[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 8, 45)       90          ['multi_head_attention_43[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 11, 45)      90          ['multi_head_attention_44[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_70 (Dropout)           (None, 8, 45)        0           ['layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 8, 45)        0           ['layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 11, 45)       0           ['layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_42 (G  (None, 45)          0           ['dropout_70[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_43 (G  (None, 45)          0           ['dropout_71[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_44 (G  (None, 45)          0           ['dropout_72[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_42[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_43[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_44[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 135)          0           ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          17408       ['dropout_73[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 128)          0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            129         ['dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.1297 - accuracy: 0.9484 - val_loss: 0.0607 - val_accuracy: 0.9852\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0291 - accuracy: 0.9939 - val_loss: 0.0445 - val_accuracy: 0.9885\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0254 - accuracy: 0.9948 - val_loss: 0.0528 - val_accuracy: 0.9845\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0243 - accuracy: 0.9952 - val_loss: 0.0505 - val_accuracy: 0.9869\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0220 - accuracy: 0.9955 - val_loss: 0.0768 - val_accuracy: 0.9761\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 0.0460 - val_accuracy: 0.9892\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0199 - accuracy: 0.9961 - val_loss: 0.0408 - val_accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0182 - accuracy: 0.9966 - val_loss: 0.0632 - val_accuracy: 0.9876\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.0433 - val_accuracy: 0.9881\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.0593 - val_accuracy: 0.9849\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_46 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_47 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_48 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (TFOpL  (None, 8, 45)       0           ['input_46[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_46 (TFOpL  (None, 8, 45)       0           ['input_47[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (TFOpL  (None, 11, 45)      0           ['input_48[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_45 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_45[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_45[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_46 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_46[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_46[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_47 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_47[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_47[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 8, 45)       90          ['multi_head_attention_45[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 8, 45)       90          ['multi_head_attention_46[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 11, 45)      90          ['multi_head_attention_47[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 8, 45)        0           ['layer_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)           (None, 8, 45)        0           ['layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 11, 45)       0           ['layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_45 (G  (None, 45)          0           ['dropout_75[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_46 (G  (None, 45)          0           ['dropout_76[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_47 (G  (None, 45)          0           ['dropout_77[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_45[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_46[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 135)          0           ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 128)          17408       ['dropout_78[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)           (None, 128)          0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            129         ['dropout_79[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.1847 - accuracy: 0.9280 - val_loss: 0.4344 - val_accuracy: 0.8590\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0943 - accuracy: 0.9767 - val_loss: 0.4668 - val_accuracy: 0.8693\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0867 - accuracy: 0.9775 - val_loss: 0.4616 - val_accuracy: 0.8722\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0848 - accuracy: 0.9773 - val_loss: 0.4351 - val_accuracy: 0.8659\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0829 - accuracy: 0.9782 - val_loss: 0.4764 - val_accuracy: 0.8700\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0785 - accuracy: 0.9787 - val_loss: 0.4103 - val_accuracy: 0.8719\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0765 - accuracy: 0.9796 - val_loss: 0.5167 - val_accuracy: 0.8743\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0696 - accuracy: 0.9802 - val_loss: 0.4664 - val_accuracy: 0.8746\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0650 - accuracy: 0.9807 - val_loss: 0.5009 - val_accuracy: 0.8703\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0620 - accuracy: 0.9813 - val_loss: 0.4892 - val_accuracy: 0.8686\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_49 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_50 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_51 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_48 (TFOpL  (None, 8, 45)       0           ['input_49[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_49 (TFOpL  (None, 8, 45)       0           ['input_50[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (TFOpL  (None, 11, 45)      0           ['input_51[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_48 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_48[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_48[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_49 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_49[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_49[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_50 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_50[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_50[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_48 (LayerN  (None, 8, 45)       90          ['multi_head_attention_48[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 8, 45)       90          ['multi_head_attention_49[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 11, 45)      90          ['multi_head_attention_50[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 8, 45)        0           ['layer_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_81 (Dropout)           (None, 8, 45)        0           ['layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_82 (Dropout)           (None, 11, 45)       0           ['layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_48 (G  (None, 45)          0           ['dropout_80[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_49 (G  (None, 45)          0           ['dropout_81[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_50 (G  (None, 45)          0           ['dropout_82[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_48[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_49[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_50[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_83 (Dropout)           (None, 135)          0           ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          17408       ['dropout_83[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_84 (Dropout)           (None, 128)          0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 1)            129         ['dropout_84[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.3071 - accuracy: 0.8708 - val_loss: 0.1018 - val_accuracy: 0.9556\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2033 - accuracy: 0.9266 - val_loss: 0.1277 - val_accuracy: 0.9493\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1739 - accuracy: 0.9352 - val_loss: 0.0749 - val_accuracy: 0.9594\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1576 - accuracy: 0.9391 - val_loss: 0.0895 - val_accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1471 - accuracy: 0.9445 - val_loss: 0.0625 - val_accuracy: 0.9646\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1383 - accuracy: 0.9480 - val_loss: 0.0771 - val_accuracy: 0.9584\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1337 - accuracy: 0.9497 - val_loss: 0.0674 - val_accuracy: 0.9630\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1294 - accuracy: 0.9505 - val_loss: 0.0724 - val_accuracy: 0.9589\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1230 - accuracy: 0.9529 - val_loss: 0.0872 - val_accuracy: 0.9546\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1205 - accuracy: 0.9541 - val_loss: 0.0760 - val_accuracy: 0.9622\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 2 19911\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_52 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_53 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_54 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_51 (TFOpL  (None, 8, 45)       0           ['input_52[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_52 (TFOpL  (None, 8, 45)       0           ['input_53[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_53 (TFOpL  (None, 11, 45)      0           ['input_54[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_51 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_51[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_51[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_52 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_52[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_52[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_53 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_53[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_53[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 8, 45)       90          ['multi_head_attention_51[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 8, 45)       90          ['multi_head_attention_52[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 11, 45)      90          ['multi_head_attention_53[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_85 (Dropout)           (None, 8, 45)        0           ['layer_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_86 (Dropout)           (None, 8, 45)        0           ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_87 (Dropout)           (None, 11, 45)       0           ['layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_51 (G  (None, 45)          0           ['dropout_85[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_52 (G  (None, 45)          0           ['dropout_86[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_53 (G  (None, 45)          0           ['dropout_87[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_51[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_52[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_53[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 135)          0           ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          17408       ['dropout_88[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 128)          0           ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 1)            129         ['dropout_89[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.4445 - accuracy: 0.7891 - val_loss: 0.2181 - val_accuracy: 0.9474\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2824 - accuracy: 0.8926 - val_loss: 0.2283 - val_accuracy: 0.9321\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2522 - accuracy: 0.9058 - val_loss: 0.1519 - val_accuracy: 0.9419\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2334 - accuracy: 0.9152 - val_loss: 0.1986 - val_accuracy: 0.9302\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2188 - accuracy: 0.9191 - val_loss: 0.2665 - val_accuracy: 0.9116\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2074 - accuracy: 0.9229 - val_loss: 0.2947 - val_accuracy: 0.8903\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2012 - accuracy: 0.9245 - val_loss: 0.2248 - val_accuracy: 0.9152\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1905 - accuracy: 0.9288 - val_loss: 0.2284 - val_accuracy: 0.9173\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1825 - accuracy: 0.9312 - val_loss: 0.3119 - val_accuracy: 0.8975\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1803 - accuracy: 0.9335 - val_loss: 0.2179 - val_accuracy: 0.9231\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_55 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_56 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_57 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 8, 45)       0           ['input_55[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  (None, 8, 45)       0           ['input_56[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_56 (TFOpL  (None, 11, 45)      0           ['input_57[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_54 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_54[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_55 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_55[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_56 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_56[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_56[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 8, 45)       90          ['multi_head_attention_54[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 8, 45)       90          ['multi_head_attention_55[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 11, 45)      90          ['multi_head_attention_56[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_90 (Dropout)           (None, 8, 45)        0           ['layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)           (None, 8, 45)        0           ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)           (None, 11, 45)       0           ['layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_54 (G  (None, 45)          0           ['dropout_90[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_55 (G  (None, 45)          0           ['dropout_91[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_56 (G  (None, 45)          0           ['dropout_92[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_54[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_55[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_56[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)           (None, 135)          0           ['concatenate_18[0][0]']         \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 128)          17408       ['dropout_93[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)           (None, 128)          0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 1)            129         ['dropout_94[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.3226 - accuracy: 0.8421 - val_loss: 0.2013 - val_accuracy: 0.9051\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1690 - accuracy: 0.9251 - val_loss: 0.1768 - val_accuracy: 0.9467\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1475 - accuracy: 0.9376 - val_loss: 0.1505 - val_accuracy: 0.9410\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1322 - accuracy: 0.9457 - val_loss: 0.2164 - val_accuracy: 0.9458\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1223 - accuracy: 0.9494 - val_loss: 0.2303 - val_accuracy: 0.9283\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1169 - accuracy: 0.9522 - val_loss: 0.1484 - val_accuracy: 0.9582\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1108 - accuracy: 0.9562 - val_loss: 0.1594 - val_accuracy: 0.9520\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1053 - accuracy: 0.9592 - val_loss: 0.2110 - val_accuracy: 0.9450\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1026 - accuracy: 0.9604 - val_loss: 0.1806 - val_accuracy: 0.9513\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0961 - accuracy: 0.9625 - val_loss: 0.2176 - val_accuracy: 0.9539\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_58 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_59 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_60 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_57 (TFOpL  (None, 8, 45)       0           ['input_58[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_58 (TFOpL  (None, 8, 45)       0           ['input_59[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_59 (TFOpL  (None, 11, 45)      0           ['input_60[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_57 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_57[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_57[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_58 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_58[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_58[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_59 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_59[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_59[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 8, 45)       90          ['multi_head_attention_57[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_58 (LayerN  (None, 8, 45)       90          ['multi_head_attention_58[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_59 (LayerN  (None, 11, 45)      90          ['multi_head_attention_59[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)           (None, 8, 45)        0           ['layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_96 (Dropout)           (None, 8, 45)        0           ['layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_97 (Dropout)           (None, 11, 45)       0           ['layer_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_57 (G  (None, 45)          0           ['dropout_95[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_58 (G  (None, 45)          0           ['dropout_96[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_59 (G  (None, 45)          0           ['dropout_97[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_57[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_58[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_59[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_98 (Dropout)           (None, 135)          0           ['concatenate_19[0][0]']         \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 128)          17408       ['dropout_98[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_99 (Dropout)           (None, 128)          0           ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 1)            129         ['dropout_99[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.2025 - accuracy: 0.9277 - val_loss: 0.7177 - val_accuracy: 0.8342\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0992 - accuracy: 0.9797 - val_loss: 0.6347 - val_accuracy: 0.8313\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0929 - accuracy: 0.9802 - val_loss: 0.6416 - val_accuracy: 0.8363\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0903 - accuracy: 0.9805 - val_loss: 0.6768 - val_accuracy: 0.8392\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0862 - accuracy: 0.9809 - val_loss: 0.5406 - val_accuracy: 0.8234\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0826 - accuracy: 0.9816 - val_loss: 0.7320 - val_accuracy: 0.8349\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0839 - accuracy: 0.9812 - val_loss: 0.6373 - val_accuracy: 0.8397\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0814 - accuracy: 0.9815 - val_loss: 0.6478 - val_accuracy: 0.8389\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0798 - accuracy: 0.9823 - val_loss: 0.4939 - val_accuracy: 0.8366\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0800 - accuracy: 0.9815 - val_loss: 0.5893 - val_accuracy: 0.8356\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_61 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_62 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_63 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_60 (TFOpL  (None, 8, 45)       0           ['input_61[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_61 (TFOpL  (None, 8, 45)       0           ['input_62[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_62 (TFOpL  (None, 11, 45)      0           ['input_63[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_60 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_60[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_60[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_61 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_61[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_61[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_62 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_62[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_62[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_60 (LayerN  (None, 8, 45)       90          ['multi_head_attention_60[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_61 (LayerN  (None, 8, 45)       90          ['multi_head_attention_61[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_62 (LayerN  (None, 11, 45)      90          ['multi_head_attention_62[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_100 (Dropout)          (None, 8, 45)        0           ['layer_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_101 (Dropout)          (None, 8, 45)        0           ['layer_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_102 (Dropout)          (None, 11, 45)       0           ['layer_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_60 (G  (None, 45)          0           ['dropout_100[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_61 (G  (None, 45)          0           ['dropout_101[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_62 (G  (None, 45)          0           ['dropout_102[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_60[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_61[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_62[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_103 (Dropout)          (None, 135)          0           ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 128)          17408       ['dropout_103[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_104 (Dropout)          (None, 128)          0           ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 1)            129         ['dropout_104[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.3825 - accuracy: 0.8337 - val_loss: 0.1532 - val_accuracy: 0.9458\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2601 - accuracy: 0.9033 - val_loss: 0.1110 - val_accuracy: 0.9661\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.2423 - accuracy: 0.9072 - val_loss: 0.1404 - val_accuracy: 0.9450\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2174 - accuracy: 0.9163 - val_loss: 0.1707 - val_accuracy: 0.9388\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2050 - accuracy: 0.9232 - val_loss: 0.2355 - val_accuracy: 0.9173\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1942 - accuracy: 0.9270 - val_loss: 0.1971 - val_accuracy: 0.9226\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1829 - accuracy: 0.9292 - val_loss: 0.2316 - val_accuracy: 0.9171\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1756 - accuracy: 0.9342 - val_loss: 0.2142 - val_accuracy: 0.9168\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1691 - accuracy: 0.9354 - val_loss: 0.1930 - val_accuracy: 0.9257\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1667 - accuracy: 0.9358 - val_loss: 0.1173 - val_accuracy: 0.9534\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_64 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_65 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_66 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_63 (TFOpL  (None, 8, 45)       0           ['input_64[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_64 (TFOpL  (None, 8, 45)       0           ['input_65[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_65 (TFOpL  (None, 11, 45)      0           ['input_66[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_63 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_63[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_63[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_64 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_64[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_64[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_65 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_65[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_65[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_63 (LayerN  (None, 8, 45)       90          ['multi_head_attention_63[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_64 (LayerN  (None, 8, 45)       90          ['multi_head_attention_64[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_65 (LayerN  (None, 11, 45)      90          ['multi_head_attention_65[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_105 (Dropout)          (None, 8, 45)        0           ['layer_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_106 (Dropout)          (None, 8, 45)        0           ['layer_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_107 (Dropout)          (None, 11, 45)       0           ['layer_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_63 (G  (None, 45)          0           ['dropout_105[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_64 (G  (None, 45)          0           ['dropout_106[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_65 (G  (None, 45)          0           ['dropout_107[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_63[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_64[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_65[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_108 (Dropout)          (None, 135)          0           ['concatenate_21[0][0]']         \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 128)          17408       ['dropout_108[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_109 (Dropout)          (None, 128)          0           ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 1)            129         ['dropout_109[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.1321 - accuracy: 0.9498 - val_loss: 0.0338 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0360 - accuracy: 0.9906 - val_loss: 0.0349 - val_accuracy: 0.9921\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0300 - val_accuracy: 0.9950\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.0391 - val_accuracy: 0.9890\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.0273 - val_accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.0339 - val_accuracy: 0.9947\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 0.0328 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0320 - val_accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0416 - val_accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.0379 - val_accuracy: 0.9945\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_67 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_68 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_69 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_66 (TFOpL  (None, 8, 45)       0           ['input_67[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_67 (TFOpL  (None, 8, 45)       0           ['input_68[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (TFOpL  (None, 11, 45)      0           ['input_69[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_66 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_66[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_66[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_67 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_67[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_67[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_68 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_68[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_66 (LayerN  (None, 8, 45)       90          ['multi_head_attention_66[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_67 (LayerN  (None, 8, 45)       90          ['multi_head_attention_67[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_68 (LayerN  (None, 11, 45)      90          ['multi_head_attention_68[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_110 (Dropout)          (None, 8, 45)        0           ['layer_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_111 (Dropout)          (None, 8, 45)        0           ['layer_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_112 (Dropout)          (None, 11, 45)       0           ['layer_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_66 (G  (None, 45)          0           ['dropout_110[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_67 (G  (None, 45)          0           ['dropout_111[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_68 (G  (None, 45)          0           ['dropout_112[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_66[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_67[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_68[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_113 (Dropout)          (None, 135)          0           ['concatenate_22[0][0]']         \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 128)          17408       ['dropout_113[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_114 (Dropout)          (None, 128)          0           ['dense_44[0][0]']               \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 1)            129         ['dropout_114[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.1547 - accuracy: 0.9376 - val_loss: 0.1406 - val_accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0369 - accuracy: 0.9918 - val_loss: 0.0694 - val_accuracy: 0.9663\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0277 - accuracy: 0.9940 - val_loss: 0.0236 - val_accuracy: 0.9916\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0258 - accuracy: 0.9944 - val_loss: 0.0568 - val_accuracy: 0.9713\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0203 - accuracy: 0.9959 - val_loss: 0.0219 - val_accuracy: 0.9943\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0247 - accuracy: 0.9942 - val_loss: 0.0233 - val_accuracy: 0.9940\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0190 - accuracy: 0.9961 - val_loss: 0.0229 - val_accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.0319 - val_accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0203 - accuracy: 0.9955 - val_loss: 0.0305 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.0740 - val_accuracy: 0.9809\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_70 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_71 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_72 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (TFOpL  (None, 8, 45)       0           ['input_70[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 8, 45)       0           ['input_71[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 11, 45)      0           ['input_72[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_69 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_69[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_70 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_70[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_71 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_71[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_71[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_69 (LayerN  (None, 8, 45)       90          ['multi_head_attention_69[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_70 (LayerN  (None, 8, 45)       90          ['multi_head_attention_70[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_71 (LayerN  (None, 11, 45)      90          ['multi_head_attention_71[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_115 (Dropout)          (None, 8, 45)        0           ['layer_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)          (None, 8, 45)        0           ['layer_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)          (None, 11, 45)       0           ['layer_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_69 (G  (None, 45)          0           ['dropout_115[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_70 (G  (None, 45)          0           ['dropout_116[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_71 (G  (None, 45)          0           ['dropout_117[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_69[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_70[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_71[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_118 (Dropout)          (None, 135)          0           ['concatenate_23[0][0]']         \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 128)          17408       ['dropout_118[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_119 (Dropout)          (None, 128)          0           ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 1)            129         ['dropout_119[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.1590 - accuracy: 0.9437 - val_loss: 0.5368 - val_accuracy: 0.8542\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0911 - accuracy: 0.9786 - val_loss: 0.4337 - val_accuracy: 0.8581\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0844 - accuracy: 0.9798 - val_loss: 0.4646 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0813 - accuracy: 0.9794 - val_loss: 0.5419 - val_accuracy: 0.8554\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0790 - accuracy: 0.9804 - val_loss: 0.3971 - val_accuracy: 0.8595\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0787 - accuracy: 0.9801 - val_loss: 0.4342 - val_accuracy: 0.8600\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0755 - accuracy: 0.9812 - val_loss: 0.4527 - val_accuracy: 0.8590\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0759 - accuracy: 0.9812 - val_loss: 0.5100 - val_accuracy: 0.8607\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0737 - accuracy: 0.9815 - val_loss: 0.5036 - val_accuracy: 0.8612\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0723 - accuracy: 0.9818 - val_loss: 0.4462 - val_accuracy: 0.8624\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_73 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_74 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_75 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_72 (TFOpL  (None, 8, 45)       0           ['input_73[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_73 (TFOpL  (None, 8, 45)       0           ['input_74[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_74 (TFOpL  (None, 11, 45)      0           ['input_75[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_72 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_72[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_72[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_73 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_73[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_73[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_74 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_74[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_74[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_72 (LayerN  (None, 8, 45)       90          ['multi_head_attention_72[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_73 (LayerN  (None, 8, 45)       90          ['multi_head_attention_73[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_74 (LayerN  (None, 11, 45)      90          ['multi_head_attention_74[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_120 (Dropout)          (None, 8, 45)        0           ['layer_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_121 (Dropout)          (None, 8, 45)        0           ['layer_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_122 (Dropout)          (None, 11, 45)       0           ['layer_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_72 (G  (None, 45)          0           ['dropout_120[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_73 (G  (None, 45)          0           ['dropout_121[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_74 (G  (None, 45)          0           ['dropout_122[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_72[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_73[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_74[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_123 (Dropout)          (None, 135)          0           ['concatenate_24[0][0]']         \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 128)          17408       ['dropout_123[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_124 (Dropout)          (None, 128)          0           ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 1)            129         ['dropout_124[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.3108 - accuracy: 0.8684 - val_loss: 0.1572 - val_accuracy: 0.9013\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1993 - accuracy: 0.9276 - val_loss: 0.1482 - val_accuracy: 0.9016\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1725 - accuracy: 0.9337 - val_loss: 0.1244 - val_accuracy: 0.9324\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1569 - accuracy: 0.9391 - val_loss: 0.1060 - val_accuracy: 0.9489\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1458 - accuracy: 0.9434 - val_loss: 0.0951 - val_accuracy: 0.9527\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1382 - accuracy: 0.9475 - val_loss: 0.1231 - val_accuracy: 0.9314\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1327 - accuracy: 0.9508 - val_loss: 0.1572 - val_accuracy: 0.9207\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1278 - accuracy: 0.9494 - val_loss: 0.1220 - val_accuracy: 0.9341\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1250 - accuracy: 0.9513 - val_loss: 0.2601 - val_accuracy: 0.9092\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1216 - accuracy: 0.9530 - val_loss: 0.1197 - val_accuracy: 0.9479\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 3 19922\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_76 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_77 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_78 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_75 (TFOpL  (None, 8, 45)       0           ['input_76[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_76 (TFOpL  (None, 8, 45)       0           ['input_77[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_77 (TFOpL  (None, 11, 45)      0           ['input_78[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_75 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_75[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_75[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_76 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_76[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_76[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_77 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_77[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_77[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_75 (LayerN  (None, 8, 45)       90          ['multi_head_attention_75[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_76 (LayerN  (None, 8, 45)       90          ['multi_head_attention_76[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_77 (LayerN  (None, 11, 45)      90          ['multi_head_attention_77[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_125 (Dropout)          (None, 8, 45)        0           ['layer_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_126 (Dropout)          (None, 8, 45)        0           ['layer_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_127 (Dropout)          (None, 11, 45)       0           ['layer_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_75 (G  (None, 45)          0           ['dropout_125[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_76 (G  (None, 45)          0           ['dropout_126[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_77 (G  (None, 45)          0           ['dropout_127[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_75[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_76[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_77[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_128 (Dropout)          (None, 135)          0           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 128)          17408       ['dropout_128[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_129 (Dropout)          (None, 128)          0           ['dense_50[0][0]']               \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 1)            129         ['dropout_129[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.4358 - accuracy: 0.7974 - val_loss: 0.2144 - val_accuracy: 0.9450\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.2808 - accuracy: 0.8948 - val_loss: 0.2642 - val_accuracy: 0.9049\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2468 - accuracy: 0.9089 - val_loss: 0.1799 - val_accuracy: 0.9305\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2253 - accuracy: 0.9156 - val_loss: 0.1395 - val_accuracy: 0.9441\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2121 - accuracy: 0.9229 - val_loss: 0.1676 - val_accuracy: 0.9393\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.2039 - accuracy: 0.9237 - val_loss: 0.1526 - val_accuracy: 0.9467\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1969 - accuracy: 0.9282 - val_loss: 0.1992 - val_accuracy: 0.9269\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1899 - accuracy: 0.9305 - val_loss: 0.1893 - val_accuracy: 0.9381\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1808 - accuracy: 0.9329 - val_loss: 0.1739 - val_accuracy: 0.9415\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1759 - accuracy: 0.9358 - val_loss: 0.1200 - val_accuracy: 0.9570\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_79 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_80 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_81 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_78 (TFOpL  (None, 8, 45)       0           ['input_79[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_79 (TFOpL  (None, 8, 45)       0           ['input_80[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_80 (TFOpL  (None, 11, 45)      0           ['input_81[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_78 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_78[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_78[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_79 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_79[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_79[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_80 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_80[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_80[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_78 (LayerN  (None, 8, 45)       90          ['multi_head_attention_78[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_79 (LayerN  (None, 8, 45)       90          ['multi_head_attention_79[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_80 (LayerN  (None, 11, 45)      90          ['multi_head_attention_80[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_130 (Dropout)          (None, 8, 45)        0           ['layer_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, 8, 45)        0           ['layer_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_132 (Dropout)          (None, 11, 45)       0           ['layer_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_78 (G  (None, 45)          0           ['dropout_130[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_79 (G  (None, 45)          0           ['dropout_131[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_80 (G  (None, 45)          0           ['dropout_132[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_78[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_79[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_80[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_133 (Dropout)          (None, 135)          0           ['concatenate_26[0][0]']         \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 128)          17408       ['dropout_133[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_134 (Dropout)          (None, 128)          0           ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 1)            129         ['dropout_134[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.2984 - accuracy: 0.8599 - val_loss: 0.3089 - val_accuracy: 0.8870\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1558 - accuracy: 0.9380 - val_loss: 0.2672 - val_accuracy: 0.8836\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1562 - accuracy: 0.9399 - val_loss: 0.2707 - val_accuracy: 0.8607\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1274 - accuracy: 0.9507 - val_loss: 0.2322 - val_accuracy: 0.8958\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1202 - accuracy: 0.9535 - val_loss: 0.2288 - val_accuracy: 0.8681\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.2854 - val_accuracy: 0.8499\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1062 - accuracy: 0.9594 - val_loss: 0.2838 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1022 - accuracy: 0.9613 - val_loss: 0.2772 - val_accuracy: 0.8726\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0955 - accuracy: 0.9642 - val_loss: 0.2716 - val_accuracy: 0.8870\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0901 - accuracy: 0.9670 - val_loss: 0.2116 - val_accuracy: 0.9011\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_82 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_83 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_84 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_81 (TFOpL  (None, 8, 45)       0           ['input_82[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_82 (TFOpL  (None, 8, 45)       0           ['input_83[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_83 (TFOpL  (None, 11, 45)      0           ['input_84[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_81 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_81[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_81[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_82 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_82[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_82[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_83 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_83[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_83[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_81 (LayerN  (None, 8, 45)       90          ['multi_head_attention_81[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_82 (LayerN  (None, 8, 45)       90          ['multi_head_attention_82[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_83 (LayerN  (None, 11, 45)      90          ['multi_head_attention_83[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_135 (Dropout)          (None, 8, 45)        0           ['layer_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 8, 45)        0           ['layer_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 11, 45)       0           ['layer_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_81 (G  (None, 45)          0           ['dropout_135[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_82 (G  (None, 45)          0           ['dropout_136[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_83 (G  (None, 45)          0           ['dropout_137[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_81[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_82[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_83[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 135)          0           ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 128)          17408       ['dropout_138[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 128)          0           ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 1)            129         ['dropout_139[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.2346 - accuracy: 0.9162 - val_loss: 0.1057 - val_accuracy: 0.9888\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1385 - accuracy: 0.9666 - val_loss: 0.0678 - val_accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1277 - accuracy: 0.9680 - val_loss: 0.0760 - val_accuracy: 0.9904\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1263 - accuracy: 0.9671 - val_loss: 0.0866 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1217 - accuracy: 0.9678 - val_loss: 0.0837 - val_accuracy: 0.9895\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1135 - accuracy: 0.9682 - val_loss: 0.0557 - val_accuracy: 0.9878\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1049 - accuracy: 0.9685 - val_loss: 0.0570 - val_accuracy: 0.9897\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1058 - accuracy: 0.9690 - val_loss: 0.1090 - val_accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1001 - accuracy: 0.9688 - val_loss: 0.0846 - val_accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0986 - accuracy: 0.9688 - val_loss: 0.0712 - val_accuracy: 0.9907\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_85 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_86 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_87 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_84 (TFOpL  (None, 8, 45)       0           ['input_85[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_85 (TFOpL  (None, 8, 45)       0           ['input_86[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_86 (TFOpL  (None, 11, 45)      0           ['input_87[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_84 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_84[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_84[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_85 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_85[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_85[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_86 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_86[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_86[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_84 (LayerN  (None, 8, 45)       90          ['multi_head_attention_84[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_85 (LayerN  (None, 8, 45)       90          ['multi_head_attention_85[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_86 (LayerN  (None, 11, 45)      90          ['multi_head_attention_86[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 8, 45)        0           ['layer_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 8, 45)        0           ['layer_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 11, 45)       0           ['layer_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_84 (G  (None, 45)          0           ['dropout_140[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_85 (G  (None, 45)          0           ['dropout_141[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_86 (G  (None, 45)          0           ['dropout_142[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_84[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_85[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_86[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 135)          0           ['concatenate_28[0][0]']         \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 128)          17408       ['dropout_143[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_144 (Dropout)          (None, 128)          0           ['dense_56[0][0]']               \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 1)            129         ['dropout_144[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.3563 - accuracy: 0.8513 - val_loss: 0.1801 - val_accuracy: 0.9336\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2464 - accuracy: 0.9103 - val_loss: 0.1922 - val_accuracy: 0.9422\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2210 - accuracy: 0.9174 - val_loss: 0.2338 - val_accuracy: 0.8882\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2050 - accuracy: 0.9213 - val_loss: 0.2937 - val_accuracy: 0.8789\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1931 - accuracy: 0.9260 - val_loss: 0.1620 - val_accuracy: 0.9453\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1821 - accuracy: 0.9302 - val_loss: 0.1924 - val_accuracy: 0.9171\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1713 - accuracy: 0.9358 - val_loss: 0.2335 - val_accuracy: 0.9192\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1651 - accuracy: 0.9379 - val_loss: 0.1806 - val_accuracy: 0.9314\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1567 - accuracy: 0.9408 - val_loss: 0.2666 - val_accuracy: 0.8992\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1531 - accuracy: 0.9413 - val_loss: 0.1912 - val_accuracy: 0.9259\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_88 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_89 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_90 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_87 (TFOpL  (None, 8, 45)       0           ['input_88[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_88 (TFOpL  (None, 8, 45)       0           ['input_89[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_89 (TFOpL  (None, 11, 45)      0           ['input_90[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_87 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_87[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_87[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_88 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_88[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_88[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_89 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_89[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_89[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_87 (LayerN  (None, 8, 45)       90          ['multi_head_attention_87[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_88 (LayerN  (None, 8, 45)       90          ['multi_head_attention_88[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_89 (LayerN  (None, 11, 45)      90          ['multi_head_attention_89[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_145 (Dropout)          (None, 8, 45)        0           ['layer_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 8, 45)        0           ['layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 11, 45)       0           ['layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_87 (G  (None, 45)          0           ['dropout_145[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_88 (G  (None, 45)          0           ['dropout_146[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_89 (G  (None, 45)          0           ['dropout_147[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_87[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_88[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_89[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_148 (Dropout)          (None, 135)          0           ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 128)          17408       ['dropout_148[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_149 (Dropout)          (None, 128)          0           ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 1)            129         ['dropout_149[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.1356 - accuracy: 0.9482 - val_loss: 0.1133 - val_accuracy: 0.9625\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.0322 - val_accuracy: 0.9909\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.0435 - val_accuracy: 0.9912\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.0336 - val_accuracy: 0.9924\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.0467 - val_accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0372 - val_accuracy: 0.9947\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0361 - val_accuracy: 0.9945\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.0373 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0407 - val_accuracy: 0.9916\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_91 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_92 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_93 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_90 (TFOpL  (None, 8, 45)       0           ['input_91[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_91 (TFOpL  (None, 8, 45)       0           ['input_92[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_92 (TFOpL  (None, 11, 45)      0           ['input_93[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_90 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_90[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_90[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_91 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_91[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_91[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_92 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_92[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_92[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_90 (LayerN  (None, 8, 45)       90          ['multi_head_attention_90[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_91 (LayerN  (None, 8, 45)       90          ['multi_head_attention_91[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_92 (LayerN  (None, 11, 45)      90          ['multi_head_attention_92[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_150 (Dropout)          (None, 8, 45)        0           ['layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_151 (Dropout)          (None, 8, 45)        0           ['layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_152 (Dropout)          (None, 11, 45)       0           ['layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_90 (G  (None, 45)          0           ['dropout_150[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_91 (G  (None, 45)          0           ['dropout_151[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_92 (G  (None, 45)          0           ['dropout_152[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_90[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_91[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_92[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_153 (Dropout)          (None, 135)          0           ['concatenate_30[0][0]']         \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 128)          17408       ['dropout_153[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_154 (Dropout)          (None, 128)          0           ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 1)            129         ['dropout_154[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.1326 - accuracy: 0.9497 - val_loss: 0.0714 - val_accuracy: 0.9838\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0356 - accuracy: 0.9919 - val_loss: 0.0712 - val_accuracy: 0.9811\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0248 - accuracy: 0.9953 - val_loss: 0.1047 - val_accuracy: 0.9802\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0232 - accuracy: 0.9956 - val_loss: 0.0960 - val_accuracy: 0.9816\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.0244 - accuracy: 0.9952 - val_loss: 0.0811 - val_accuracy: 0.9840\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0216 - accuracy: 0.9956 - val_loss: 0.0699 - val_accuracy: 0.9835\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0206 - accuracy: 0.9958 - val_loss: 0.0747 - val_accuracy: 0.9838\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0210 - accuracy: 0.9957 - val_loss: 0.0610 - val_accuracy: 0.9852\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0174 - accuracy: 0.9965 - val_loss: 0.0622 - val_accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0202 - accuracy: 0.9959 - val_loss: 0.0958 - val_accuracy: 0.9761\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_94 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_95 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_96 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_93 (TFOpL  (None, 8, 45)       0           ['input_94[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_94 (TFOpL  (None, 8, 45)       0           ['input_95[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_95 (TFOpL  (None, 11, 45)      0           ['input_96[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_93 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_93[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_93[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_94 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_94[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_94[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_95 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_95[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_95[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_93 (LayerN  (None, 8, 45)       90          ['multi_head_attention_93[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_94 (LayerN  (None, 8, 45)       90          ['multi_head_attention_94[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_95 (LayerN  (None, 11, 45)      90          ['multi_head_attention_95[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_155 (Dropout)          (None, 8, 45)        0           ['layer_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_156 (Dropout)          (None, 8, 45)        0           ['layer_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_157 (Dropout)          (None, 11, 45)       0           ['layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_93 (G  (None, 45)          0           ['dropout_155[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_94 (G  (None, 45)          0           ['dropout_156[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_95 (G  (None, 45)          0           ['dropout_157[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_93[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_94[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_95[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_158 (Dropout)          (None, 135)          0           ['concatenate_31[0][0]']         \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 128)          17408       ['dropout_158[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_159 (Dropout)          (None, 128)          0           ['dense_62[0][0]']               \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 1)            129         ['dropout_159[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.2037 - accuracy: 0.9255 - val_loss: 0.0431 - val_accuracy: 0.9907\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1175 - accuracy: 0.9708 - val_loss: 0.0517 - val_accuracy: 0.9933\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1090 - accuracy: 0.9715 - val_loss: 0.0365 - val_accuracy: 0.9924\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1019 - accuracy: 0.9729 - val_loss: 0.0328 - val_accuracy: 0.9902\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0974 - accuracy: 0.9736 - val_loss: 0.0351 - val_accuracy: 0.9931\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0968 - accuracy: 0.9741 - val_loss: 0.0308 - val_accuracy: 0.9926\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0901 - accuracy: 0.9751 - val_loss: 0.0362 - val_accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0853 - accuracy: 0.9758 - val_loss: 0.0368 - val_accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0840 - accuracy: 0.9755 - val_loss: 0.0580 - val_accuracy: 0.9861\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0821 - accuracy: 0.9756 - val_loss: 0.0652 - val_accuracy: 0.9900\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_97 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_98 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_99 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_96 (TFOpL  (None, 8, 45)       0           ['input_97[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_97 (TFOpL  (None, 8, 45)       0           ['input_98[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_98 (TFOpL  (None, 11, 45)      0           ['input_99[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_96 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_96[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_96[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_97 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_97[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_97[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_98 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_98[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_98[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_96 (LayerN  (None, 8, 45)       90          ['multi_head_attention_96[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_97 (LayerN  (None, 8, 45)       90          ['multi_head_attention_97[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_98 (LayerN  (None, 11, 45)      90          ['multi_head_attention_98[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_160 (Dropout)          (None, 8, 45)        0           ['layer_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_161 (Dropout)          (None, 8, 45)        0           ['layer_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_162 (Dropout)          (None, 11, 45)       0           ['layer_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_96 (G  (None, 45)          0           ['dropout_160[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_97 (G  (None, 45)          0           ['dropout_161[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_98 (G  (None, 45)          0           ['dropout_162[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_96[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_97[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_98[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_163 (Dropout)          (None, 135)          0           ['concatenate_32[0][0]']         \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 128)          17408       ['dropout_163[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_164 (Dropout)          (None, 128)          0           ['dense_64[0][0]']               \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 1)            129         ['dropout_164[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3062 - accuracy: 0.8671 - val_loss: 0.2454 - val_accuracy: 0.8550\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1889 - accuracy: 0.9338 - val_loss: 0.2552 - val_accuracy: 0.8421\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1656 - accuracy: 0.9383 - val_loss: 0.3218 - val_accuracy: 0.8437\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1540 - accuracy: 0.9420 - val_loss: 0.4022 - val_accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1433 - accuracy: 0.9449 - val_loss: 0.2710 - val_accuracy: 0.8509\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1335 - accuracy: 0.9494 - val_loss: 0.2783 - val_accuracy: 0.8487\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1279 - accuracy: 0.9520 - val_loss: 0.3307 - val_accuracy: 0.8624\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1221 - accuracy: 0.9541 - val_loss: 0.4469 - val_accuracy: 0.8485\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1208 - accuracy: 0.9547 - val_loss: 0.3495 - val_accuracy: 0.8569\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1126 - accuracy: 0.9574 - val_loss: 0.2967 - val_accuracy: 0.8750\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 4 19923\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_100 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_101 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_102 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_99 (TFOpL  (None, 8, 45)       0           ['input_100[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_100 (TFOp  (None, 8, 45)       0           ['input_101[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_101 (TFOp  (None, 11, 45)      0           ['input_102[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_99 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_99[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_99[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_100 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_100[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_100[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_101 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_101[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_101[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_99 (LayerN  (None, 8, 45)       90          ['multi_head_attention_99[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_100 (Layer  (None, 8, 45)       90          ['multi_head_attention_100[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_101 (Layer  (None, 11, 45)      90          ['multi_head_attention_101[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_165 (Dropout)          (None, 8, 45)        0           ['layer_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_166 (Dropout)          (None, 8, 45)        0           ['layer_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " dropout_167 (Dropout)          (None, 11, 45)       0           ['layer_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_99 (G  (None, 45)          0           ['dropout_165[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_100 (  (None, 45)          0           ['dropout_166[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_101 (  (None, 45)          0           ['dropout_167[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_99[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_100[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_101[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_168 (Dropout)          (None, 135)          0           ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 128)          17408       ['dropout_168[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_169 (Dropout)          (None, 128)          0           ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 1)            129         ['dropout_169[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.4309 - accuracy: 0.8033 - val_loss: 0.2019 - val_accuracy: 0.9427\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2806 - accuracy: 0.8942 - val_loss: 0.2495 - val_accuracy: 0.9161\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2537 - accuracy: 0.9064 - val_loss: 0.1991 - val_accuracy: 0.9343\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2314 - accuracy: 0.9150 - val_loss: 0.1296 - val_accuracy: 0.9508\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2195 - accuracy: 0.9228 - val_loss: 0.1704 - val_accuracy: 0.9443\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2030 - accuracy: 0.9273 - val_loss: 0.1872 - val_accuracy: 0.9350\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1947 - accuracy: 0.9307 - val_loss: 0.1856 - val_accuracy: 0.9345\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1870 - accuracy: 0.9337 - val_loss: 0.2000 - val_accuracy: 0.9462\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1796 - accuracy: 0.9358 - val_loss: 0.1507 - val_accuracy: 0.9513\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1718 - accuracy: 0.9410 - val_loss: 0.1772 - val_accuracy: 0.9441\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_103 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_104 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_105 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_102 (TFOp  (None, 8, 45)       0           ['input_103[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_103 (TFOp  (None, 8, 45)       0           ['input_104[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_104 (TFOp  (None, 11, 45)      0           ['input_105[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_102 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_102[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_102[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_103 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_103[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_103[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_104 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_104[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_104[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_102 (Layer  (None, 8, 45)       90          ['multi_head_attention_102[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_103 (Layer  (None, 8, 45)       90          ['multi_head_attention_103[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_104 (Layer  (None, 11, 45)      90          ['multi_head_attention_104[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_170 (Dropout)          (None, 8, 45)        0           ['layer_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " dropout_171 (Dropout)          (None, 8, 45)        0           ['layer_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " dropout_172 (Dropout)          (None, 11, 45)       0           ['layer_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_102 (  (None, 45)          0           ['dropout_170[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_103 (  (None, 45)          0           ['dropout_171[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_104 (  (None, 45)          0           ['dropout_172[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_102[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_103[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_104[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_173 (Dropout)          (None, 135)          0           ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 128)          17408       ['dropout_173[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_174 (Dropout)          (None, 128)          0           ['dense_68[0][0]']               \n",
      "                                                                                                  \n",
      " dense_69 (Dense)               (None, 1)            129         ['dropout_174[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.3306 - accuracy: 0.8399 - val_loss: 0.1136 - val_accuracy: 0.9675\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1721 - accuracy: 0.9310 - val_loss: 0.1727 - val_accuracy: 0.9326\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1439 - accuracy: 0.9448 - val_loss: 0.2129 - val_accuracy: 0.9317\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1287 - accuracy: 0.9520 - val_loss: 0.1733 - val_accuracy: 0.9343\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1176 - accuracy: 0.9549 - val_loss: 0.1730 - val_accuracy: 0.9477\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1138 - accuracy: 0.9582 - val_loss: 0.1607 - val_accuracy: 0.9556\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1034 - accuracy: 0.9613 - val_loss: 0.1804 - val_accuracy: 0.9388\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1034 - accuracy: 0.9637 - val_loss: 0.1234 - val_accuracy: 0.9577\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0974 - accuracy: 0.9651 - val_loss: 0.1872 - val_accuracy: 0.9355\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0918 - accuracy: 0.9674 - val_loss: 0.1255 - val_accuracy: 0.9658\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_106 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_107 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_108 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_105 (TFOp  (None, 8, 45)       0           ['input_106[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_106 (TFOp  (None, 8, 45)       0           ['input_107[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_107 (TFOp  (None, 11, 45)      0           ['input_108[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_105 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_105[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_105[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_106 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_106[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_106[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_107 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_107[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_107[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_105 (Layer  (None, 8, 45)       90          ['multi_head_attention_105[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_106 (Layer  (None, 8, 45)       90          ['multi_head_attention_106[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_107 (Layer  (None, 11, 45)      90          ['multi_head_attention_107[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_175 (Dropout)          (None, 8, 45)        0           ['layer_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " dropout_176 (Dropout)          (None, 8, 45)        0           ['layer_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " dropout_177 (Dropout)          (None, 11, 45)       0           ['layer_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_105 (  (None, 45)          0           ['dropout_175[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_106 (  (None, 45)          0           ['dropout_176[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_107 (  (None, 45)          0           ['dropout_177[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_105[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_106[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_107[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_178 (Dropout)          (None, 135)          0           ['concatenate_35[0][0]']         \n",
      "                                                                                                  \n",
      " dense_70 (Dense)               (None, 128)          17408       ['dropout_178[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_179 (Dropout)          (None, 128)          0           ['dense_70[0][0]']               \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 1)            129         ['dropout_179[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.2594 - accuracy: 0.8974 - val_loss: 0.0789 - val_accuracy: 0.9888\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1361 - accuracy: 0.9673 - val_loss: 0.0661 - val_accuracy: 0.9888\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1269 - accuracy: 0.9679 - val_loss: 0.0701 - val_accuracy: 0.9902\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1152 - accuracy: 0.9677 - val_loss: 0.0907 - val_accuracy: 0.9878\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1057 - accuracy: 0.9685 - val_loss: 0.0483 - val_accuracy: 0.9890\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1023 - accuracy: 0.9685 - val_loss: 0.0582 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0987 - accuracy: 0.9695 - val_loss: 0.0619 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0962 - accuracy: 0.9697 - val_loss: 0.0631 - val_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0955 - accuracy: 0.9706 - val_loss: 0.1099 - val_accuracy: 0.9864\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0921 - accuracy: 0.9716 - val_loss: 0.0733 - val_accuracy: 0.9892\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_109 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_110 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_111 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_108 (TFOp  (None, 8, 45)       0           ['input_109[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_109 (TFOp  (None, 8, 45)       0           ['input_110[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_110 (TFOp  (None, 11, 45)      0           ['input_111[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_108 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_108[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_108[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_109 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_109[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_109[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_110 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_110[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_110[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_108 (Layer  (None, 8, 45)       90          ['multi_head_attention_108[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_109 (Layer  (None, 8, 45)       90          ['multi_head_attention_109[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_110 (Layer  (None, 11, 45)      90          ['multi_head_attention_110[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_180 (Dropout)          (None, 8, 45)        0           ['layer_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " dropout_181 (Dropout)          (None, 8, 45)        0           ['layer_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " dropout_182 (Dropout)          (None, 11, 45)       0           ['layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_108 (  (None, 45)          0           ['dropout_180[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_109 (  (None, 45)          0           ['dropout_181[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_110 (  (None, 45)          0           ['dropout_182[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_108[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_109[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_110[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_183 (Dropout)          (None, 135)          0           ['concatenate_36[0][0]']         \n",
      "                                                                                                  \n",
      " dense_72 (Dense)               (None, 128)          17408       ['dropout_183[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_184 (Dropout)          (None, 128)          0           ['dense_72[0][0]']               \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 1)            129         ['dropout_184[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3646 - accuracy: 0.8439 - val_loss: 0.2831 - val_accuracy: 0.8910\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2426 - accuracy: 0.9132 - val_loss: 0.1602 - val_accuracy: 0.9379\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2210 - accuracy: 0.9195 - val_loss: 0.1465 - val_accuracy: 0.9395\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2032 - accuracy: 0.9232 - val_loss: 0.2427 - val_accuracy: 0.9099\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1894 - accuracy: 0.9289 - val_loss: 0.2248 - val_accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1820 - accuracy: 0.9313 - val_loss: 0.1649 - val_accuracy: 0.9307\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1663 - accuracy: 0.9365 - val_loss: 0.1968 - val_accuracy: 0.9207\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1609 - accuracy: 0.9398 - val_loss: 0.1876 - val_accuracy: 0.9235\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1557 - accuracy: 0.9421 - val_loss: 0.2226 - val_accuracy: 0.9149\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1464 - accuracy: 0.9445 - val_loss: 0.1529 - val_accuracy: 0.9529\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_112 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_113 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_114 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_111 (TFOp  (None, 8, 45)       0           ['input_112[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_112 (TFOp  (None, 8, 45)       0           ['input_113[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_113 (TFOp  (None, 11, 45)      0           ['input_114[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_111 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_111[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_111[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_112 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_112[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_112[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_113 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_113[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_113[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_111 (Layer  (None, 8, 45)       90          ['multi_head_attention_111[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_112 (Layer  (None, 8, 45)       90          ['multi_head_attention_112[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_113 (Layer  (None, 11, 45)      90          ['multi_head_attention_113[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_185 (Dropout)          (None, 8, 45)        0           ['layer_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " dropout_186 (Dropout)          (None, 8, 45)        0           ['layer_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " dropout_187 (Dropout)          (None, 11, 45)       0           ['layer_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_111 (  (None, 45)          0           ['dropout_185[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_112 (  (None, 45)          0           ['dropout_186[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_113 (  (None, 45)          0           ['dropout_187[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_111[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_112[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_113[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_188 (Dropout)          (None, 135)          0           ['concatenate_37[0][0]']         \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 128)          17408       ['dropout_188[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_189 (Dropout)          (None, 128)          0           ['dense_74[0][0]']               \n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 1)            129         ['dropout_189[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.1275 - accuracy: 0.9516 - val_loss: 0.0402 - val_accuracy: 0.9842\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.0312 - val_accuracy: 0.9890\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0269 - accuracy: 0.9927 - val_loss: 0.0510 - val_accuracy: 0.9902\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 0.0343 - val_accuracy: 0.9943\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.0321 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.0750 - val_accuracy: 0.9845\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.0343 - val_accuracy: 0.9947\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.0432 - val_accuracy: 0.9940\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 0.0313 - val_accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0284 - val_accuracy: 0.9955\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_115 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_116 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_117 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_114 (TFOp  (None, 8, 45)       0           ['input_115[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_115 (TFOp  (None, 8, 45)       0           ['input_116[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_116 (TFOp  (None, 11, 45)      0           ['input_117[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_114 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_114[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_114[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_115 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_115[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_115[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_116 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_116[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_116[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_114 (Layer  (None, 8, 45)       90          ['multi_head_attention_114[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_115 (Layer  (None, 8, 45)       90          ['multi_head_attention_115[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_116 (Layer  (None, 11, 45)      90          ['multi_head_attention_116[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_190 (Dropout)          (None, 8, 45)        0           ['layer_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " dropout_191 (Dropout)          (None, 8, 45)        0           ['layer_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " dropout_192 (Dropout)          (None, 11, 45)       0           ['layer_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_114 (  (None, 45)          0           ['dropout_190[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_115 (  (None, 45)          0           ['dropout_191[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_116 (  (None, 45)          0           ['dropout_192[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_114[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_115[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_116[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_193 (Dropout)          (None, 135)          0           ['concatenate_38[0][0]']         \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 128)          17408       ['dropout_193[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_194 (Dropout)          (None, 128)          0           ['dense_76[0][0]']               \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 1)            129         ['dropout_194[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.1419 - accuracy: 0.9456 - val_loss: 0.1696 - val_accuracy: 0.9625\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0344 - accuracy: 0.9920 - val_loss: 0.0674 - val_accuracy: 0.9835\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0278 - accuracy: 0.9939 - val_loss: 0.0885 - val_accuracy: 0.9823\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.0900 - val_accuracy: 0.9830\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0219 - accuracy: 0.9951 - val_loss: 0.1329 - val_accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 0.0633 - val_accuracy: 0.9847\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0234 - accuracy: 0.9943 - val_loss: 0.0802 - val_accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0200 - accuracy: 0.9955 - val_loss: 0.0696 - val_accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.0691 - val_accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0230 - accuracy: 0.9939 - val_loss: 0.0831 - val_accuracy: 0.9787\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_118 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_119 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_120 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_117 (TFOp  (None, 8, 45)       0           ['input_118[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_118 (TFOp  (None, 8, 45)       0           ['input_119[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_119 (TFOp  (None, 11, 45)      0           ['input_120[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_117 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_117[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_117[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_118 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_118[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_118[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_119 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_119[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_119[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_117 (Layer  (None, 8, 45)       90          ['multi_head_attention_117[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_118 (Layer  (None, 8, 45)       90          ['multi_head_attention_118[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_119 (Layer  (None, 11, 45)      90          ['multi_head_attention_119[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_195 (Dropout)          (None, 8, 45)        0           ['layer_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " dropout_196 (Dropout)          (None, 8, 45)        0           ['layer_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " dropout_197 (Dropout)          (None, 11, 45)       0           ['layer_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_117 (  (None, 45)          0           ['dropout_195[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_118 (  (None, 45)          0           ['dropout_196[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_119 (  (None, 45)          0           ['dropout_197[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_117[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_118[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_119[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_198 (Dropout)          (None, 135)          0           ['concatenate_39[0][0]']         \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 128)          17408       ['dropout_198[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_199 (Dropout)          (None, 128)          0           ['dense_78[0][0]']               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 1)            129         ['dropout_199[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.1897 - accuracy: 0.9332 - val_loss: 0.0366 - val_accuracy: 0.9919\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1180 - accuracy: 0.9699 - val_loss: 0.0334 - val_accuracy: 0.9926\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1104 - accuracy: 0.9712 - val_loss: 0.0429 - val_accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1038 - accuracy: 0.9719 - val_loss: 0.0622 - val_accuracy: 0.9900\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1002 - accuracy: 0.9731 - val_loss: 0.0343 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0972 - accuracy: 0.9735 - val_loss: 0.0312 - val_accuracy: 0.9935\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0940 - accuracy: 0.9736 - val_loss: 0.0463 - val_accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0884 - accuracy: 0.9737 - val_loss: 0.0335 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0867 - accuracy: 0.9744 - val_loss: 0.0389 - val_accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0845 - accuracy: 0.9751 - val_loss: 0.0404 - val_accuracy: 0.9950\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_121 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_122 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_123 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_120 (TFOp  (None, 8, 45)       0           ['input_121[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_121 (TFOp  (None, 8, 45)       0           ['input_122[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_122 (TFOp  (None, 11, 45)      0           ['input_123[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_120 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_120[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_120[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_121 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_121[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_121[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_122 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_122[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_122[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_120 (Layer  (None, 8, 45)       90          ['multi_head_attention_120[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_121 (Layer  (None, 8, 45)       90          ['multi_head_attention_121[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_122 (Layer  (None, 11, 45)      90          ['multi_head_attention_122[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_200 (Dropout)          (None, 8, 45)        0           ['layer_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " dropout_201 (Dropout)          (None, 8, 45)        0           ['layer_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " dropout_202 (Dropout)          (None, 11, 45)       0           ['layer_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_120 (  (None, 45)          0           ['dropout_200[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_121 (  (None, 45)          0           ['dropout_201[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_122 (  (None, 45)          0           ['dropout_202[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_120[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_121[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_122[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_203 (Dropout)          (None, 135)          0           ['concatenate_40[0][0]']         \n",
      "                                                                                                  \n",
      " dense_80 (Dense)               (None, 128)          17408       ['dropout_203[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_204 (Dropout)          (None, 128)          0           ['dense_80[0][0]']               \n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 1)            129         ['dropout_204[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.3122 - accuracy: 0.8721 - val_loss: 0.2085 - val_accuracy: 0.8836\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2037 - accuracy: 0.9255 - val_loss: 0.1861 - val_accuracy: 0.9039\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1768 - accuracy: 0.9323 - val_loss: 0.2080 - val_accuracy: 0.8946\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1639 - accuracy: 0.9377 - val_loss: 0.1652 - val_accuracy: 0.9104\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1553 - accuracy: 0.9428 - val_loss: 0.1645 - val_accuracy: 0.9097\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1468 - accuracy: 0.9454 - val_loss: 0.1542 - val_accuracy: 0.9099\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1401 - accuracy: 0.9471 - val_loss: 0.1252 - val_accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1379 - accuracy: 0.9477 - val_loss: 0.2023 - val_accuracy: 0.9063\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1340 - accuracy: 0.9497 - val_loss: 0.1355 - val_accuracy: 0.9283\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1314 - accuracy: 0.9497 - val_loss: 0.1536 - val_accuracy: 0.9200\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 5 19924\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_124 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_125 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_126 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_123 (TFOp  (None, 8, 45)       0           ['input_124[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_124 (TFOp  (None, 8, 45)       0           ['input_125[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_125 (TFOp  (None, 11, 45)      0           ['input_126[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_123 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_123[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_123[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_124 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_124[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_124[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_125 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_125[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_125[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_123 (Layer  (None, 8, 45)       90          ['multi_head_attention_123[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_124 (Layer  (None, 8, 45)       90          ['multi_head_attention_124[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_125 (Layer  (None, 11, 45)      90          ['multi_head_attention_125[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_205 (Dropout)          (None, 8, 45)        0           ['layer_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " dropout_206 (Dropout)          (None, 8, 45)        0           ['layer_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " dropout_207 (Dropout)          (None, 11, 45)       0           ['layer_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_123 (  (None, 45)          0           ['dropout_205[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_124 (  (None, 45)          0           ['dropout_206[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_125 (  (None, 45)          0           ['dropout_207[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_123[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_124[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_125[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_208 (Dropout)          (None, 135)          0           ['concatenate_41[0][0]']         \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 128)          17408       ['dropout_208[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_209 (Dropout)          (None, 128)          0           ['dense_82[0][0]']               \n",
      "                                                                                                  \n",
      " dense_83 (Dense)               (None, 1)            129         ['dropout_209[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.4674 - accuracy: 0.7768 - val_loss: 0.1895 - val_accuracy: 0.9226\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2853 - accuracy: 0.8952 - val_loss: 0.1329 - val_accuracy: 0.9575\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2583 - accuracy: 0.9049 - val_loss: 0.2825 - val_accuracy: 0.9070\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2376 - accuracy: 0.9130 - val_loss: 0.1028 - val_accuracy: 0.9649\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2198 - accuracy: 0.9187 - val_loss: 0.0921 - val_accuracy: 0.9637\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2063 - accuracy: 0.9257 - val_loss: 0.1513 - val_accuracy: 0.9501\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1946 - accuracy: 0.9289 - val_loss: 0.1451 - val_accuracy: 0.9493\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1828 - accuracy: 0.9320 - val_loss: 0.1295 - val_accuracy: 0.9484\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1750 - accuracy: 0.9346 - val_loss: 0.1366 - val_accuracy: 0.9541\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1681 - accuracy: 0.9359 - val_loss: 0.1564 - val_accuracy: 0.9412\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_127 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_128 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_129 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_126 (TFOp  (None, 8, 45)       0           ['input_127[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_127 (TFOp  (None, 8, 45)       0           ['input_128[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_128 (TFOp  (None, 11, 45)      0           ['input_129[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_126 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_126[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_126[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_127 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_127[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_127[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_128 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_128[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_128[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_126 (Layer  (None, 8, 45)       90          ['multi_head_attention_126[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_127 (Layer  (None, 8, 45)       90          ['multi_head_attention_127[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_128 (Layer  (None, 11, 45)      90          ['multi_head_attention_128[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_210 (Dropout)          (None, 8, 45)        0           ['layer_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " dropout_211 (Dropout)          (None, 8, 45)        0           ['layer_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " dropout_212 (Dropout)          (None, 11, 45)       0           ['layer_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_126 (  (None, 45)          0           ['dropout_210[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_127 (  (None, 45)          0           ['dropout_211[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_128 (  (None, 45)          0           ['dropout_212[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_126[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_127[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_128[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_213 (Dropout)          (None, 135)          0           ['concatenate_42[0][0]']         \n",
      "                                                                                                  \n",
      " dense_84 (Dense)               (None, 128)          17408       ['dropout_213[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_214 (Dropout)          (None, 128)          0           ['dense_84[0][0]']               \n",
      "                                                                                                  \n",
      " dense_85 (Dense)               (None, 1)            129         ['dropout_214[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3492 - accuracy: 0.8327 - val_loss: 0.1833 - val_accuracy: 0.9209\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1724 - accuracy: 0.9304 - val_loss: 0.1796 - val_accuracy: 0.9357\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1440 - accuracy: 0.9459 - val_loss: 0.1118 - val_accuracy: 0.9620\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1318 - accuracy: 0.9506 - val_loss: 0.0883 - val_accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1197 - accuracy: 0.9557 - val_loss: 0.1546 - val_accuracy: 0.9453\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1126 - accuracy: 0.9580 - val_loss: 0.1560 - val_accuracy: 0.9441\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1047 - accuracy: 0.9608 - val_loss: 0.1727 - val_accuracy: 0.9455\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1038 - accuracy: 0.9630 - val_loss: 0.1735 - val_accuracy: 0.9297\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0982 - accuracy: 0.9638 - val_loss: 0.1812 - val_accuracy: 0.9245\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0944 - accuracy: 0.9661 - val_loss: 0.1420 - val_accuracy: 0.9529\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_130 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_131 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_132 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_129 (TFOp  (None, 8, 45)       0           ['input_130[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_130 (TFOp  (None, 8, 45)       0           ['input_131[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_131 (TFOp  (None, 11, 45)      0           ['input_132[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_129 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_129[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_129[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_130 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_130[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_130[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_131 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_131[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_131[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_129 (Layer  (None, 8, 45)       90          ['multi_head_attention_129[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_130 (Layer  (None, 8, 45)       90          ['multi_head_attention_130[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_131 (Layer  (None, 11, 45)      90          ['multi_head_attention_131[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_215 (Dropout)          (None, 8, 45)        0           ['layer_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " dropout_216 (Dropout)          (None, 8, 45)        0           ['layer_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " dropout_217 (Dropout)          (None, 11, 45)       0           ['layer_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_129 (  (None, 45)          0           ['dropout_215[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_130 (  (None, 45)          0           ['dropout_216[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_131 (  (None, 45)          0           ['dropout_217[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_129[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_130[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_131[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_218 (Dropout)          (None, 135)          0           ['concatenate_43[0][0]']         \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 128)          17408       ['dropout_218[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_219 (Dropout)          (None, 128)          0           ['dense_86[0][0]']               \n",
      "                                                                                                  \n",
      " dense_87 (Dense)               (None, 1)            129         ['dropout_219[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.2527 - accuracy: 0.9094 - val_loss: 0.0821 - val_accuracy: 0.9854\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1475 - accuracy: 0.9672 - val_loss: 0.0818 - val_accuracy: 0.9854\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1391 - accuracy: 0.9684 - val_loss: 0.0879 - val_accuracy: 0.9859\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1353 - accuracy: 0.9682 - val_loss: 0.0843 - val_accuracy: 0.9859\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1278 - accuracy: 0.9686 - val_loss: 0.0745 - val_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1206 - accuracy: 0.9693 - val_loss: 0.0715 - val_accuracy: 0.9854\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1193 - accuracy: 0.9688 - val_loss: 0.0894 - val_accuracy: 0.9857\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1150 - accuracy: 0.9690 - val_loss: 0.1026 - val_accuracy: 0.9859\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1076 - accuracy: 0.9699 - val_loss: 0.0910 - val_accuracy: 0.9854\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1070 - accuracy: 0.9695 - val_loss: 0.1115 - val_accuracy: 0.9861\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_133 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_134 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_135 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_132 (TFOp  (None, 8, 45)       0           ['input_133[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_133 (TFOp  (None, 8, 45)       0           ['input_134[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_134 (TFOp  (None, 11, 45)      0           ['input_135[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_132 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_132[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_132[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_133 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_133[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_133[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_134 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_134[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_134[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_132 (Layer  (None, 8, 45)       90          ['multi_head_attention_132[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_133 (Layer  (None, 8, 45)       90          ['multi_head_attention_133[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_134 (Layer  (None, 11, 45)      90          ['multi_head_attention_134[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_220 (Dropout)          (None, 8, 45)        0           ['layer_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " dropout_221 (Dropout)          (None, 8, 45)        0           ['layer_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " dropout_222 (Dropout)          (None, 11, 45)       0           ['layer_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_132 (  (None, 45)          0           ['dropout_220[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_133 (  (None, 45)          0           ['dropout_221[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_134 (  (None, 45)          0           ['dropout_222[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_132[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_133[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_134[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_223 (Dropout)          (None, 135)          0           ['concatenate_44[0][0]']         \n",
      "                                                                                                  \n",
      " dense_88 (Dense)               (None, 128)          17408       ['dropout_223[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_224 (Dropout)          (None, 128)          0           ['dense_88[0][0]']               \n",
      "                                                                                                  \n",
      " dense_89 (Dense)               (None, 1)            129         ['dropout_224[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3808 - accuracy: 0.8369 - val_loss: 0.1691 - val_accuracy: 0.9472\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2500 - accuracy: 0.9095 - val_loss: 0.2285 - val_accuracy: 0.9295\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2261 - accuracy: 0.9173 - val_loss: 0.1380 - val_accuracy: 0.9491\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2068 - accuracy: 0.9218 - val_loss: 0.1742 - val_accuracy: 0.9410\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1956 - accuracy: 0.9272 - val_loss: 0.1755 - val_accuracy: 0.9422\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1852 - accuracy: 0.9298 - val_loss: 0.1440 - val_accuracy: 0.9403\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1673 - accuracy: 0.9375 - val_loss: 0.1287 - val_accuracy: 0.9470\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1623 - accuracy: 0.9372 - val_loss: 0.1385 - val_accuracy: 0.9486\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1567 - accuracy: 0.9421 - val_loss: 0.1647 - val_accuracy: 0.9453\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1527 - accuracy: 0.9431 - val_loss: 0.1452 - val_accuracy: 0.9498\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_136 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_137 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_138 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_135 (TFOp  (None, 8, 45)       0           ['input_136[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_136 (TFOp  (None, 8, 45)       0           ['input_137[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_137 (TFOp  (None, 11, 45)      0           ['input_138[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_135 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_135[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_135[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_136 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_136[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_136[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_137 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_137[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_137[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_135 (Layer  (None, 8, 45)       90          ['multi_head_attention_135[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_136 (Layer  (None, 8, 45)       90          ['multi_head_attention_136[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_137 (Layer  (None, 11, 45)      90          ['multi_head_attention_137[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_225 (Dropout)          (None, 8, 45)        0           ['layer_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " dropout_226 (Dropout)          (None, 8, 45)        0           ['layer_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " dropout_227 (Dropout)          (None, 11, 45)       0           ['layer_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_135 (  (None, 45)          0           ['dropout_225[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_136 (  (None, 45)          0           ['dropout_226[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_137 (  (None, 45)          0           ['dropout_227[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_45 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_135[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_136[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_137[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_228 (Dropout)          (None, 135)          0           ['concatenate_45[0][0]']         \n",
      "                                                                                                  \n",
      " dense_90 (Dense)               (None, 128)          17408       ['dropout_228[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_229 (Dropout)          (None, 128)          0           ['dense_90[0][0]']               \n",
      "                                                                                                  \n",
      " dense_91 (Dense)               (None, 1)            129         ['dropout_229[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.1412 - accuracy: 0.9428 - val_loss: 0.0179 - val_accuracy: 0.9928\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0285 - accuracy: 0.9926 - val_loss: 0.0113 - val_accuracy: 0.9969\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0192 - accuracy: 0.9958 - val_loss: 0.0121 - val_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0170 - accuracy: 0.9956 - val_loss: 0.0259 - val_accuracy: 0.9947\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0148 - accuracy: 0.9962 - val_loss: 0.0164 - val_accuracy: 0.9959\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0163 - val_accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0168 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0315 - val_accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0320 - val_accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0199 - val_accuracy: 0.9974\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_139 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_140 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_141 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_138 (TFOp  (None, 8, 45)       0           ['input_139[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_139 (TFOp  (None, 8, 45)       0           ['input_140[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_140 (TFOp  (None, 11, 45)      0           ['input_141[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_138 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_138[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_138[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_139 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_139[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_139[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_140 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_140[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_140[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_138 (Layer  (None, 8, 45)       90          ['multi_head_attention_138[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_139 (Layer  (None, 8, 45)       90          ['multi_head_attention_139[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_140 (Layer  (None, 11, 45)      90          ['multi_head_attention_140[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_230 (Dropout)          (None, 8, 45)        0           ['layer_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " dropout_231 (Dropout)          (None, 8, 45)        0           ['layer_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " dropout_232 (Dropout)          (None, 11, 45)       0           ['layer_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_138 (  (None, 45)          0           ['dropout_230[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_139 (  (None, 45)          0           ['dropout_231[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_140 (  (None, 45)          0           ['dropout_232[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_46 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_138[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_139[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_140[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_233 (Dropout)          (None, 135)          0           ['concatenate_46[0][0]']         \n",
      "                                                                                                  \n",
      " dense_92 (Dense)               (None, 128)          17408       ['dropout_233[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_234 (Dropout)          (None, 128)          0           ['dense_92[0][0]']               \n",
      "                                                                                                  \n",
      " dense_93 (Dense)               (None, 1)            129         ['dropout_234[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.1434 - accuracy: 0.9452 - val_loss: 0.0038 - val_accuracy: 0.9990\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0311 - accuracy: 0.9931 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0274 - accuracy: 0.9945 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0260 - accuracy: 0.9946 - val_loss: 0.0059 - val_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0229 - accuracy: 0.9955 - val_loss: 0.0045 - val_accuracy: 0.9990\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0303 - accuracy: 0.9931 - val_loss: 0.0080 - val_accuracy: 0.9983\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0195 - accuracy: 0.9956 - val_loss: 0.0056 - val_accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0199 - accuracy: 0.9955 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.0084 - val_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.0046 - val_accuracy: 0.9990\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_142 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_143 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_144 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_141 (TFOp  (None, 8, 45)       0           ['input_142[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_142 (TFOp  (None, 8, 45)       0           ['input_143[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_143 (TFOp  (None, 11, 45)      0           ['input_144[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_141 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_141[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_141[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_142 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_142[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_142[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_143 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_143[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_143[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_141 (Layer  (None, 8, 45)       90          ['multi_head_attention_141[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_142 (Layer  (None, 8, 45)       90          ['multi_head_attention_142[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_143 (Layer  (None, 11, 45)      90          ['multi_head_attention_143[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_235 (Dropout)          (None, 8, 45)        0           ['layer_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " dropout_236 (Dropout)          (None, 8, 45)        0           ['layer_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " dropout_237 (Dropout)          (None, 11, 45)       0           ['layer_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_141 (  (None, 45)          0           ['dropout_235[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_142 (  (None, 45)          0           ['dropout_236[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_143 (  (None, 45)          0           ['dropout_237[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_141[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_142[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_143[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_238 (Dropout)          (None, 135)          0           ['concatenate_47[0][0]']         \n",
      "                                                                                                  \n",
      " dense_94 (Dense)               (None, 128)          17408       ['dropout_238[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_239 (Dropout)          (None, 128)          0           ['dense_94[0][0]']               \n",
      "                                                                                                  \n",
      " dense_95 (Dense)               (None, 1)            129         ['dropout_239[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.1818 - accuracy: 0.9352 - val_loss: 0.1450 - val_accuracy: 0.9792\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1159 - accuracy: 0.9692 - val_loss: 0.1642 - val_accuracy: 0.9795\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1083 - accuracy: 0.9702 - val_loss: 0.1614 - val_accuracy: 0.9818\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1030 - accuracy: 0.9718 - val_loss: 0.1497 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1019 - accuracy: 0.9730 - val_loss: 0.1405 - val_accuracy: 0.9838\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0955 - accuracy: 0.9735 - val_loss: 0.1934 - val_accuracy: 0.9821\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0949 - accuracy: 0.9734 - val_loss: 0.1444 - val_accuracy: 0.9830\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0906 - accuracy: 0.9739 - val_loss: 0.2217 - val_accuracy: 0.9806\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0892 - accuracy: 0.9749 - val_loss: 0.2451 - val_accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0875 - accuracy: 0.9747 - val_loss: 0.2143 - val_accuracy: 0.9799\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_145 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_146 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_147 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_144 (TFOp  (None, 8, 45)       0           ['input_145[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_145 (TFOp  (None, 8, 45)       0           ['input_146[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_146 (TFOp  (None, 11, 45)      0           ['input_147[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_144 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_144[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_144[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_145 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_145[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_145[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_146 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_146[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_146[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_144 (Layer  (None, 8, 45)       90          ['multi_head_attention_144[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_145 (Layer  (None, 8, 45)       90          ['multi_head_attention_145[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_146 (Layer  (None, 11, 45)      90          ['multi_head_attention_146[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_240 (Dropout)          (None, 8, 45)        0           ['layer_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " dropout_241 (Dropout)          (None, 8, 45)        0           ['layer_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " dropout_242 (Dropout)          (None, 11, 45)       0           ['layer_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_144 (  (None, 45)          0           ['dropout_240[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_145 (  (None, 45)          0           ['dropout_241[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_146 (  (None, 45)          0           ['dropout_242[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_144[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_145[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_146[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_243 (Dropout)          (None, 135)          0           ['concatenate_48[0][0]']         \n",
      "                                                                                                  \n",
      " dense_96 (Dense)               (None, 128)          17408       ['dropout_243[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_244 (Dropout)          (None, 128)          0           ['dense_96[0][0]']               \n",
      "                                                                                                  \n",
      " dense_97 (Dense)               (None, 1)            129         ['dropout_244[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3120 - accuracy: 0.8682 - val_loss: 0.1979 - val_accuracy: 0.9099\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2075 - accuracy: 0.9276 - val_loss: 0.1762 - val_accuracy: 0.9023\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1795 - accuracy: 0.9321 - val_loss: 0.1521 - val_accuracy: 0.9278\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1650 - accuracy: 0.9351 - val_loss: 0.1475 - val_accuracy: 0.9314\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1547 - accuracy: 0.9393 - val_loss: 0.1506 - val_accuracy: 0.9204\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1472 - accuracy: 0.9418 - val_loss: 0.1250 - val_accuracy: 0.9376\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1365 - accuracy: 0.9461 - val_loss: 0.1817 - val_accuracy: 0.9197\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1348 - accuracy: 0.9480 - val_loss: 0.1752 - val_accuracy: 0.9300\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1278 - accuracy: 0.9505 - val_loss: 0.1272 - val_accuracy: 0.9450\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1265 - accuracy: 0.9519 - val_loss: 0.1590 - val_accuracy: 0.9317\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 6 19928\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_148 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_149 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_150 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_147 (TFOp  (None, 8, 45)       0           ['input_148[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_148 (TFOp  (None, 8, 45)       0           ['input_149[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_149 (TFOp  (None, 11, 45)      0           ['input_150[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_147 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_147[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_147[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_148 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_148[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_148[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_149 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_149[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_149[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_147 (Layer  (None, 8, 45)       90          ['multi_head_attention_147[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_148 (Layer  (None, 8, 45)       90          ['multi_head_attention_148[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_149 (Layer  (None, 11, 45)      90          ['multi_head_attention_149[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_245 (Dropout)          (None, 8, 45)        0           ['layer_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " dropout_246 (Dropout)          (None, 8, 45)        0           ['layer_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " dropout_247 (Dropout)          (None, 11, 45)       0           ['layer_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_147 (  (None, 45)          0           ['dropout_245[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_148 (  (None, 45)          0           ['dropout_246[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_149 (  (None, 45)          0           ['dropout_247[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_147[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_148[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_149[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_248 (Dropout)          (None, 135)          0           ['concatenate_49[0][0]']         \n",
      "                                                                                                  \n",
      " dense_98 (Dense)               (None, 128)          17408       ['dropout_248[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_249 (Dropout)          (None, 128)          0           ['dense_98[0][0]']               \n",
      "                                                                                                  \n",
      " dense_99 (Dense)               (None, 1)            129         ['dropout_249[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.4622 - accuracy: 0.7787 - val_loss: 0.3450 - val_accuracy: 0.8784\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2802 - accuracy: 0.8973 - val_loss: 0.1898 - val_accuracy: 0.9159\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2506 - accuracy: 0.9075 - val_loss: 0.2168 - val_accuracy: 0.9214\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2340 - accuracy: 0.9139 - val_loss: 0.1858 - val_accuracy: 0.9302\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2160 - accuracy: 0.9202 - val_loss: 0.1743 - val_accuracy: 0.9472\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2075 - accuracy: 0.9240 - val_loss: 0.1409 - val_accuracy: 0.9548\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2029 - accuracy: 0.9239 - val_loss: 0.1335 - val_accuracy: 0.9486\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1899 - accuracy: 0.9302 - val_loss: 0.1209 - val_accuracy: 0.9563\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1802 - accuracy: 0.9336 - val_loss: 0.1632 - val_accuracy: 0.9431\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1739 - accuracy: 0.9350 - val_loss: 0.3033 - val_accuracy: 0.9049\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_151 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_152 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_153 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_150 (TFOp  (None, 8, 45)       0           ['input_151[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_151 (TFOp  (None, 8, 45)       0           ['input_152[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_152 (TFOp  (None, 11, 45)      0           ['input_153[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_150 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_150[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_150[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_151 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_151[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_151[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_152 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_152[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_152[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_150 (Layer  (None, 8, 45)       90          ['multi_head_attention_150[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_151 (Layer  (None, 8, 45)       90          ['multi_head_attention_151[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_152 (Layer  (None, 11, 45)      90          ['multi_head_attention_152[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_250 (Dropout)          (None, 8, 45)        0           ['layer_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " dropout_251 (Dropout)          (None, 8, 45)        0           ['layer_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " dropout_252 (Dropout)          (None, 11, 45)       0           ['layer_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_150 (  (None, 45)          0           ['dropout_250[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_151 (  (None, 45)          0           ['dropout_251[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_152 (  (None, 45)          0           ['dropout_252[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_50 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_150[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_151[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_152[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_253 (Dropout)          (None, 135)          0           ['concatenate_50[0][0]']         \n",
      "                                                                                                  \n",
      " dense_100 (Dense)              (None, 128)          17408       ['dropout_253[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_254 (Dropout)          (None, 128)          0           ['dense_100[0][0]']              \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 1)            129         ['dropout_254[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.3488 - accuracy: 0.8310 - val_loss: 0.1730 - val_accuracy: 0.9372\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1752 - accuracy: 0.9275 - val_loss: 0.1760 - val_accuracy: 0.9450\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1505 - accuracy: 0.9386 - val_loss: 0.1404 - val_accuracy: 0.9589\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1454 - accuracy: 0.9410 - val_loss: 0.1470 - val_accuracy: 0.9587\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1375 - accuracy: 0.9471 - val_loss: 0.0804 - val_accuracy: 0.9795\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1296 - accuracy: 0.9501 - val_loss: 0.1018 - val_accuracy: 0.9768\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1234 - accuracy: 0.9520 - val_loss: 0.1540 - val_accuracy: 0.9515\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1186 - accuracy: 0.9542 - val_loss: 0.1202 - val_accuracy: 0.9618\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1098 - accuracy: 0.9579 - val_loss: 0.0804 - val_accuracy: 0.9751\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1030 - accuracy: 0.9596 - val_loss: 0.1011 - val_accuracy: 0.9670\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_154 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_155 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_156 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_153 (TFOp  (None, 8, 45)       0           ['input_154[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_154 (TFOp  (None, 8, 45)       0           ['input_155[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_155 (TFOp  (None, 11, 45)      0           ['input_156[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_153 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_153[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_153[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_154 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_154[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_154[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_155 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_155[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_155[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_153 (Layer  (None, 8, 45)       90          ['multi_head_attention_153[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_154 (Layer  (None, 8, 45)       90          ['multi_head_attention_154[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_155 (Layer  (None, 11, 45)      90          ['multi_head_attention_155[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_255 (Dropout)          (None, 8, 45)        0           ['layer_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " dropout_256 (Dropout)          (None, 8, 45)        0           ['layer_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " dropout_257 (Dropout)          (None, 11, 45)       0           ['layer_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_153 (  (None, 45)          0           ['dropout_255[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_154 (  (None, 45)          0           ['dropout_256[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_155 (  (None, 45)          0           ['dropout_257[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_51 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_153[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_154[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_155[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_258 (Dropout)          (None, 135)          0           ['concatenate_51[0][0]']         \n",
      "                                                                                                  \n",
      " dense_102 (Dense)              (None, 128)          17408       ['dropout_258[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_259 (Dropout)          (None, 128)          0           ['dense_102[0][0]']              \n",
      "                                                                                                  \n",
      " dense_103 (Dense)              (None, 1)            129         ['dropout_259[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.2468 - accuracy: 0.9149 - val_loss: 0.0798 - val_accuracy: 0.9897\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1557 - accuracy: 0.9662 - val_loss: 0.0838 - val_accuracy: 0.9919\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1470 - accuracy: 0.9666 - val_loss: 0.0743 - val_accuracy: 0.9926\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1384 - accuracy: 0.9678 - val_loss: 0.0644 - val_accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1311 - accuracy: 0.9679 - val_loss: 0.0740 - val_accuracy: 0.9869\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1261 - accuracy: 0.9681 - val_loss: 0.0736 - val_accuracy: 0.9943\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1201 - accuracy: 0.9681 - val_loss: 0.0582 - val_accuracy: 0.9904\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1104 - accuracy: 0.9684 - val_loss: 0.0806 - val_accuracy: 0.9845\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1052 - accuracy: 0.9683 - val_loss: 0.0581 - val_accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1001 - accuracy: 0.9685 - val_loss: 0.0672 - val_accuracy: 0.9933\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_157 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_158 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_159 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_156 (TFOp  (None, 8, 45)       0           ['input_157[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_157 (TFOp  (None, 8, 45)       0           ['input_158[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_158 (TFOp  (None, 11, 45)      0           ['input_159[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_156 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_156[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_156[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_157 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_157[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_157[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_158 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_158[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_158[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_156 (Layer  (None, 8, 45)       90          ['multi_head_attention_156[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_157 (Layer  (None, 8, 45)       90          ['multi_head_attention_157[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_158 (Layer  (None, 11, 45)      90          ['multi_head_attention_158[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_260 (Dropout)          (None, 8, 45)        0           ['layer_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " dropout_261 (Dropout)          (None, 8, 45)        0           ['layer_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " dropout_262 (Dropout)          (None, 11, 45)       0           ['layer_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_156 (  (None, 45)          0           ['dropout_260[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_157 (  (None, 45)          0           ['dropout_261[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_158 (  (None, 45)          0           ['dropout_262[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_52 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_156[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_157[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_158[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_263 (Dropout)          (None, 135)          0           ['concatenate_52[0][0]']         \n",
      "                                                                                                  \n",
      " dense_104 (Dense)              (None, 128)          17408       ['dropout_263[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_264 (Dropout)          (None, 128)          0           ['dense_104[0][0]']              \n",
      "                                                                                                  \n",
      " dense_105 (Dense)              (None, 1)            129         ['dropout_264[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.3768 - accuracy: 0.8393 - val_loss: 0.1647 - val_accuracy: 0.9381\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2592 - accuracy: 0.9051 - val_loss: 0.1207 - val_accuracy: 0.9427\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2334 - accuracy: 0.9137 - val_loss: 0.1830 - val_accuracy: 0.9223\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2151 - accuracy: 0.9203 - val_loss: 0.1960 - val_accuracy: 0.9188\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2047 - accuracy: 0.9239 - val_loss: 0.1421 - val_accuracy: 0.9400\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1959 - accuracy: 0.9267 - val_loss: 0.1338 - val_accuracy: 0.9462\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1829 - accuracy: 0.9322 - val_loss: 0.1324 - val_accuracy: 0.9474\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1764 - accuracy: 0.9364 - val_loss: 0.1799 - val_accuracy: 0.9321\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1694 - accuracy: 0.9379 - val_loss: 0.1791 - val_accuracy: 0.9269\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1671 - accuracy: 0.9391 - val_loss: 0.2167 - val_accuracy: 0.9247\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_160 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_161 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_162 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_159 (TFOp  (None, 8, 45)       0           ['input_160[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_160 (TFOp  (None, 8, 45)       0           ['input_161[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_161 (TFOp  (None, 11, 45)      0           ['input_162[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_159 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_159[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_159[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_160 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_160[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_160[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_161 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_161[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_161[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_159 (Layer  (None, 8, 45)       90          ['multi_head_attention_159[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_160 (Layer  (None, 8, 45)       90          ['multi_head_attention_160[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_161 (Layer  (None, 11, 45)      90          ['multi_head_attention_161[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_265 (Dropout)          (None, 8, 45)        0           ['layer_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " dropout_266 (Dropout)          (None, 8, 45)        0           ['layer_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " dropout_267 (Dropout)          (None, 11, 45)       0           ['layer_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_159 (  (None, 45)          0           ['dropout_265[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_160 (  (None, 45)          0           ['dropout_266[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_161 (  (None, 45)          0           ['dropout_267[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_53 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_159[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_160[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_161[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_268 (Dropout)          (None, 135)          0           ['concatenate_53[0][0]']         \n",
      "                                                                                                  \n",
      " dense_106 (Dense)              (None, 128)          17408       ['dropout_268[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_269 (Dropout)          (None, 128)          0           ['dense_106[0][0]']              \n",
      "                                                                                                  \n",
      " dense_107 (Dense)              (None, 1)            129         ['dropout_269[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.1374 - accuracy: 0.9470 - val_loss: 0.0644 - val_accuracy: 0.9778\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0327 - accuracy: 0.9911 - val_loss: 0.0431 - val_accuracy: 0.9895\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0242 - accuracy: 0.9943 - val_loss: 0.0454 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.0470 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.0453 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.0731 - val_accuracy: 0.9873\n",
      "Epoch 7/10\n",
      "429/938 [============>.................] - ETA: 9s - loss: 0.0140 - accuracy: 0.9964\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_55\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_166 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_167 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_168 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_165 (TFOp  (None, 8, 45)       0           ['input_166[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_166 (TFOp  (None, 8, 45)       0           ['input_167[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_167 (TFOp  (None, 11, 45)      0           ['input_168[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_165 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_165[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_165[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_166 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_166[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_166[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_167 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_167[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_167[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_165 (Layer  (None, 8, 45)       90          ['multi_head_attention_165[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_166 (Layer  (None, 8, 45)       90          ['multi_head_attention_166[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_167 (Layer  (None, 11, 45)      90          ['multi_head_attention_167[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_275 (Dropout)          (None, 8, 45)        0           ['layer_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " dropout_276 (Dropout)          (None, 8, 45)        0           ['layer_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " dropout_277 (Dropout)          (None, 11, 45)       0           ['layer_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_165 (  (None, 45)          0           ['dropout_275[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_166 (  (None, 45)          0           ['dropout_276[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_167 (  (None, 45)          0           ['dropout_277[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_55 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_165[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_166[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_167[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_278 (Dropout)          (None, 135)          0           ['concatenate_55[0][0]']         \n",
      "                                                                                                  \n",
      " dense_110 (Dense)              (None, 128)          17408       ['dropout_278[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_279 (Dropout)          (None, 128)          0           ['dense_110[0][0]']              \n",
      "                                                                                                  \n",
      " dense_111 (Dense)              (None, 1)            129         ['dropout_279[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.1948 - accuracy: 0.9303 - val_loss: 0.0484 - val_accuracy: 0.9907\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1162 - accuracy: 0.9698 - val_loss: 0.0379 - val_accuracy: 0.9926\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1138 - accuracy: 0.9704 - val_loss: 0.0342 - val_accuracy: 0.9931\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1083 - accuracy: 0.9706 - val_loss: 0.0460 - val_accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0967 - accuracy: 0.9730 - val_loss: 0.0342 - val_accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0926 - accuracy: 0.9733 - val_loss: 0.0312 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0944 - accuracy: 0.9729 - val_loss: 0.0352 - val_accuracy: 0.9943\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_169 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_170 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_171 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_168 (TFOp  (None, 8, 45)       0           ['input_169[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_169 (TFOp  (None, 8, 45)       0           ['input_170[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_170 (TFOp  (None, 11, 45)      0           ['input_171[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_168 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_168[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_168[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_169 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_169[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_169[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_170 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_170[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_170[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_168 (Layer  (None, 8, 45)       90          ['multi_head_attention_168[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_169 (Layer  (None, 8, 45)       90          ['multi_head_attention_169[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_170 (Layer  (None, 11, 45)      90          ['multi_head_attention_170[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_280 (Dropout)          (None, 8, 45)        0           ['layer_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " dropout_281 (Dropout)          (None, 8, 45)        0           ['layer_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " dropout_282 (Dropout)          (None, 11, 45)       0           ['layer_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_168 (  (None, 45)          0           ['dropout_280[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_169 (  (None, 45)          0           ['dropout_281[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_170 (  (None, 45)          0           ['dropout_282[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_56 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_168[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_169[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_170[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_283 (Dropout)          (None, 135)          0           ['concatenate_56[0][0]']         \n",
      "                                                                                                  \n",
      " dense_112 (Dense)              (None, 128)          17408       ['dropout_283[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_284 (Dropout)          (None, 128)          0           ['dense_112[0][0]']              \n",
      "                                                                                                  \n",
      " dense_113 (Dense)              (None, 1)            129         ['dropout_284[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.3113 - accuracy: 0.8685 - val_loss: 0.1915 - val_accuracy: 0.9161\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2109 - accuracy: 0.9217 - val_loss: 0.2010 - val_accuracy: 0.9216\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.1855 - accuracy: 0.9294 - val_loss: 0.1674 - val_accuracy: 0.9207\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.1677 - accuracy: 0.9346 - val_loss: 0.1530 - val_accuracy: 0.9252\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1564 - accuracy: 0.9382 - val_loss: 0.1730 - val_accuracy: 0.9266\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1482 - accuracy: 0.9412 - val_loss: 0.2548 - val_accuracy: 0.9082\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1444 - accuracy: 0.9431 - val_loss: 0.1609 - val_accuracy: 0.9274\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1373 - accuracy: 0.9458 - val_loss: 0.1781 - val_accuracy: 0.9286\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1331 - accuracy: 0.9474 - val_loss: 0.1298 - val_accuracy: 0.9379\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1318 - accuracy: 0.9480 - val_loss: 0.1727 - val_accuracy: 0.9295\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 7 19929\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_172 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_173 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_174 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_171 (TFOp  (None, 8, 45)       0           ['input_172[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_172 (TFOp  (None, 8, 45)       0           ['input_173[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_173 (TFOp  (None, 11, 45)      0           ['input_174[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_171 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_171[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_171[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_172 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_172[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_172[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_173 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_173[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_173[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_171 (Layer  (None, 8, 45)       90          ['multi_head_attention_171[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_172 (Layer  (None, 8, 45)       90          ['multi_head_attention_172[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_173 (Layer  (None, 11, 45)      90          ['multi_head_attention_173[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_285 (Dropout)          (None, 8, 45)        0           ['layer_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " dropout_286 (Dropout)          (None, 8, 45)        0           ['layer_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " dropout_287 (Dropout)          (None, 11, 45)       0           ['layer_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_171 (  (None, 45)          0           ['dropout_285[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_172 (  (None, 45)          0           ['dropout_286[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_173 (  (None, 45)          0           ['dropout_287[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_57 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_171[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_172[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_173[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_288 (Dropout)          (None, 135)          0           ['concatenate_57[0][0]']         \n",
      "                                                                                                  \n",
      " dense_114 (Dense)              (None, 128)          17408       ['dropout_288[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_289 (Dropout)          (None, 128)          0           ['dense_114[0][0]']              \n",
      "                                                                                                  \n",
      " dense_115 (Dense)              (None, 1)            129         ['dropout_289[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.4578 - accuracy: 0.7817 - val_loss: 0.2702 - val_accuracy: 0.8920\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2769 - accuracy: 0.8969 - val_loss: 0.2028 - val_accuracy: 0.9309\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2452 - accuracy: 0.9090 - val_loss: 0.1804 - val_accuracy: 0.9293\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2322 - accuracy: 0.9150 - val_loss: 0.2222 - val_accuracy: 0.9166\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2168 - accuracy: 0.9183 - val_loss: 0.1169 - val_accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2122 - accuracy: 0.9218 - val_loss: 0.1425 - val_accuracy: 0.9410\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2016 - accuracy: 0.9253 - val_loss: 0.1829 - val_accuracy: 0.9250\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1970 - accuracy: 0.9276 - val_loss: 0.1917 - val_accuracy: 0.9295\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1914 - accuracy: 0.9292 - val_loss: 0.1569 - val_accuracy: 0.9372\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1849 - accuracy: 0.9317 - val_loss: 0.2489 - val_accuracy: 0.9118\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_175 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_176 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_177 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_174 (TFOp  (None, 8, 45)       0           ['input_175[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_175 (TFOp  (None, 8, 45)       0           ['input_176[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_176 (TFOp  (None, 11, 45)      0           ['input_177[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_174 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_174[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_174[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_175 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_175[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_175[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_176 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_176[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_176[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_174 (Layer  (None, 8, 45)       90          ['multi_head_attention_174[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_175 (Layer  (None, 8, 45)       90          ['multi_head_attention_175[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_176 (Layer  (None, 11, 45)      90          ['multi_head_attention_176[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_290 (Dropout)          (None, 8, 45)        0           ['layer_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " dropout_291 (Dropout)          (None, 8, 45)        0           ['layer_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " dropout_292 (Dropout)          (None, 11, 45)       0           ['layer_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_174 (  (None, 45)          0           ['dropout_290[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_175 (  (None, 45)          0           ['dropout_291[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_176 (  (None, 45)          0           ['dropout_292[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_58 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_174[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_175[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_176[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_293 (Dropout)          (None, 135)          0           ['concatenate_58[0][0]']         \n",
      "                                                                                                  \n",
      " dense_116 (Dense)              (None, 128)          17408       ['dropout_293[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_294 (Dropout)          (None, 128)          0           ['dense_116[0][0]']              \n",
      "                                                                                                  \n",
      " dense_117 (Dense)              (None, 1)            129         ['dropout_294[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.3121 - accuracy: 0.8509 - val_loss: 0.1324 - val_accuracy: 0.9601\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.1576 - accuracy: 0.9378 - val_loss: 0.1477 - val_accuracy: 0.9608\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1452 - accuracy: 0.9443 - val_loss: 0.1308 - val_accuracy: 0.9577\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1298 - accuracy: 0.9498 - val_loss: 0.2156 - val_accuracy: 0.8996\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1252 - accuracy: 0.9509 - val_loss: 0.1442 - val_accuracy: 0.9424\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1173 - accuracy: 0.9557 - val_loss: 0.1095 - val_accuracy: 0.9644\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1098 - accuracy: 0.9584 - val_loss: 0.1041 - val_accuracy: 0.9699\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1031 - accuracy: 0.9613 - val_loss: 0.0980 - val_accuracy: 0.9689\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1008 - accuracy: 0.9631 - val_loss: 0.1219 - val_accuracy: 0.9544\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0947 - accuracy: 0.9651 - val_loss: 0.1258 - val_accuracy: 0.9565\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_178 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_179 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_180 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_177 (TFOp  (None, 8, 45)       0           ['input_178[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_178 (TFOp  (None, 8, 45)       0           ['input_179[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_179 (TFOp  (None, 11, 45)      0           ['input_180[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_177 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_177[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_177[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_178 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_178[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_178[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_179 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_179[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_179[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_177 (Layer  (None, 8, 45)       90          ['multi_head_attention_177[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_178 (Layer  (None, 8, 45)       90          ['multi_head_attention_178[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_179 (Layer  (None, 11, 45)      90          ['multi_head_attention_179[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_295 (Dropout)          (None, 8, 45)        0           ['layer_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " dropout_296 (Dropout)          (None, 8, 45)        0           ['layer_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " dropout_297 (Dropout)          (None, 11, 45)       0           ['layer_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_177 (  (None, 45)          0           ['dropout_295[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_178 (  (None, 45)          0           ['dropout_296[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_179 (  (None, 45)          0           ['dropout_297[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_59 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_177[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_178[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_179[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_298 (Dropout)          (None, 135)          0           ['concatenate_59[0][0]']         \n",
      "                                                                                                  \n",
      " dense_118 (Dense)              (None, 128)          17408       ['dropout_298[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_299 (Dropout)          (None, 128)          0           ['dense_118[0][0]']              \n",
      "                                                                                                  \n",
      " dense_119 (Dense)              (None, 1)            129         ['dropout_299[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.2618 - accuracy: 0.9019 - val_loss: 0.0516 - val_accuracy: 0.9931\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1433 - accuracy: 0.9662 - val_loss: 0.0555 - val_accuracy: 0.9940\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1319 - accuracy: 0.9674 - val_loss: 0.0570 - val_accuracy: 0.9943\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1265 - accuracy: 0.9675 - val_loss: 0.0458 - val_accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1221 - accuracy: 0.9682 - val_loss: 0.0641 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1152 - accuracy: 0.9679 - val_loss: 0.0662 - val_accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1090 - accuracy: 0.9687 - val_loss: 0.0350 - val_accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1045 - accuracy: 0.9693 - val_loss: 0.0449 - val_accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1037 - accuracy: 0.9686 - val_loss: 0.0553 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0982 - accuracy: 0.9692 - val_loss: 0.0439 - val_accuracy: 0.9945\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_181 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_182 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_183 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_180 (TFOp  (None, 8, 45)       0           ['input_181[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_181 (TFOp  (None, 8, 45)       0           ['input_182[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_182 (TFOp  (None, 11, 45)      0           ['input_183[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_180 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_180[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_180[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_181 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_181[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_181[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_182 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_182[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_182[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_180 (Layer  (None, 8, 45)       90          ['multi_head_attention_180[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_181 (Layer  (None, 8, 45)       90          ['multi_head_attention_181[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_182 (Layer  (None, 11, 45)      90          ['multi_head_attention_182[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_300 (Dropout)          (None, 8, 45)        0           ['layer_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " dropout_301 (Dropout)          (None, 8, 45)        0           ['layer_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " dropout_302 (Dropout)          (None, 11, 45)       0           ['layer_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_180 (  (None, 45)          0           ['dropout_300[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_181 (  (None, 45)          0           ['dropout_301[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_182 (  (None, 45)          0           ['dropout_302[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_60 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_180[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_181[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_182[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_303 (Dropout)          (None, 135)          0           ['concatenate_60[0][0]']         \n",
      "                                                                                                  \n",
      " dense_120 (Dense)              (None, 128)          17408       ['dropout_303[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_304 (Dropout)          (None, 128)          0           ['dense_120[0][0]']              \n",
      "                                                                                                  \n",
      " dense_121 (Dense)              (None, 1)            129         ['dropout_304[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.3617 - accuracy: 0.8455 - val_loss: 0.1549 - val_accuracy: 0.9422\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2439 - accuracy: 0.9141 - val_loss: 0.1706 - val_accuracy: 0.9245\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2201 - accuracy: 0.9207 - val_loss: 0.1431 - val_accuracy: 0.9352\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2088 - accuracy: 0.9217 - val_loss: 0.1976 - val_accuracy: 0.9288\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1945 - accuracy: 0.9255 - val_loss: 0.1516 - val_accuracy: 0.9386\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1834 - accuracy: 0.9295 - val_loss: 0.1222 - val_accuracy: 0.9453\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1745 - accuracy: 0.9342 - val_loss: 0.1611 - val_accuracy: 0.9398\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1644 - accuracy: 0.9371 - val_loss: 0.1586 - val_accuracy: 0.9319\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1563 - accuracy: 0.9405 - val_loss: 0.1364 - val_accuracy: 0.9379\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1514 - accuracy: 0.9412 - val_loss: 0.1409 - val_accuracy: 0.9360\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_61\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_184 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_185 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_186 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_183 (TFOp  (None, 8, 45)       0           ['input_184[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_184 (TFOp  (None, 8, 45)       0           ['input_185[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_185 (TFOp  (None, 11, 45)      0           ['input_186[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_183 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_183[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_183[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_184 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_184[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_184[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_185 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_185[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_185[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_183 (Layer  (None, 8, 45)       90          ['multi_head_attention_183[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_184 (Layer  (None, 8, 45)       90          ['multi_head_attention_184[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_185 (Layer  (None, 11, 45)      90          ['multi_head_attention_185[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_305 (Dropout)          (None, 8, 45)        0           ['layer_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " dropout_306 (Dropout)          (None, 8, 45)        0           ['layer_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " dropout_307 (Dropout)          (None, 11, 45)       0           ['layer_normalization_185[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_183 (  (None, 45)          0           ['dropout_305[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_184 (  (None, 45)          0           ['dropout_306[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_185 (  (None, 45)          0           ['dropout_307[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_61 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_183[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_184[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_185[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_308 (Dropout)          (None, 135)          0           ['concatenate_61[0][0]']         \n",
      "                                                                                                  \n",
      " dense_122 (Dense)              (None, 128)          17408       ['dropout_308[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_309 (Dropout)          (None, 128)          0           ['dense_122[0][0]']              \n",
      "                                                                                                  \n",
      " dense_123 (Dense)              (None, 1)            129         ['dropout_309[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.1271 - accuracy: 0.9453 - val_loss: 0.1111 - val_accuracy: 0.9725\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0188 - accuracy: 0.9965 - val_loss: 0.0173 - val_accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 0.0114 - val_accuracy: 0.9978\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0201 - accuracy: 0.9957 - val_loss: 0.0128 - val_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.0141 - val_accuracy: 0.9962\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0997 - accuracy: 0.9733 - val_loss: 0.0799 - val_accuracy: 0.9797\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0992 - accuracy: 0.9739 - val_loss: 0.0714 - val_accuracy: 0.9849\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.0974 - accuracy: 0.9735 - val_loss: 0.0749 - val_accuracy: 0.9830\n",
      "Epoch 7/10\n",
      "936/938 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9746\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_64\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_193 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_194 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_195 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_192 (TFOp  (None, 8, 45)       0           ['input_193[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_193 (TFOp  (None, 8, 45)       0           ['input_194[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_194 (TFOp  (None, 11, 45)      0           ['input_195[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_192 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_192[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_192[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_193 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_193[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_193[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_194 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_194[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_194[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_192 (Layer  (None, 8, 45)       90          ['multi_head_attention_192[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_193 (Layer  (None, 8, 45)       90          ['multi_head_attention_193[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_194 (Layer  (None, 11, 45)      90          ['multi_head_attention_194[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_320 (Dropout)          (None, 8, 45)        0           ['layer_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " dropout_321 (Dropout)          (None, 8, 45)        0           ['layer_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " dropout_322 (Dropout)          (None, 11, 45)       0           ['layer_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_192 (  (None, 45)          0           ['dropout_320[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_193 (  (None, 45)          0           ['dropout_321[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_194 (  (None, 45)          0           ['dropout_322[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_64 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_192[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_193[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_194[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_323 (Dropout)          (None, 135)          0           ['concatenate_64[0][0]']         \n",
      "                                                                                                  \n",
      " dense_128 (Dense)              (None, 128)          17408       ['dropout_323[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_324 (Dropout)          (None, 128)          0           ['dense_128[0][0]']              \n",
      "                                                                                                  \n",
      " dense_129 (Dense)              (None, 1)            129         ['dropout_324[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3157 - accuracy: 0.8663 - val_loss: 0.2048 - val_accuracy: 0.8956\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2012 - accuracy: 0.9249 - val_loss: 0.1774 - val_accuracy: 0.8939\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1722 - accuracy: 0.9328 - val_loss: 0.2153 - val_accuracy: 0.9142\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1619 - accuracy: 0.9363 - val_loss: 0.1505 - val_accuracy: 0.9262\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.1544 - accuracy: 0.9401 - val_loss: 0.1195 - val_accuracy: 0.9395\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1464 - accuracy: 0.9413 - val_loss: 0.1654 - val_accuracy: 0.9276\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1426 - accuracy: 0.9438 - val_loss: 0.1240 - val_accuracy: 0.9415\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1387 - accuracy: 0.9443 - val_loss: 0.1873 - val_accuracy: 0.9290\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.1348 - accuracy: 0.9463 - val_loss: 0.1357 - val_accuracy: 0.9391\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1290 - accuracy: 0.9494 - val_loss: 0.1237 - val_accuracy: 0.9460\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 8 19930\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_65\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_196 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_197 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_198 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_195 (TFOp  (None, 8, 45)       0           ['input_196[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_196 (TFOp  (None, 8, 45)       0           ['input_197[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_197 (TFOp  (None, 11, 45)      0           ['input_198[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_195 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_195[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_195[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_196 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_196[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_196[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_197 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_197[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_197[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_195 (Layer  (None, 8, 45)       90          ['multi_head_attention_195[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_196 (Layer  (None, 8, 45)       90          ['multi_head_attention_196[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_197 (Layer  (None, 11, 45)      90          ['multi_head_attention_197[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_325 (Dropout)          (None, 8, 45)        0           ['layer_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " dropout_326 (Dropout)          (None, 8, 45)        0           ['layer_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " dropout_327 (Dropout)          (None, 11, 45)       0           ['layer_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_195 (  (None, 45)          0           ['dropout_325[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_196 (  (None, 45)          0           ['dropout_326[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_197 (  (None, 45)          0           ['dropout_327[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_65 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_195[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_196[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_197[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_328 (Dropout)          (None, 135)          0           ['concatenate_65[0][0]']         \n",
      "                                                                                                  \n",
      " dense_130 (Dense)              (None, 128)          17408       ['dropout_328[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_329 (Dropout)          (None, 128)          0           ['dense_130[0][0]']              \n",
      "                                                                                                  \n",
      " dense_131 (Dense)              (None, 1)            129         ['dropout_329[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.4486 - accuracy: 0.7859 - val_loss: 0.3471 - val_accuracy: 0.8886\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2781 - accuracy: 0.8949 - val_loss: 0.0971 - val_accuracy: 0.9601\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2492 - accuracy: 0.9070 - val_loss: 0.1608 - val_accuracy: 0.9381\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2329 - accuracy: 0.9140 - val_loss: 0.2309 - val_accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2140 - accuracy: 0.9208 - val_loss: 0.1878 - val_accuracy: 0.9412\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2075 - accuracy: 0.9221 - val_loss: 0.1573 - val_accuracy: 0.9395\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1953 - accuracy: 0.9281 - val_loss: 0.1163 - val_accuracy: 0.9577\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1929 - accuracy: 0.9296 - val_loss: 0.1264 - val_accuracy: 0.9527\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1832 - accuracy: 0.9326 - val_loss: 0.1658 - val_accuracy: 0.9352\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1809 - accuracy: 0.9342 - val_loss: 0.1300 - val_accuracy: 0.9505\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_66\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_199 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_200 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_201 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_198 (TFOp  (None, 8, 45)       0           ['input_199[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_199 (TFOp  (None, 8, 45)       0           ['input_200[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_200 (TFOp  (None, 11, 45)      0           ['input_201[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_198 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_198[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_198[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_199 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_199[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_199[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_200 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_200[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_200[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_198 (Layer  (None, 8, 45)       90          ['multi_head_attention_198[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_199 (Layer  (None, 8, 45)       90          ['multi_head_attention_199[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_200 (Layer  (None, 11, 45)      90          ['multi_head_attention_200[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_330 (Dropout)          (None, 8, 45)        0           ['layer_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " dropout_331 (Dropout)          (None, 8, 45)        0           ['layer_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " dropout_332 (Dropout)          (None, 11, 45)       0           ['layer_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_198 (  (None, 45)          0           ['dropout_330[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_199 (  (None, 45)          0           ['dropout_331[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_200 (  (None, 45)          0           ['dropout_332[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_66 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_198[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_199[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_200[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_333 (Dropout)          (None, 135)          0           ['concatenate_66[0][0]']         \n",
      "                                                                                                  \n",
      " dense_132 (Dense)              (None, 128)          17408       ['dropout_333[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_334 (Dropout)          (None, 128)          0           ['dense_132[0][0]']              \n",
      "                                                                                                  \n",
      " dense_133 (Dense)              (None, 1)            129         ['dropout_334[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.3118 - accuracy: 0.8507 - val_loss: 0.1134 - val_accuracy: 0.9654\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1716 - accuracy: 0.9308 - val_loss: 0.1105 - val_accuracy: 0.9646\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1542 - accuracy: 0.9369 - val_loss: 0.0722 - val_accuracy: 0.9809\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1455 - accuracy: 0.9461 - val_loss: 0.1128 - val_accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1333 - accuracy: 0.9500 - val_loss: 0.2071 - val_accuracy: 0.9102\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1236 - accuracy: 0.9523 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1166 - accuracy: 0.9564 - val_loss: 0.0954 - val_accuracy: 0.9728\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1167 - accuracy: 0.9555 - val_loss: 0.1029 - val_accuracy: 0.9697\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1083 - accuracy: 0.9591 - val_loss: 0.0753 - val_accuracy: 0.9766\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1051 - accuracy: 0.9600 - val_loss: 0.1897 - val_accuracy: 0.9259\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_67\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_202 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_203 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_204 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_201 (TFOp  (None, 8, 45)       0           ['input_202[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_202 (TFOp  (None, 8, 45)       0           ['input_203[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_203 (TFOp  (None, 11, 45)      0           ['input_204[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_201 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_201[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_201[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_202 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_202[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_202[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_203 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_203[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_203[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_201 (Layer  (None, 8, 45)       90          ['multi_head_attention_201[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_202 (Layer  (None, 8, 45)       90          ['multi_head_attention_202[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_203 (Layer  (None, 11, 45)      90          ['multi_head_attention_203[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_335 (Dropout)          (None, 8, 45)        0           ['layer_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " dropout_336 (Dropout)          (None, 8, 45)        0           ['layer_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " dropout_337 (Dropout)          (None, 11, 45)       0           ['layer_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_201 (  (None, 45)          0           ['dropout_335[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_202 (  (None, 45)          0           ['dropout_336[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_203 (  (None, 45)          0           ['dropout_337[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_67 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_201[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_202[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_203[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_338 (Dropout)          (None, 135)          0           ['concatenate_67[0][0]']         \n",
      "                                                                                                  \n",
      " dense_134 (Dense)              (None, 128)          17408       ['dropout_338[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_339 (Dropout)          (None, 128)          0           ['dense_134[0][0]']              \n",
      "                                                                                                  \n",
      " dense_135 (Dense)              (None, 1)            129         ['dropout_339[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.2404 - accuracy: 0.9120 - val_loss: 0.0736 - val_accuracy: 0.9909\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1372 - accuracy: 0.9669 - val_loss: 0.0470 - val_accuracy: 0.9919\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1275 - accuracy: 0.9684 - val_loss: 0.0813 - val_accuracy: 0.9926\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1206 - accuracy: 0.9692 - val_loss: 0.0747 - val_accuracy: 0.9926\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1605 - accuracy: 0.9398 - val_loss: 0.1218 - val_accuracy: 0.9568\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_69\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_208 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_209 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_210 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_207 (TFOp  (None, 8, 45)       0           ['input_208[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_208 (TFOp  (None, 8, 45)       0           ['input_209[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_209 (TFOp  (None, 11, 45)      0           ['input_210[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_207 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_207[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_207[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_208 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_208[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_208[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_209 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_209[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_209[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_207 (Layer  (None, 8, 45)       90          ['multi_head_attention_207[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_208 (Layer  (None, 8, 45)       90          ['multi_head_attention_208[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_209 (Layer  (None, 11, 45)      90          ['multi_head_attention_209[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_345 (Dropout)          (None, 8, 45)        0           ['layer_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " dropout_346 (Dropout)          (None, 8, 45)        0           ['layer_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " dropout_347 (Dropout)          (None, 11, 45)       0           ['layer_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_207 (  (None, 45)          0           ['dropout_345[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_208 (  (None, 45)          0           ['dropout_346[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_209 (  (None, 45)          0           ['dropout_347[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_69 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_207[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_208[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_209[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_348 (Dropout)          (None, 135)          0           ['concatenate_69[0][0]']         \n",
      "                                                                                                  \n",
      " dense_138 (Dense)              (None, 128)          17408       ['dropout_348[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_349 (Dropout)          (None, 128)          0           ['dense_138[0][0]']              \n",
      "                                                                                                  \n",
      " dense_139 (Dense)              (None, 1)            129         ['dropout_349[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.1496 - accuracy: 0.9348 - val_loss: 0.0400 - val_accuracy: 0.9871\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0384 - accuracy: 0.9899 - val_loss: 0.0461 - val_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0251 - accuracy: 0.9937 - val_loss: 0.0221 - val_accuracy: 0.9919\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.0270 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.0330 - val_accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.0243 - val_accuracy: 0.9955\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_70\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_211 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_212 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_213 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_210 (TFOp  (None, 8, 45)       0           ['input_211[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_211 (TFOp  (None, 8, 45)       0           ['input_212[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_212 (TFOp  (None, 11, 45)      0           ['input_213[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_210 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_210[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_210[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_211 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_211[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_211[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_212 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_212[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_212[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_210 (Layer  (None, 8, 45)       90          ['multi_head_attention_210[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_211 (Layer  (None, 8, 45)       90          ['multi_head_attention_211[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_212 (Layer  (None, 11, 45)      90          ['multi_head_attention_212[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_350 (Dropout)          (None, 8, 45)        0           ['layer_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " dropout_351 (Dropout)          (None, 8, 45)        0           ['layer_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " dropout_352 (Dropout)          (None, 11, 45)       0           ['layer_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_210 (  (None, 45)          0           ['dropout_350[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_211 (  (None, 45)          0           ['dropout_351[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_212 (  (None, 45)          0           ['dropout_352[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_70 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_210[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_211[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_212[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_353 (Dropout)          (None, 135)          0           ['concatenate_70[0][0]']         \n",
      "                                                                                                  \n",
      " dense_140 (Dense)              (None, 128)          17408       ['dropout_353[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_354 (Dropout)          (None, 128)          0           ['dense_140[0][0]']              \n",
      "                                                                                                  \n",
      " dense_141 (Dense)              (None, 1)            129         ['dropout_354[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.1502 - accuracy: 0.9393 - val_loss: 0.0952 - val_accuracy: 0.9680\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0315 - accuracy: 0.9927 - val_loss: 0.0821 - val_accuracy: 0.9790\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0223 - accuracy: 0.9950 - val_loss: 0.0576 - val_accuracy: 0.9857\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.0521 - val_accuracy: 0.9857\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0198 - accuracy: 0.9954 - val_loss: 0.0504 - val_accuracy: 0.9840\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0206 - accuracy: 0.9952 - val_loss: 0.0538 - val_accuracy: 0.9873\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.0348 - val_accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0166 - accuracy: 0.9959 - val_loss: 0.0459 - val_accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0175 - accuracy: 0.9960 - val_loss: 0.0566 - val_accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0142 - accuracy: 0.9970 - val_loss: 0.0396 - val_accuracy: 0.9909\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_71\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_214 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_215 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_216 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_213 (TFOp  (None, 8, 45)       0           ['input_214[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_214 (TFOp  (None, 8, 45)       0           ['input_215[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_215 (TFOp  (None, 11, 45)      0           ['input_216[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_213 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_213[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_213[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_214 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_214[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_214[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_215 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_215[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_215[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_213 (Layer  (None, 8, 45)       90          ['multi_head_attention_213[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_214 (Layer  (None, 8, 45)       90          ['multi_head_attention_214[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_215 (Layer  (None, 11, 45)      90          ['multi_head_attention_215[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_355 (Dropout)          (None, 8, 45)        0           ['layer_normalization_213[0][0]']\n",
      "                                                                                                  \n",
      " dropout_356 (Dropout)          (None, 8, 45)        0           ['layer_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " dropout_357 (Dropout)          (None, 11, 45)       0           ['layer_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_213 (  (None, 45)          0           ['dropout_355[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_214 (  (None, 45)          0           ['dropout_356[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_215 (  (None, 45)          0           ['dropout_357[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_71 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_213[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_214[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_215[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_358 (Dropout)          (None, 135)          0           ['concatenate_71[0][0]']         \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 128)          17408       ['dropout_358[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_359 (Dropout)          (None, 128)          0           ['dense_142[0][0]']              \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 1)            129         ['dropout_359[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.1916 - accuracy: 0.9315 - val_loss: 0.0498 - val_accuracy: 0.9873\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1143 - accuracy: 0.9693 - val_loss: 0.0553 - val_accuracy: 0.9840\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1079 - accuracy: 0.9711 - val_loss: 0.0653 - val_accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1033 - accuracy: 0.9712 - val_loss: 0.0490 - val_accuracy: 0.9878\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1019 - accuracy: 0.9718 - val_loss: 0.0510 - val_accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0980 - accuracy: 0.9715 - val_loss: 0.0475 - val_accuracy: 0.9878\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0960 - accuracy: 0.9732 - val_loss: 0.0511 - val_accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.0919 - accuracy: 0.9731 - val_loss: 0.0482 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0901 - accuracy: 0.9729 - val_loss: 0.0521 - val_accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0863 - accuracy: 0.9739 - val_loss: 0.0608 - val_accuracy: 0.9864\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_72\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_217 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_218 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_219 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_216 (TFOp  (None, 8, 45)       0           ['input_217[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_217 (TFOp  (None, 8, 45)       0           ['input_218[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_218 (TFOp  (None, 11, 45)      0           ['input_219[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_216 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_216[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_216[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_217 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_217[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_217[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_218 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_218[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_218[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_216 (Layer  (None, 8, 45)       90          ['multi_head_attention_216[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_217 (Layer  (None, 8, 45)       90          ['multi_head_attention_217[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_218 (Layer  (None, 11, 45)      90          ['multi_head_attention_218[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_360 (Dropout)          (None, 8, 45)        0           ['layer_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " dropout_361 (Dropout)          (None, 8, 45)        0           ['layer_normalization_217[0][0]']\n",
      "                                                                                                  \n",
      " dropout_362 (Dropout)          (None, 11, 45)       0           ['layer_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_216 (  (None, 45)          0           ['dropout_360[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_217 (  (None, 45)          0           ['dropout_361[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_218 (  (None, 45)          0           ['dropout_362[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_72 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_216[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_217[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_218[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_363 (Dropout)          (None, 135)          0           ['concatenate_72[0][0]']         \n",
      "                                                                                                  \n",
      " dense_144 (Dense)              (None, 128)          17408       ['dropout_363[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_364 (Dropout)          (None, 128)          0           ['dense_144[0][0]']              \n",
      "                                                                                                  \n",
      " dense_145 (Dense)              (None, 1)            129         ['dropout_364[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.3164 - accuracy: 0.8650 - val_loss: 0.2585 - val_accuracy: 0.8253\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2017 - accuracy: 0.9257 - val_loss: 0.1566 - val_accuracy: 0.9283\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1776 - accuracy: 0.9310 - val_loss: 0.1396 - val_accuracy: 0.9362\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1633 - accuracy: 0.9361 - val_loss: 0.1341 - val_accuracy: 0.9374\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1518 - accuracy: 0.9396 - val_loss: 0.1485 - val_accuracy: 0.9379\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1435 - accuracy: 0.9442 - val_loss: 0.2023 - val_accuracy: 0.9288\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1356 - accuracy: 0.9469 - val_loss: 0.1540 - val_accuracy: 0.9391\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1292 - accuracy: 0.9499 - val_loss: 0.1756 - val_accuracy: 0.9374\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1280 - accuracy: 0.9499 - val_loss: 0.1964 - val_accuracy: 0.9228\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1259 - accuracy: 0.9525 - val_loss: 0.1640 - val_accuracy: 0.9443\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 9 19931\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_73\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_220 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_221 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_222 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_219 (TFOp  (None, 8, 45)       0           ['input_220[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_220 (TFOp  (None, 8, 45)       0           ['input_221[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_221 (TFOp  (None, 11, 45)      0           ['input_222[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_219 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_219[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_219[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_220 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_220[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_220[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_221 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_221[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_221[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_219 (Layer  (None, 8, 45)       90          ['multi_head_attention_219[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_220 (Layer  (None, 8, 45)       90          ['multi_head_attention_220[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_221 (Layer  (None, 11, 45)      90          ['multi_head_attention_221[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_365 (Dropout)          (None, 8, 45)        0           ['layer_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " dropout_366 (Dropout)          (None, 8, 45)        0           ['layer_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " dropout_367 (Dropout)          (None, 11, 45)       0           ['layer_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_219 (  (None, 45)          0           ['dropout_365[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_220 (  (None, 45)          0           ['dropout_366[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_221 (  (None, 45)          0           ['dropout_367[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_73 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_219[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_220[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_221[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_368 (Dropout)          (None, 135)          0           ['concatenate_73[0][0]']         \n",
      "                                                                                                  \n",
      " dense_146 (Dense)              (None, 128)          17408       ['dropout_368[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_369 (Dropout)          (None, 128)          0           ['dense_146[0][0]']              \n",
      "                                                                                                  \n",
      " dense_147 (Dense)              (None, 1)            129         ['dropout_369[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.4179 - accuracy: 0.8064 - val_loss: 0.2907 - val_accuracy: 0.9051\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2686 - accuracy: 0.9015 - val_loss: 0.1415 - val_accuracy: 0.9508\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1032 - accuracy: 0.9610 - val_loss: 0.0572 - val_accuracy: 0.9787\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0945 - accuracy: 0.9648 - val_loss: 0.0645 - val_accuracy: 0.9754\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_75\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_226 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_227 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_228 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_225 (TFOp  (None, 8, 45)       0           ['input_226[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_226 (TFOp  (None, 8, 45)       0           ['input_227[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_227 (TFOp  (None, 11, 45)      0           ['input_228[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_225 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_225[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_225[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_226 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_226[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_226[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_227 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_227[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_227[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_225 (Layer  (None, 8, 45)       90          ['multi_head_attention_225[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_226 (Layer  (None, 8, 45)       90          ['multi_head_attention_226[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_227 (Layer  (None, 11, 45)      90          ['multi_head_attention_227[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_375 (Dropout)          (None, 8, 45)        0           ['layer_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " dropout_376 (Dropout)          (None, 8, 45)        0           ['layer_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " dropout_377 (Dropout)          (None, 11, 45)       0           ['layer_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_225 (  (None, 45)          0           ['dropout_375[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_226 (  (None, 45)          0           ['dropout_376[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_227 (  (None, 45)          0           ['dropout_377[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_75 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_225[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_226[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_227[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_378 (Dropout)          (None, 135)          0           ['concatenate_75[0][0]']         \n",
      "                                                                                                  \n",
      " dense_150 (Dense)              (None, 128)          17408       ['dropout_378[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_379 (Dropout)          (None, 128)          0           ['dense_150[0][0]']              \n",
      "                                                                                                  \n",
      " dense_151 (Dense)              (None, 1)            129         ['dropout_379[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.2525 - accuracy: 0.9096 - val_loss: 0.0730 - val_accuracy: 0.9871\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1375 - accuracy: 0.9667 - val_loss: 0.0671 - val_accuracy: 0.9916\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1315 - accuracy: 0.9674 - val_loss: 0.0492 - val_accuracy: 0.9921\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1251 - accuracy: 0.9679 - val_loss: 0.0690 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "242/938 [======>.......................] - ETA: 11s - loss: 0.1189 - accuracy: 0.9703\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_76\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_229 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_230 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_231 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_228 (TFOp  (None, 8, 45)       0           ['input_229[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_229 (TFOp  (None, 8, 45)       0           ['input_230[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_230 (TFOp  (None, 11, 45)      0           ['input_231[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_228 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_228[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_228[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_229 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_229[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_229[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_230 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_230[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_230[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_228 (Layer  (None, 8, 45)       90          ['multi_head_attention_228[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_229 (Layer  (None, 8, 45)       90          ['multi_head_attention_229[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_230 (Layer  (None, 11, 45)      90          ['multi_head_attention_230[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_380 (Dropout)          (None, 8, 45)        0           ['layer_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " dropout_381 (Dropout)          (None, 8, 45)        0           ['layer_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " dropout_382 (Dropout)          (None, 11, 45)       0           ['layer_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_228 (  (None, 45)          0           ['dropout_380[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_229 (  (None, 45)          0           ['dropout_381[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_230 (  (None, 45)          0           ['dropout_382[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_76 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_228[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_229[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_230[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_383 (Dropout)          (None, 135)          0           ['concatenate_76[0][0]']         \n",
      "                                                                                                  \n",
      " dense_152 (Dense)              (None, 128)          17408       ['dropout_383[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_384 (Dropout)          (None, 128)          0           ['dense_152[0][0]']              \n",
      "                                                                                                  \n",
      " dense_153 (Dense)              (None, 1)            129         ['dropout_384[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3640 - accuracy: 0.8458 - val_loss: 0.2155 - val_accuracy: 0.9252\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2508 - accuracy: 0.9082 - val_loss: 0.2067 - val_accuracy: 0.9250\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2301 - accuracy: 0.9145 - val_loss: 0.1726 - val_accuracy: 0.9297\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2144 - accuracy: 0.9180 - val_loss: 0.1733 - val_accuracy: 0.9503\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2019 - accuracy: 0.9231 - val_loss: 0.1433 - val_accuracy: 0.9424\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1901 - accuracy: 0.9293 - val_loss: 0.1331 - val_accuracy: 0.9470\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1855 - accuracy: 0.9292 - val_loss: 0.1145 - val_accuracy: 0.9489\n",
      "Epoch 8/10\n",
      "120/938 [==>...........................] - ETA: 14s - loss: 0.1736 - accuracy: 0.9346\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_77\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_232 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_233 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_234 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_231 (TFOp  (None, 8, 45)       0           ['input_232[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_232 (TFOp  (None, 8, 45)       0           ['input_233[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_233 (TFOp  (None, 11, 45)      0           ['input_234[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_231 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_231[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_231[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_232 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_232[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_232[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_233 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_233[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_233[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_231 (Layer  (None, 8, 45)       90          ['multi_head_attention_231[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_232 (Layer  (None, 8, 45)       90          ['multi_head_attention_232[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_233 (Layer  (None, 11, 45)      90          ['multi_head_attention_233[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_385 (Dropout)          (None, 8, 45)        0           ['layer_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " dropout_386 (Dropout)          (None, 8, 45)        0           ['layer_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " dropout_387 (Dropout)          (None, 11, 45)       0           ['layer_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_231 (  (None, 45)          0           ['dropout_385[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_232 (  (None, 45)          0           ['dropout_386[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_233 (  (None, 45)          0           ['dropout_387[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_77 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_231[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_232[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_233[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_388 (Dropout)          (None, 135)          0           ['concatenate_77[0][0]']         \n",
      "                                                                                                  \n",
      " dense_154 (Dense)              (None, 128)          17408       ['dropout_388[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_389 (Dropout)          (None, 128)          0           ['dense_154[0][0]']              \n",
      "                                                                                                  \n",
      " dense_155 (Dense)              (None, 1)            129         ['dropout_389[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.1305 - accuracy: 0.9473 - val_loss: 0.0605 - val_accuracy: 0.9785\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0313 - accuracy: 0.9917 - val_loss: 0.0332 - val_accuracy: 0.9916\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 0.0273 - val_accuracy: 0.9919\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0182 - accuracy: 0.9959 - val_loss: 0.0389 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 0.0208 - val_accuracy: 0.9947\n",
      "Epoch 6/10\n",
      "728/938 [======================>.......] - ETA: 3s - loss: 0.0139 - accuracy: 0.9969TRAIN pc 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_78\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_235 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_236 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_237 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_234 (TFOp  (None, 8, 45)       0           ['input_235[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_235 (TFOp  (None, 8, 45)       0           ['input_236[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_236 (TFOp  (None, 11, 45)      0           ['input_237[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_234 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_234[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_234[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_235 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_235[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_235[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_236 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_236[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_236[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_234 (Layer  (None, 8, 45)       90          ['multi_head_attention_234[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_235 (Layer  (None, 8, 45)       90          ['multi_head_attention_235[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_236 (Layer  (None, 11, 45)      90          ['multi_head_attention_236[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_390 (Dropout)          (None, 8, 45)        0           ['layer_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " dropout_391 (Dropout)          (None, 8, 45)        0           ['layer_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " dropout_392 (Dropout)          (None, 11, 45)       0           ['layer_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_234 (  (None, 45)          0           ['dropout_390[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_235 (  (None, 45)          0           ['dropout_391[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_236 (  (None, 45)          0           ['dropout_392[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_78 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_234[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_235[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_236[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_393 (Dropout)          (None, 135)          0           ['concatenate_78[0][0]']         \n",
      "                                                                                                  \n",
      " dense_156 (Dense)              (None, 128)          17408       ['dropout_393[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_394 (Dropout)          (None, 128)          0           ['dense_156[0][0]']              \n",
      "                                                                                                  \n",
      " dense_157 (Dense)              (None, 1)            129         ['dropout_394[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.1427 - accuracy: 0.9451 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0315 - accuracy: 0.9933 - val_loss: 0.0160 - val_accuracy: 0.9971\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0278 - accuracy: 0.9949 - val_loss: 0.0224 - val_accuracy: 0.9950\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0261 - accuracy: 0.9947 - val_loss: 0.0466 - val_accuracy: 0.9885\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.0247 - accuracy: 0.9953 - val_loss: 0.0187 - val_accuracy: 0.9957\n",
      "Epoch 6/10\n",
      "469/938 [==============>...............] - ETA: 7s - loss: 0.0186 - accuracy: 0.9963\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_79\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_238 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_239 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_240 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_237 (TFOp  (None, 8, 45)       0           ['input_238[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_238 (TFOp  (None, 8, 45)       0           ['input_239[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_239 (TFOp  (None, 11, 45)      0           ['input_240[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_237 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_237[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_237[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_238 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_238[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_238[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_239 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_239[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_239[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_237 (Layer  (None, 8, 45)       90          ['multi_head_attention_237[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_238 (Layer  (None, 8, 45)       90          ['multi_head_attention_238[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_239 (Layer  (None, 11, 45)      90          ['multi_head_attention_239[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_395 (Dropout)          (None, 8, 45)        0           ['layer_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " dropout_396 (Dropout)          (None, 8, 45)        0           ['layer_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " dropout_397 (Dropout)          (None, 11, 45)       0           ['layer_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_237 (  (None, 45)          0           ['dropout_395[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_238 (  (None, 45)          0           ['dropout_396[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_239 (  (None, 45)          0           ['dropout_397[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_79 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_237[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_238[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_239[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_398 (Dropout)          (None, 135)          0           ['concatenate_79[0][0]']         \n",
      "                                                                                                  \n",
      " dense_158 (Dense)              (None, 128)          17408       ['dropout_398[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_399 (Dropout)          (None, 128)          0           ['dense_158[0][0]']              \n",
      "                                                                                                  \n",
      " dense_159 (Dense)              (None, 1)            129         ['dropout_399[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.2035 - accuracy: 0.9233 - val_loss: 0.0590 - val_accuracy: 0.9897\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1189 - accuracy: 0.9698 - val_loss: 0.0454 - val_accuracy: 0.9909\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1119 - accuracy: 0.9706 - val_loss: 0.0538 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1083 - accuracy: 0.9712 - val_loss: 0.0492 - val_accuracy: 0.9873\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1046 - accuracy: 0.9720 - val_loss: 0.0634 - val_accuracy: 0.9857\n",
      "Epoch 6/10\n",
      "337/938 [=========>....................] - ETA: 10s - loss: 0.1015 - accuracy: 0.9726\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_80\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_241 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_242 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_243 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_240 (TFOp  (None, 8, 45)       0           ['input_241[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_241 (TFOp  (None, 8, 45)       0           ['input_242[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_242 (TFOp  (None, 11, 45)      0           ['input_243[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_240 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_240[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_240[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_241 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_241[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_241[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_242 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_242[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_242[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_240 (Layer  (None, 8, 45)       90          ['multi_head_attention_240[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_241 (Layer  (None, 8, 45)       90          ['multi_head_attention_241[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_242 (Layer  (None, 11, 45)      90          ['multi_head_attention_242[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_400 (Dropout)          (None, 8, 45)        0           ['layer_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " dropout_401 (Dropout)          (None, 8, 45)        0           ['layer_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " dropout_402 (Dropout)          (None, 11, 45)       0           ['layer_normalization_242[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_240 (  (None, 45)          0           ['dropout_400[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_241 (  (None, 45)          0           ['dropout_401[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_242 (  (None, 45)          0           ['dropout_402[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_80 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_240[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_241[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_242[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_403 (Dropout)          (None, 135)          0           ['concatenate_80[0][0]']         \n",
      "                                                                                                  \n",
      " dense_160 (Dense)              (None, 128)          17408       ['dropout_403[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_404 (Dropout)          (None, 128)          0           ['dense_160[0][0]']              \n",
      "                                                                                                  \n",
      " dense_161 (Dense)              (None, 1)            129         ['dropout_404[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.3356 - accuracy: 0.8527 - val_loss: 0.1622 - val_accuracy: 0.9142\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.2081 - accuracy: 0.9252 - val_loss: 0.1539 - val_accuracy: 0.9250\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1876 - accuracy: 0.9305 - val_loss: 0.1094 - val_accuracy: 0.9341\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1672 - accuracy: 0.9361 - val_loss: 0.1806 - val_accuracy: 0.9145\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1570 - accuracy: 0.9407 - val_loss: 0.1357 - val_accuracy: 0.9391\n",
      "Epoch 6/10\n",
      " 32/938 [>.............................] - ETA: 15s - loss: 0.1680 - accuracy: 0.9404\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_81\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_244 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_245 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_246 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_243 (TFOp  (None, 8, 45)       0           ['input_244[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_244 (TFOp  (None, 8, 45)       0           ['input_245[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_245 (TFOp  (None, 11, 45)      0           ['input_246[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_243 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_243[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_243[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_244 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_244[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_244[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_245 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_245[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_245[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_243 (Layer  (None, 8, 45)       90          ['multi_head_attention_243[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_244 (Layer  (None, 8, 45)       90          ['multi_head_attention_244[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_245 (Layer  (None, 11, 45)      90          ['multi_head_attention_245[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_405 (Dropout)          (None, 8, 45)        0           ['layer_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " dropout_406 (Dropout)          (None, 8, 45)        0           ['layer_normalization_244[0][0]']\n",
      "                                                                                                  \n",
      " dropout_407 (Dropout)          (None, 11, 45)       0           ['layer_normalization_245[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_243 (  (None, 45)          0           ['dropout_405[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_244 (  (None, 45)          0           ['dropout_406[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_245 (  (None, 45)          0           ['dropout_407[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_81 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_243[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_244[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_245[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_408 (Dropout)          (None, 135)          0           ['concatenate_81[0][0]']         \n",
      "                                                                                                  \n",
      " dense_162 (Dense)              (None, 128)          17408       ['dropout_408[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_409 (Dropout)          (None, 128)          0           ['dense_162[0][0]']              \n",
      "                                                                                                  \n",
      " dense_163 (Dense)              (None, 1)            129         ['dropout_409[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.4219 - accuracy: 0.8097 - val_loss: 0.1556 - val_accuracy: 0.9515\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2834 - accuracy: 0.8916 - val_loss: 0.1301 - val_accuracy: 0.9632\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2543 - accuracy: 0.9058 - val_loss: 0.1275 - val_accuracy: 0.9627\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2372 - accuracy: 0.9128 - val_loss: 0.0779 - val_accuracy: 0.9694\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2283 - accuracy: 0.9162 - val_loss: 0.1544 - val_accuracy: 0.9448\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2135 - accuracy: 0.9211 - val_loss: 0.1346 - val_accuracy: 0.9481\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1789 - accuracy: 0.9341 - val_loss: 0.1867 - val_accuracy: 0.9266\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_247 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_248 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_249 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_246 (TFOp  (None, 8, 45)       0           ['input_247[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_247 (TFOp  (None, 8, 45)       0           ['input_248[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_248 (TFOp  (None, 11, 45)      0           ['input_249[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_246 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_246[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_246[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_247 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_247[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_247[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_248 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_248[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_248[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_246 (Layer  (None, 8, 45)       90          ['multi_head_attention_246[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_247 (Layer  (None, 8, 45)       90          ['multi_head_attention_247[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_248 (Layer  (None, 11, 45)      90          ['multi_head_attention_248[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_410 (Dropout)          (None, 8, 45)        0           ['layer_normalization_246[0][0]']\n",
      "                                                                                                  \n",
      " dropout_411 (Dropout)          (None, 8, 45)        0           ['layer_normalization_247[0][0]']\n",
      "                                                                                                  \n",
      " dropout_412 (Dropout)          (None, 11, 45)       0           ['layer_normalization_248[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_246 (  (None, 45)          0           ['dropout_410[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_247 (  (None, 45)          0           ['dropout_411[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_248 (  (None, 45)          0           ['dropout_412[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_82 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_246[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_247[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_248[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_413 (Dropout)          (None, 135)          0           ['concatenate_82[0][0]']         \n",
      "                                                                                                  \n",
      " dense_164 (Dense)              (None, 128)          17408       ['dropout_413[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_414 (Dropout)          (None, 128)          0           ['dense_164[0][0]']              \n",
      "                                                                                                  \n",
      " dense_165 (Dense)              (None, 1)            129         ['dropout_414[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.3209 - accuracy: 0.8449 - val_loss: 0.1146 - val_accuracy: 0.9634\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1740 - accuracy: 0.9248 - val_loss: 0.1797 - val_accuracy: 0.9216\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1548 - accuracy: 0.9351 - val_loss: 0.1626 - val_accuracy: 0.9350\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1408 - accuracy: 0.9413 - val_loss: 0.1262 - val_accuracy: 0.9541\n",
      "Epoch 5/10\n",
      "466/938 [=============>................] - ETA: 8s - loss: 0.1294 - accuracy: 0.9477\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_83\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_250 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_251 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_252 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_249 (TFOp  (None, 8, 45)       0           ['input_250[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_250 (TFOp  (None, 8, 45)       0           ['input_251[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_251 (TFOp  (None, 11, 45)      0           ['input_252[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_249 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_249[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_249[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_250 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_250[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_250[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_251 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_251[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_251[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_249 (Layer  (None, 8, 45)       90          ['multi_head_attention_249[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_250 (Layer  (None, 8, 45)       90          ['multi_head_attention_250[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_251 (Layer  (None, 11, 45)      90          ['multi_head_attention_251[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_415 (Dropout)          (None, 8, 45)        0           ['layer_normalization_249[0][0]']\n",
      "                                                                                                  \n",
      " dropout_416 (Dropout)          (None, 8, 45)        0           ['layer_normalization_250[0][0]']\n",
      "                                                                                                  \n",
      " dropout_417 (Dropout)          (None, 11, 45)       0           ['layer_normalization_251[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_249 (  (None, 45)          0           ['dropout_415[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_250 (  (None, 45)          0           ['dropout_416[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_251 (  (None, 45)          0           ['dropout_417[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_83 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_249[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_250[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_251[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_418 (Dropout)          (None, 135)          0           ['concatenate_83[0][0]']         \n",
      "                                                                                                  \n",
      " dense_166 (Dense)              (None, 128)          17408       ['dropout_418[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_419 (Dropout)          (None, 128)          0           ['dense_166[0][0]']              \n",
      "                                                                                                  \n",
      " dense_167 (Dense)              (None, 1)            129         ['dropout_419[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.2583 - accuracy: 0.9094 - val_loss: 0.0541 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1432 - accuracy: 0.9653 - val_loss: 0.0667 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1344 - accuracy: 0.9657 - val_loss: 0.0742 - val_accuracy: 0.9912\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.1273 - accuracy: 0.9665 - val_loss: 0.0447 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1245 - accuracy: 0.9666 - val_loss: 0.0523 - val_accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1016 - accuracy: 0.9673 - val_loss: 0.0717 - val_accuracy: 0.9909\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_84\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_253 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_254 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_255 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_252 (TFOp  (None, 8, 45)       0           ['input_253[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_253 (TFOp  (None, 8, 45)       0           ['input_254[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_254 (TFOp  (None, 11, 45)      0           ['input_255[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_252 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_252[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_252[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_253 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_253[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_253[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_254 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_254[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_254[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_252 (Layer  (None, 8, 45)       90          ['multi_head_attention_252[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_253 (Layer  (None, 8, 45)       90          ['multi_head_attention_253[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_254 (Layer  (None, 11, 45)      90          ['multi_head_attention_254[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_420 (Dropout)          (None, 8, 45)        0           ['layer_normalization_252[0][0]']\n",
      "                                                                                                  \n",
      " dropout_421 (Dropout)          (None, 8, 45)        0           ['layer_normalization_253[0][0]']\n",
      "                                                                                                  \n",
      " dropout_422 (Dropout)          (None, 11, 45)       0           ['layer_normalization_254[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_252 (  (None, 45)          0           ['dropout_420[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_253 (  (None, 45)          0           ['dropout_421[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_254 (  (None, 45)          0           ['dropout_422[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_84 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_252[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_253[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_254[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_423 (Dropout)          (None, 135)          0           ['concatenate_84[0][0]']         \n",
      "                                                                                                  \n",
      " dense_168 (Dense)              (None, 128)          17408       ['dropout_423[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_424 (Dropout)          (None, 128)          0           ['dense_168[0][0]']              \n",
      "                                                                                                  \n",
      " dense_169 (Dense)              (None, 1)            129         ['dropout_424[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.3666 - accuracy: 0.8422 - val_loss: 0.1821 - val_accuracy: 0.9216\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2444 - accuracy: 0.9116 - val_loss: 0.1253 - val_accuracy: 0.9314\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2248 - accuracy: 0.9182 - val_loss: 0.1745 - val_accuracy: 0.9290\n",
      "Epoch 4/10\n",
      "557/938 [================>.............] - ETA: 6s - loss: 0.2156 - accuracy: 0.9231\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_85\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_256 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_257 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_258 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_255 (TFOp  (None, 8, 45)       0           ['input_256[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_256 (TFOp  (None, 8, 45)       0           ['input_257[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_257 (TFOp  (None, 11, 45)      0           ['input_258[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_255 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_255[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_255[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_256 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_256[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_256[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_257 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_257[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_257[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_255 (Layer  (None, 8, 45)       90          ['multi_head_attention_255[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_256 (Layer  (None, 8, 45)       90          ['multi_head_attention_256[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_257 (Layer  (None, 11, 45)      90          ['multi_head_attention_257[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_425 (Dropout)          (None, 8, 45)        0           ['layer_normalization_255[0][0]']\n",
      "                                                                                                  \n",
      " dropout_426 (Dropout)          (None, 8, 45)        0           ['layer_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " dropout_427 (Dropout)          (None, 11, 45)       0           ['layer_normalization_257[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_255 (  (None, 45)          0           ['dropout_425[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_256 (  (None, 45)          0           ['dropout_426[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_257 (  (None, 45)          0           ['dropout_427[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_85 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_255[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_256[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_257[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_428 (Dropout)          (None, 135)          0           ['concatenate_85[0][0]']         \n",
      "                                                                                                  \n",
      " dense_170 (Dense)              (None, 128)          17408       ['dropout_428[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_429 (Dropout)          (None, 128)          0           ['dense_170[0][0]']              \n",
      "                                                                                                  \n",
      " dense_171 (Dense)              (None, 1)            129         ['dropout_429[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.1337 - accuracy: 0.9464 - val_loss: 0.0448 - val_accuracy: 0.9859\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0311 - accuracy: 0.9919 - val_loss: 0.0525 - val_accuracy: 0.9921\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.0488 - val_accuracy: 0.9914\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.0588 - val_accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.0673 - val_accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0920 - val_accuracy: 0.9933\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_86\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_259 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_260 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_261 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_258 (TFOp  (None, 8, 45)       0           ['input_259[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_259 (TFOp  (None, 8, 45)       0           ['input_260[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_260 (TFOp  (None, 11, 45)      0           ['input_261[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_258 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_258[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_258[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_259 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_259[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_259[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_260 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_260[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_260[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_258 (Layer  (None, 8, 45)       90          ['multi_head_attention_258[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_259 (Layer  (None, 8, 45)       90          ['multi_head_attention_259[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_260 (Layer  (None, 11, 45)      90          ['multi_head_attention_260[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_430 (Dropout)          (None, 8, 45)        0           ['layer_normalization_258[0][0]']\n",
      "                                                                                                  \n",
      " dropout_431 (Dropout)          (None, 8, 45)        0           ['layer_normalization_259[0][0]']\n",
      "                                                                                                  \n",
      " dropout_432 (Dropout)          (None, 11, 45)       0           ['layer_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_258 (  (None, 45)          0           ['dropout_430[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_259 (  (None, 45)          0           ['dropout_431[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_260 (  (None, 45)          0           ['dropout_432[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_86 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_258[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_259[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_260[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_433 (Dropout)          (None, 135)          0           ['concatenate_86[0][0]']         \n",
      "                                                                                                  \n",
      " dense_172 (Dense)              (None, 128)          17408       ['dropout_433[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_434 (Dropout)          (None, 128)          0           ['dense_172[0][0]']              \n",
      "                                                                                                  \n",
      " dense_173 (Dense)              (None, 1)            129         ['dropout_434[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.1302 - accuracy: 0.9515 - val_loss: 0.0398 - val_accuracy: 0.9926\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0284 - accuracy: 0.9937 - val_loss: 0.0303 - val_accuracy: 0.9940\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0255 - accuracy: 0.9949 - val_loss: 0.0177 - val_accuracy: 0.9962\n",
      "Epoch 4/10\n",
      "402/938 [===========>..................] - ETA: 9s - loss: 0.0190 - accuracy: 0.9965 \t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_87\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_262 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_263 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_264 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_261 (TFOp  (None, 8, 45)       0           ['input_262[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_262 (TFOp  (None, 8, 45)       0           ['input_263[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_263 (TFOp  (None, 11, 45)      0           ['input_264[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_261 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_261[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_261[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_262 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_262[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_262[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_263 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_263[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_263[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_261 (Layer  (None, 8, 45)       90          ['multi_head_attention_261[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_262 (Layer  (None, 8, 45)       90          ['multi_head_attention_262[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_263 (Layer  (None, 11, 45)      90          ['multi_head_attention_263[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_435 (Dropout)          (None, 8, 45)        0           ['layer_normalization_261[0][0]']\n",
      "                                                                                                  \n",
      " dropout_436 (Dropout)          (None, 8, 45)        0           ['layer_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " dropout_437 (Dropout)          (None, 11, 45)       0           ['layer_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_261 (  (None, 45)          0           ['dropout_435[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_262 (  (None, 45)          0           ['dropout_436[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_263 (  (None, 45)          0           ['dropout_437[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_87 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_261[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_262[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_263[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_438 (Dropout)          (None, 135)          0           ['concatenate_87[0][0]']         \n",
      "                                                                                                  \n",
      " dense_174 (Dense)              (None, 128)          17408       ['dropout_438[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_439 (Dropout)          (None, 128)          0           ['dense_174[0][0]']              \n",
      "                                                                                                  \n",
      " dense_175 (Dense)              (None, 1)            129         ['dropout_439[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.1875 - accuracy: 0.9328 - val_loss: 0.0698 - val_accuracy: 0.9771\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.1135 - accuracy: 0.9711 - val_loss: 0.0843 - val_accuracy: 0.9768\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1093 - accuracy: 0.9712 - val_loss: 0.0810 - val_accuracy: 0.9759\n",
      "Epoch 4/10\n",
      "894/938 [===========================>..] - ETA: 0s - loss: 0.1042 - accuracy: 0.9723\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_88\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_265 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_266 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_267 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_264 (TFOp  (None, 8, 45)       0           ['input_265[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_265 (TFOp  (None, 8, 45)       0           ['input_266[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_266 (TFOp  (None, 11, 45)      0           ['input_267[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_264 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_264[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_264[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_265 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_265[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_265[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_266 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_266[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_266[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_264 (Layer  (None, 8, 45)       90          ['multi_head_attention_264[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_265 (Layer  (None, 8, 45)       90          ['multi_head_attention_265[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_266 (Layer  (None, 11, 45)      90          ['multi_head_attention_266[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_440 (Dropout)          (None, 8, 45)        0           ['layer_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " dropout_441 (Dropout)          (None, 8, 45)        0           ['layer_normalization_265[0][0]']\n",
      "                                                                                                  \n",
      " dropout_442 (Dropout)          (None, 11, 45)       0           ['layer_normalization_266[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_264 (  (None, 45)          0           ['dropout_440[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_265 (  (None, 45)          0           ['dropout_441[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_266 (  (None, 45)          0           ['dropout_442[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_88 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_264[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_265[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_266[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_443 (Dropout)          (None, 135)          0           ['concatenate_88[0][0]']         \n",
      "                                                                                                  \n",
      " dense_176 (Dense)              (None, 128)          17408       ['dropout_443[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_444 (Dropout)          (None, 128)          0           ['dense_176[0][0]']              \n",
      "                                                                                                  \n",
      " dense_177 (Dense)              (None, 1)            129         ['dropout_444[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.3268 - accuracy: 0.8628 - val_loss: 0.1565 - val_accuracy: 0.9171\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.2093 - accuracy: 0.9219 - val_loss: 0.1282 - val_accuracy: 0.9317\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1822 - accuracy: 0.9300 - val_loss: 0.1137 - val_accuracy: 0.9345\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.1651 - accuracy: 0.9375 - val_loss: 0.1051 - val_accuracy: 0.9455\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1322 - accuracy: 0.9498 - val_loss: 0.1386 - val_accuracy: 0.9376\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1287 - accuracy: 0.9501 - val_loss: 0.1599 - val_accuracy: 0.9228\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 11 19933\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN toileting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_89\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_268 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_269 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_270 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_267 (TFOp  (None, 8, 45)       0           ['input_268[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_268 (TFOp  (None, 8, 45)       0           ['input_269[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_269 (TFOp  (None, 11, 45)      0           ['input_270[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_267 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_267[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_267[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_268 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_268[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_268[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_269 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_269[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_269[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_267 (Layer  (None, 8, 45)       90          ['multi_head_attention_267[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_268 (Layer  (None, 8, 45)       90          ['multi_head_attention_268[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_269 (Layer  (None, 11, 45)      90          ['multi_head_attention_269[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_445 (Dropout)          (None, 8, 45)        0           ['layer_normalization_267[0][0]']\n",
      "                                                                                                  \n",
      " dropout_446 (Dropout)          (None, 8, 45)        0           ['layer_normalization_268[0][0]']\n",
      "                                                                                                  \n",
      " dropout_447 (Dropout)          (None, 11, 45)       0           ['layer_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_267 (  (None, 45)          0           ['dropout_445[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_268 (  (None, 45)          0           ['dropout_446[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_269 (  (None, 45)          0           ['dropout_447[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_89 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_267[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_268[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_269[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_448 (Dropout)          (None, 135)          0           ['concatenate_89[0][0]']         \n",
      "                                                                                                  \n",
      " dense_178 (Dense)              (None, 128)          17408       ['dropout_448[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_449 (Dropout)          (None, 128)          0           ['dense_178[0][0]']              \n",
      "                                                                                                  \n",
      " dense_179 (Dense)              (None, 1)            129         ['dropout_449[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.4240 - accuracy: 0.8075 - val_loss: 0.2317 - val_accuracy: 0.9405\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2842 - accuracy: 0.8953 - val_loss: 0.1508 - val_accuracy: 0.9216\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2437 - accuracy: 0.9095 - val_loss: 0.1503 - val_accuracy: 0.9384\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2264 - accuracy: 0.9180 - val_loss: 0.1832 - val_accuracy: 0.9254\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1761 - accuracy: 0.9371 - val_loss: 0.1521 - val_accuracy: 0.9407\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1677 - accuracy: 0.9406 - val_loss: 0.2248 - val_accuracy: 0.9254\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1649 - accuracy: 0.9426 - val_loss: 0.1887 - val_accuracy: 0.9321\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN resting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_90\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_271 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_272 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_273 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_270 (TFOp  (None, 8, 45)       0           ['input_271[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_271 (TFOp  (None, 8, 45)       0           ['input_272[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_272 (TFOp  (None, 11, 45)      0           ['input_273[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_270 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_270[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_270[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_271 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_271[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_271[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_272 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_272[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_272[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_270 (Layer  (None, 8, 45)       90          ['multi_head_attention_270[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_271 (Layer  (None, 8, 45)       90          ['multi_head_attention_271[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_272 (Layer  (None, 11, 45)      90          ['multi_head_attention_272[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_450 (Dropout)          (None, 8, 45)        0           ['layer_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " dropout_451 (Dropout)          (None, 8, 45)        0           ['layer_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " dropout_452 (Dropout)          (None, 11, 45)       0           ['layer_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_270 (  (None, 45)          0           ['dropout_450[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_271 (  (None, 45)          0           ['dropout_451[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_272 (  (None, 45)          0           ['dropout_452[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_90 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_270[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_271[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_272[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_453 (Dropout)          (None, 135)          0           ['concatenate_90[0][0]']         \n",
      "                                                                                                  \n",
      " dense_180 (Dense)              (None, 128)          17408       ['dropout_453[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_454 (Dropout)          (None, 128)          0           ['dense_180[0][0]']              \n",
      "                                                                                                  \n",
      " dense_181 (Dense)              (None, 1)            129         ['dropout_454[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3206 - accuracy: 0.8496 - val_loss: 0.2182 - val_accuracy: 0.8487\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1697 - accuracy: 0.9268 - val_loss: 0.1358 - val_accuracy: 0.9756\n",
      "Epoch 3/10\n",
      "482/938 [==============>...............] - ETA: 7s - loss: 0.1526 - accuracy: 0.9343\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN exit 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_91\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_274 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_275 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_276 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_273 (TFOp  (None, 8, 45)       0           ['input_274[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_274 (TFOp  (None, 8, 45)       0           ['input_275[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_275 (TFOp  (None, 11, 45)      0           ['input_276[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_273 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_273[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_273[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_274 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_274[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_274[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_275 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_275[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_275[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_273 (Layer  (None, 8, 45)       90          ['multi_head_attention_273[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_274 (Layer  (None, 8, 45)       90          ['multi_head_attention_274[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_275 (Layer  (None, 11, 45)      90          ['multi_head_attention_275[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_455 (Dropout)          (None, 8, 45)        0           ['layer_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " dropout_456 (Dropout)          (None, 8, 45)        0           ['layer_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " dropout_457 (Dropout)          (None, 11, 45)       0           ['layer_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_273 (  (None, 45)          0           ['dropout_455[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_274 (  (None, 45)          0           ['dropout_456[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_275 (  (None, 45)          0           ['dropout_457[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_91 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_273[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_274[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_275[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_458 (Dropout)          (None, 135)          0           ['concatenate_91[0][0]']         \n",
      "                                                                                                  \n",
      " dense_182 (Dense)              (None, 128)          17408       ['dropout_458[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_459 (Dropout)          (None, 128)          0           ['dense_182[0][0]']              \n",
      "                                                                                                  \n",
      " dense_183 (Dense)              (None, 1)            129         ['dropout_459[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.2281 - accuracy: 0.9218 - val_loss: 0.0714 - val_accuracy: 0.9866\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1416 - accuracy: 0.9661 - val_loss: 0.0729 - val_accuracy: 0.9866\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1316 - accuracy: 0.9680 - val_loss: 0.0658 - val_accuracy: 0.9878\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1243 - accuracy: 0.9685 - val_loss: 0.0699 - val_accuracy: 0.9878\n",
      "Epoch 5/10\n",
      "484/938 [==============>...............] - ETA: 7s - loss: 0.1298 - accuracy: 0.9662\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN cooking 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_92\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_277 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_278 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_279 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_276 (TFOp  (None, 8, 45)       0           ['input_277[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_277 (TFOp  (None, 8, 45)       0           ['input_278[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_278 (TFOp  (None, 11, 45)      0           ['input_279[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_276 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_276[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_276[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_277 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_277[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_277[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_278 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_278[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_278[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_276 (Layer  (None, 8, 45)       90          ['multi_head_attention_276[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_277 (Layer  (None, 8, 45)       90          ['multi_head_attention_277[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_278 (Layer  (None, 11, 45)      90          ['multi_head_attention_278[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_460 (Dropout)          (None, 8, 45)        0           ['layer_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " dropout_461 (Dropout)          (None, 8, 45)        0           ['layer_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " dropout_462 (Dropout)          (None, 11, 45)       0           ['layer_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_276 (  (None, 45)          0           ['dropout_460[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_277 (  (None, 45)          0           ['dropout_461[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_278 (  (None, 45)          0           ['dropout_462[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_92 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_276[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_277[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_278[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_463 (Dropout)          (None, 135)          0           ['concatenate_92[0][0]']         \n",
      "                                                                                                  \n",
      " dense_184 (Dense)              (None, 128)          17408       ['dropout_463[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_464 (Dropout)          (None, 128)          0           ['dense_184[0][0]']              \n",
      "                                                                                                  \n",
      " dense_185 (Dense)              (None, 1)            129         ['dropout_464[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.3668 - accuracy: 0.8480 - val_loss: 0.1269 - val_accuracy: 0.9324\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2508 - accuracy: 0.9089 - val_loss: 0.2357 - val_accuracy: 0.8843\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2302 - accuracy: 0.9138 - val_loss: 0.1545 - val_accuracy: 0.9161\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2111 - accuracy: 0.9196 - val_loss: 0.2146 - val_accuracy: 0.8810\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1563 - accuracy: 0.9399 - val_loss: 0.1063 - val_accuracy: 0.9575\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN shower 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_93\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_280 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_281 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_282 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_279 (TFOp  (None, 8, 45)       0           ['input_280[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_280 (TFOp  (None, 8, 45)       0           ['input_281[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_281 (TFOp  (None, 11, 45)      0           ['input_282[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_279 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_279[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_279[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_280 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_280[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_280[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_281 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_281[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_281[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_279 (Layer  (None, 8, 45)       90          ['multi_head_attention_279[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_280 (Layer  (None, 8, 45)       90          ['multi_head_attention_280[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_281 (Layer  (None, 11, 45)      90          ['multi_head_attention_281[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_465 (Dropout)          (None, 8, 45)        0           ['layer_normalization_279[0][0]']\n",
      "                                                                                                  \n",
      " dropout_466 (Dropout)          (None, 8, 45)        0           ['layer_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " dropout_467 (Dropout)          (None, 11, 45)       0           ['layer_normalization_281[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_279 (  (None, 45)          0           ['dropout_465[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_280 (  (None, 45)          0           ['dropout_466[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_281 (  (None, 45)          0           ['dropout_467[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_93 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_279[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_280[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_281[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_468 (Dropout)          (None, 135)          0           ['concatenate_93[0][0]']         \n",
      "                                                                                                  \n",
      " dense_186 (Dense)              (None, 128)          17408       ['dropout_468[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_469 (Dropout)          (None, 128)          0           ['dense_186[0][0]']              \n",
      "                                                                                                  \n",
      " dense_187 (Dense)              (None, 1)            129         ['dropout_469[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.1498 - accuracy: 0.9440 - val_loss: 0.0354 - val_accuracy: 0.9859\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.0417 - accuracy: 0.9884 - val_loss: 0.0390 - val_accuracy: 0.9876\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0317 - accuracy: 0.9920 - val_loss: 0.0280 - val_accuracy: 0.9904\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.0144 - val_accuracy: 0.9957\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0118 - val_accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.0162 - val_accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 20ms/step - loss: 0.0112 - accuracy: 0.9975 - val_loss: 0.0170 - val_accuracy: 0.9947\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN pc 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_94\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_283 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_284 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_285 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_282 (TFOp  (None, 8, 45)       0           ['input_283[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_283 (TFOp  (None, 8, 45)       0           ['input_284[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_284 (TFOp  (None, 11, 45)      0           ['input_285[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_282 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_282[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_282[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_283 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_283[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_283[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_284 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_284[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_284[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_282 (Layer  (None, 8, 45)       90          ['multi_head_attention_282[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_283 (Layer  (None, 8, 45)       90          ['multi_head_attention_283[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_284 (Layer  (None, 11, 45)      90          ['multi_head_attention_284[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_470 (Dropout)          (None, 8, 45)        0           ['layer_normalization_282[0][0]']\n",
      "                                                                                                  \n",
      " dropout_471 (Dropout)          (None, 8, 45)        0           ['layer_normalization_283[0][0]']\n",
      "                                                                                                  \n",
      " dropout_472 (Dropout)          (None, 11, 45)       0           ['layer_normalization_284[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_282 (  (None, 45)          0           ['dropout_470[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_283 (  (None, 45)          0           ['dropout_471[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_284 (  (None, 45)          0           ['dropout_472[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_94 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_282[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_283[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_284[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_473 (Dropout)          (None, 135)          0           ['concatenate_94[0][0]']         \n",
      "                                                                                                  \n",
      " dense_188 (Dense)              (None, 128)          17408       ['dropout_473[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_474 (Dropout)          (None, 128)          0           ['dense_188[0][0]']              \n",
      "                                                                                                  \n",
      " dense_189 (Dense)              (None, 1)            129         ['dropout_474[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.1346 - accuracy: 0.9473 - val_loss: 0.0516 - val_accuracy: 0.9895\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0232 - accuracy: 0.9950 - val_loss: 0.0609 - val_accuracy: 0.9859\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0197 - accuracy: 0.9957 - val_loss: 0.0644 - val_accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0173 - accuracy: 0.9961 - val_loss: 0.0467 - val_accuracy: 0.9878\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN sleep 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_95\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_286 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_287 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_288 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_285 (TFOp  (None, 8, 45)       0           ['input_286[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_286 (TFOp  (None, 8, 45)       0           ['input_287[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_287 (TFOp  (None, 11, 45)      0           ['input_288[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_285 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_285[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_285[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_286 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_286[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_286[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_287 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_287[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_287[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_285 (Layer  (None, 8, 45)       90          ['multi_head_attention_285[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_286 (Layer  (None, 8, 45)       90          ['multi_head_attention_286[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_287 (Layer  (None, 11, 45)      90          ['multi_head_attention_287[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_475 (Dropout)          (None, 8, 45)        0           ['layer_normalization_285[0][0]']\n",
      "                                                                                                  \n",
      " dropout_476 (Dropout)          (None, 8, 45)        0           ['layer_normalization_286[0][0]']\n",
      "                                                                                                  \n",
      " dropout_477 (Dropout)          (None, 11, 45)       0           ['layer_normalization_287[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_285 (  (None, 45)          0           ['dropout_475[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_286 (  (None, 45)          0           ['dropout_476[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_287 (  (None, 45)          0           ['dropout_477[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_95 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_285[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_286[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_287[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_478 (Dropout)          (None, 135)          0           ['concatenate_95[0][0]']         \n",
      "                                                                                                  \n",
      " dense_190 (Dense)              (None, 128)          17408       ['dropout_478[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_479 (Dropout)          (None, 128)          0           ['dense_190[0][0]']              \n",
      "                                                                                                  \n",
      " dense_191 (Dense)              (None, 1)            129         ['dropout_479[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.2171 - accuracy: 0.9180 - val_loss: 0.0417 - val_accuracy: 0.9924\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1193 - accuracy: 0.9690 - val_loss: 0.0422 - val_accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1163 - accuracy: 0.9692 - val_loss: 0.0508 - val_accuracy: 0.9938\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1035 - accuracy: 0.9711 - val_loss: 0.0376 - val_accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1031 - accuracy: 0.9715 - val_loss: 0.0372 - val_accuracy: 0.9873\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1022 - accuracy: 0.9713 - val_loss: 0.0310 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0997 - accuracy: 0.9724 - val_loss: 0.0311 - val_accuracy: 0.9945\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_96\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_289 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_290 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_291 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_288 (TFOp  (None, 8, 45)       0           ['input_289[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_289 (TFOp  (None, 8, 45)       0           ['input_290[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_290 (TFOp  (None, 11, 45)      0           ['input_291[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_288 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_288[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_288[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_289 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_289[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_289[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_290 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_290[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_290[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_288 (Layer  (None, 8, 45)       90          ['multi_head_attention_288[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_289 (Layer  (None, 8, 45)       90          ['multi_head_attention_289[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_290 (Layer  (None, 11, 45)      90          ['multi_head_attention_290[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_480 (Dropout)          (None, 8, 45)        0           ['layer_normalization_288[0][0]']\n",
      "                                                                                                  \n",
      " dropout_481 (Dropout)          (None, 8, 45)        0           ['layer_normalization_289[0][0]']\n",
      "                                                                                                  \n",
      " dropout_482 (Dropout)          (None, 11, 45)       0           ['layer_normalization_290[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_288 (  (None, 45)          0           ['dropout_480[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_289 (  (None, 45)          0           ['dropout_481[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_290 (  (None, 45)          0           ['dropout_482[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_96 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_288[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_289[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_290[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_483 (Dropout)          (None, 135)          0           ['concatenate_96[0][0]']         \n",
      "                                                                                                  \n",
      " dense_192 (Dense)              (None, 128)          17408       ['dropout_483[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_484 (Dropout)          (None, 128)          0           ['dense_192[0][0]']              \n",
      "                                                                                                  \n",
      " dense_193 (Dense)              (None, 1)            129         ['dropout_484[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1267 - accuracy: 0.9496 - val_loss: 0.1158 - val_accuracy: 0.9496\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 12 19934\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN toileting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_97\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_292 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_293 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_294 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_291 (TFOp  (None, 8, 45)       0           ['input_292[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_292 (TFOp  (None, 8, 45)       0           ['input_293[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_293 (TFOp  (None, 11, 45)      0           ['input_294[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_291 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_291[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_291[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_292 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_292[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_292[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_293 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_293[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_293[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_291 (Layer  (None, 8, 45)       90          ['multi_head_attention_291[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_292 (Layer  (None, 8, 45)       90          ['multi_head_attention_292[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_293 (Layer  (None, 11, 45)      90          ['multi_head_attention_293[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_485 (Dropout)          (None, 8, 45)        0           ['layer_normalization_291[0][0]']\n",
      "                                                                                                  \n",
      " dropout_486 (Dropout)          (None, 8, 45)        0           ['layer_normalization_292[0][0]']\n",
      "                                                                                                  \n",
      " dropout_487 (Dropout)          (None, 11, 45)       0           ['layer_normalization_293[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_291 (  (None, 45)          0           ['dropout_485[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_292 (  (None, 45)          0           ['dropout_486[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_293 (  (None, 45)          0           ['dropout_487[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_97 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_291[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_292[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_293[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_488 (Dropout)          (None, 135)          0           ['concatenate_97[0][0]']         \n",
      "                                                                                                  \n",
      " dense_194 (Dense)              (None, 128)          17408       ['dropout_488[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_489 (Dropout)          (None, 128)          0           ['dense_194[0][0]']              \n",
      "                                                                                                  \n",
      " dense_195 (Dense)              (None, 1)            129         ['dropout_489[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.4367 - accuracy: 0.7941 - val_loss: 0.3865 - val_accuracy: 0.8509\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2891 - accuracy: 0.8919 - val_loss: 0.1388 - val_accuracy: 0.9503\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.2542 - accuracy: 0.9072 - val_loss: 0.1620 - val_accuracy: 0.9357\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.2346 - accuracy: 0.9157 - val_loss: 0.1038 - val_accuracy: 0.9601\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1891 - accuracy: 0.9335 - val_loss: 0.1649 - val_accuracy: 0.9398\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1802 - accuracy: 0.9340 - val_loss: 0.1231 - val_accuracy: 0.9522\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN resting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_98\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_295 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_296 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_297 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_294 (TFOp  (None, 8, 45)       0           ['input_295[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_295 (TFOp  (None, 8, 45)       0           ['input_296[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_296 (TFOp  (None, 11, 45)      0           ['input_297[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_294 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_294[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_294[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_295 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_295[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_295[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_296 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_296[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_296[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_294 (Layer  (None, 8, 45)       90          ['multi_head_attention_294[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_295 (Layer  (None, 8, 45)       90          ['multi_head_attention_295[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_296 (Layer  (None, 11, 45)      90          ['multi_head_attention_296[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_490 (Dropout)          (None, 8, 45)        0           ['layer_normalization_294[0][0]']\n",
      "                                                                                                  \n",
      " dropout_491 (Dropout)          (None, 8, 45)        0           ['layer_normalization_295[0][0]']\n",
      "                                                                                                  \n",
      " dropout_492 (Dropout)          (None, 11, 45)       0           ['layer_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_294 (  (None, 45)          0           ['dropout_490[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_295 (  (None, 45)          0           ['dropout_491[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_296 (  (None, 45)          0           ['dropout_492[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_98 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_294[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_295[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_296[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_493 (Dropout)          (None, 135)          0           ['concatenate_98[0][0]']         \n",
      "                                                                                                  \n",
      " dense_196 (Dense)              (None, 128)          17408       ['dropout_493[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_494 (Dropout)          (None, 128)          0           ['dense_196[0][0]']              \n",
      "                                                                                                  \n",
      " dense_197 (Dense)              (None, 1)            129         ['dropout_494[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.3329 - accuracy: 0.8319 - val_loss: 0.1100 - val_accuracy: 0.9646\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1717 - accuracy: 0.9247 - val_loss: 0.1388 - val_accuracy: 0.9145\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1026 - accuracy: 0.9591 - val_loss: 0.1100 - val_accuracy: 0.9498\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN exit 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_99\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_298 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_299 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_300 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_297 (TFOp  (None, 8, 45)       0           ['input_298[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_298 (TFOp  (None, 8, 45)       0           ['input_299[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_299 (TFOp  (None, 11, 45)      0           ['input_300[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_297 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_297[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_297[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_298 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_298[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_298[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_299 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_299[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_299[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_297 (Layer  (None, 8, 45)       90          ['multi_head_attention_297[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_298 (Layer  (None, 8, 45)       90          ['multi_head_attention_298[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_299 (Layer  (None, 11, 45)      90          ['multi_head_attention_299[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_495 (Dropout)          (None, 8, 45)        0           ['layer_normalization_297[0][0]']\n",
      "                                                                                                  \n",
      " dropout_496 (Dropout)          (None, 8, 45)        0           ['layer_normalization_298[0][0]']\n",
      "                                                                                                  \n",
      " dropout_497 (Dropout)          (None, 11, 45)       0           ['layer_normalization_299[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_297 (  (None, 45)          0           ['dropout_495[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_298 (  (None, 45)          0           ['dropout_496[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_299 (  (None, 45)          0           ['dropout_497[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_99 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_297[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_298[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_299[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_498 (Dropout)          (None, 135)          0           ['concatenate_99[0][0]']         \n",
      "                                                                                                  \n",
      " dense_198 (Dense)              (None, 128)          17408       ['dropout_498[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_499 (Dropout)          (None, 128)          0           ['dense_198[0][0]']              \n",
      "                                                                                                  \n",
      " dense_199 (Dense)              (None, 1)            129         ['dropout_499[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.2399 - accuracy: 0.9128 - val_loss: 0.0834 - val_accuracy: 0.9924\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1377 - accuracy: 0.9671 - val_loss: 0.0546 - val_accuracy: 0.9926\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1301 - accuracy: 0.9684 - val_loss: 0.0506 - val_accuracy: 0.9931\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1258 - accuracy: 0.9686 - val_loss: 0.0654 - val_accuracy: 0.9935\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1005 - accuracy: 0.9693 - val_loss: 0.1246 - val_accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0962 - accuracy: 0.9690 - val_loss: 0.0466 - val_accuracy: 0.9926\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN cooking 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_100\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_301 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_302 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_303 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_300 (TFOp  (None, 8, 45)       0           ['input_301[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_301 (TFOp  (None, 8, 45)       0           ['input_302[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_302 (TFOp  (None, 11, 45)      0           ['input_303[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_300 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_300[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_300[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_301 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_301[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_301[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_302 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_302[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_302[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_300 (Layer  (None, 8, 45)       90          ['multi_head_attention_300[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_301 (Layer  (None, 8, 45)       90          ['multi_head_attention_301[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_302 (Layer  (None, 11, 45)      90          ['multi_head_attention_302[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_500 (Dropout)          (None, 8, 45)        0           ['layer_normalization_300[0][0]']\n",
      "                                                                                                  \n",
      " dropout_501 (Dropout)          (None, 8, 45)        0           ['layer_normalization_301[0][0]']\n",
      "                                                                                                  \n",
      " dropout_502 (Dropout)          (None, 11, 45)       0           ['layer_normalization_302[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_300 (  (None, 45)          0           ['dropout_500[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_301 (  (None, 45)          0           ['dropout_501[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_302 (  (None, 45)          0           ['dropout_502[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_100 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_300[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_301[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_302[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_503 (Dropout)          (None, 135)          0           ['concatenate_100[0][0]']        \n",
      "                                                                                                  \n",
      " dense_200 (Dense)              (None, 128)          17408       ['dropout_503[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_504 (Dropout)          (None, 128)          0           ['dense_200[0][0]']              \n",
      "                                                                                                  \n",
      " dense_201 (Dense)              (None, 1)            129         ['dropout_504[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.3661 - accuracy: 0.8422 - val_loss: 0.1375 - val_accuracy: 0.9417\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2472 - accuracy: 0.9067 - val_loss: 0.1548 - val_accuracy: 0.9319\n",
      "Epoch 3/10\n",
      " 41/938 [>.............................] - ETA: 15s - loss: 0.2523 - accuracy: 0.9017\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN shower 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_101\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_304 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_305 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_306 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_303 (TFOp  (None, 8, 45)       0           ['input_304[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_304 (TFOp  (None, 8, 45)       0           ['input_305[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_305 (TFOp  (None, 11, 45)      0           ['input_306[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_303 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_303[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_303[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_304 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_304[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_304[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_305 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_305[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_305[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_303 (Layer  (None, 8, 45)       90          ['multi_head_attention_303[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_304 (Layer  (None, 8, 45)       90          ['multi_head_attention_304[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_305 (Layer  (None, 11, 45)      90          ['multi_head_attention_305[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_505 (Dropout)          (None, 8, 45)        0           ['layer_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " dropout_506 (Dropout)          (None, 8, 45)        0           ['layer_normalization_304[0][0]']\n",
      "                                                                                                  \n",
      " dropout_507 (Dropout)          (None, 11, 45)       0           ['layer_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_303 (  (None, 45)          0           ['dropout_505[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_304 (  (None, 45)          0           ['dropout_506[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_305 (  (None, 45)          0           ['dropout_507[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_101 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_303[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_304[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_305[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_508 (Dropout)          (None, 135)          0           ['concatenate_101[0][0]']        \n",
      "                                                                                                  \n",
      " dense_202 (Dense)              (None, 128)          17408       ['dropout_508[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_509 (Dropout)          (None, 128)          0           ['dense_202[0][0]']              \n",
      "                                                                                                  \n",
      " dense_203 (Dense)              (None, 1)            129         ['dropout_509[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.1374 - accuracy: 0.9447 - val_loss: 0.0479 - val_accuracy: 0.9864\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.0262 - val_accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "740/938 [======================>.......] - ETA: 3s - loss: 0.0186 - accuracy: 0.9951\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN pc 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_102\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_307 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_308 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_309 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_306 (TFOp  (None, 8, 45)       0           ['input_307[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_307 (TFOp  (None, 8, 45)       0           ['input_308[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_308 (TFOp  (None, 11, 45)      0           ['input_309[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_306 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_306[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_306[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_307 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_307[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_307[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_308 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_308[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_308[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_306 (Layer  (None, 8, 45)       90          ['multi_head_attention_306[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_307 (Layer  (None, 8, 45)       90          ['multi_head_attention_307[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_308 (Layer  (None, 11, 45)      90          ['multi_head_attention_308[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_510 (Dropout)          (None, 8, 45)        0           ['layer_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " dropout_511 (Dropout)          (None, 8, 45)        0           ['layer_normalization_307[0][0]']\n",
      "                                                                                                  \n",
      " dropout_512 (Dropout)          (None, 11, 45)       0           ['layer_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_306 (  (None, 45)          0           ['dropout_510[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_307 (  (None, 45)          0           ['dropout_511[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_308 (  (None, 45)          0           ['dropout_512[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_102 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_306[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_307[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_308[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_513 (Dropout)          (None, 135)          0           ['concatenate_102[0][0]']        \n",
      "                                                                                                  \n",
      " dense_204 (Dense)              (None, 128)          17408       ['dropout_513[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_514 (Dropout)          (None, 128)          0           ['dense_204[0][0]']              \n",
      "                                                                                                  \n",
      " dense_205 (Dense)              (None, 1)            129         ['dropout_514[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.1540 - accuracy: 0.9378 - val_loss: 0.0078 - val_accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0302 - accuracy: 0.9938 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.0244 - accuracy: 0.9951 - val_loss: 0.0071 - val_accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 0.0074 - val_accuracy: 0.9986\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0096 - val_accuracy: 0.9986\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0104 - val_accuracy: 0.9981\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN sleep 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_103\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_310 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_311 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_312 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_309 (TFOp  (None, 8, 45)       0           ['input_310[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_310 (TFOp  (None, 8, 45)       0           ['input_311[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_311 (TFOp  (None, 11, 45)      0           ['input_312[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_309 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_309[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_309[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_310 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_310[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_310[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_311 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_311[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_311[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_309 (Layer  (None, 8, 45)       90          ['multi_head_attention_309[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_310 (Layer  (None, 8, 45)       90          ['multi_head_attention_310[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_311 (Layer  (None, 11, 45)      90          ['multi_head_attention_311[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_515 (Dropout)          (None, 8, 45)        0           ['layer_normalization_309[0][0]']\n",
      "                                                                                                  \n",
      " dropout_516 (Dropout)          (None, 8, 45)        0           ['layer_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " dropout_517 (Dropout)          (None, 11, 45)       0           ['layer_normalization_311[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_309 (  (None, 45)          0           ['dropout_515[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_310 (  (None, 45)          0           ['dropout_516[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_311 (  (None, 45)          0           ['dropout_517[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_103 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_309[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_310[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_311[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_518 (Dropout)          (None, 135)          0           ['concatenate_103[0][0]']        \n",
      "                                                                                                  \n",
      " dense_206 (Dense)              (None, 128)          17408       ['dropout_518[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_519 (Dropout)          (None, 128)          0           ['dense_206[0][0]']              \n",
      "                                                                                                  \n",
      " dense_207 (Dense)              (None, 1)            129         ['dropout_519[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.2030 - accuracy: 0.9239 - val_loss: 0.0417 - val_accuracy: 0.9902\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1197 - accuracy: 0.9683 - val_loss: 0.0429 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "753/938 [=======================>......] - ETA: 3s - loss: 0.1101 - accuracy: 0.9706TRAIN kitchen 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_104\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_313 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_314 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_315 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_312 (TFOp  (None, 8, 45)       0           ['input_313[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_313 (TFOp  (None, 8, 45)       0           ['input_314[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_314 (TFOp  (None, 11, 45)      0           ['input_315[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_312 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_312[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_312[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_313 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_313[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_313[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_314 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_314[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_314[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_312 (Layer  (None, 8, 45)       90          ['multi_head_attention_312[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_313 (Layer  (None, 8, 45)       90          ['multi_head_attention_313[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_314 (Layer  (None, 11, 45)      90          ['multi_head_attention_314[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_520 (Dropout)          (None, 8, 45)        0           ['layer_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " dropout_521 (Dropout)          (None, 8, 45)        0           ['layer_normalization_313[0][0]']\n",
      "                                                                                                  \n",
      " dropout_522 (Dropout)          (None, 11, 45)       0           ['layer_normalization_314[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_312 (  (None, 45)          0           ['dropout_520[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_313 (  (None, 45)          0           ['dropout_521[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_314 (  (None, 45)          0           ['dropout_522[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_312[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_313[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_314[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_523 (Dropout)          (None, 135)          0           ['concatenate_104[0][0]']        \n",
      "                                                                                                  \n",
      " dense_208 (Dense)              (None, 128)          17408       ['dropout_523[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_524 (Dropout)          (None, 128)          0           ['dense_208[0][0]']              \n",
      "                                                                                                  \n",
      " dense_209 (Dense)              (None, 1)            129         ['dropout_524[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.3343 - accuracy: 0.8536 - val_loss: 0.1565 - val_accuracy: 0.9202\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2015 - accuracy: 0.9251 - val_loss: 0.1243 - val_accuracy: 0.9393\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1758 - accuracy: 0.9320 - val_loss: 0.1133 - val_accuracy: 0.9422\n",
      "Epoch 4/10\n",
      "731/938 [======================>.......] - ETA: 3s - loss: 0.1588 - accuracy: 0.9377\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN toileting 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_105\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_316 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_317 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_318 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_315 (TFOp  (None, 8, 45)       0           ['input_316[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_316 (TFOp  (None, 8, 45)       0           ['input_317[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_317 (TFOp  (None, 11, 45)      0           ['input_318[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_315 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_315[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_315[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_316 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_316[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_316[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_317 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_317[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_317[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_315 (Layer  (None, 8, 45)       90          ['multi_head_attention_315[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_316 (Layer  (None, 8, 45)       90          ['multi_head_attention_316[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_317 (Layer  (None, 11, 45)      90          ['multi_head_attention_317[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_525 (Dropout)          (None, 8, 45)        0           ['layer_normalization_315[0][0]']\n",
      "                                                                                                  \n",
      " dropout_526 (Dropout)          (None, 8, 45)        0           ['layer_normalization_316[0][0]']\n",
      "                                                                                                  \n",
      " dropout_527 (Dropout)          (None, 11, 45)       0           ['layer_normalization_317[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_315 (  (None, 45)          0           ['dropout_525[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_316 (  (None, 45)          0           ['dropout_526[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_317 (  (None, 45)          0           ['dropout_527[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_105 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_315[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_316[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_317[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_528 (Dropout)          (None, 135)          0           ['concatenate_105[0][0]']        \n",
      "                                                                                                  \n",
      " dense_210 (Dense)              (None, 128)          17408       ['dropout_528[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_529 (Dropout)          (None, 128)          0           ['dense_210[0][0]']              \n",
      "                                                                                                  \n",
      " dense_211 (Dense)              (None, 1)            129         ['dropout_529[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.4516 - accuracy: 0.7812 - val_loss: 0.2048 - val_accuracy: 0.9472\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2730 - accuracy: 0.8972 - val_loss: 0.3312 - val_accuracy: 0.8686\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2442 - accuracy: 0.9114 - val_loss: 0.3332 - val_accuracy: 0.8624\n",
      "Epoch 4/10\n",
      "614/938 [==================>...........] - ETA: 5s - loss: 0.2318 - accuracy: 0.9138\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN resting 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_106\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_319 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_320 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_321 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_318 (TFOp  (None, 8, 45)       0           ['input_319[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_319 (TFOp  (None, 8, 45)       0           ['input_320[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_320 (TFOp  (None, 11, 45)      0           ['input_321[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_318 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_318[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_318[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_319 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_319[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_319[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_320 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_320[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_320[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_318 (Layer  (None, 8, 45)       90          ['multi_head_attention_318[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_319 (Layer  (None, 8, 45)       90          ['multi_head_attention_319[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_320 (Layer  (None, 11, 45)      90          ['multi_head_attention_320[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_530 (Dropout)          (None, 8, 45)        0           ['layer_normalization_318[0][0]']\n",
      "                                                                                                  \n",
      " dropout_531 (Dropout)          (None, 8, 45)        0           ['layer_normalization_319[0][0]']\n",
      "                                                                                                  \n",
      " dropout_532 (Dropout)          (None, 11, 45)       0           ['layer_normalization_320[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_318 (  (None, 45)          0           ['dropout_530[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_319 (  (None, 45)          0           ['dropout_531[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_320 (  (None, 45)          0           ['dropout_532[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_106 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_318[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_319[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_320[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_533 (Dropout)          (None, 135)          0           ['concatenate_106[0][0]']        \n",
      "                                                                                                  \n",
      " dense_212 (Dense)              (None, 128)          17408       ['dropout_533[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_534 (Dropout)          (None, 128)          0           ['dense_212[0][0]']              \n",
      "                                                                                                  \n",
      " dense_213 (Dense)              (None, 1)            129         ['dropout_534[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 23s 20ms/step - loss: 0.3044 - accuracy: 0.8561 - val_loss: 0.1291 - val_accuracy: 0.9706\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1606 - accuracy: 0.9327 - val_loss: 0.1620 - val_accuracy: 0.9522\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1468 - accuracy: 0.9377 - val_loss: 0.1498 - val_accuracy: 0.9541\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1078 - accuracy: 0.9580 - val_loss: 0.1301 - val_accuracy: 0.9431\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN exit 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_107\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_322 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_323 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_324 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_321 (TFOp  (None, 8, 45)       0           ['input_322[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_322 (TFOp  (None, 8, 45)       0           ['input_323[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_323 (TFOp  (None, 11, 45)      0           ['input_324[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_321 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_321[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_321[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_322 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_322[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_322[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_323 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_323[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_323[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_321 (Layer  (None, 8, 45)       90          ['multi_head_attention_321[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_322 (Layer  (None, 8, 45)       90          ['multi_head_attention_322[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_323 (Layer  (None, 11, 45)      90          ['multi_head_attention_323[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_535 (Dropout)          (None, 8, 45)        0           ['layer_normalization_321[0][0]']\n",
      "                                                                                                  \n",
      " dropout_536 (Dropout)          (None, 8, 45)        0           ['layer_normalization_322[0][0]']\n",
      "                                                                                                  \n",
      " dropout_537 (Dropout)          (None, 11, 45)       0           ['layer_normalization_323[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_321 (  (None, 45)          0           ['dropout_535[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_322 (  (None, 45)          0           ['dropout_536[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_323 (  (None, 45)          0           ['dropout_537[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_107 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_321[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_322[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_323[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_538 (Dropout)          (None, 135)          0           ['concatenate_107[0][0]']        \n",
      "                                                                                                  \n",
      " dense_214 (Dense)              (None, 128)          17408       ['dropout_538[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_539 (Dropout)          (None, 128)          0           ['dense_214[0][0]']              \n",
      "                                                                                                  \n",
      " dense_215 (Dense)              (None, 1)            129         ['dropout_539[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.2537 - accuracy: 0.9055 - val_loss: 0.1164 - val_accuracy: 0.9797\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1372 - accuracy: 0.9669 - val_loss: 0.1048 - val_accuracy: 0.9799\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.1258 - accuracy: 0.9685 - val_loss: 0.1065 - val_accuracy: 0.9775\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0918 - accuracy: 0.9703 - val_loss: 0.1388 - val_accuracy: 0.9816\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN cooking 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_108\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_325 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_326 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_327 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_324 (TFOp  (None, 8, 45)       0           ['input_325[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_325 (TFOp  (None, 8, 45)       0           ['input_326[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_326 (TFOp  (None, 11, 45)      0           ['input_327[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_324 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_324[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_324[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_325 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_325[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_325[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_326 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_326[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_326[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_324 (Layer  (None, 8, 45)       90          ['multi_head_attention_324[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_325 (Layer  (None, 8, 45)       90          ['multi_head_attention_325[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_326 (Layer  (None, 11, 45)      90          ['multi_head_attention_326[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_540 (Dropout)          (None, 8, 45)        0           ['layer_normalization_324[0][0]']\n",
      "                                                                                                  \n",
      " dropout_541 (Dropout)          (None, 8, 45)        0           ['layer_normalization_325[0][0]']\n",
      "                                                                                                  \n",
      " dropout_542 (Dropout)          (None, 11, 45)       0           ['layer_normalization_326[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_324 (  (None, 45)          0           ['dropout_540[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_325 (  (None, 45)          0           ['dropout_541[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_326 (  (None, 45)          0           ['dropout_542[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_108 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_324[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_325[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_326[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_543 (Dropout)          (None, 135)          0           ['concatenate_108[0][0]']        \n",
      "                                                                                                  \n",
      " dense_216 (Dense)              (None, 128)          17408       ['dropout_543[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_544 (Dropout)          (None, 128)          0           ['dense_216[0][0]']              \n",
      "                                                                                                  \n",
      " dense_217 (Dense)              (None, 1)            129         ['dropout_544[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 20ms/step - loss: 0.3768 - accuracy: 0.8367 - val_loss: 0.1888 - val_accuracy: 0.9137\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2470 - accuracy: 0.9083 - val_loss: 0.1383 - val_accuracy: 0.9400\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2261 - accuracy: 0.9158 - val_loss: 0.2570 - val_accuracy: 0.8719\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.2086 - accuracy: 0.9210 - val_loss: 0.1509 - val_accuracy: 0.9474\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1617 - accuracy: 0.9387 - val_loss: 0.2138 - val_accuracy: 0.9111\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.1548 - accuracy: 0.9423 - val_loss: 0.1841 - val_accuracy: 0.9326\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 19s 20ms/step - loss: 0.1485 - accuracy: 0.9455 - val_loss: 0.1228 - val_accuracy: 0.9596\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN shower 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_109\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_328 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_329 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_330 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_327 (TFOp  (None, 8, 45)       0           ['input_328[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_328 (TFOp  (None, 8, 45)       0           ['input_329[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_329 (TFOp  (None, 11, 45)      0           ['input_330[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_327 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_327[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_327[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_328 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_328[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_328[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_329 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_329[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_329[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_327 (Layer  (None, 8, 45)       90          ['multi_head_attention_327[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_328 (Layer  (None, 8, 45)       90          ['multi_head_attention_328[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_329 (Layer  (None, 11, 45)      90          ['multi_head_attention_329[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_545 (Dropout)          (None, 8, 45)        0           ['layer_normalization_327[0][0]']\n",
      "                                                                                                  \n",
      " dropout_546 (Dropout)          (None, 8, 45)        0           ['layer_normalization_328[0][0]']\n",
      "                                                                                                  \n",
      " dropout_547 (Dropout)          (None, 11, 45)       0           ['layer_normalization_329[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_327 (  (None, 45)          0           ['dropout_545[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_328 (  (None, 45)          0           ['dropout_546[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_329 (  (None, 45)          0           ['dropout_547[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_109 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_327[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_328[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_329[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_548 (Dropout)          (None, 135)          0           ['concatenate_109[0][0]']        \n",
      "                                                                                                  \n",
      " dense_218 (Dense)              (None, 128)          17408       ['dropout_548[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_549 (Dropout)          (None, 128)          0           ['dense_218[0][0]']              \n",
      "                                                                                                  \n",
      " dense_219 (Dense)              (None, 1)            129         ['dropout_549[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.1246 - accuracy: 0.9511 - val_loss: 0.0789 - val_accuracy: 0.9775\n",
      "Epoch 2/10\n",
      "227/938 [======>.......................] - ETA: 12s - loss: 0.0437 - accuracy: 0.9882\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN pc 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_110\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_331 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_332 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_333 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_330 (TFOp  (None, 8, 45)       0           ['input_331[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_331 (TFOp  (None, 8, 45)       0           ['input_332[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_332 (TFOp  (None, 11, 45)      0           ['input_333[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_330 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_330[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_330[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_331 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_331[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_331[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_332 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_332[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_332[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_330 (Layer  (None, 8, 45)       90          ['multi_head_attention_330[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_331 (Layer  (None, 8, 45)       90          ['multi_head_attention_331[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_332 (Layer  (None, 11, 45)      90          ['multi_head_attention_332[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_550 (Dropout)          (None, 8, 45)        0           ['layer_normalization_330[0][0]']\n",
      "                                                                                                  \n",
      " dropout_551 (Dropout)          (None, 8, 45)        0           ['layer_normalization_331[0][0]']\n",
      "                                                                                                  \n",
      " dropout_552 (Dropout)          (None, 11, 45)       0           ['layer_normalization_332[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_330 (  (None, 45)          0           ['dropout_550[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_331 (  (None, 45)          0           ['dropout_551[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_332 (  (None, 45)          0           ['dropout_552[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_110 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_330[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_331[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_332[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_553 (Dropout)          (None, 135)          0           ['concatenate_110[0][0]']        \n",
      "                                                                                                  \n",
      " dense_220 (Dense)              (None, 128)          17408       ['dropout_553[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_554 (Dropout)          (None, 128)          0           ['dense_220[0][0]']              \n",
      "                                                                                                  \n",
      " dense_221 (Dense)              (None, 1)            129         ['dropout_554[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 22s 19ms/step - loss: 0.1451 - accuracy: 0.9431 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0351 - accuracy: 0.9926 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.0307 - accuracy: 0.9938 - val_loss: 0.0022 - val_accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "623/938 [==================>...........] - ETA: 5s - loss: 0.0321 - accuracy: 0.9933\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN sleep 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_111\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_334 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_335 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_336 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_333 (TFOp  (None, 8, 45)       0           ['input_334[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_334 (TFOp  (None, 8, 45)       0           ['input_335[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_335 (TFOp  (None, 11, 45)      0           ['input_336[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_333 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_333[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_333[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_334 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_334[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_334[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_335 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_335[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_335[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_333 (Layer  (None, 8, 45)       90          ['multi_head_attention_333[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_334 (Layer  (None, 8, 45)       90          ['multi_head_attention_334[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_335 (Layer  (None, 11, 45)      90          ['multi_head_attention_335[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_555 (Dropout)          (None, 8, 45)        0           ['layer_normalization_333[0][0]']\n",
      "                                                                                                  \n",
      " dropout_556 (Dropout)          (None, 8, 45)        0           ['layer_normalization_334[0][0]']\n",
      "                                                                                                  \n",
      " dropout_557 (Dropout)          (None, 11, 45)       0           ['layer_normalization_335[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_333 (  (None, 45)          0           ['dropout_555[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_334 (  (None, 45)          0           ['dropout_556[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_335 (  (None, 45)          0           ['dropout_557[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_111 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_333[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_334[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_335[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_558 (Dropout)          (None, 135)          0           ['concatenate_111[0][0]']        \n",
      "                                                                                                  \n",
      " dense_222 (Dense)              (None, 128)          17408       ['dropout_558[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_559 (Dropout)          (None, 128)          0           ['dense_222[0][0]']              \n",
      "                                                                                                  \n",
      " dense_223 (Dense)              (None, 1)            129         ['dropout_559[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 18ms/step - loss: 0.1865 - accuracy: 0.9348 - val_loss: 0.0534 - val_accuracy: 0.9869\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1172 - accuracy: 0.9701 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1083 - accuracy: 0.9717 - val_loss: 0.0512 - val_accuracy: 0.9826\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1050 - accuracy: 0.9723 - val_loss: 0.0409 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "212/938 [=====>........................] - ETA: 12s - loss: 0.0922 - accuracy: 0.9757\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN kitchen 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_112\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_337 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_338 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_339 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_336 (TFOp  (None, 8, 45)       0           ['input_337[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_337 (TFOp  (None, 8, 45)       0           ['input_338[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_338 (TFOp  (None, 11, 45)      0           ['input_339[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_336 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_336[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_336[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_337 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_337[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_337[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_338 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_338[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_338[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_336 (Layer  (None, 8, 45)       90          ['multi_head_attention_336[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_337 (Layer  (None, 8, 45)       90          ['multi_head_attention_337[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_338 (Layer  (None, 11, 45)      90          ['multi_head_attention_338[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_560 (Dropout)          (None, 8, 45)        0           ['layer_normalization_336[0][0]']\n",
      "                                                                                                  \n",
      " dropout_561 (Dropout)          (None, 8, 45)        0           ['layer_normalization_337[0][0]']\n",
      "                                                                                                  \n",
      " dropout_562 (Dropout)          (None, 11, 45)       0           ['layer_normalization_338[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_336 (  (None, 45)          0           ['dropout_560[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_337 (  (None, 45)          0           ['dropout_561[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_338 (  (None, 45)          0           ['dropout_562[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_112 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_336[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_337[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_338[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_563 (Dropout)          (None, 135)          0           ['concatenate_112[0][0]']        \n",
      "                                                                                                  \n",
      " dense_224 (Dense)              (None, 128)          17408       ['dropout_563[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_564 (Dropout)          (None, 128)          0           ['dense_224[0][0]']              \n",
      "                                                                                                  \n",
      " dense_225 (Dense)              (None, 1)            129         ['dropout_564[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 19ms/step - loss: 0.3019 - accuracy: 0.8729 - val_loss: 0.1540 - val_accuracy: 0.9197\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1927 - accuracy: 0.9275 - val_loss: 0.1370 - val_accuracy: 0.9238\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1710 - accuracy: 0.9360 - val_loss: 0.1494 - val_accuracy: 0.9195\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1569 - accuracy: 0.9386 - val_loss: 0.1421 - val_accuracy: 0.9276\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1479 - accuracy: 0.9442 - val_loss: 0.1255 - val_accuracy: 0.9489\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.1437 - accuracy: 0.9450 - val_loss: 0.1538 - val_accuracy: 0.9388\n",
      "Epoch 7/10\n",
      "131/131 [==============================] - 1s 5ms/steploss: 0.1300 - ac\n",
      "(4185, 1)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "SizeTrainOk=4000\n",
    "SizeTrainKo=6000\n",
    "\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    print(\"\\t\",dx,day)\n",
    "    other_dx= [other for other in range(0,len(days)) if other != dx]\n",
    "\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    \n",
    "    for ax,activity in enumerate(activities):\n",
    "            print(ax,activity)\n",
    "            \n",
    "            ##TRAING DATA\n",
    "            L1=[]\n",
    "            L2=[]\n",
    "            S=[]\n",
    "            Y=[]\n",
    "            for ux,user in enumerate(users):\n",
    "                    print(\"\\t\\t\",ux,user)\n",
    "                    other_ux= [other for other in range(0,len(users)) if other != ux]\n",
    "                    print(day,user,other_dx,other_ux)\n",
    "\n",
    "                    #OK act\n",
    "                    for ix in range(0,SizeTrainOk):\n",
    "                        #print(\"SizeTrainOk\",ix,\"vs\",SizeTrainOk)\n",
    "                        filtered_elements = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 1)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            #print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                            X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        Ss=[]\n",
    "                        for sx, sensor in enumerate(sensors):\n",
    "                            Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                        L1.append(X1s)\n",
    "                        L2.append(X2s)\n",
    "                        S.append(Ss)\n",
    "                        Y.append(user_activity[index])\n",
    "                        \n",
    "                    #KO act\n",
    "                    ix=0\n",
    "                    while ix < SizeTrainKo:\n",
    "                        #print(\"SizeTrainKo\",ix,\"vs\",SizeTrainKo)\n",
    "                        filtered_elements_specific = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 0)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        none=True\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            #if(ax2==ax):\n",
    "                                r=np.random.rand()\n",
    "                                #print(\" removing loc?:\",loc_user[ax2][iu][idy][tt],r)\n",
    "                                if(r<loc_user[ax2][iu][idy][tt]+0.05):\n",
    "                                    #print(\"NOT  removing loc:\",loc_user[ax2][iu][idy][tt])\n",
    "                                    none=False\n",
    "                                    \n",
    "                                X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                                X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        if not none:\n",
    "                            L1.append(X1s)\n",
    "                            L2.append(X2s)\n",
    "                            Ss=[]\n",
    "                            for sx, sensor in enumerate(sensors):\n",
    "                                Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                            S.append(Ss)\n",
    "                            Y.append(user_activity[index])       \n",
    "                            ix=ix+1\n",
    "\n",
    "            L1=np.array(L1)        \n",
    "            L2=np.array(L2)        \n",
    "            S=np.array(S)\n",
    "            Y=np.array(Y)\n",
    "            print(\"TRAIN\",activity,day,L1.shape,L2.shape,S.shape,Y.shape)\n",
    "            \n",
    "            \n",
    "            model=getModelHAR()\n",
    "            model.summary()\n",
    "            \n",
    "            ##TEST DATA\n",
    "            TL1=[]\n",
    "            TL2=[]\n",
    "            TS=[]\n",
    "            TY=[]\n",
    "            \n",
    "            \n",
    "            (t0,tN)=t0N_days[day]\n",
    "            ts=list(range(TWA,sizeT(t0,tN)-TWB))\n",
    "            \n",
    "            for ux2,user2 in enumerate(users):\n",
    "                other_ux2= [other for other in range(0,len(users)) if other != ux2]\n",
    "\n",
    "                for tx in ts:\n",
    "\n",
    "                    Ss=[]\n",
    "                    for sx, sensor in enumerate(sensors):\n",
    "                        Ss.append(act_sensors[sx][dx][tx-TWA:tx+TWB])\n",
    "                    \n",
    "                    X1s=[]\n",
    "                    X2s=[]\n",
    "                    for ax2,activity2 in enumerate(activities):\n",
    "                        X1s.append(loc_user[ax2][ux2][dx][tx-TWA:tx+TWB])\n",
    "                        X2s.append(np.amax(loc_user[ax2,other_ux2,dx,tx-TWA:tx+TWB],axis=0))\n",
    "\n",
    "\n",
    "                    TL1.append(X1s)\n",
    "                    TL2.append(X2s)\n",
    "                    TS.append(Ss)\n",
    "                    TY.append(user_activity[ax, ux2, dx, tx])\n",
    "                        \n",
    "            TL1=np.array(TL1)        \n",
    "            TL2=np.array(TL2)        \n",
    "            TS=np.array(TS)\n",
    "            TY=np.array(TY)\n",
    "            print(\"EVAL\",activity,day,TL1.shape,TL2.shape,TS.shape,TY.shape)\n",
    "            \n",
    "            history = model.fit([L1,L2,S] , Y, shuffle=True, batch_size=32,epochs=10, validation_data = ([TL1,TL2,TS], TY))\n",
    "            YT_prediction = model.predict([TL1,TL2,TS])\n",
    "            print(YT_prediction.shape)\n",
    "            \n",
    "            ix=0\n",
    "            for ux2,user2 in enumerate(users):\n",
    "                with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/PREDICTION-Transformer-position-encoding-45+0.\"+user2+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                    for tx in (ts):\n",
    "                        tt=tx*time_step2+t0\n",
    "                        #print(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0]))\n",
    "                        file.write(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0])+\"\\n\")\n",
    "                        \n",
    "                        ix=ix+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fc952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
