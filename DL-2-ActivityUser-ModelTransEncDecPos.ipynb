{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934b764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2024-07-05': ['0001', '3d57', 'ed9c'], '2024-07-06': ['0001', '3d57', 'ed9c'], '2024-07-07': ['0001', '3d57', 'ed9c'], '2024-07-18': ['16fe', 'f02e', 'ed9c'], '2024-07-19': ['16fe', 'f02e', 'ed9c'], '2024-07-20': ['16fe', 'f02e', 'ed9c'], '2024-07-24': ['16fe', '5b66', 'ed9c'], '2024-07-25': ['16fe', '5b66', 'ed9c'], '2024-07-26': ['16fe', '5b66', 'ed9c'], '2024-07-27': ['16fe', '5b66', 'ed9c'], '2024-07-28': ['16fe', '5b66', 'ed9c'], '2024-07-29': ['16fe', '5b66', 'ed9c'], '2024-07-30': ['16fe', '5b66', 'ed9c'], '2024-07-31': ['16fe', '5b66', 'ed9c']}\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('agg-config.txt')\n",
    "\n",
    "\n",
    "time_step = int(config.get('Configuration', 'time_step'))\n",
    "time_step2 = int(config.get('Configuration', 'time_step2'))\n",
    "\n",
    "window_size = int(config.get('Configuration', 'window_size'))\n",
    "processed_data_folder = config.get('Configuration', 'processed_data_folder')\n",
    "raw_data_folder = config.get('Configuration', 'raw_data_folder')\n",
    "\n",
    "ini_date = config.get('Configuration', 'ini_date')\n",
    "end_date = config.get('Configuration', 'end_date')\n",
    "\n",
    "\n",
    "activities=config.get('Configuration', 'learn_activities')\n",
    "activities = [(item.strip()) for item in activities.split(',')]\n",
    "\n",
    "cross_days=config.get('Configuration', 'cross_days')\n",
    "cross_days = [(item.strip()) for item in cross_days.split(',')]\n",
    "\n",
    "sensors=config.get('Configuration', 'sensors')\n",
    "sensors = [(item.strip()) for item in sensors.split(',')]\n",
    "\n",
    "w = int(config.get('Configuration', 'w'))\n",
    "h = int(config.get('Configuration', 'h'))\n",
    "\n",
    "users_day={}\n",
    "for cross_day in cross_days:\n",
    "    users_day[cross_day]=config.get('Configuration', cross_day)\n",
    "    users_day[cross_day] = [(item.strip()) for item in users_day[cross_day].split(',')]\n",
    "print(users_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ea50ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv    \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "off_zone=60*60*2\n",
    "\n",
    "def day_time(t0,tN,ti):\n",
    "    return int((int)((ti+off_zone)/(60*60*24)))\n",
    "\n",
    "\n",
    "def time2str(t0,tN,tt):\n",
    "    return datetime.fromtimestamp(tt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def day_time0(t0,tN,ti):\n",
    "    return day_time(ti)-day_time(t0)+1\n",
    "\n",
    "def relT(t0,tN,ti):\n",
    "    return (int)((ti-t0)/time_step2)\n",
    "\n",
    "def sizeT(t0,tN):\n",
    "    return relT(t0,tN,tN)+1\n",
    "\n",
    "\n",
    "def initTime(ini_date,end_date):\n",
    "    tN = (int)(datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "\n",
    "    t0 = (int)(datetime.strptime(ini_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    print (ini_date,\"Init date is\", t0, \"day:\",day_time(t0,tN,t0), time2str(t0,tN,t0))\n",
    "    print (end_date,\"End date is\", tN, \"day:\",day_time(t0,tN,tN), time2str(t0,tN,tN))\n",
    "\n",
    "    day=list(range(day_time(t0,tN,t0),day_time(t0,tN,tN)+1))[0]\n",
    "    return day,t0,tN\n",
    "    \n",
    "initTime(ini_date,end_date)\n",
    "\n",
    "\n",
    "def getStrDatefrom(day_number):\n",
    "    # Reference date (1970-01-01)\n",
    "    reference_date = datetime(1970, 1, 1)\n",
    "    \n",
    "    # Compute the date corresponding to the day number\n",
    "    resulting_date = reference_date + timedelta(days=day_number)\n",
    "    \n",
    "    return resulting_date.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeeab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ed8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-05\n",
      "New ini_date: 2024-07-05 02:00:00\n",
      "New end_date: 2024-07-06 01:59:59\n",
      "2024-07-05 02:00:00 Init date is 1720137600 day: 19909 2024-07-05 02:00:00\n",
      "2024-07-06 01:59:59 End date is 1720223999 day: 19910 2024-07-06 01:59:59\n",
      "2024-07-06\n",
      "New ini_date: 2024-07-06 02:00:00\n",
      "New end_date: 2024-07-07 01:59:59\n",
      "2024-07-06 02:00:00 Init date is 1720224000 day: 19910 2024-07-06 02:00:00\n",
      "2024-07-07 01:59:59 End date is 1720310399 day: 19911 2024-07-07 01:59:59\n",
      "2024-07-07\n",
      "New ini_date: 2024-07-07 02:00:00\n",
      "New end_date: 2024-07-08 01:59:59\n",
      "2024-07-07 02:00:00 Init date is 1720310400 day: 19911 2024-07-07 02:00:00\n",
      "2024-07-08 01:59:59 End date is 1720396799 day: 19912 2024-07-08 01:59:59\n",
      "2024-07-18\n",
      "New ini_date: 2024-07-18 02:00:00\n",
      "New end_date: 2024-07-19 01:59:59\n",
      "2024-07-18 02:00:00 Init date is 1721260800 day: 19922 2024-07-18 02:00:00\n",
      "2024-07-19 01:59:59 End date is 1721347199 day: 19923 2024-07-19 01:59:59\n",
      "2024-07-19\n",
      "New ini_date: 2024-07-19 02:00:00\n",
      "New end_date: 2024-07-20 01:59:59\n",
      "2024-07-19 02:00:00 Init date is 1721347200 day: 19923 2024-07-19 02:00:00\n",
      "2024-07-20 01:59:59 End date is 1721433599 day: 19924 2024-07-20 01:59:59\n",
      "2024-07-20\n",
      "New ini_date: 2024-07-20 02:00:00\n",
      "New end_date: 2024-07-21 01:59:59\n",
      "2024-07-20 02:00:00 Init date is 1721433600 day: 19924 2024-07-20 02:00:00\n",
      "2024-07-21 01:59:59 End date is 1721519999 day: 19925 2024-07-21 01:59:59\n",
      "2024-07-24\n",
      "New ini_date: 2024-07-24 02:00:00\n",
      "New end_date: 2024-07-25 01:59:59\n",
      "2024-07-24 02:00:00 Init date is 1721779200 day: 19928 2024-07-24 02:00:00\n",
      "2024-07-25 01:59:59 End date is 1721865599 day: 19929 2024-07-25 01:59:59\n",
      "2024-07-25\n",
      "New ini_date: 2024-07-25 02:00:00\n",
      "New end_date: 2024-07-26 01:59:59\n",
      "2024-07-25 02:00:00 Init date is 1721865600 day: 19929 2024-07-25 02:00:00\n",
      "2024-07-26 01:59:59 End date is 1721951999 day: 19930 2024-07-26 01:59:59\n",
      "2024-07-26\n",
      "New ini_date: 2024-07-26 02:00:00\n",
      "New end_date: 2024-07-27 01:59:59\n",
      "2024-07-26 02:00:00 Init date is 1721952000 day: 19930 2024-07-26 02:00:00\n",
      "2024-07-27 01:59:59 End date is 1722038399 day: 19931 2024-07-27 01:59:59\n",
      "2024-07-27\n",
      "New ini_date: 2024-07-27 02:00:00\n",
      "New end_date: 2024-07-28 01:59:59\n",
      "2024-07-27 02:00:00 Init date is 1722038400 day: 19931 2024-07-27 02:00:00\n",
      "2024-07-28 01:59:59 End date is 1722124799 day: 19932 2024-07-28 01:59:59\n",
      "2024-07-28\n",
      "New ini_date: 2024-07-28 02:00:00\n",
      "New end_date: 2024-07-29 01:59:59\n",
      "2024-07-28 02:00:00 Init date is 1722124800 day: 19932 2024-07-28 02:00:00\n",
      "2024-07-29 01:59:59 End date is 1722211199 day: 19933 2024-07-29 01:59:59\n",
      "2024-07-29\n",
      "New ini_date: 2024-07-29 02:00:00\n",
      "New end_date: 2024-07-30 01:59:59\n",
      "2024-07-29 02:00:00 Init date is 1722211200 day: 19933 2024-07-29 02:00:00\n",
      "2024-07-30 01:59:59 End date is 1722297599 day: 19934 2024-07-30 01:59:59\n",
      "2024-07-30\n",
      "New ini_date: 2024-07-30 02:00:00\n",
      "New end_date: 2024-07-31 01:59:59\n",
      "2024-07-30 02:00:00 Init date is 1722297600 day: 19934 2024-07-30 02:00:00\n",
      "2024-07-31 01:59:59 End date is 1722383999 day: 19935 2024-07-31 01:59:59\n",
      "2024-07-31\n",
      "New ini_date: 2024-07-31 02:00:00\n",
      "New end_date: 2024-08-01 01:59:59\n",
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n",
      "[19909, 19910, 19911, 19922, 19923, 19924, 19928, 19929, 19930, 19931, 19932, 19933, 19934, 19935]\n",
      "{19909: (1720137600, 1720223999), 19910: (1720224000, 1720310399), 19911: (1720310400, 1720396799), 19922: (1721260800, 1721347199), 19923: (1721347200, 1721433599), 19924: (1721433600, 1721519999), 19928: (1721779200, 1721865599), 19929: (1721865600, 1721951999), 19930: (1721952000, 1722038399), 19931: (1722038400, 1722124799), 19932: (1722124800, 1722211199), 19933: (1722211200, 1722297599), 19934: (1722297600, 1722383999), 19935: (1722384000, 1722470399)}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "days=[]\n",
    "t0N_days={}\n",
    "\n",
    "for cross_day in cross_days:\n",
    "    print(cross_day)\n",
    "    # Convertir las fechas a objetos datetime\n",
    "    ini_date_dt = datetime.strptime(ini_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    cross_day_dt = datetime.strptime(cross_day, \"%Y-%m-%d\")\n",
    "\n",
    "    # Reemplazar el d√≠a manteniendo la hora original\n",
    "    new_ini_date = cross_day_dt.replace(hour=ini_date_dt.hour, minute=ini_date_dt.minute, second=ini_date_dt.second)\n",
    "    new_end_date = cross_day_dt.replace(hour=end_date_dt.hour, minute=end_date_dt.minute, second=end_date_dt.second) + timedelta(days=1)\n",
    "\n",
    "    # Convertir las fechas de nuevo a cadena si es necesario\n",
    "    new_ini_date_str = new_ini_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    new_end_date_str = new_end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    print(f\"New ini_date: {new_ini_date_str}\")\n",
    "    print(f\"New end_date: {new_end_date_str}\")\n",
    "    day,t0,tN=initTime(new_ini_date_str,new_end_date_str)\n",
    "    days.append(day)\n",
    "    t0N_days[day]=(t0,tN)\n",
    "    \n",
    "\n",
    "print(days)\n",
    "print(t0N_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 14, 1440)\n",
      "\t toileting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.toileting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.toileting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.toileting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.toileting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.toileting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.toileting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.toileting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.toileting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.toileting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.toileting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.toileting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.toileting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.toileting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.toileting.tsv\n",
      "19935 (1440,)\n",
      "\t resting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.resting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.resting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.resting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.resting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.resting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.resting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.resting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.resting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.resting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.resting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.resting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.resting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.resting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.resting.tsv\n",
      "19935 (1440,)\n",
      "\t exit\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.exit.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.exit.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.exit.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.exit.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.exit.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.exit.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.exit.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.exit.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.exit.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.exit.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.exit.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.exit.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.exit.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.exit.tsv\n",
      "19935 (1440,)\n",
      "\t cooking\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.cooking.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.cooking.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.cooking.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.cooking.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.cooking.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.cooking.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.cooking.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.cooking.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.cooking.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.cooking.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.cooking.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.cooking.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.cooking.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.cooking.tsv\n",
      "19935 (1440,)\n",
      "\t shower\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.shower.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.shower.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.shower.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.shower.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.shower.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.shower.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.shower.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.shower.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.shower.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.shower.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.shower.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.shower.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.shower.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.shower.tsv\n",
      "19935 (1440,)\n",
      "\t pc\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.pc.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.pc.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.pc.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.pc.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.pc.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.pc.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.pc.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.pc.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.pc.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.pc.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.pc.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.pc.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.pc.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.pc.tsv\n",
      "19935 (1440,)\n",
      "\t sleep\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.sleep.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.sleep.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.sleep.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.sleep.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.sleep.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.sleep.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.sleep.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.sleep.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.sleep.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.sleep.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.sleep.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.sleep.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.sleep.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.sleep.tsv\n",
      "19935 (1440,)\n",
      "\t kitchen\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.kitchen.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.kitchen.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.kitchen.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.kitchen.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.kitchen.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.kitchen.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.kitchen.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.kitchen.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.kitchen.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.kitchen.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.kitchen.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.kitchen.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.kitchen.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.kitchen.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "len_users=3\n",
    "loc_user=np.zeros((len(activities),len_users,len(days),sizeT(t0,tN)))\n",
    "print(loc_user.shape)\n",
    "for ax,activity in enumerate(activities):\n",
    "    print(\"\\t\",activity)\n",
    "    for dx,day in enumerate(days):\n",
    "        day_str=getStrDatefrom(day)\n",
    "        users=users_day[day_str]\n",
    "        print(day,users)\n",
    "        for ux,user in enumerate(users):\n",
    "            print(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\")\n",
    "            series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"loc\"])\n",
    "            series=series[\"loc\"].values\n",
    "            print(day,series.shape)\n",
    "            loc_user[ax][ux][dx]=series\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9631e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 14, 1440)\n",
      "\t fridge_13\n",
      "./data-har//DAY_19909/object_sensor/fridge_13.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/fridge_13.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/fridge_13.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/fridge_13.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/fridge_13.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/fridge_13.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/fridge_13.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/fridge_13.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/fridge_13.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/fridge_13.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/fridge_13.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/fridge_13.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/fridge_13.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/fridge_13.tsv\n",
      "19935 (1440,)\n",
      "\t tap_22\n",
      "./data-har//DAY_19909/object_sensor/tap_22.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/tap_22.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/tap_22.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/tap_22.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/tap_22.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/tap_22.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/tap_22.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/tap_22.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/tap_22.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/tap_22.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/tap_22.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/tap_22.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/tap_22.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/tap_22.tsv\n",
      "19935 (1440,)\n",
      "\t micro_5\n",
      "./data-har//DAY_19909/object_sensor/micro_5.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/micro_5.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/micro_5.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/micro_5.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/micro_5.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/micro_5.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/micro_5.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/micro_5.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/micro_5.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/micro_5.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/micro_5.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/micro_5.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/micro_5.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/micro_5.tsv\n",
      "19935 (1440,)\n",
      "\t pans_8\n",
      "./data-har//DAY_19909/object_sensor/pans_8.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pans_8.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pans_8.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pans_8.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pans_8.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pans_8.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pans_8.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pans_8.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pans_8.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pans_8.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pans_8.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pans_8.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pans_8.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pans_8.tsv\n",
      "19935 (1440,)\n",
      "\t dishes_9\n",
      "./data-har//DAY_19909/object_sensor/dishes_9.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/dishes_9.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/dishes_9.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/dishes_9.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/dishes_9.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/dishes_9.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/dishes_9.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/dishes_9.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/dishes_9.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/dishes_9.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/dishes_9.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/dishes_9.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/dishes_9.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/dishes_9.tsv\n",
      "19935 (1440,)\n",
      "\t shower_24_apertura\n",
      "./data-har//DAY_19909/object_sensor/shower_24_apertura.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_24_apertura.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_24_apertura.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_24_apertura.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_24_apertura.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_24_apertura.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_24_apertura.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_24_apertura.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_24_apertura.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_24_apertura.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_24_apertura.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_24_apertura.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_24_apertura.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_24_apertura.tsv\n",
      "19935 (1440,)\n",
      "\t hum_shower_25\n",
      "./data-har//DAY_19909/object_sensor/hum_shower_25.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/hum_shower_25.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/hum_shower_25.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/hum_shower_25.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/hum_shower_25.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/hum_shower_25.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/hum_shower_25.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/hum_shower_25.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/hum_shower_25.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/hum_shower_25.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/hum_shower_25.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/hum_shower_25.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/hum_shower_25.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/hum_shower_25.tsv\n",
      "19935 (1440,)\n",
      "\t shower_31\n",
      "./data-har//DAY_19909/object_sensor/shower_31.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_31.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_31.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_31.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_31.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_31.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_31.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_31.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_31.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_31.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_31.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_31.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_31.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_31.tsv\n",
      "19935 (1440,)\n",
      "\t wc_17\n",
      "./data-har//DAY_19909/object_sensor/wc_17.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/wc_17.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/wc_17.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/wc_17.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/wc_17.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/wc_17.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/wc_17.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/wc_17.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/wc_17.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/wc_17.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/wc_17.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/wc_17.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/wc_17.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/wc_17.tsv\n",
      "19935 (1440,)\n",
      "\t sink_21\n",
      "./data-har//DAY_19909/object_sensor/sink_21.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/sink_21.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/sink_21.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/sink_21.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/sink_21.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/sink_21.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/sink_21.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/sink_21.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/sink_21.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/sink_21.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/sink_21.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/sink_21.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/sink_21.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/sink_21.tsv\n",
      "19935 (1440,)\n",
      "\t pc_1_current_consumption\n",
      "./data-har//DAY_19909/object_sensor/pc_1_current_consumption.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pc_1_current_consumption.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pc_1_current_consumption.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pc_1_current_consumption.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pc_1_current_consumption.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pc_1_current_consumption.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pc_1_current_consumption.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pc_1_current_consumption.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pc_1_current_consumption.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pc_1_current_consumption.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pc_1_current_consumption.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pc_1_current_consumption.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pc_1_current_consumption.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pc_1_current_consumption.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "act_sensors=np.zeros((len(sensors),len(days),sizeT(t0,tN)))\n",
    "print(act_sensors.shape)\n",
    "for sx,sensor in enumerate(sensors):\n",
    "    print(\"\\t\",sensor)\n",
    "    for dx,day in enumerate(days):\n",
    "        print(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\")\n",
    "        series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"status\"])\n",
    "        series=series[\"status\"].values\n",
    "        print(day,series.shape)\n",
    "        act_sensors[sx][dx]=series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n"
     ]
    }
   ],
   "source": [
    "user_activity=np.zeros((len(activities),len(users),len(days),sizeT(t0,tN)))\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            df_total=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/INTERVAL.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"ix\",\"d0\",\"dN\"])\n",
    "            #print(df_total)\n",
    "            #print(pd.to_datetime(df_total['d0']))\n",
    "            df_total['d0'] = pd.to_datetime(df_total['d0'])\n",
    "            df_total['dN'] = pd.to_datetime(df_total['dN'])\n",
    "            #print(df_total)\n",
    "\n",
    "            for tx,tt in enumerate(ts):\n",
    "                ttt=pd.to_datetime(time2str(t0,tN,tt))\n",
    "#                print(ttt)\n",
    "                row = df_total[(df_total['d0'] <= ttt) & (df_total['dN'] >= ttt)]\n",
    "#                print(\"df_in#tervalo\",row)\n",
    "                if(row.size>0):\n",
    "                    user_activity[ax][ux][dx][tx]=1\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "            \n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/LABEL3.\"+user+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                for tx,tt in enumerate(ts):\n",
    "                    file.write(time2str(t0,tN,tt)+\"\\t\"+str(user_activity[ax][ux][dx][tx])+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3b92a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 11\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_196 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_197 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_198 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 8, 45)       0           ['input_196[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 8, 45)       0           ['input_197[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 11, 45)      0           ['input_198[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_97 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_24[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_98 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_25[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_99 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_26[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_86 (LayerN  (None, 8, 45)       90          ['multi_head_attention_97[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_87 (LayerN  (None, 8, 45)       90          ['multi_head_attention_98[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_88 (LayerN  (None, 11, 45)      90          ['multi_head_attention_99[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_129 (Dropout)          (None, 8, 45)        0           ['layer_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_130 (Dropout)          (None, 8, 45)        0           ['layer_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, 11, 45)       0           ['layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_31 (G  (None, 45)          0           ['dropout_129[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_32 (G  (None, 45)          0           ['dropout_130[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_33 (G  (None, 45)          0           ['dropout_131[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_31[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_32[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_33[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_132 (Dropout)          (None, 135)          0           ['concatenate_24[0][0]']         \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 128)          17408       ['dropout_132[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_133 (Dropout)          (None, 128)          0           ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 1)            129         ['dropout_133[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, MultiHeadAttention, LayerNormalization, Dropout, Concatenate, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "N1 = len(activities)\n",
    "N2 = len(activities)\n",
    "N3 = len(sensors)\n",
    "\n",
    "TWA = 30\n",
    "TWB = 15\n",
    "T = TWA + TWB\n",
    "\n",
    "print(N1,N2,N3)\n",
    "\n",
    "# Positional Encoding function\n",
    "def getPositionEncoding(seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Computes positional encoding for a given sequence length and embedding dimension.\n",
    "    \"\"\"\n",
    "    position = np.arange(seq_len)[:, np.newaxis]  # (seq_len, 1)\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "\n",
    "    pos_enc = np.zeros((seq_len, d_model))  # Inicializar matriz de codificaci√≥n posicional\n",
    "\n",
    "    # Llenar columnas pares con seno\n",
    "    pos_enc[:, 0::2] = np.sin(position * div_term)\n",
    "\n",
    "    # Llenar columnas impares con coseno\n",
    "    pos_enc[:, 1::2] = np.cos(position * div_term[:len(pos_enc[0, 1::2])])\n",
    "\n",
    "    # Expandir dimensiones para coincidir con batch size\n",
    "    pos_enc = np.expand_dims(pos_enc, axis=0)  # (1, seq_len, d_model)\n",
    "\n",
    "    return tf.cast(pos_enc, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modelo con Positional Encoding\n",
    "def getModelHAR():\n",
    "    # Define inputs\n",
    "    input1 = Input(shape=(8, 45))  # Forma de L1: (batch_size, 8, 45)\n",
    "    input2 = Input(shape=(8, 45))  # Forma de L2: (batch_size, 8, 45)\n",
    "    input3 = Input(shape=(11, 45))  # Forma de S: (batch_size, 11, 45)\n",
    "\n",
    "    # Codificaci√≥n posicional\n",
    "    pos_enc1 = getPositionEncoding(8, 45)\n",
    "    pos_enc2 = getPositionEncoding(8, 45)\n",
    "    pos_enc3 = getPositionEncoding(11, 45)\n",
    "\n",
    "    # A√±adir Positional Encoding a las entradas\n",
    "    encoded1 = input1 + pos_enc1\n",
    "    encoded2 = input2 + pos_enc2\n",
    "    encoded3 = input3 + pos_enc3\n",
    "\n",
    "    # Encoder para la primera secuencia\n",
    "    encoder1 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded1, encoded1)\n",
    "    encoder1 = LayerNormalization()(encoder1)\n",
    "    encoder1 = Dropout(0.5)(encoder1)\n",
    "\n",
    "    # Encoder para la segunda secuencia\n",
    "    encoder2 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded2, encoded2)\n",
    "    encoder2 = LayerNormalization()(encoder2)\n",
    "    encoder2 = Dropout(0.5)(encoder2)\n",
    "\n",
    "    # Encoder para la tercera secuencia\n",
    "    encoder3 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded3, encoded3)\n",
    "    encoder3 = LayerNormalization()(encoder3)\n",
    "    encoder3 = Dropout(0.5)(encoder3)\n",
    "\n",
    "    # Reducir las dimensiones de las secuencias\n",
    "    reduced1 = GlobalAveragePooling1D()(encoder1)\n",
    "    reduced2 = GlobalAveragePooling1D()(encoder2)\n",
    "    reduced3 = GlobalAveragePooling1D()(encoder3)\n",
    "\n",
    "    # Concatenar las secuencias reducidas\n",
    "    merged_encoded = Concatenate(axis=-1)([reduced1, reduced2, reduced3])\n",
    "\n",
    "    # Capa Bottleneck\n",
    "    bottleneck = Dropout(0.5)(merged_encoded)\n",
    "\n",
    "    # Capas densas para clasificaci√≥n\n",
    "    dense = Dense(128, activation='relu')(bottleneck)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = Model(inputs=[input1, input2, input3], outputs=output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = getModelHAR()\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "386cb41e-bb1e-4043-b002-ea2c550f5dbd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a216fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 19909\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_199 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_200 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_201 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 8, 45)       0           ['input_199[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 8, 45)       0           ['input_200[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 11, 45)      0           ['input_201[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_100 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_27[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_101 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_28[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_102 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_29[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_89 (LayerN  (None, 8, 45)       90          ['multi_head_attention_100[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_90 (LayerN  (None, 8, 45)       90          ['multi_head_attention_101[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_91 (LayerN  (None, 11, 45)      90          ['multi_head_attention_102[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " dropout_134 (Dropout)          (None, 8, 45)        0           ['layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_135 (Dropout)          (None, 8, 45)        0           ['layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 11, 45)       0           ['layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_34 (G  (None, 45)          0           ['dropout_134[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_35 (G  (None, 45)          0           ['dropout_135[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_36 (G  (None, 45)          0           ['dropout_136[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_34[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_35[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_36[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 135)          0           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 128)          17408       ['dropout_137[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 128)          0           ['dense_68[0][0]']               \n",
      "                                                                                                  \n",
      " dense_69 (Dense)               (None, 1)            129         ['dropout_138[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:34:49.563434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-11-27 13:34:49.600818: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f8af4863f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-27 13:34:49.600872: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-11-27 13:34:49.613059: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-27 13:34:49.821684: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 17s 14ms/step - loss: 0.2377 - accuracy: 0.8942 - val_loss: 0.0423 - val_accuracy: 0.9883\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0680 - accuracy: 0.9769 - val_loss: 0.0287 - val_accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0474 - accuracy: 0.9836 - val_loss: 0.0159 - val_accuracy: 0.9945\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 0.0345 - val_accuracy: 0.9871\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0275 - val_accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.0567 - val_accuracy: 0.9861\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0289 - accuracy: 0.9898 - val_loss: 0.0325 - val_accuracy: 0.9904\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0273 - accuracy: 0.9895 - val_loss: 0.0186 - val_accuracy: 0.9959\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0231 - accuracy: 0.9913 - val_loss: 0.0151 - val_accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.0233 - val_accuracy: 0.9933\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_202 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_203 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_204 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 8, 45)       0           ['input_202[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 8, 45)       0           ['input_203[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 11, 45)      0           ['input_204[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_103 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_30[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_104 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_31[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_31[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_105 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_32[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_92 (LayerN  (None, 8, 45)       90          ['multi_head_attention_103[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_93 (LayerN  (None, 8, 45)       90          ['multi_head_attention_104[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_94 (LayerN  (None, 11, 45)      90          ['multi_head_attention_105[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 8, 45)        0           ['layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 8, 45)        0           ['layer_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 11, 45)       0           ['layer_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_37 (G  (None, 45)          0           ['dropout_139[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_38 (G  (None, 45)          0           ['dropout_140[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_39 (G  (None, 45)          0           ['dropout_141[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_37[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_38[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_39[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 135)          0           ['concatenate_26[0][0]']         \n",
      "                                                                                                  \n",
      " dense_70 (Dense)               (None, 128)          17408       ['dropout_142[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 128)          0           ['dense_70[0][0]']               \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 1)            129         ['dropout_143[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 13ms/step - loss: 0.2693 - accuracy: 0.8699 - val_loss: 0.3794 - val_accuracy: 0.8867\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1105 - accuracy: 0.9594 - val_loss: 0.2296 - val_accuracy: 0.8910\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0896 - accuracy: 0.9666 - val_loss: 0.3553 - val_accuracy: 0.8808\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0791 - accuracy: 0.9711 - val_loss: 0.3632 - val_accuracy: 0.8729\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0668 - accuracy: 0.9767 - val_loss: 0.3775 - val_accuracy: 0.8858\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0622 - accuracy: 0.9781 - val_loss: 0.3575 - val_accuracy: 0.8982\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0594 - accuracy: 0.9794 - val_loss: 0.2483 - val_accuracy: 0.8975\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0537 - accuracy: 0.9816 - val_loss: 0.4362 - val_accuracy: 0.8939\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.4807 - val_accuracy: 0.8898\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0471 - accuracy: 0.9830 - val_loss: 0.4193 - val_accuracy: 0.8805\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_205 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_206 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_207 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 8, 45)       0           ['input_205[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 8, 45)       0           ['input_206[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 11, 45)      0           ['input_207[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_106 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_33[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_107 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_34[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_108 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_35[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_95 (LayerN  (None, 8, 45)       90          ['multi_head_attention_106[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_96 (LayerN  (None, 8, 45)       90          ['multi_head_attention_107[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_97 (LayerN  (None, 11, 45)      90          ['multi_head_attention_108[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " dropout_144 (Dropout)          (None, 8, 45)        0           ['layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_145 (Dropout)          (None, 8, 45)        0           ['layer_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 11, 45)       0           ['layer_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_40 (G  (None, 45)          0           ['dropout_144[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_41 (G  (None, 45)          0           ['dropout_145[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_42 (G  (None, 45)          0           ['dropout_146[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_40[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_41[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_42[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 135)          0           ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      " dense_72 (Dense)               (None, 128)          17408       ['dropout_147[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_148 (Dropout)          (None, 128)          0           ['dense_72[0][0]']               \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 1)            129         ['dropout_148[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 14ms/step - loss: 0.2374 - accuracy: 0.9019 - val_loss: 0.0517 - val_accuracy: 0.9943\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.1161 - accuracy: 0.9709 - val_loss: 0.0359 - val_accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.1054 - accuracy: 0.9720 - val_loss: 0.0519 - val_accuracy: 0.9962\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0997 - accuracy: 0.9726 - val_loss: 0.0396 - val_accuracy: 0.9952\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0935 - accuracy: 0.9740 - val_loss: 0.0314 - val_accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0893 - accuracy: 0.9740 - val_loss: 0.0453 - val_accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0930 - accuracy: 0.9741 - val_loss: 0.0216 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0757 - accuracy: 0.9759 - val_loss: 0.0391 - val_accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0725 - accuracy: 0.9761 - val_loss: 0.0309 - val_accuracy: 0.9943\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0694 - accuracy: 0.9757 - val_loss: 0.0450 - val_accuracy: 0.9943\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_208 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_209 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_210 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (TFOpL  (None, 8, 45)       0           ['input_208[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (TFOpL  (None, 8, 45)       0           ['input_209[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (TFOpL  (None, 11, 45)      0           ['input_210[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_109 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_36[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_36[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_110 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_37[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_37[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_111 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_38[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_38[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_98 (LayerN  (None, 8, 45)       90          ['multi_head_attention_109[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_99 (LayerN  (None, 8, 45)       90          ['multi_head_attention_110[0][0]'\n",
      " ormalization)                                                   ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_100 (Layer  (None, 11, 45)      90          ['multi_head_attention_111[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_149 (Dropout)          (None, 8, 45)        0           ['layer_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_150 (Dropout)          (None, 8, 45)        0           ['layer_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_151 (Dropout)          (None, 11, 45)       0           ['layer_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_43 (G  (None, 45)          0           ['dropout_149[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_44 (G  (None, 45)          0           ['dropout_150[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_45 (G  (None, 45)          0           ['dropout_151[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_43[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_44[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_45[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_152 (Dropout)          (None, 135)          0           ['concatenate_28[0][0]']         \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 128)          17408       ['dropout_152[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_153 (Dropout)          (None, 128)          0           ['dense_74[0][0]']               \n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 1)            129         ['dropout_153[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 14ms/step - loss: 0.1917 - accuracy: 0.9159 - val_loss: 0.0541 - val_accuracy: 0.9830\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0667 - accuracy: 0.9793 - val_loss: 0.0475 - val_accuracy: 0.9873\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0549 - accuracy: 0.9838 - val_loss: 0.0393 - val_accuracy: 0.9845\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0422 - accuracy: 0.9862 - val_loss: 0.0264 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0421 - accuracy: 0.9866 - val_loss: 0.0257 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0347 - accuracy: 0.9886 - val_loss: 0.0471 - val_accuracy: 0.9876\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 0.0352 - val_accuracy: 0.9873\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.0428 - val_accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0345 - val_accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0278 - accuracy: 0.9903 - val_loss: 0.0415 - val_accuracy: 0.9878\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_211 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_212 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_213 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (TFOpL  (None, 8, 45)       0           ['input_211[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (TFOpL  (None, 8, 45)       0           ['input_212[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (TFOpL  (None, 11, 45)      0           ['input_213[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_112 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_39[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_39[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_113 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_40[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_40[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_114 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_41[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_41[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_101 (Layer  (None, 8, 45)       90          ['multi_head_attention_112[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_102 (Layer  (None, 8, 45)       90          ['multi_head_attention_113[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_103 (Layer  (None, 11, 45)      90          ['multi_head_attention_114[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_154 (Dropout)          (None, 8, 45)        0           ['layer_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " dropout_155 (Dropout)          (None, 8, 45)        0           ['layer_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " dropout_156 (Dropout)          (None, 11, 45)       0           ['layer_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_46 (G  (None, 45)          0           ['dropout_154[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_47 (G  (None, 45)          0           ['dropout_155[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_48 (G  (None, 45)          0           ['dropout_156[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_46[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_47[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_48[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_157 (Dropout)          (None, 135)          0           ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 128)          17408       ['dropout_157[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_158 (Dropout)          (None, 128)          0           ['dense_76[0][0]']               \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 1)            129         ['dropout_158[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 14ms/step - loss: 0.0981 - accuracy: 0.9601 - val_loss: 0.0234 - val_accuracy: 0.9952\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 0.0194 - val_accuracy: 0.9957\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.0213 - val_accuracy: 0.9947\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.0098 - val_accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.0173 - val_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.0079 - val_accuracy: 0.9983\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0056 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0122 - val_accuracy: 0.9978\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_214 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_215 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_216 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (TFOpL  (None, 8, 45)       0           ['input_214[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (TFOpL  (None, 8, 45)       0           ['input_215[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  (None, 11, 45)      0           ['input_216[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_115 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_42[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_42[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_116 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_43[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_43[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_117 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_44[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_104 (Layer  (None, 8, 45)       90          ['multi_head_attention_115[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_105 (Layer  (None, 8, 45)       90          ['multi_head_attention_116[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_106 (Layer  (None, 11, 45)      90          ['multi_head_attention_117[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_159 (Dropout)          (None, 8, 45)        0           ['layer_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " dropout_160 (Dropout)          (None, 8, 45)        0           ['layer_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " dropout_161 (Dropout)          (None, 11, 45)       0           ['layer_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_49 (G  (None, 45)          0           ['dropout_159[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_50 (G  (None, 45)          0           ['dropout_160[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_51 (G  (None, 45)          0           ['dropout_161[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_49[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_50[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_51[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_162 (Dropout)          (None, 135)          0           ['concatenate_30[0][0]']         \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 128)          17408       ['dropout_162[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_163 (Dropout)          (None, 128)          0           ['dense_78[0][0]']               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 1)            129         ['dropout_163[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 14ms/step - loss: 0.1102 - accuracy: 0.9578 - val_loss: 0.0141 - val_accuracy: 0.9957\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0185 - val_accuracy: 0.9955\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0132 - val_accuracy: 0.9952\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.0136 - val_accuracy: 0.9964\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.0163 - val_accuracy: 0.9959\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.0089 - val_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.0380 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.0304 - val_accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0071 - val_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0132 - val_accuracy: 0.9947\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_217 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_218 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_219 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (TFOpL  (None, 8, 45)       0           ['input_217[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_46 (TFOpL  (None, 8, 45)       0           ['input_218[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (TFOpL  (None, 11, 45)      0           ['input_219[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_118 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_45[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_45[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_119 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_46[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_46[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_120 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_47[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_47[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_107 (Layer  (None, 8, 45)       90          ['multi_head_attention_118[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_108 (Layer  (None, 8, 45)       90          ['multi_head_attention_119[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_109 (Layer  (None, 11, 45)      90          ['multi_head_attention_120[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_164 (Dropout)          (None, 8, 45)        0           ['layer_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " dropout_165 (Dropout)          (None, 8, 45)        0           ['layer_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " dropout_166 (Dropout)          (None, 11, 45)       0           ['layer_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_52 (G  (None, 45)          0           ['dropout_164[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_53 (G  (None, 45)          0           ['dropout_165[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_54 (G  (None, 45)          0           ['dropout_166[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_52[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_53[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_54[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_167 (Dropout)          (None, 135)          0           ['concatenate_31[0][0]']         \n",
      "                                                                                                  \n",
      " dense_80 (Dense)               (None, 128)          17408       ['dropout_167[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_168 (Dropout)          (None, 128)          0           ['dense_80[0][0]']               \n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 1)            129         ['dropout_168[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 14ms/step - loss: 0.1847 - accuracy: 0.9301 - val_loss: 0.0254 - val_accuracy: 0.9938\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1051 - accuracy: 0.9728 - val_loss: 0.0340 - val_accuracy: 0.9955\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0991 - accuracy: 0.9737 - val_loss: 0.0251 - val_accuracy: 0.9909\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0966 - accuracy: 0.9740 - val_loss: 0.0773 - val_accuracy: 0.9732\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0879 - accuracy: 0.9757 - val_loss: 0.0169 - val_accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0835 - accuracy: 0.9761 - val_loss: 0.0256 - val_accuracy: 0.9931\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0837 - accuracy: 0.9752 - val_loss: 0.0524 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0771 - accuracy: 0.9769 - val_loss: 0.0189 - val_accuracy: 0.9950\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0767 - accuracy: 0.9768 - val_loss: 0.0383 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0740 - accuracy: 0.9771 - val_loss: 0.0162 - val_accuracy: 0.9964\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_220 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_221 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_222 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_48 (TFOpL  (None, 8, 45)       0           ['input_220[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_49 (TFOpL  (None, 8, 45)       0           ['input_221[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (TFOpL  (None, 11, 45)      0           ['input_222[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_121 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_48[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_48[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_122 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_49[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_49[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_123 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_50[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_50[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_110 (Layer  (None, 8, 45)       90          ['multi_head_attention_121[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_111 (Layer  (None, 8, 45)       90          ['multi_head_attention_122[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_112 (Layer  (None, 11, 45)      90          ['multi_head_attention_123[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_169 (Dropout)          (None, 8, 45)        0           ['layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " dropout_170 (Dropout)          (None, 8, 45)        0           ['layer_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " dropout_171 (Dropout)          (None, 11, 45)       0           ['layer_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_55 (G  (None, 45)          0           ['dropout_169[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_56 (G  (None, 45)          0           ['dropout_170[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_57 (G  (None, 45)          0           ['dropout_171[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_55[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_56[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_172 (Dropout)          (None, 135)          0           ['concatenate_32[0][0]']         \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 128)          17408       ['dropout_172[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_173 (Dropout)          (None, 128)          0           ['dense_82[0][0]']               \n",
      "                                                                                                  \n",
      " dense_83 (Dense)               (None, 1)            129         ['dropout_173[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 14ms/step - loss: 0.2653 - accuracy: 0.8879 - val_loss: 0.1161 - val_accuracy: 0.9369\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1215 - accuracy: 0.9556 - val_loss: 0.1015 - val_accuracy: 0.9599\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0969 - accuracy: 0.9669 - val_loss: 0.1073 - val_accuracy: 0.9685\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0844 - accuracy: 0.9712 - val_loss: 0.1000 - val_accuracy: 0.9735\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0794 - accuracy: 0.9730 - val_loss: 0.1130 - val_accuracy: 0.9697\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0707 - accuracy: 0.9769 - val_loss: 0.0805 - val_accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 0.0979 - val_accuracy: 0.9749\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0623 - accuracy: 0.9789 - val_loss: 0.1204 - val_accuracy: 0.9754\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0620 - accuracy: 0.9796 - val_loss: 0.1160 - val_accuracy: 0.9713\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0568 - accuracy: 0.9807 - val_loss: 0.1087 - val_accuracy: 0.9756\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 1 19910\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_223 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_224 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_225 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_51 (TFOpL  (None, 8, 45)       0           ['input_223[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_52 (TFOpL  (None, 8, 45)       0           ['input_224[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_53 (TFOpL  (None, 11, 45)      0           ['input_225[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_124 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_51[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_51[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_125 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_52[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_52[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_126 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_53[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_53[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_113 (Layer  (None, 8, 45)       90          ['multi_head_attention_124[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_114 (Layer  (None, 8, 45)       90          ['multi_head_attention_125[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_115 (Layer  (None, 11, 45)      90          ['multi_head_attention_126[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_174 (Dropout)          (None, 8, 45)        0           ['layer_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " dropout_175 (Dropout)          (None, 8, 45)        0           ['layer_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " dropout_176 (Dropout)          (None, 11, 45)       0           ['layer_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_58 (G  (None, 45)          0           ['dropout_174[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_59 (G  (None, 45)          0           ['dropout_175[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_60 (G  (None, 45)          0           ['dropout_176[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_58[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_59[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_60[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_177 (Dropout)          (None, 135)          0           ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " dense_84 (Dense)               (None, 128)          17408       ['dropout_177[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_178 (Dropout)          (None, 128)          0           ['dense_84[0][0]']               \n",
      "                                                                                                  \n",
      " dense_85 (Dense)               (None, 1)            129         ['dropout_178[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 14ms/step - loss: 0.2289 - accuracy: 0.9013 - val_loss: 0.0432 - val_accuracy: 0.9888\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0781 - accuracy: 0.9767 - val_loss: 0.0087 - val_accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0562 - accuracy: 0.9798 - val_loss: 0.0328 - val_accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0443 - accuracy: 0.9843 - val_loss: 0.0208 - val_accuracy: 0.9924\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0398 - accuracy: 0.9856 - val_loss: 0.0167 - val_accuracy: 0.9924\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0319 - accuracy: 0.9890 - val_loss: 0.0145 - val_accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0305 - accuracy: 0.9891 - val_loss: 0.0204 - val_accuracy: 0.9947\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.0146 - val_accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.0516 - val_accuracy: 0.9852\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0286 - accuracy: 0.9909 - val_loss: 0.0354 - val_accuracy: 0.9935\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_226 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_227 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_228 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 8, 45)       0           ['input_226[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  (None, 8, 45)       0           ['input_227[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_56 (TFOpL  (None, 11, 45)      0           ['input_228[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_127 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_54[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_128 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_55[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_129 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_56[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_56[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_116 (Layer  (None, 8, 45)       90          ['multi_head_attention_127[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_117 (Layer  (None, 8, 45)       90          ['multi_head_attention_128[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_118 (Layer  (None, 11, 45)      90          ['multi_head_attention_129[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_179 (Dropout)          (None, 8, 45)        0           ['layer_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " dropout_180 (Dropout)          (None, 8, 45)        0           ['layer_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " dropout_181 (Dropout)          (None, 11, 45)       0           ['layer_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_61 (G  (None, 45)          0           ['dropout_179[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_62 (G  (None, 45)          0           ['dropout_180[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_63 (G  (None, 45)          0           ['dropout_181[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_61[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_62[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_63[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_182 (Dropout)          (None, 135)          0           ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 128)          17408       ['dropout_182[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_183 (Dropout)          (None, 128)          0           ['dense_86[0][0]']               \n",
      "                                                                                                  \n",
      " dense_87 (Dense)               (None, 1)            129         ['dropout_183[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3061 - accuracy: 0.8479 - val_loss: 0.0640 - val_accuracy: 0.9732\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1380 - accuracy: 0.9398 - val_loss: 0.0437 - val_accuracy: 0.9823\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.1205 - accuracy: 0.9491 - val_loss: 0.0449 - val_accuracy: 0.9818\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1146 - accuracy: 0.9507 - val_loss: 0.0292 - val_accuracy: 0.9924\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1045 - accuracy: 0.9559 - val_loss: 0.0463 - val_accuracy: 0.9849\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0972 - accuracy: 0.9597 - val_loss: 0.0225 - val_accuracy: 0.9957\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0932 - accuracy: 0.9607 - val_loss: 0.0137 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0828 - accuracy: 0.9666 - val_loss: 0.0512 - val_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0822 - accuracy: 0.9660 - val_loss: 0.0246 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0757 - accuracy: 0.9701 - val_loss: 0.0277 - val_accuracy: 0.9895\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_229 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_230 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_231 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_57 (TFOpL  (None, 8, 45)       0           ['input_229[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_58 (TFOpL  (None, 8, 45)       0           ['input_230[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_59 (TFOpL  (None, 11, 45)      0           ['input_231[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_130 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_57[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_57[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_131 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_58[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_58[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_132 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_59[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_59[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_119 (Layer  (None, 8, 45)       90          ['multi_head_attention_130[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_120 (Layer  (None, 8, 45)       90          ['multi_head_attention_131[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_121 (Layer  (None, 11, 45)      90          ['multi_head_attention_132[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_184 (Dropout)          (None, 8, 45)        0           ['layer_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " dropout_185 (Dropout)          (None, 8, 45)        0           ['layer_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " dropout_186 (Dropout)          (None, 11, 45)       0           ['layer_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_64 (G  (None, 45)          0           ['dropout_184[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_65 (G  (None, 45)          0           ['dropout_185[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_66 (G  (None, 45)          0           ['dropout_186[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_64[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_65[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_66[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_187 (Dropout)          (None, 135)          0           ['concatenate_35[0][0]']         \n",
      "                                                                                                  \n",
      " dense_88 (Dense)               (None, 128)          17408       ['dropout_187[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_188 (Dropout)          (None, 128)          0           ['dense_88[0][0]']               \n",
      "                                                                                                  \n",
      " dense_89 (Dense)               (None, 1)            129         ['dropout_188[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 14ms/step - loss: 0.2056 - accuracy: 0.9208 - val_loss: 0.4269 - val_accuracy: 0.8781\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0973 - accuracy: 0.9785 - val_loss: 0.4491 - val_accuracy: 0.8796\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0862 - accuracy: 0.9798 - val_loss: 0.5250 - val_accuracy: 0.8779\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0784 - accuracy: 0.9803 - val_loss: 0.3722 - val_accuracy: 0.8796\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0731 - accuracy: 0.9815 - val_loss: 0.4608 - val_accuracy: 0.8793\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0682 - accuracy: 0.9822 - val_loss: 0.3972 - val_accuracy: 0.8796\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0625 - accuracy: 0.9821 - val_loss: 0.5135 - val_accuracy: 0.8793\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0571 - accuracy: 0.9823 - val_loss: 0.4186 - val_accuracy: 0.8774\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0540 - accuracy: 0.9829 - val_loss: 0.4099 - val_accuracy: 0.8779\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0511 - accuracy: 0.9839 - val_loss: 0.3653 - val_accuracy: 0.8789\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_232 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_233 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_234 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_60 (TFOpL  (None, 8, 45)       0           ['input_232[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_61 (TFOpL  (None, 8, 45)       0           ['input_233[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_62 (TFOpL  (None, 11, 45)      0           ['input_234[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_133 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_60[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_60[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_134 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_61[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_61[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_135 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_62[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_62[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_122 (Layer  (None, 8, 45)       90          ['multi_head_attention_133[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_123 (Layer  (None, 8, 45)       90          ['multi_head_attention_134[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_124 (Layer  (None, 11, 45)      90          ['multi_head_attention_135[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_189 (Dropout)          (None, 8, 45)        0           ['layer_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " dropout_190 (Dropout)          (None, 8, 45)        0           ['layer_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " dropout_191 (Dropout)          (None, 11, 45)       0           ['layer_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_67 (G  (None, 45)          0           ['dropout_189[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_68 (G  (None, 45)          0           ['dropout_190[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_69 (G  (None, 45)          0           ['dropout_191[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_67[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_68[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_69[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_192 (Dropout)          (None, 135)          0           ['concatenate_36[0][0]']         \n",
      "                                                                                                  \n",
      " dense_90 (Dense)               (None, 128)          17408       ['dropout_192[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_193 (Dropout)          (None, 128)          0           ['dense_90[0][0]']               \n",
      "                                                                                                  \n",
      " dense_91 (Dense)               (None, 1)            129         ['dropout_193[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 13ms/step - loss: 0.1779 - accuracy: 0.9257 - val_loss: 0.1303 - val_accuracy: 0.9673\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0664 - accuracy: 0.9799 - val_loss: 0.0293 - val_accuracy: 0.9907\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0541 - accuracy: 0.9847 - val_loss: 0.0327 - val_accuracy: 0.9924\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0491 - accuracy: 0.9861 - val_loss: 0.0362 - val_accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.0424 - accuracy: 0.9882 - val_loss: 0.0339 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0250 - val_accuracy: 0.9938\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0325 - accuracy: 0.9901 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.0350 - val_accuracy: 0.9921\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.0326 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0421 - val_accuracy: 0.9904\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_235 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_236 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_237 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_63 (TFOpL  (None, 8, 45)       0           ['input_235[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_64 (TFOpL  (None, 8, 45)       0           ['input_236[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_65 (TFOpL  (None, 11, 45)      0           ['input_237[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_136 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_63[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_63[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_137 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_64[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_64[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_138 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_65[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_65[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_125 (Layer  (None, 8, 45)       90          ['multi_head_attention_136[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_126 (Layer  (None, 8, 45)       90          ['multi_head_attention_137[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_127 (Layer  (None, 11, 45)      90          ['multi_head_attention_138[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_194 (Dropout)          (None, 8, 45)        0           ['layer_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " dropout_195 (Dropout)          (None, 8, 45)        0           ['layer_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " dropout_196 (Dropout)          (None, 11, 45)       0           ['layer_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_70 (G  (None, 45)          0           ['dropout_194[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_71 (G  (None, 45)          0           ['dropout_195[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_72 (G  (None, 45)          0           ['dropout_196[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_70[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_71[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_72[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_197 (Dropout)          (None, 135)          0           ['concatenate_37[0][0]']         \n",
      "                                                                                                  \n",
      " dense_92 (Dense)               (None, 128)          17408       ['dropout_197[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_198 (Dropout)          (None, 128)          0           ['dense_92[0][0]']               \n",
      "                                                                                                  \n",
      " dense_93 (Dense)               (None, 1)            129         ['dropout_198[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.0999 - accuracy: 0.9576 - val_loss: 0.0123 - val_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0207 - accuracy: 0.9957 - val_loss: 0.0082 - val_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9971\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0121 - accuracy: 0.9975 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.0113 - val_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0046 - val_accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0054 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.0057 - val_accuracy: 0.9993\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_238 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_239 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_240 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_66 (TFOpL  (None, 8, 45)       0           ['input_238[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_67 (TFOpL  (None, 8, 45)       0           ['input_239[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (TFOpL  (None, 11, 45)      0           ['input_240[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_139 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_66[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_66[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_140 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_67[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_67[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_141 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_68[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_128 (Layer  (None, 8, 45)       90          ['multi_head_attention_139[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_129 (Layer  (None, 8, 45)       90          ['multi_head_attention_140[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_130 (Layer  (None, 11, 45)      90          ['multi_head_attention_141[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_199 (Dropout)          (None, 8, 45)        0           ['layer_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " dropout_200 (Dropout)          (None, 8, 45)        0           ['layer_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " dropout_201 (Dropout)          (None, 11, 45)       0           ['layer_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_73 (G  (None, 45)          0           ['dropout_199[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_74 (G  (None, 45)          0           ['dropout_200[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_75 (G  (None, 45)          0           ['dropout_201[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_73[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_74[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_75[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_202 (Dropout)          (None, 135)          0           ['concatenate_38[0][0]']         \n",
      "                                                                                                  \n",
      " dense_94 (Dense)               (None, 128)          17408       ['dropout_202[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_203 (Dropout)          (None, 128)          0           ['dense_94[0][0]']               \n",
      "                                                                                                  \n",
      " dense_95 (Dense)               (None, 1)            129         ['dropout_203[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.0915 - accuracy: 0.9658 - val_loss: 0.0575 - val_accuracy: 0.9900\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0249 - accuracy: 0.9946 - val_loss: 0.0344 - val_accuracy: 0.9888\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.0380 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0375 - val_accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.0397 - val_accuracy: 0.9924\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.0278 - val_accuracy: 0.9912\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.0328 - val_accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0398 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0377 - val_accuracy: 0.9919\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0412 - val_accuracy: 0.9919\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_241 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_242 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_243 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (TFOpL  (None, 8, 45)       0           ['input_241[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 8, 45)       0           ['input_242[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 11, 45)      0           ['input_243[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_142 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_69[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_143 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_70[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_144 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_71[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_71[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_131 (Layer  (None, 8, 45)       90          ['multi_head_attention_142[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_132 (Layer  (None, 8, 45)       90          ['multi_head_attention_143[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_133 (Layer  (None, 11, 45)      90          ['multi_head_attention_144[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_204 (Dropout)          (None, 8, 45)        0           ['layer_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " dropout_205 (Dropout)          (None, 8, 45)        0           ['layer_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " dropout_206 (Dropout)          (None, 11, 45)       0           ['layer_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_76 (G  (None, 45)          0           ['dropout_204[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_77 (G  (None, 45)          0           ['dropout_205[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_78 (G  (None, 45)          0           ['dropout_206[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_76[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_77[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_78[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_207 (Dropout)          (None, 135)          0           ['concatenate_39[0][0]']         \n",
      "                                                                                                  \n",
      " dense_96 (Dense)               (None, 128)          17408       ['dropout_207[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_208 (Dropout)          (None, 128)          0           ['dense_96[0][0]']               \n",
      "                                                                                                  \n",
      " dense_97 (Dense)               (None, 1)            129         ['dropout_208[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1623 - accuracy: 0.9374 - val_loss: 0.4196 - val_accuracy: 0.8760\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0829 - accuracy: 0.9803 - val_loss: 0.4292 - val_accuracy: 0.8736\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0757 - accuracy: 0.9813 - val_loss: 0.5084 - val_accuracy: 0.8633\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0688 - accuracy: 0.9820 - val_loss: 0.4425 - val_accuracy: 0.8762\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0676 - accuracy: 0.9825 - val_loss: 0.4503 - val_accuracy: 0.8729\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0657 - accuracy: 0.9827 - val_loss: 0.3655 - val_accuracy: 0.8743\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0616 - accuracy: 0.9839 - val_loss: 0.4846 - val_accuracy: 0.8736\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0587 - accuracy: 0.9842 - val_loss: 0.5409 - val_accuracy: 0.8753\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0559 - accuracy: 0.9849 - val_loss: 0.5153 - val_accuracy: 0.8784\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0536 - accuracy: 0.9843 - val_loss: 0.5119 - val_accuracy: 0.8765\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_244 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_245 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_246 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_72 (TFOpL  (None, 8, 45)       0           ['input_244[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_73 (TFOpL  (None, 8, 45)       0           ['input_245[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_74 (TFOpL  (None, 11, 45)      0           ['input_246[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_145 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_72[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_72[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_146 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_73[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_73[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_147 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_74[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_74[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_134 (Layer  (None, 8, 45)       90          ['multi_head_attention_145[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_135 (Layer  (None, 8, 45)       90          ['multi_head_attention_146[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_136 (Layer  (None, 11, 45)      90          ['multi_head_attention_147[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_209 (Dropout)          (None, 8, 45)        0           ['layer_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " dropout_210 (Dropout)          (None, 8, 45)        0           ['layer_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " dropout_211 (Dropout)          (None, 11, 45)       0           ['layer_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_79 (G  (None, 45)          0           ['dropout_209[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_80 (G  (None, 45)          0           ['dropout_210[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_81 (G  (None, 45)          0           ['dropout_211[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_79[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_80[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_81[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_212 (Dropout)          (None, 135)          0           ['concatenate_40[0][0]']         \n",
      "                                                                                                  \n",
      " dense_98 (Dense)               (None, 128)          17408       ['dropout_212[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_213 (Dropout)          (None, 128)          0           ['dense_98[0][0]']               \n",
      "                                                                                                  \n",
      " dense_99 (Dense)               (None, 1)            129         ['dropout_213[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2533 - accuracy: 0.8961 - val_loss: 0.0504 - val_accuracy: 0.9754\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1195 - accuracy: 0.9596 - val_loss: 0.0355 - val_accuracy: 0.9842\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1000 - accuracy: 0.9664 - val_loss: 0.0393 - val_accuracy: 0.9845\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0890 - accuracy: 0.9702 - val_loss: 0.0507 - val_accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0820 - accuracy: 0.9717 - val_loss: 0.0577 - val_accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0758 - accuracy: 0.9747 - val_loss: 0.0390 - val_accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0742 - accuracy: 0.9746 - val_loss: 0.0481 - val_accuracy: 0.9814\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0709 - accuracy: 0.9759 - val_loss: 0.0471 - val_accuracy: 0.9845\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 0.0455 - val_accuracy: 0.9823\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0679 - accuracy: 0.9772 - val_loss: 0.0416 - val_accuracy: 0.9864\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 2 19911\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_247 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_248 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_249 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_75 (TFOpL  (None, 8, 45)       0           ['input_247[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_76 (TFOpL  (None, 8, 45)       0           ['input_248[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_77 (TFOpL  (None, 11, 45)      0           ['input_249[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_148 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_75[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_75[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_149 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_76[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_76[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_150 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_77[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_77[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_137 (Layer  (None, 8, 45)       90          ['multi_head_attention_148[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_138 (Layer  (None, 8, 45)       90          ['multi_head_attention_149[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_139 (Layer  (None, 11, 45)      90          ['multi_head_attention_150[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_214 (Dropout)          (None, 8, 45)        0           ['layer_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " dropout_215 (Dropout)          (None, 8, 45)        0           ['layer_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " dropout_216 (Dropout)          (None, 11, 45)       0           ['layer_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_82 (G  (None, 45)          0           ['dropout_214[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_83 (G  (None, 45)          0           ['dropout_215[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_84 (G  (None, 45)          0           ['dropout_216[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_82[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_83[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_84[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_217 (Dropout)          (None, 135)          0           ['concatenate_41[0][0]']         \n",
      "                                                                                                  \n",
      " dense_100 (Dense)              (None, 128)          17408       ['dropout_217[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_218 (Dropout)          (None, 128)          0           ['dense_100[0][0]']              \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 1)            129         ['dropout_218[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2067 - accuracy: 0.9121 - val_loss: 0.0673 - val_accuracy: 0.9840\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 0.0387 - val_accuracy: 0.9890\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0517 - accuracy: 0.9821 - val_loss: 0.0409 - val_accuracy: 0.9885\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0364 - accuracy: 0.9875 - val_loss: 0.0336 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0367 - accuracy: 0.9864 - val_loss: 0.0336 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0364 - val_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0275 - accuracy: 0.9900 - val_loss: 0.0395 - val_accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0290 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.0536 - val_accuracy: 0.9892\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0507 - val_accuracy: 0.9842\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_250 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_251 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_252 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_78 (TFOpL  (None, 8, 45)       0           ['input_250[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_79 (TFOpL  (None, 8, 45)       0           ['input_251[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_80 (TFOpL  (None, 11, 45)      0           ['input_252[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_151 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_78[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_78[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_152 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_79[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_79[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_153 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_80[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_80[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_140 (Layer  (None, 8, 45)       90          ['multi_head_attention_151[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_141 (Layer  (None, 8, 45)       90          ['multi_head_attention_152[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_142 (Layer  (None, 11, 45)      90          ['multi_head_attention_153[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_219 (Dropout)          (None, 8, 45)        0           ['layer_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " dropout_220 (Dropout)          (None, 8, 45)        0           ['layer_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " dropout_221 (Dropout)          (None, 11, 45)       0           ['layer_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_85 (G  (None, 45)          0           ['dropout_219[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_86 (G  (None, 45)          0           ['dropout_220[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_87 (G  (None, 45)          0           ['dropout_221[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_85[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_86[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_87[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_222 (Dropout)          (None, 135)          0           ['concatenate_42[0][0]']         \n",
      "                                                                                                  \n",
      " dense_102 (Dense)              (None, 128)          17408       ['dropout_222[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_223 (Dropout)          (None, 128)          0           ['dense_102[0][0]']              \n",
      "                                                                                                  \n",
      " dense_103 (Dense)              (None, 1)            129         ['dropout_223[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.3556 - accuracy: 0.8127 - val_loss: 0.1065 - val_accuracy: 0.9553\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1391 - accuracy: 0.9380 - val_loss: 0.1037 - val_accuracy: 0.9529\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1210 - accuracy: 0.9489 - val_loss: 0.0899 - val_accuracy: 0.9673\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1088 - accuracy: 0.9540 - val_loss: 0.1192 - val_accuracy: 0.9532\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0995 - accuracy: 0.9595 - val_loss: 0.1070 - val_accuracy: 0.9670\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0932 - accuracy: 0.9631 - val_loss: 0.1309 - val_accuracy: 0.9642\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0829 - accuracy: 0.9663 - val_loss: 0.1250 - val_accuracy: 0.9603\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0830 - accuracy: 0.9686 - val_loss: 0.0974 - val_accuracy: 0.9670\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0747 - accuracy: 0.9722 - val_loss: 0.1757 - val_accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0717 - accuracy: 0.9723 - val_loss: 0.1209 - val_accuracy: 0.9682\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_253 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_254 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_255 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_81 (TFOpL  (None, 8, 45)       0           ['input_253[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_82 (TFOpL  (None, 8, 45)       0           ['input_254[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_83 (TFOpL  (None, 11, 45)      0           ['input_255[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_154 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_81[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_81[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_155 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_82[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_82[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_156 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_83[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_83[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_143 (Layer  (None, 8, 45)       90          ['multi_head_attention_154[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_144 (Layer  (None, 8, 45)       90          ['multi_head_attention_155[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_145 (Layer  (None, 11, 45)      90          ['multi_head_attention_156[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_224 (Dropout)          (None, 8, 45)        0           ['layer_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " dropout_225 (Dropout)          (None, 8, 45)        0           ['layer_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " dropout_226 (Dropout)          (None, 11, 45)       0           ['layer_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_88 (G  (None, 45)          0           ['dropout_224[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_89 (G  (None, 45)          0           ['dropout_225[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_90 (G  (None, 45)          0           ['dropout_226[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_88[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_89[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_90[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_227 (Dropout)          (None, 135)          0           ['concatenate_43[0][0]']         \n",
      "                                                                                                  \n",
      " dense_104 (Dense)              (None, 128)          17408       ['dropout_227[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_228 (Dropout)          (None, 128)          0           ['dense_104[0][0]']              \n",
      "                                                                                                  \n",
      " dense_105 (Dense)              (None, 1)            129         ['dropout_228[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1592 - accuracy: 0.9424 - val_loss: 0.6752 - val_accuracy: 0.8378\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0725 - accuracy: 0.9834 - val_loss: 0.6275 - val_accuracy: 0.8406\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0703 - accuracy: 0.9832 - val_loss: 0.6682 - val_accuracy: 0.8394\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0628 - accuracy: 0.9855 - val_loss: 0.6247 - val_accuracy: 0.8404\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0601 - accuracy: 0.9859 - val_loss: 0.6905 - val_accuracy: 0.8387\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0583 - accuracy: 0.9866 - val_loss: 0.5711 - val_accuracy: 0.8394\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0552 - accuracy: 0.9864 - val_loss: 0.6414 - val_accuracy: 0.8411\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0542 - accuracy: 0.9866 - val_loss: 0.8573 - val_accuracy: 0.8404\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0500 - accuracy: 0.9875 - val_loss: 1.0422 - val_accuracy: 0.8401\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0491 - accuracy: 0.9881 - val_loss: 0.7421 - val_accuracy: 0.8349\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_256 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_257 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_258 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_84 (TFOpL  (None, 8, 45)       0           ['input_256[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_85 (TFOpL  (None, 8, 45)       0           ['input_257[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_86 (TFOpL  (None, 11, 45)      0           ['input_258[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_157 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_84[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_84[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_158 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_85[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_85[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_159 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_86[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_86[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_146 (Layer  (None, 8, 45)       90          ['multi_head_attention_157[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_147 (Layer  (None, 8, 45)       90          ['multi_head_attention_158[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_148 (Layer  (None, 11, 45)      90          ['multi_head_attention_159[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_229 (Dropout)          (None, 8, 45)        0           ['layer_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " dropout_230 (Dropout)          (None, 8, 45)        0           ['layer_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " dropout_231 (Dropout)          (None, 11, 45)       0           ['layer_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_91 (G  (None, 45)          0           ['dropout_229[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_92 (G  (None, 45)          0           ['dropout_230[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_93 (G  (None, 45)          0           ['dropout_231[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_91[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_92[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_93[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_232 (Dropout)          (None, 135)          0           ['concatenate_44[0][0]']         \n",
      "                                                                                                  \n",
      " dense_106 (Dense)              (None, 128)          17408       ['dropout_232[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_233 (Dropout)          (None, 128)          0           ['dense_106[0][0]']              \n",
      "                                                                                                  \n",
      " dense_107 (Dense)              (None, 1)            129         ['dropout_233[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1822 - accuracy: 0.9237 - val_loss: 0.0568 - val_accuracy: 0.9835\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0650 - accuracy: 0.9815 - val_loss: 0.0604 - val_accuracy: 0.9840\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0502 - accuracy: 0.9852 - val_loss: 0.0561 - val_accuracy: 0.9811\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0477 - accuracy: 0.9863 - val_loss: 0.0497 - val_accuracy: 0.9838\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0420 - accuracy: 0.9871 - val_loss: 0.0524 - val_accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.0730 - val_accuracy: 0.9795\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0376 - val_accuracy: 0.9845\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.0684 - val_accuracy: 0.9830\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0313 - accuracy: 0.9901 - val_loss: 0.0584 - val_accuracy: 0.9847\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.0480 - val_accuracy: 0.9859\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_259 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_260 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_261 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_87 (TFOpL  (None, 8, 45)       0           ['input_259[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_88 (TFOpL  (None, 8, 45)       0           ['input_260[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_89 (TFOpL  (None, 11, 45)      0           ['input_261[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_160 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_87[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_87[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_161 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_88[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_88[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_162 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_89[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_89[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_149 (Layer  (None, 8, 45)       90          ['multi_head_attention_160[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_150 (Layer  (None, 8, 45)       90          ['multi_head_attention_161[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_151 (Layer  (None, 11, 45)      90          ['multi_head_attention_162[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_234 (Dropout)          (None, 8, 45)        0           ['layer_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " dropout_235 (Dropout)          (None, 8, 45)        0           ['layer_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " dropout_236 (Dropout)          (None, 11, 45)       0           ['layer_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_94 (G  (None, 45)          0           ['dropout_234[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_95 (G  (None, 45)          0           ['dropout_235[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_96 (G  (None, 45)          0           ['dropout_236[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_45 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_94[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_95[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_96[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_237 (Dropout)          (None, 135)          0           ['concatenate_45[0][0]']         \n",
      "                                                                                                  \n",
      " dense_108 (Dense)              (None, 128)          17408       ['dropout_237[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_238 (Dropout)          (None, 128)          0           ['dense_108[0][0]']              \n",
      "                                                                                                  \n",
      " dense_109 (Dense)              (None, 1)            129         ['dropout_238[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.0900 - accuracy: 0.9626 - val_loss: 0.0302 - val_accuracy: 0.9943\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0165 - accuracy: 0.9968 - val_loss: 0.0312 - val_accuracy: 0.9940\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0388 - val_accuracy: 0.9945\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0297 - val_accuracy: 0.9955\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0368 - val_accuracy: 0.9957\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0258 - val_accuracy: 0.9967\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0520 - val_accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0271 - val_accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0317 - val_accuracy: 0.9938\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0364 - val_accuracy: 0.9964\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_262 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_263 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_264 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_90 (TFOpL  (None, 8, 45)       0           ['input_262[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_91 (TFOpL  (None, 8, 45)       0           ['input_263[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_92 (TFOpL  (None, 11, 45)      0           ['input_264[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_163 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_90[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_90[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_164 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_91[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_91[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_165 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_92[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_92[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_152 (Layer  (None, 8, 45)       90          ['multi_head_attention_163[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_153 (Layer  (None, 8, 45)       90          ['multi_head_attention_164[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_154 (Layer  (None, 11, 45)      90          ['multi_head_attention_165[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_239 (Dropout)          (None, 8, 45)        0           ['layer_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " dropout_240 (Dropout)          (None, 8, 45)        0           ['layer_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " dropout_241 (Dropout)          (None, 11, 45)       0           ['layer_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_97 (G  (None, 45)          0           ['dropout_239[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_98 (G  (None, 45)          0           ['dropout_240[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_99 (G  (None, 45)          0           ['dropout_241[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_46 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_97[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_98[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_99[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_242 (Dropout)          (None, 135)          0           ['concatenate_46[0][0]']         \n",
      "                                                                                                  \n",
      " dense_110 (Dense)              (None, 128)          17408       ['dropout_242[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_243 (Dropout)          (None, 128)          0           ['dense_110[0][0]']              \n",
      "                                                                                                  \n",
      " dense_111 (Dense)              (None, 1)            129         ['dropout_243[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1077 - accuracy: 0.9585 - val_loss: 0.1748 - val_accuracy: 0.9568\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0261 - accuracy: 0.9948 - val_loss: 0.0795 - val_accuracy: 0.9594\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0207 - accuracy: 0.9961 - val_loss: 0.1058 - val_accuracy: 0.9589\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 0.0761 - val_accuracy: 0.9639\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 0.0062 - val_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.1077 - val_accuracy: 0.9637\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 0.0555 - val_accuracy: 0.9658\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.0030 - val_accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0648 - val_accuracy: 0.9615\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0078 - val_accuracy: 0.9969\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_265 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_266 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_267 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_93 (TFOpL  (None, 8, 45)       0           ['input_265[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_94 (TFOpL  (None, 8, 45)       0           ['input_266[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_95 (TFOpL  (None, 11, 45)      0           ['input_267[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_166 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_93[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_93[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_167 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_94[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_94[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_168 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_95[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_95[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_155 (Layer  (None, 8, 45)       90          ['multi_head_attention_166[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_156 (Layer  (None, 8, 45)       90          ['multi_head_attention_167[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_157 (Layer  (None, 11, 45)      90          ['multi_head_attention_168[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_244 (Dropout)          (None, 8, 45)        0           ['layer_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " dropout_245 (Dropout)          (None, 8, 45)        0           ['layer_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " dropout_246 (Dropout)          (None, 11, 45)       0           ['layer_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_100 (  (None, 45)          0           ['dropout_244[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_101 (  (None, 45)          0           ['dropout_245[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_102 (  (None, 45)          0           ['dropout_246[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_100[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_101[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_102[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_247 (Dropout)          (None, 135)          0           ['concatenate_47[0][0]']         \n",
      "                                                                                                  \n",
      " dense_112 (Dense)              (None, 128)          17408       ['dropout_247[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_248 (Dropout)          (None, 128)          0           ['dense_112[0][0]']              \n",
      "                                                                                                  \n",
      " dense_113 (Dense)              (None, 1)            129         ['dropout_248[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1645 - accuracy: 0.9359 - val_loss: 0.4058 - val_accuracy: 0.8624\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0820 - accuracy: 0.9814 - val_loss: 0.4082 - val_accuracy: 0.8664\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0718 - accuracy: 0.9831 - val_loss: 0.4735 - val_accuracy: 0.8657\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0697 - accuracy: 0.9833 - val_loss: 0.5093 - val_accuracy: 0.8671\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0648 - accuracy: 0.9841 - val_loss: 0.5349 - val_accuracy: 0.8683\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0638 - accuracy: 0.9840 - val_loss: 0.3935 - val_accuracy: 0.8681\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0613 - accuracy: 0.9852 - val_loss: 0.4155 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0602 - accuracy: 0.9850 - val_loss: 0.4007 - val_accuracy: 0.8671\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0584 - accuracy: 0.9852 - val_loss: 0.5413 - val_accuracy: 0.8671\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0601 - accuracy: 0.9847 - val_loss: 0.4607 - val_accuracy: 0.8655\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_268 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_269 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_270 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_96 (TFOpL  (None, 8, 45)       0           ['input_268[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_97 (TFOpL  (None, 8, 45)       0           ['input_269[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_98 (TFOpL  (None, 11, 45)      0           ['input_270[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_169 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_96[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_96[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_170 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_97[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_97[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_171 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_98[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_98[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_158 (Layer  (None, 8, 45)       90          ['multi_head_attention_169[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_159 (Layer  (None, 8, 45)       90          ['multi_head_attention_170[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_160 (Layer  (None, 11, 45)      90          ['multi_head_attention_171[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_249 (Dropout)          (None, 8, 45)        0           ['layer_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " dropout_250 (Dropout)          (None, 8, 45)        0           ['layer_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " dropout_251 (Dropout)          (None, 11, 45)       0           ['layer_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_103 (  (None, 45)          0           ['dropout_249[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_104 (  (None, 45)          0           ['dropout_250[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_105 (  (None, 45)          0           ['dropout_251[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_103[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_104[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_105[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_252 (Dropout)          (None, 135)          0           ['concatenate_48[0][0]']         \n",
      "                                                                                                  \n",
      " dense_114 (Dense)              (None, 128)          17408       ['dropout_252[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_253 (Dropout)          (None, 128)          0           ['dense_114[0][0]']              \n",
      "                                                                                                  \n",
      " dense_115 (Dense)              (None, 1)            129         ['dropout_253[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2737 - accuracy: 0.8879 - val_loss: 0.2036 - val_accuracy: 0.8977\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1378 - accuracy: 0.9512 - val_loss: 0.1756 - val_accuracy: 0.9245\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1138 - accuracy: 0.9615 - val_loss: 0.0685 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0959 - accuracy: 0.9665 - val_loss: 0.0833 - val_accuracy: 0.9668\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0894 - accuracy: 0.9707 - val_loss: 0.0607 - val_accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0849 - accuracy: 0.9711 - val_loss: 0.0854 - val_accuracy: 0.9689\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0795 - accuracy: 0.9722 - val_loss: 0.0760 - val_accuracy: 0.9720\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0751 - accuracy: 0.9740 - val_loss: 0.0893 - val_accuracy: 0.9687\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0730 - accuracy: 0.9752 - val_loss: 0.0920 - val_accuracy: 0.9711\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0684 - accuracy: 0.9756 - val_loss: 0.0711 - val_accuracy: 0.9766\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 3 19922\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_271 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_272 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_273 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_99 (TFOpL  (None, 8, 45)       0           ['input_271[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_100 (TFOp  (None, 8, 45)       0           ['input_272[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_101 (TFOp  (None, 11, 45)      0           ['input_273[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_172 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_99[0][0]',\n",
      " iHeadAttention)                                                  'tf.__operators__.add_99[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_173 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_100[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_100[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_174 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_101[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_101[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_161 (Layer  (None, 8, 45)       90          ['multi_head_attention_172[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_162 (Layer  (None, 8, 45)       90          ['multi_head_attention_173[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_163 (Layer  (None, 11, 45)      90          ['multi_head_attention_174[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_254 (Dropout)          (None, 8, 45)        0           ['layer_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " dropout_255 (Dropout)          (None, 8, 45)        0           ['layer_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " dropout_256 (Dropout)          (None, 11, 45)       0           ['layer_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_106 (  (None, 45)          0           ['dropout_254[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_107 (  (None, 45)          0           ['dropout_255[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_108 (  (None, 45)          0           ['dropout_256[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_106[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_107[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_108[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_257 (Dropout)          (None, 135)          0           ['concatenate_49[0][0]']         \n",
      "                                                                                                  \n",
      " dense_116 (Dense)              (None, 128)          17408       ['dropout_257[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_258 (Dropout)          (None, 128)          0           ['dense_116[0][0]']              \n",
      "                                                                                                  \n",
      " dense_117 (Dense)              (None, 1)            129         ['dropout_258[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2050 - accuracy: 0.9104 - val_loss: 0.1172 - val_accuracy: 0.9649\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0711 - accuracy: 0.9765 - val_loss: 0.0409 - val_accuracy: 0.9852\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0509 - accuracy: 0.9835 - val_loss: 0.0387 - val_accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0474 - accuracy: 0.9834 - val_loss: 0.0282 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0377 - accuracy: 0.9864 - val_loss: 0.0425 - val_accuracy: 0.9849\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0331 - accuracy: 0.9881 - val_loss: 0.0434 - val_accuracy: 0.9878\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0294 - accuracy: 0.9900 - val_loss: 0.0383 - val_accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0256 - accuracy: 0.9911 - val_loss: 0.0323 - val_accuracy: 0.9885\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0482 - val_accuracy: 0.9840\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.0767 - val_accuracy: 0.9823\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_274 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_275 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_276 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_102 (TFOp  (None, 8, 45)       0           ['input_274[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_103 (TFOp  (None, 8, 45)       0           ['input_275[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_104 (TFOp  (None, 11, 45)      0           ['input_276[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_175 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_102[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_102[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_176 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_103[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_103[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_177 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_104[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_104[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_164 (Layer  (None, 8, 45)       90          ['multi_head_attention_175[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_165 (Layer  (None, 8, 45)       90          ['multi_head_attention_176[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_166 (Layer  (None, 11, 45)      90          ['multi_head_attention_177[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_259 (Dropout)          (None, 8, 45)        0           ['layer_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " dropout_260 (Dropout)          (None, 8, 45)        0           ['layer_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " dropout_261 (Dropout)          (None, 11, 45)       0           ['layer_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_109 (  (None, 45)          0           ['dropout_259[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_110 (  (None, 45)          0           ['dropout_260[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_111 (  (None, 45)          0           ['dropout_261[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_50 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_109[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_110[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_111[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_262 (Dropout)          (None, 135)          0           ['concatenate_50[0][0]']         \n",
      "                                                                                                  \n",
      " dense_118 (Dense)              (None, 128)          17408       ['dropout_262[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_263 (Dropout)          (None, 128)          0           ['dense_118[0][0]']              \n",
      "                                                                                                  \n",
      " dense_119 (Dense)              (None, 1)            129         ['dropout_263[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2846 - accuracy: 0.8614 - val_loss: 0.3294 - val_accuracy: 0.7792\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1337 - accuracy: 0.9467 - val_loss: 0.2322 - val_accuracy: 0.8963\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1111 - accuracy: 0.9547 - val_loss: 0.2171 - val_accuracy: 0.8848\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1023 - accuracy: 0.9584 - val_loss: 0.1997 - val_accuracy: 0.8930\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0934 - accuracy: 0.9616 - val_loss: 0.1896 - val_accuracy: 0.9085\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0880 - accuracy: 0.9633 - val_loss: 0.4134 - val_accuracy: 0.9008\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0836 - accuracy: 0.9649 - val_loss: 0.1737 - val_accuracy: 0.8953\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0789 - accuracy: 0.9674 - val_loss: 0.1825 - val_accuracy: 0.9097\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0780 - accuracy: 0.9683 - val_loss: 0.1977 - val_accuracy: 0.9185\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0708 - accuracy: 0.9717 - val_loss: 0.2247 - val_accuracy: 0.8980\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_277 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_278 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_279 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_105 (TFOp  (None, 8, 45)       0           ['input_277[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_106 (TFOp  (None, 8, 45)       0           ['input_278[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_107 (TFOp  (None, 11, 45)      0           ['input_279[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_178 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_105[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_105[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_179 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_106[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_106[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_180 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_107[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_107[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_167 (Layer  (None, 8, 45)       90          ['multi_head_attention_178[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_168 (Layer  (None, 8, 45)       90          ['multi_head_attention_179[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_169 (Layer  (None, 11, 45)      90          ['multi_head_attention_180[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_264 (Dropout)          (None, 8, 45)        0           ['layer_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " dropout_265 (Dropout)          (None, 8, 45)        0           ['layer_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " dropout_266 (Dropout)          (None, 11, 45)       0           ['layer_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_112 (  (None, 45)          0           ['dropout_264[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_113 (  (None, 45)          0           ['dropout_265[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_114 (  (None, 45)          0           ['dropout_266[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_51 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_112[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_113[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_114[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_267 (Dropout)          (None, 135)          0           ['concatenate_51[0][0]']         \n",
      "                                                                                                  \n",
      " dense_120 (Dense)              (None, 128)          17408       ['dropout_267[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_268 (Dropout)          (None, 128)          0           ['dense_120[0][0]']              \n",
      "                                                                                                  \n",
      " dense_121 (Dense)              (None, 1)            129         ['dropout_268[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.2104 - accuracy: 0.9257 - val_loss: 0.0405 - val_accuracy: 0.9909\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1182 - accuracy: 0.9714 - val_loss: 0.0521 - val_accuracy: 0.9919\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1074 - accuracy: 0.9730 - val_loss: 0.0378 - val_accuracy: 0.9919\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1023 - accuracy: 0.9736 - val_loss: 0.0544 - val_accuracy: 0.9938\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1002 - accuracy: 0.9738 - val_loss: 0.0420 - val_accuracy: 0.9943\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0954 - accuracy: 0.9743 - val_loss: 0.0916 - val_accuracy: 0.9914\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0932 - accuracy: 0.9749 - val_loss: 0.0434 - val_accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0884 - accuracy: 0.9752 - val_loss: 0.0464 - val_accuracy: 0.9945\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0781 - accuracy: 0.9761 - val_loss: 0.0406 - val_accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0748 - accuracy: 0.9757 - val_loss: 0.0433 - val_accuracy: 0.9959\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_280 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_281 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_282 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_108 (TFOp  (None, 8, 45)       0           ['input_280[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_109 (TFOp  (None, 8, 45)       0           ['input_281[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_110 (TFOp  (None, 11, 45)      0           ['input_282[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_181 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_108[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_108[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_182 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_109[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_109[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_183 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_110[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_110[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_170 (Layer  (None, 8, 45)       90          ['multi_head_attention_181[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_171 (Layer  (None, 8, 45)       90          ['multi_head_attention_182[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_172 (Layer  (None, 11, 45)      90          ['multi_head_attention_183[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_269 (Dropout)          (None, 8, 45)        0           ['layer_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " dropout_270 (Dropout)          (None, 8, 45)        0           ['layer_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " dropout_271 (Dropout)          (None, 11, 45)       0           ['layer_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_115 (  (None, 45)          0           ['dropout_269[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_116 (  (None, 45)          0           ['dropout_270[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_117 (  (None, 45)          0           ['dropout_271[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_52 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_115[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_116[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_117[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_272 (Dropout)          (None, 135)          0           ['concatenate_52[0][0]']         \n",
      "                                                                                                  \n",
      " dense_122 (Dense)              (None, 128)          17408       ['dropout_272[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_273 (Dropout)          (None, 128)          0           ['dense_122[0][0]']              \n",
      "                                                                                                  \n",
      " dense_123 (Dense)              (None, 1)            129         ['dropout_273[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1899 - accuracy: 0.9181 - val_loss: 0.0866 - val_accuracy: 0.9749\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.0531 - val_accuracy: 0.9795\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0500 - accuracy: 0.9864 - val_loss: 0.0514 - val_accuracy: 0.9854\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 0.0333 - val_accuracy: 0.9881\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0397 - accuracy: 0.9879 - val_loss: 0.0510 - val_accuracy: 0.9852\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0341 - accuracy: 0.9898 - val_loss: 0.0779 - val_accuracy: 0.9761\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0311 - accuracy: 0.9907 - val_loss: 0.0591 - val_accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0279 - accuracy: 0.9906 - val_loss: 0.0907 - val_accuracy: 0.9759\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.0685 - val_accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0283 - accuracy: 0.9913 - val_loss: 0.0611 - val_accuracy: 0.9845\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_283 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_284 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_285 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_111 (TFOp  (None, 8, 45)       0           ['input_283[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_112 (TFOp  (None, 8, 45)       0           ['input_284[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_113 (TFOp  (None, 11, 45)      0           ['input_285[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_184 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_111[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_111[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_185 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_112[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_112[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_186 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_113[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_113[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_173 (Layer  (None, 8, 45)       90          ['multi_head_attention_184[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_174 (Layer  (None, 8, 45)       90          ['multi_head_attention_185[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_175 (Layer  (None, 11, 45)      90          ['multi_head_attention_186[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_274 (Dropout)          (None, 8, 45)        0           ['layer_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " dropout_275 (Dropout)          (None, 8, 45)        0           ['layer_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " dropout_276 (Dropout)          (None, 11, 45)       0           ['layer_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_118 (  (None, 45)          0           ['dropout_274[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_119 (  (None, 45)          0           ['dropout_275[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_120 (  (None, 45)          0           ['dropout_276[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_53 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_118[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_119[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_120[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_277 (Dropout)          (None, 135)          0           ['concatenate_53[0][0]']         \n",
      "                                                                                                  \n",
      " dense_124 (Dense)              (None, 128)          17408       ['dropout_277[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_278 (Dropout)          (None, 128)          0           ['dense_124[0][0]']              \n",
      "                                                                                                  \n",
      " dense_125 (Dense)              (None, 1)            129         ['dropout_278[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1025 - accuracy: 0.9582 - val_loss: 0.0297 - val_accuracy: 0.9935\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0188 - accuracy: 0.9964 - val_loss: 0.0260 - val_accuracy: 0.9945\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.0296 - val_accuracy: 0.9959\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0118 - accuracy: 0.9977 - val_loss: 0.0241 - val_accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 0.0263 - val_accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.0179 - val_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0386 - val_accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0278 - val_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0285 - val_accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0247 - val_accuracy: 0.9983\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_286 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_287 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_288 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_114 (TFOp  (None, 8, 45)       0           ['input_286[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_115 (TFOp  (None, 8, 45)       0           ['input_287[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_116 (TFOp  (None, 11, 45)      0           ['input_288[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_187 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_114[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_114[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_188 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_115[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_115[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_189 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_116[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_116[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_176 (Layer  (None, 8, 45)       90          ['multi_head_attention_187[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_177 (Layer  (None, 8, 45)       90          ['multi_head_attention_188[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_178 (Layer  (None, 11, 45)      90          ['multi_head_attention_189[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_279 (Dropout)          (None, 8, 45)        0           ['layer_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " dropout_280 (Dropout)          (None, 8, 45)        0           ['layer_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " dropout_281 (Dropout)          (None, 11, 45)       0           ['layer_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_121 (  (None, 45)          0           ['dropout_279[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_122 (  (None, 45)          0           ['dropout_280[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_123 (  (None, 45)          0           ['dropout_281[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_54 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_121[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_122[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_123[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_282 (Dropout)          (None, 135)          0           ['concatenate_54[0][0]']         \n",
      "                                                                                                  \n",
      " dense_126 (Dense)              (None, 128)          17408       ['dropout_282[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_283 (Dropout)          (None, 128)          0           ['dense_126[0][0]']              \n",
      "                                                                                                  \n",
      " dense_127 (Dense)              (None, 1)            129         ['dropout_283[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1077 - accuracy: 0.9571 - val_loss: 0.1049 - val_accuracy: 0.9806\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0213 - accuracy: 0.9956 - val_loss: 0.0593 - val_accuracy: 0.9823\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.0557 - val_accuracy: 0.9864\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.0477 - val_accuracy: 0.9873\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0536 - val_accuracy: 0.9878\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.0768 - val_accuracy: 0.9871\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.0439 - val_accuracy: 0.9885\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0546 - val_accuracy: 0.9849\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0663 - val_accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0101 - accuracy: 0.9977 - val_loss: 0.0372 - val_accuracy: 0.9888\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_289 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_290 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_291 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_117 (TFOp  (None, 8, 45)       0           ['input_289[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_118 (TFOp  (None, 8, 45)       0           ['input_290[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_119 (TFOp  (None, 11, 45)      0           ['input_291[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_190 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_117[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_117[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_191 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_118[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_118[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_192 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_119[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_119[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_179 (Layer  (None, 8, 45)       90          ['multi_head_attention_190[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_180 (Layer  (None, 8, 45)       90          ['multi_head_attention_191[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_181 (Layer  (None, 11, 45)      90          ['multi_head_attention_192[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_284 (Dropout)          (None, 8, 45)        0           ['layer_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " dropout_285 (Dropout)          (None, 8, 45)        0           ['layer_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " dropout_286 (Dropout)          (None, 11, 45)       0           ['layer_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_124 (  (None, 45)          0           ['dropout_284[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_125 (  (None, 45)          0           ['dropout_285[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_126 (  (None, 45)          0           ['dropout_286[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_55 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_124[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_125[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_126[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_287 (Dropout)          (None, 135)          0           ['concatenate_55[0][0]']         \n",
      "                                                                                                  \n",
      " dense_128 (Dense)              (None, 128)          17408       ['dropout_287[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_288 (Dropout)          (None, 128)          0           ['dense_128[0][0]']              \n",
      "                                                                                                  \n",
      " dense_129 (Dense)              (None, 1)            129         ['dropout_288[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1720 - accuracy: 0.9392 - val_loss: 0.0257 - val_accuracy: 0.9962\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1014 - accuracy: 0.9761 - val_loss: 0.0273 - val_accuracy: 0.9873\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0958 - accuracy: 0.9771 - val_loss: 0.0281 - val_accuracy: 0.9959\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0869 - accuracy: 0.9781 - val_loss: 0.0395 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0792 - accuracy: 0.9782 - val_loss: 0.0465 - val_accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0796 - accuracy: 0.9780 - val_loss: 0.0565 - val_accuracy: 0.9864\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0775 - accuracy: 0.9784 - val_loss: 0.0275 - val_accuracy: 0.9950\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0739 - accuracy: 0.9788 - val_loss: 0.0482 - val_accuracy: 0.9969\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0705 - accuracy: 0.9791 - val_loss: 0.0464 - val_accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0690 - accuracy: 0.9794 - val_loss: 0.0229 - val_accuracy: 0.9967\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_292 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_293 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_294 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_120 (TFOp  (None, 8, 45)       0           ['input_292[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_121 (TFOp  (None, 8, 45)       0           ['input_293[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_122 (TFOp  (None, 11, 45)      0           ['input_294[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_193 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_120[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_120[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_194 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_121[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_121[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_195 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_122[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_122[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_182 (Layer  (None, 8, 45)       90          ['multi_head_attention_193[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_183 (Layer  (None, 8, 45)       90          ['multi_head_attention_194[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_184 (Layer  (None, 11, 45)      90          ['multi_head_attention_195[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_289 (Dropout)          (None, 8, 45)        0           ['layer_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " dropout_290 (Dropout)          (None, 8, 45)        0           ['layer_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " dropout_291 (Dropout)          (None, 11, 45)       0           ['layer_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_127 (  (None, 45)          0           ['dropout_289[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_128 (  (None, 45)          0           ['dropout_290[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_129 (  (None, 45)          0           ['dropout_291[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_56 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_127[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_128[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_129[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_292 (Dropout)          (None, 135)          0           ['concatenate_56[0][0]']         \n",
      "                                                                                                  \n",
      " dense_130 (Dense)              (None, 128)          17408       ['dropout_292[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_293 (Dropout)          (None, 128)          0           ['dense_130[0][0]']              \n",
      "                                                                                                  \n",
      " dense_131 (Dense)              (None, 1)            129         ['dropout_293[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2573 - accuracy: 0.8951 - val_loss: 0.2821 - val_accuracy: 0.8444\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1168 - accuracy: 0.9587 - val_loss: 0.3019 - val_accuracy: 0.8889\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0923 - accuracy: 0.9692 - val_loss: 0.1730 - val_accuracy: 0.9011\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0828 - accuracy: 0.9737 - val_loss: 0.3036 - val_accuracy: 0.8903\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0763 - accuracy: 0.9759 - val_loss: 0.2112 - val_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0748 - accuracy: 0.9758 - val_loss: 0.2249 - val_accuracy: 0.9042\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0699 - accuracy: 0.9779 - val_loss: 0.3497 - val_accuracy: 0.8918\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0642 - accuracy: 0.9784 - val_loss: 0.3122 - val_accuracy: 0.8920\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0623 - accuracy: 0.9798 - val_loss: 0.1847 - val_accuracy: 0.9441\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0588 - accuracy: 0.9808 - val_loss: 0.2723 - val_accuracy: 0.8980\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 4 19923\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_55\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_295 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_296 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_297 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_123 (TFOp  (None, 8, 45)       0           ['input_295[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_124 (TFOp  (None, 8, 45)       0           ['input_296[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_125 (TFOp  (None, 11, 45)      0           ['input_297[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_196 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_123[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_123[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_197 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_124[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_124[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_198 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_125[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_125[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_185 (Layer  (None, 8, 45)       90          ['multi_head_attention_196[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_186 (Layer  (None, 8, 45)       90          ['multi_head_attention_197[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_187 (Layer  (None, 11, 45)      90          ['multi_head_attention_198[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_294 (Dropout)          (None, 8, 45)        0           ['layer_normalization_185[0][0]']\n",
      "                                                                                                  \n",
      " dropout_295 (Dropout)          (None, 8, 45)        0           ['layer_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " dropout_296 (Dropout)          (None, 11, 45)       0           ['layer_normalization_187[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_130 (  (None, 45)          0           ['dropout_294[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_131 (  (None, 45)          0           ['dropout_295[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_132 (  (None, 45)          0           ['dropout_296[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_57 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_130[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_131[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_132[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_297 (Dropout)          (None, 135)          0           ['concatenate_57[0][0]']         \n",
      "                                                                                                  \n",
      " dense_132 (Dense)              (None, 128)          17408       ['dropout_297[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_298 (Dropout)          (None, 128)          0           ['dense_132[0][0]']              \n",
      "                                                                                                  \n",
      " dense_133 (Dense)              (None, 1)            129         ['dropout_298[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1996 - accuracy: 0.9138 - val_loss: 0.0619 - val_accuracy: 0.9873\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0716 - accuracy: 0.9770 - val_loss: 0.0464 - val_accuracy: 0.9878\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0510 - accuracy: 0.9816 - val_loss: 0.0614 - val_accuracy: 0.9823\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0454 - accuracy: 0.9847 - val_loss: 0.0339 - val_accuracy: 0.9895\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.0341 - val_accuracy: 0.9928\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0334 - accuracy: 0.9887 - val_loss: 0.0634 - val_accuracy: 0.9864\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0307 - accuracy: 0.9899 - val_loss: 0.0317 - val_accuracy: 0.9935\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.0384 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.0559 - val_accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.0388 - val_accuracy: 0.9921\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_298 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_299 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_300 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_126 (TFOp  (None, 8, 45)       0           ['input_298[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_127 (TFOp  (None, 8, 45)       0           ['input_299[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_128 (TFOp  (None, 11, 45)      0           ['input_300[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_199 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_126[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_126[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_200 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_127[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_127[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_201 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_128[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_128[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_188 (Layer  (None, 8, 45)       90          ['multi_head_attention_199[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_189 (Layer  (None, 8, 45)       90          ['multi_head_attention_200[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_190 (Layer  (None, 11, 45)      90          ['multi_head_attention_201[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_299 (Dropout)          (None, 8, 45)        0           ['layer_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " dropout_300 (Dropout)          (None, 8, 45)        0           ['layer_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " dropout_301 (Dropout)          (None, 11, 45)       0           ['layer_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_133 (  (None, 45)          0           ['dropout_299[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_134 (  (None, 45)          0           ['dropout_300[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_135 (  (None, 45)          0           ['dropout_301[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_58 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_133[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_134[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_135[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_302 (Dropout)          (None, 135)          0           ['concatenate_58[0][0]']         \n",
      "                                                                                                  \n",
      " dense_134 (Dense)              (None, 128)          17408       ['dropout_302[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_303 (Dropout)          (None, 128)          0           ['dense_134[0][0]']              \n",
      "                                                                                                  \n",
      " dense_135 (Dense)              (None, 1)            129         ['dropout_303[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2978 - accuracy: 0.8552 - val_loss: 0.0943 - val_accuracy: 0.9685\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1229 - accuracy: 0.9529 - val_loss: 0.1158 - val_accuracy: 0.9649\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1044 - accuracy: 0.9592 - val_loss: 0.1316 - val_accuracy: 0.9663\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0927 - accuracy: 0.9634 - val_loss: 0.1455 - val_accuracy: 0.9493\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0883 - accuracy: 0.9657 - val_loss: 0.1040 - val_accuracy: 0.9668\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0854 - accuracy: 0.9681 - val_loss: 0.1563 - val_accuracy: 0.9529\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0814 - accuracy: 0.9690 - val_loss: 0.1730 - val_accuracy: 0.9438\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0772 - accuracy: 0.9701 - val_loss: 0.1580 - val_accuracy: 0.9489\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0715 - accuracy: 0.9725 - val_loss: 0.1414 - val_accuracy: 0.9651\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0683 - accuracy: 0.9736 - val_loss: 0.1204 - val_accuracy: 0.9611\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_301 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_302 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_303 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_129 (TFOp  (None, 8, 45)       0           ['input_301[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_130 (TFOp  (None, 8, 45)       0           ['input_302[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_131 (TFOp  (None, 11, 45)      0           ['input_303[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_202 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_129[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_129[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_203 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_130[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_130[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_204 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_131[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_131[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_191 (Layer  (None, 8, 45)       90          ['multi_head_attention_202[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_192 (Layer  (None, 8, 45)       90          ['multi_head_attention_203[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_193 (Layer  (None, 11, 45)      90          ['multi_head_attention_204[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_304 (Dropout)          (None, 8, 45)        0           ['layer_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " dropout_305 (Dropout)          (None, 8, 45)        0           ['layer_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " dropout_306 (Dropout)          (None, 11, 45)       0           ['layer_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_136 (  (None, 45)          0           ['dropout_304[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_137 (  (None, 45)          0           ['dropout_305[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_138 (  (None, 45)          0           ['dropout_306[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_59 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_136[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_137[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_138[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_307 (Dropout)          (None, 135)          0           ['concatenate_59[0][0]']         \n",
      "                                                                                                  \n",
      " dense_136 (Dense)              (None, 128)          17408       ['dropout_307[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_308 (Dropout)          (None, 128)          0           ['dense_136[0][0]']              \n",
      "                                                                                                  \n",
      " dense_137 (Dense)              (None, 1)            129         ['dropout_308[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.2031 - accuracy: 0.9284 - val_loss: 0.0496 - val_accuracy: 0.9900\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1174 - accuracy: 0.9723 - val_loss: 0.0587 - val_accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1073 - accuracy: 0.9740 - val_loss: 0.0571 - val_accuracy: 0.9924\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1016 - accuracy: 0.9743 - val_loss: 0.0616 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0959 - accuracy: 0.9753 - val_loss: 0.0612 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0916 - accuracy: 0.9759 - val_loss: 0.0550 - val_accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0838 - accuracy: 0.9758 - val_loss: 0.0797 - val_accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0777 - accuracy: 0.9761 - val_loss: 0.0748 - val_accuracy: 0.9933\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0737 - accuracy: 0.9764 - val_loss: 0.0463 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0679 - accuracy: 0.9770 - val_loss: 0.0614 - val_accuracy: 0.9914\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_304 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_305 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_306 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_132 (TFOp  (None, 8, 45)       0           ['input_304[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_133 (TFOp  (None, 8, 45)       0           ['input_305[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_134 (TFOp  (None, 11, 45)      0           ['input_306[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_205 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_132[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_132[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_206 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_133[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_133[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_207 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_134[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_134[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_194 (Layer  (None, 8, 45)       90          ['multi_head_attention_205[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_195 (Layer  (None, 8, 45)       90          ['multi_head_attention_206[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_196 (Layer  (None, 11, 45)      90          ['multi_head_attention_207[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_309 (Dropout)          (None, 8, 45)        0           ['layer_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " dropout_310 (Dropout)          (None, 8, 45)        0           ['layer_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " dropout_311 (Dropout)          (None, 11, 45)       0           ['layer_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_139 (  (None, 45)          0           ['dropout_309[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_140 (  (None, 45)          0           ['dropout_310[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_141 (  (None, 45)          0           ['dropout_311[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_60 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_139[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_140[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_141[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_312 (Dropout)          (None, 135)          0           ['concatenate_60[0][0]']         \n",
      "                                                                                                  \n",
      " dense_138 (Dense)              (None, 128)          17408       ['dropout_312[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_313 (Dropout)          (None, 128)          0           ['dense_138[0][0]']              \n",
      "                                                                                                  \n",
      " dense_139 (Dense)              (None, 1)            129         ['dropout_313[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1715 - accuracy: 0.9269 - val_loss: 0.0604 - val_accuracy: 0.9840\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0621 - accuracy: 0.9813 - val_loss: 0.0486 - val_accuracy: 0.9871\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0493 - accuracy: 0.9862 - val_loss: 0.0546 - val_accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0439 - accuracy: 0.9880 - val_loss: 0.0658 - val_accuracy: 0.9833\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0388 - accuracy: 0.9887 - val_loss: 0.0890 - val_accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0602 - val_accuracy: 0.9864\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0332 - accuracy: 0.9906 - val_loss: 0.0568 - val_accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 0.0559 - val_accuracy: 0.9864\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 0.0668 - val_accuracy: 0.9857\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0650 - val_accuracy: 0.9840\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_307 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_308 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_309 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_135 (TFOp  (None, 8, 45)       0           ['input_307[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_136 (TFOp  (None, 8, 45)       0           ['input_308[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_137 (TFOp  (None, 11, 45)      0           ['input_309[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_208 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_135[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_135[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_209 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_136[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_136[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_210 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_137[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_137[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_197 (Layer  (None, 8, 45)       90          ['multi_head_attention_208[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_198 (Layer  (None, 8, 45)       90          ['multi_head_attention_209[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_199 (Layer  (None, 11, 45)      90          ['multi_head_attention_210[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_314 (Dropout)          (None, 8, 45)        0           ['layer_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " dropout_315 (Dropout)          (None, 8, 45)        0           ['layer_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " dropout_316 (Dropout)          (None, 11, 45)       0           ['layer_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_142 (  (None, 45)          0           ['dropout_314[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_143 (  (None, 45)          0           ['dropout_315[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_144 (  (None, 45)          0           ['dropout_316[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_61 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_142[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_143[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_144[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_317 (Dropout)          (None, 135)          0           ['concatenate_61[0][0]']         \n",
      "                                                                                                  \n",
      " dense_140 (Dense)              (None, 128)          17408       ['dropout_317[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_318 (Dropout)          (None, 128)          0           ['dense_140[0][0]']              \n",
      "                                                                                                  \n",
      " dense_141 (Dense)              (None, 1)            129         ['dropout_318[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 17ms/step - loss: 0.0911 - accuracy: 0.9632 - val_loss: 0.0118 - val_accuracy: 0.9964\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.0124 - val_accuracy: 0.9967\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0127 - accuracy: 0.9972 - val_loss: 0.0117 - val_accuracy: 0.9959\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0326 - val_accuracy: 0.9943\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.0136 - val_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0231 - val_accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0156 - val_accuracy: 0.9976\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.0180 - val_accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0236 - val_accuracy: 0.9969\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0191 - val_accuracy: 0.9964\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_310 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_311 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_312 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_138 (TFOp  (None, 8, 45)       0           ['input_310[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_139 (TFOp  (None, 8, 45)       0           ['input_311[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_140 (TFOp  (None, 11, 45)      0           ['input_312[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_211 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_138[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_138[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_212 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_139[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_139[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_213 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_140[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_140[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_200 (Layer  (None, 8, 45)       90          ['multi_head_attention_211[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_201 (Layer  (None, 8, 45)       90          ['multi_head_attention_212[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_202 (Layer  (None, 11, 45)      90          ['multi_head_attention_213[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_319 (Dropout)          (None, 8, 45)        0           ['layer_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " dropout_320 (Dropout)          (None, 8, 45)        0           ['layer_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " dropout_321 (Dropout)          (None, 11, 45)       0           ['layer_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_145 (  (None, 45)          0           ['dropout_319[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_146 (  (None, 45)          0           ['dropout_320[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_147 (  (None, 45)          0           ['dropout_321[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_62 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_145[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_146[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_147[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_322 (Dropout)          (None, 135)          0           ['concatenate_62[0][0]']         \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 128)          17408       ['dropout_322[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_323 (Dropout)          (None, 128)          0           ['dense_142[0][0]']              \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 1)            129         ['dropout_323[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.0967 - accuracy: 0.9628 - val_loss: 0.0758 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.1140 - val_accuracy: 0.9759\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0171 - accuracy: 0.9971 - val_loss: 0.0729 - val_accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 0.0700 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0905 - val_accuracy: 0.9845\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0133 - accuracy: 0.9970 - val_loss: 0.0569 - val_accuracy: 0.9847\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.0688 - val_accuracy: 0.9852\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0152 - accuracy: 0.9967 - val_loss: 0.0390 - val_accuracy: 0.9878\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0404 - val_accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 0.0524 - val_accuracy: 0.9885\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_61\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_313 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_314 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_315 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_141 (TFOp  (None, 8, 45)       0           ['input_313[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_142 (TFOp  (None, 8, 45)       0           ['input_314[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_143 (TFOp  (None, 11, 45)      0           ['input_315[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_214 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_141[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_141[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_215 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_142[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_142[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_216 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_143[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_143[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_203 (Layer  (None, 8, 45)       90          ['multi_head_attention_214[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_204 (Layer  (None, 8, 45)       90          ['multi_head_attention_215[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_205 (Layer  (None, 11, 45)      90          ['multi_head_attention_216[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_324 (Dropout)          (None, 8, 45)        0           ['layer_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " dropout_325 (Dropout)          (None, 8, 45)        0           ['layer_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " dropout_326 (Dropout)          (None, 11, 45)       0           ['layer_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_148 (  (None, 45)          0           ['dropout_324[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_149 (  (None, 45)          0           ['dropout_325[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_150 (  (None, 45)          0           ['dropout_326[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_63 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_148[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_149[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_150[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_327 (Dropout)          (None, 135)          0           ['concatenate_63[0][0]']         \n",
      "                                                                                                  \n",
      " dense_144 (Dense)              (None, 128)          17408       ['dropout_327[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_328 (Dropout)          (None, 128)          0           ['dense_144[0][0]']              \n",
      "                                                                                                  \n",
      " dense_145 (Dense)              (None, 1)            129         ['dropout_328[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1970 - accuracy: 0.9217 - val_loss: 0.0243 - val_accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1044 - accuracy: 0.9744 - val_loss: 0.0336 - val_accuracy: 0.9938\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0999 - accuracy: 0.9750 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0964 - accuracy: 0.9748 - val_loss: 0.0229 - val_accuracy: 0.9964\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0898 - accuracy: 0.9752 - val_loss: 0.0156 - val_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0836 - accuracy: 0.9769 - val_loss: 0.0133 - val_accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0803 - accuracy: 0.9768 - val_loss: 0.0182 - val_accuracy: 0.9967\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0730 - accuracy: 0.9788 - val_loss: 0.0091 - val_accuracy: 0.9986\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0711 - accuracy: 0.9780 - val_loss: 0.0175 - val_accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0715 - accuracy: 0.9783 - val_loss: 0.0171 - val_accuracy: 0.9969\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_316 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_317 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_318 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_144 (TFOp  (None, 8, 45)       0           ['input_316[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_145 (TFOp  (None, 8, 45)       0           ['input_317[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_146 (TFOp  (None, 11, 45)      0           ['input_318[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_217 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_144[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_144[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_218 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_145[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_145[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_219 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_146[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_146[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_206 (Layer  (None, 8, 45)       90          ['multi_head_attention_217[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_207 (Layer  (None, 8, 45)       90          ['multi_head_attention_218[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_208 (Layer  (None, 11, 45)      90          ['multi_head_attention_219[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_329 (Dropout)          (None, 8, 45)        0           ['layer_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " dropout_330 (Dropout)          (None, 8, 45)        0           ['layer_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " dropout_331 (Dropout)          (None, 11, 45)       0           ['layer_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_151 (  (None, 45)          0           ['dropout_329[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_152 (  (None, 45)          0           ['dropout_330[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_153 (  (None, 45)          0           ['dropout_331[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_64 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_151[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_152[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_153[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_332 (Dropout)          (None, 135)          0           ['concatenate_64[0][0]']         \n",
      "                                                                                                  \n",
      " dense_146 (Dense)              (None, 128)          17408       ['dropout_332[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_333 (Dropout)          (None, 128)          0           ['dense_146[0][0]']              \n",
      "                                                                                                  \n",
      " dense_147 (Dense)              (None, 1)            129         ['dropout_333[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2684 - accuracy: 0.8811 - val_loss: 0.1455 - val_accuracy: 0.9121\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1234 - accuracy: 0.9558 - val_loss: 0.1049 - val_accuracy: 0.9594\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0976 - accuracy: 0.9666 - val_loss: 0.1025 - val_accuracy: 0.9546\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0912 - accuracy: 0.9697 - val_loss: 0.1465 - val_accuracy: 0.9527\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0851 - accuracy: 0.9717 - val_loss: 0.1035 - val_accuracy: 0.9625\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 0.1616 - val_accuracy: 0.9472\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0743 - accuracy: 0.9741 - val_loss: 0.2787 - val_accuracy: 0.9159\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0717 - accuracy: 0.9753 - val_loss: 0.1233 - val_accuracy: 0.9579\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0700 - accuracy: 0.9758 - val_loss: 0.1423 - val_accuracy: 0.9520\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0655 - accuracy: 0.9770 - val_loss: 0.1600 - val_accuracy: 0.9527\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 5 19924\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_63\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_319 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_320 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_321 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_147 (TFOp  (None, 8, 45)       0           ['input_319[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_148 (TFOp  (None, 8, 45)       0           ['input_320[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_149 (TFOp  (None, 11, 45)      0           ['input_321[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_220 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_147[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_147[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_221 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_148[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_148[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_222 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_149[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_149[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_209 (Layer  (None, 8, 45)       90          ['multi_head_attention_220[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_210 (Layer  (None, 8, 45)       90          ['multi_head_attention_221[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_211 (Layer  (None, 11, 45)      90          ['multi_head_attention_222[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_334 (Dropout)          (None, 8, 45)        0           ['layer_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " dropout_335 (Dropout)          (None, 8, 45)        0           ['layer_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " dropout_336 (Dropout)          (None, 11, 45)       0           ['layer_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_154 (  (None, 45)          0           ['dropout_334[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_155 (  (None, 45)          0           ['dropout_335[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_156 (  (None, 45)          0           ['dropout_336[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_65 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_154[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_155[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_156[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_337 (Dropout)          (None, 135)          0           ['concatenate_65[0][0]']         \n",
      "                                                                                                  \n",
      " dense_148 (Dense)              (None, 128)          17408       ['dropout_337[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_338 (Dropout)          (None, 128)          0           ['dense_148[0][0]']              \n",
      "                                                                                                  \n",
      " dense_149 (Dense)              (None, 1)            129         ['dropout_338[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.2497 - accuracy: 0.8879 - val_loss: 0.0239 - val_accuracy: 0.9924\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0731 - accuracy: 0.9775 - val_loss: 0.0380 - val_accuracy: 0.9883\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0493 - accuracy: 0.9834 - val_loss: 0.0179 - val_accuracy: 0.9926\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0404 - accuracy: 0.9860 - val_loss: 0.0186 - val_accuracy: 0.9945\n",
      "Epoch 5/10\n",
      "248/938 [======>.......................] - ETA: 9s - loss: 0.0335 - accuracy: 0.9887\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_66\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_328 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_329 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_330 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_156 (TFOp  (None, 8, 45)       0           ['input_328[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_157 (TFOp  (None, 8, 45)       0           ['input_329[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_158 (TFOp  (None, 11, 45)      0           ['input_330[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_229 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_156[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_156[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_230 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_157[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_157[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_231 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_158[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_158[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_218 (Layer  (None, 8, 45)       90          ['multi_head_attention_229[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_219 (Layer  (None, 8, 45)       90          ['multi_head_attention_230[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_220 (Layer  (None, 11, 45)      90          ['multi_head_attention_231[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_349 (Dropout)          (None, 8, 45)        0           ['layer_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " dropout_350 (Dropout)          (None, 8, 45)        0           ['layer_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " dropout_351 (Dropout)          (None, 11, 45)       0           ['layer_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_163 (  (None, 45)          0           ['dropout_349[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_164 (  (None, 45)          0           ['dropout_350[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_165 (  (None, 45)          0           ['dropout_351[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_68 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_163[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_164[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_165[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_352 (Dropout)          (None, 135)          0           ['concatenate_68[0][0]']         \n",
      "                                                                                                  \n",
      " dense_154 (Dense)              (None, 128)          17408       ['dropout_352[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_353 (Dropout)          (None, 128)          0           ['dense_154[0][0]']              \n",
      "                                                                                                  \n",
      " dense_155 (Dense)              (None, 1)            129         ['dropout_353[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1740 - accuracy: 0.9249 - val_loss: 0.0839 - val_accuracy: 0.9783\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0622 - accuracy: 0.9819 - val_loss: 0.0597 - val_accuracy: 0.9828\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0492 - accuracy: 0.9855 - val_loss: 0.0747 - val_accuracy: 0.9799\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0645 - val_accuracy: 0.9804\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.0593 - val_accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: 0.0707 - val_accuracy: 0.9787\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0520 - val_accuracy: 0.9885\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.0593 - val_accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "296/938 [========>.....................] - ETA: 9s - loss: 0.0269 - accuracy: 0.9910\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_67\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_331 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_332 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_333 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_159 (TFOp  (None, 8, 45)       0           ['input_331[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_160 (TFOp  (None, 8, 45)       0           ['input_332[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_161 (TFOp  (None, 11, 45)      0           ['input_333[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_232 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_159[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_159[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_233 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_160[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_160[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_234 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_161[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_161[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_221 (Layer  (None, 8, 45)       90          ['multi_head_attention_232[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_222 (Layer  (None, 8, 45)       90          ['multi_head_attention_233[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_223 (Layer  (None, 11, 45)      90          ['multi_head_attention_234[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_354 (Dropout)          (None, 8, 45)        0           ['layer_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " dropout_355 (Dropout)          (None, 8, 45)        0           ['layer_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " dropout_356 (Dropout)          (None, 11, 45)       0           ['layer_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_166 (  (None, 45)          0           ['dropout_354[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_167 (  (None, 45)          0           ['dropout_355[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_168 (  (None, 45)          0           ['dropout_356[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_69 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_166[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_167[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_168[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_357 (Dropout)          (None, 135)          0           ['concatenate_69[0][0]']         \n",
      "                                                                                                  \n",
      " dense_156 (Dense)              (None, 128)          17408       ['dropout_357[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_358 (Dropout)          (None, 128)          0           ['dense_156[0][0]']              \n",
      "                                                                                                  \n",
      " dense_157 (Dense)              (None, 1)            129         ['dropout_358[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1095 - accuracy: 0.9497 - val_loss: 0.0109 - val_accuracy: 0.9974\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0212 - val_accuracy: 0.9950\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.0202 - val_accuracy: 0.9955\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0228 - val_accuracy: 0.9955\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0188 - val_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0228 - val_accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0240 - accuracy: 0.9952 - val_loss: 4.2721e-04 - val_accuracy: 0.9998\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0181 - accuracy: 0.9961 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 5.7995e-04 - val_accuracy: 0.9998\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 8.1463e-04 - val_accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0971 - accuracy: 0.9742 - val_loss: 0.1390 - val_accuracy: 0.9876\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0952 - accuracy: 0.9741 - val_loss: 0.1072 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0900 - accuracy: 0.9756 - val_loss: 0.1427 - val_accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0871 - accuracy: 0.9757 - val_loss: 0.1518 - val_accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0811 - accuracy: 0.9769 - val_loss: 0.1525 - val_accuracy: 0.9871\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0758 - accuracy: 0.9773 - val_loss: 0.1969 - val_accuracy: 0.9876\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0739 - accuracy: 0.9783 - val_loss: 0.1774 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0989 - accuracy: 0.9658 - val_loss: 0.1050 - val_accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0878 - accuracy: 0.9697 - val_loss: 0.0928 - val_accuracy: 0.9668\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0807 - accuracy: 0.9724 - val_loss: 0.0831 - val_accuracy: 0.9677\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0764 - accuracy: 0.9743 - val_loss: 0.0557 - val_accuracy: 0.9763\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0771 - accuracy: 0.9736 - val_loss: 0.0699 - val_accuracy: 0.9728\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0709 - accuracy: 0.9753 - val_loss: 0.0916 - val_accuracy: 0.9646\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0689 - accuracy: 0.9760 - val_loss: 0.0663 - val_accuracy: 0.9761\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 6 19928\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0407 - accuracy: 0.9855 - val_loss: 0.0450 - val_accuracy: 0.9828\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0382 - accuracy: 0.9868 - val_loss: 0.0279 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.0292 - val_accuracy: 0.9914\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0309 - accuracy: 0.9891 - val_loss: 0.0327 - val_accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.0157 - val_accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0261 - val_accuracy: 0.9933\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0230 - val_accuracy: 0.9947\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_72\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_346 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_347 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_348 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_174 (TFOp  (None, 8, 45)       0           ['input_346[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_175 (TFOp  (None, 8, 45)       0           ['input_347[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_176 (TFOp  (None, 11, 45)      0           ['input_348[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_247 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_174[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_174[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_248 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_175[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_175[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_249 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_176[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_176[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_236 (Layer  (None, 8, 45)       90          ['multi_head_attention_247[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_237 (Layer  (None, 8, 45)       90          ['multi_head_attention_248[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_238 (Layer  (None, 11, 45)      90          ['multi_head_attention_249[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_379 (Dropout)          (None, 8, 45)        0           ['layer_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " dropout_380 (Dropout)          (None, 8, 45)        0           ['layer_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " dropout_381 (Dropout)          (None, 11, 45)       0           ['layer_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_181 (  (None, 45)          0           ['dropout_379[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_182 (  (None, 45)          0           ['dropout_380[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_183 (  (None, 45)          0           ['dropout_381[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_74 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_181[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_182[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_183[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_382 (Dropout)          (None, 135)          0           ['concatenate_74[0][0]']         \n",
      "                                                                                                  \n",
      " dense_166 (Dense)              (None, 128)          17408       ['dropout_382[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_383 (Dropout)          (None, 128)          0           ['dense_166[0][0]']              \n",
      "                                                                                                  \n",
      " dense_167 (Dense)              (None, 1)            129         ['dropout_383[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0944 - accuracy: 0.9606 - val_loss: 0.1422 - val_accuracy: 0.9235\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0935 - accuracy: 0.9626 - val_loss: 0.0442 - val_accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0860 - accuracy: 0.9653 - val_loss: 0.1003 - val_accuracy: 0.9673\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0787 - accuracy: 0.9686 - val_loss: 0.0784 - val_accuracy: 0.9701\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0751 - accuracy: 0.9692 - val_loss: 0.0570 - val_accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0711 - accuracy: 0.9724 - val_loss: 0.1009 - val_accuracy: 0.9608\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_73\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_349 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_350 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_351 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_177 (TFOp  (None, 8, 45)       0           ['input_349[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_178 (TFOp  (None, 8, 45)       0           ['input_350[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_179 (TFOp  (None, 11, 45)      0           ['input_351[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_250 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_177[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_177[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_251 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_178[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_178[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_252 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_179[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_179[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_239 (Layer  (None, 8, 45)       90          ['multi_head_attention_250[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_240 (Layer  (None, 8, 45)       90          ['multi_head_attention_251[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_241 (Layer  (None, 11, 45)      90          ['multi_head_attention_252[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_384 (Dropout)          (None, 8, 45)        0           ['layer_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " dropout_385 (Dropout)          (None, 8, 45)        0           ['layer_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " dropout_386 (Dropout)          (None, 11, 45)       0           ['layer_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_184 (  (None, 45)          0           ['dropout_384[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_185 (  (None, 45)          0           ['dropout_385[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_186 (  (None, 45)          0           ['dropout_386[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_75 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_184[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_185[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_186[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_387 (Dropout)          (None, 135)          0           ['concatenate_75[0][0]']         \n",
      "                                                                                                  \n",
      " dense_168 (Dense)              (None, 128)          17408       ['dropout_387[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_388 (Dropout)          (None, 128)          0           ['dense_168[0][0]']              \n",
      "                                                                                                  \n",
      " dense_169 (Dense)              (None, 1)            129         ['dropout_388[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1012 - accuracy: 0.9714 - val_loss: 0.0231 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0894 - accuracy: 0.9727 - val_loss: 0.0405 - val_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0807 - accuracy: 0.9735 - val_loss: 0.0493 - val_accuracy: 0.9914\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0779 - accuracy: 0.9743 - val_loss: 0.0405 - val_accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0721 - accuracy: 0.9754 - val_loss: 0.0223 - val_accuracy: 0.9957\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0695 - accuracy: 0.9761 - val_loss: 0.0321 - val_accuracy: 0.9981\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0546 - accuracy: 0.9834 - val_loss: 0.0681 - val_accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 0.0470 - val_accuracy: 0.9849\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0405 - accuracy: 0.9863 - val_loss: 0.0424 - val_accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0395 - accuracy: 0.9870 - val_loss: 0.0544 - val_accuracy: 0.9854\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0373 - accuracy: 0.9873 - val_loss: 0.0468 - val_accuracy: 0.9849\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0307 - accuracy: 0.9897 - val_loss: 0.0708 - val_accuracy: 0.9840\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0309 - accuracy: 0.9894 - val_loss: 0.0647 - val_accuracy: 0.9847\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1053 - accuracy: 0.9555 - val_loss: 0.0071 - val_accuracy: 0.9983\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0156 - val_accuracy: 0.9969\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9976\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0113 - val_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0168 - val_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0201 - val_accuracy: 0.9976\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.0952 - accuracy: 0.9638 - val_loss: 0.0138 - val_accuracy: 0.9957\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0235 - accuracy: 0.9949 - val_loss: 0.0315 - val_accuracy: 0.9919\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0228 - accuracy: 0.9951 - val_loss: 0.0076 - val_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.0065 - val_accuracy: 0.9988\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0057 - val_accuracy: 0.9988\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0088 - val_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0124 - accuracy: 0.9977 - val_loss: 0.0157 - val_accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1001 - accuracy: 0.9755 - val_loss: 0.0264 - val_accuracy: 0.9959\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0923 - accuracy: 0.9770 - val_loss: 0.0198 - val_accuracy: 0.9962\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0903 - accuracy: 0.9776 - val_loss: 0.0308 - val_accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0852 - accuracy: 0.9775 - val_loss: 0.0280 - val_accuracy: 0.9957\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0842 - accuracy: 0.9778 - val_loss: 0.0257 - val_accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0805 - accuracy: 0.9781 - val_loss: 0.0265 - val_accuracy: 0.9959\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0787 - accuracy: 0.9785 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1081 - accuracy: 0.9627 - val_loss: 0.0815 - val_accuracy: 0.9682\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0989 - accuracy: 0.9672 - val_loss: 0.0777 - val_accuracy: 0.9708\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0895 - accuracy: 0.9706 - val_loss: 0.0792 - val_accuracy: 0.9704\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0831 - accuracy: 0.9730 - val_loss: 0.0640 - val_accuracy: 0.9775\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0790 - accuracy: 0.9744 - val_loss: 0.0596 - val_accuracy: 0.9799\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0791 - accuracy: 0.9742 - val_loss: 0.0719 - val_accuracy: 0.9730\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0742 - accuracy: 0.9749 - val_loss: 0.0682 - val_accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.0404 - val_accuracy: 0.9816\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0346 - accuracy: 0.9882 - val_loss: 0.0849 - val_accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0404 - val_accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.0185 - val_accuracy: 0.9943\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0199 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.0327 - val_accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 0.0215 - val_accuracy: 0.9921\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_80\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_370 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_371 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_372 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_198 (TFOp  (None, 8, 45)       0           ['input_370[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_199 (TFOp  (None, 8, 45)       0           ['input_371[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_200 (TFOp  (None, 11, 45)      0           ['input_372[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_271 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_198[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_198[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_272 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_199[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_199[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_273 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_200[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_200[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_260 (Layer  (None, 8, 45)       90          ['multi_head_attention_271[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_261 (Layer  (None, 8, 45)       90          ['multi_head_attention_272[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_262 (Layer  (None, 11, 45)      90          ['multi_head_attention_273[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_419 (Dropout)          (None, 8, 45)        0           ['layer_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " dropout_420 (Dropout)          (None, 8, 45)        0           ['layer_normalization_261[0][0]']\n",
      "                                                                                                  \n",
      " dropout_421 (Dropout)          (None, 11, 45)       0           ['layer_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_205 (  (None, 45)          0           ['dropout_419[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_206 (  (None, 45)          0           ['dropout_420[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_207 (  (None, 45)          0           ['dropout_421[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_82 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_205[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_206[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_207[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_422 (Dropout)          (None, 135)          0           ['concatenate_82[0][0]']         \n",
      "                                                                                                  \n",
      " dense_182 (Dense)              (None, 128)          17408       ['dropout_422[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_423 (Dropout)          (None, 128)          0           ['dense_182[0][0]']              \n",
      "                                                                                                  \n",
      " dense_183 (Dense)              (None, 1)            129         ['dropout_423[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0966 - accuracy: 0.9616 - val_loss: 0.1439 - val_accuracy: 0.9369\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0903 - accuracy: 0.9657 - val_loss: 0.0760 - val_accuracy: 0.9697\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0860 - accuracy: 0.9674 - val_loss: 0.0744 - val_accuracy: 0.9713\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0808 - accuracy: 0.9697 - val_loss: 0.0989 - val_accuracy: 0.9611\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0755 - accuracy: 0.9713 - val_loss: 0.0761 - val_accuracy: 0.9754\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0719 - accuracy: 0.9736 - val_loss: 0.0760 - val_accuracy: 0.9771\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_81\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_373 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_374 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_375 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_201 (TFOp  (None, 8, 45)       0           ['input_373[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_202 (TFOp  (None, 8, 45)       0           ['input_374[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_203 (TFOp  (None, 11, 45)      0           ['input_375[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_274 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_201[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_201[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_275 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_202[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_202[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_276 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_203[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_203[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_263 (Layer  (None, 8, 45)       90          ['multi_head_attention_274[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_264 (Layer  (None, 8, 45)       90          ['multi_head_attention_275[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_265 (Layer  (None, 11, 45)      90          ['multi_head_attention_276[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_424 (Dropout)          (None, 8, 45)        0           ['layer_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " dropout_425 (Dropout)          (None, 8, 45)        0           ['layer_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " dropout_426 (Dropout)          (None, 11, 45)       0           ['layer_normalization_265[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_208 (  (None, 45)          0           ['dropout_424[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_209 (  (None, 45)          0           ['dropout_425[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_210 (  (None, 45)          0           ['dropout_426[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_83 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_208[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_209[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_210[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_427 (Dropout)          (None, 135)          0           ['concatenate_83[0][0]']         \n",
      "                                                                                                  \n",
      " dense_184 (Dense)              (None, 128)          17408       ['dropout_427[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_428 (Dropout)          (None, 128)          0           ['dense_184[0][0]']              \n",
      "                                                                                                  \n",
      " dense_185 (Dense)              (None, 1)            129         ['dropout_428[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0744 - accuracy: 0.9771 - val_loss: 0.0176 - val_accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0696 - accuracy: 0.9773 - val_loss: 0.0590 - val_accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0701 - accuracy: 0.9773 - val_loss: 0.0190 - val_accuracy: 0.9990\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_376 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_377 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_378 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_204 (TFOp  (None, 8, 45)       0           ['input_376[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_205 (TFOp  (None, 8, 45)       0           ['input_377[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_206 (TFOp  (None, 11, 45)      0           ['input_378[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_277 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_204[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_204[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_278 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_205[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_205[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_279 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_206[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_206[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_266 (Layer  (None, 8, 45)       90          ['multi_head_attention_277[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_267 (Layer  (None, 8, 45)       90          ['multi_head_attention_278[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_268 (Layer  (None, 11, 45)      90          ['multi_head_attention_279[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_429 (Dropout)          (None, 8, 45)        0           ['layer_normalization_266[0][0]']\n",
      "                                                                                                  \n",
      " dropout_430 (Dropout)          (None, 8, 45)        0           ['layer_normalization_267[0][0]']\n",
      "                                                                                                  \n",
      " dropout_431 (Dropout)          (None, 11, 45)       0           ['layer_normalization_268[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_211 (  (None, 45)          0           ['dropout_429[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_212 (  (None, 45)          0           ['dropout_430[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_213 (  (None, 45)          0           ['dropout_431[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_84 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_211[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_212[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_213[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_432 (Dropout)          (None, 135)          0           ['concatenate_84[0][0]']         \n",
      "                                                                                                  \n",
      " dense_186 (Dense)              (None, 128)          17408       ['dropout_432[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_433 (Dropout)          (None, 128)          0           ['dense_186[0][0]']              \n",
      "                                                                                                  \n",
      " dense_187 (Dense)              (None, 1)            129         ['dropout_433[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1918 - accuracy: 0.9153 - val_loss: 0.0880 - val_accuracy: 0.9687\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0690 - accuracy: 0.9792 - val_loss: 0.0516 - val_accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0539 - accuracy: 0.9837 - val_loss: 0.0289 - val_accuracy: 0.9931\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0328 - accuracy: 0.9885 - val_loss: 0.0268 - val_accuracy: 0.9935\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0628 - val_accuracy: 0.9823\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_83\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_379 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_380 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_381 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_207 (TFOp  (None, 8, 45)       0           ['input_379[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_208 (TFOp  (None, 8, 45)       0           ['input_380[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_209 (TFOp  (None, 11, 45)      0           ['input_381[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_280 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_207[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_207[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_281 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_208[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_208[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_282 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_209[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_209[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_269 (Layer  (None, 8, 45)       90          ['multi_head_attention_280[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_270 (Layer  (None, 8, 45)       90          ['multi_head_attention_281[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_271 (Layer  (None, 11, 45)      90          ['multi_head_attention_282[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_434 (Dropout)          (None, 8, 45)        0           ['layer_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " dropout_435 (Dropout)          (None, 8, 45)        0           ['layer_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " dropout_436 (Dropout)          (None, 11, 45)       0           ['layer_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_214 (  (None, 45)          0           ['dropout_434[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_215 (  (None, 45)          0           ['dropout_435[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_216 (  (None, 45)          0           ['dropout_436[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_85 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_214[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_215[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_216[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_437 (Dropout)          (None, 135)          0           ['concatenate_85[0][0]']         \n",
      "                                                                                                  \n",
      " dense_188 (Dense)              (None, 128)          17408       ['dropout_437[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_438 (Dropout)          (None, 128)          0           ['dense_188[0][0]']              \n",
      "                                                                                                  \n",
      " dense_189 (Dense)              (None, 1)            129         ['dropout_438[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.0972 - accuracy: 0.9615 - val_loss: 0.0160 - val_accuracy: 0.9957\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0234 - accuracy: 0.9951 - val_loss: 0.0186 - val_accuracy: 0.9964\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.0514 - val_accuracy: 0.9916\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0133 - val_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.0185 - val_accuracy: 0.9969\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0044 - val_accuracy: 0.9986\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_84\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_382 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_383 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_384 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_210 (TFOp  (None, 8, 45)       0           ['input_382[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_211 (TFOp  (None, 8, 45)       0           ['input_383[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_212 (TFOp  (None, 11, 45)      0           ['input_384[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_283 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_210[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_210[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_284 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_211[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_211[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_285 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_212[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_212[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_272 (Layer  (None, 8, 45)       90          ['multi_head_attention_283[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_273 (Layer  (None, 8, 45)       90          ['multi_head_attention_284[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_274 (Layer  (None, 11, 45)      90          ['multi_head_attention_285[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_439 (Dropout)          (None, 8, 45)        0           ['layer_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " dropout_440 (Dropout)          (None, 8, 45)        0           ['layer_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " dropout_441 (Dropout)          (None, 11, 45)       0           ['layer_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_217 (  (None, 45)          0           ['dropout_439[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_218 (  (None, 45)          0           ['dropout_440[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_219 (  (None, 45)          0           ['dropout_441[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_86 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_217[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_218[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_219[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_442 (Dropout)          (None, 135)          0           ['concatenate_86[0][0]']         \n",
      "                                                                                                  \n",
      " dense_190 (Dense)              (None, 128)          17408       ['dropout_442[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_443 (Dropout)          (None, 128)          0           ['dense_190[0][0]']              \n",
      "                                                                                                  \n",
      " dense_191 (Dense)              (None, 1)            129         ['dropout_443[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1070 - accuracy: 0.9601 - val_loss: 0.0192 - val_accuracy: 0.9938\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0250 - accuracy: 0.9946 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0198 - accuracy: 0.9959 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0199 - accuracy: 0.9965 - val_loss: 0.0272 - val_accuracy: 0.9902\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0175 - accuracy: 0.9967 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "484/938 [==============>...............] - ETA: 6s - loss: 0.0147 - accuracy: 0.9973TRAIN sleep 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_85\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_385 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_386 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_387 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_213 (TFOp  (None, 8, 45)       0           ['input_385[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_214 (TFOp  (None, 8, 45)       0           ['input_386[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_215 (TFOp  (None, 11, 45)      0           ['input_387[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_286 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_213[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_213[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_287 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_214[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_214[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_288 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_215[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_215[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_275 (Layer  (None, 8, 45)       90          ['multi_head_attention_286[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_276 (Layer  (None, 8, 45)       90          ['multi_head_attention_287[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_277 (Layer  (None, 11, 45)      90          ['multi_head_attention_288[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_444 (Dropout)          (None, 8, 45)        0           ['layer_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " dropout_445 (Dropout)          (None, 8, 45)        0           ['layer_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " dropout_446 (Dropout)          (None, 11, 45)       0           ['layer_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_220 (  (None, 45)          0           ['dropout_444[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_221 (  (None, 45)          0           ['dropout_445[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_222 (  (None, 45)          0           ['dropout_446[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_87 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_220[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_221[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_222[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_447 (Dropout)          (None, 135)          0           ['concatenate_87[0][0]']         \n",
      "                                                                                                  \n",
      " dense_192 (Dense)              (None, 128)          17408       ['dropout_447[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_448 (Dropout)          (None, 128)          0           ['dense_192[0][0]']              \n",
      "                                                                                                  \n",
      " dense_193 (Dense)              (None, 1)            129         ['dropout_448[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1697 - accuracy: 0.9385 - val_loss: 0.0732 - val_accuracy: 0.9838\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1043 - accuracy: 0.9745 - val_loss: 0.0736 - val_accuracy: 0.9854\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0962 - accuracy: 0.9759 - val_loss: 0.1191 - val_accuracy: 0.9814\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0914 - accuracy: 0.9766 - val_loss: 0.0638 - val_accuracy: 0.9845\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0895 - accuracy: 0.9764 - val_loss: 0.0736 - val_accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "659/938 [====================>.........] - ETA: 4s - loss: 0.0854 - accuracy: 0.9781TRAIN kitchen 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_86\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_388 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_389 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_390 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_216 (TFOp  (None, 8, 45)       0           ['input_388[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_217 (TFOp  (None, 8, 45)       0           ['input_389[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_218 (TFOp  (None, 11, 45)      0           ['input_390[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_289 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_216[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_216[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_290 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_217[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_217[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_291 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_218[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_218[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_278 (Layer  (None, 8, 45)       90          ['multi_head_attention_289[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_279 (Layer  (None, 8, 45)       90          ['multi_head_attention_290[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_280 (Layer  (None, 11, 45)      90          ['multi_head_attention_291[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_449 (Dropout)          (None, 8, 45)        0           ['layer_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " dropout_450 (Dropout)          (None, 8, 45)        0           ['layer_normalization_279[0][0]']\n",
      "                                                                                                  \n",
      " dropout_451 (Dropout)          (None, 11, 45)       0           ['layer_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_223 (  (None, 45)          0           ['dropout_449[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_224 (  (None, 45)          0           ['dropout_450[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_225 (  (None, 45)          0           ['dropout_451[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_88 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_223[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_224[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_225[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_452 (Dropout)          (None, 135)          0           ['concatenate_88[0][0]']         \n",
      "                                                                                                  \n",
      " dense_194 (Dense)              (None, 128)          17408       ['dropout_452[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_453 (Dropout)          (None, 128)          0           ['dense_194[0][0]']              \n",
      "                                                                                                  \n",
      " dense_195 (Dense)              (None, 1)            129         ['dropout_453[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2769 - accuracy: 0.8850 - val_loss: 0.1588 - val_accuracy: 0.9262\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1448 - accuracy: 0.9460 - val_loss: 0.0753 - val_accuracy: 0.9656\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1142 - accuracy: 0.9596 - val_loss: 0.0818 - val_accuracy: 0.9663\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0991 - accuracy: 0.9659 - val_loss: 0.1161 - val_accuracy: 0.9584\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0921 - accuracy: 0.9682 - val_loss: 0.1565 - val_accuracy: 0.9309\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.2287 - accuracy: 0.8947 - val_loss: 0.0312 - val_accuracy: 0.9912\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0759 - accuracy: 0.9759 - val_loss: 0.0339 - val_accuracy: 0.9866\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.0188 - val_accuracy: 0.9926\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0440 - accuracy: 0.9854 - val_loss: 0.0371 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0404 - accuracy: 0.9873 - val_loss: 0.0296 - val_accuracy: 0.9892\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.3008 - accuracy: 0.8499 - val_loss: 0.1853 - val_accuracy: 0.8848\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1305 - accuracy: 0.9463 - val_loss: 0.0730 - val_accuracy: 0.9816\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1085 - accuracy: 0.9543 - val_loss: 0.1274 - val_accuracy: 0.9699\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1028 - accuracy: 0.9595 - val_loss: 0.0970 - val_accuracy: 0.9675\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0906 - accuracy: 0.9633 - val_loss: 0.0574 - val_accuracy: 0.9804\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0865 - accuracy: 0.9670 - val_loss: 0.1075 - val_accuracy: 0.9548\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1158 - accuracy: 0.9721 - val_loss: 0.0417 - val_accuracy: 0.9983\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1023 - accuracy: 0.9744 - val_loss: 0.0276 - val_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0947 - accuracy: 0.9749 - val_loss: 0.0486 - val_accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0895 - accuracy: 0.9755 - val_loss: 0.0315 - val_accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0794 - accuracy: 0.9760 - val_loss: 0.0476 - val_accuracy: 0.9971\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0797 - accuracy: 0.9759 - val_loss: 0.0406 - val_accuracy: 0.9967\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0475 - accuracy: 0.9867 - val_loss: 0.0507 - val_accuracy: 0.9833\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0405 - accuracy: 0.9884 - val_loss: 0.0514 - val_accuracy: 0.9833\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 0.0404 - val_accuracy: 0.9873\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.0401 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0302 - accuracy: 0.9903 - val_loss: 0.0523 - val_accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0348 - val_accuracy: 0.9885\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.0201 - val_accuracy: 0.9940\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0099 - accuracy: 0.9980 - val_loss: 0.0029 - val_accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0066 - val_accuracy: 0.9986\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0238 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9983\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_92\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_406 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_407 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_408 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_234 (TFOp  (None, 8, 45)       0           ['input_406[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_235 (TFOp  (None, 8, 45)       0           ['input_407[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_236 (TFOp  (None, 11, 45)      0           ['input_408[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_307 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_234[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_234[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_308 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_235[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_235[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_309 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_236[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_236[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_296 (Layer  (None, 8, 45)       90          ['multi_head_attention_307[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_297 (Layer  (None, 8, 45)       90          ['multi_head_attention_308[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_298 (Layer  (None, 11, 45)      90          ['multi_head_attention_309[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_479 (Dropout)          (None, 8, 45)        0           ['layer_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " dropout_480 (Dropout)          (None, 8, 45)        0           ['layer_normalization_297[0][0]']\n",
      "                                                                                                  \n",
      " dropout_481 (Dropout)          (None, 11, 45)       0           ['layer_normalization_298[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_241 (  (None, 45)          0           ['dropout_479[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_242 (  (None, 45)          0           ['dropout_480[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_243 (  (None, 45)          0           ['dropout_481[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_94 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_241[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_242[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_243[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_482 (Dropout)          (None, 135)          0           ['concatenate_94[0][0]']         \n",
      "                                                                                                  \n",
      " dense_206 (Dense)              (None, 128)          17408       ['dropout_482[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_483 (Dropout)          (None, 128)          0           ['dense_206[0][0]']              \n",
      "                                                                                                  \n",
      " dense_207 (Dense)              (None, 1)            129         ['dropout_483[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1170 - accuracy: 0.9555 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.0515 - val_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.0408 - val_accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.0350 - val_accuracy: 0.9924\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 0.0393 - val_accuracy: 0.9924\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0379 - val_accuracy: 0.9943\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_93\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_409 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_410 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_411 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_237 (TFOp  (None, 8, 45)       0           ['input_409[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_238 (TFOp  (None, 8, 45)       0           ['input_410[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_239 (TFOp  (None, 11, 45)      0           ['input_411[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_310 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_237[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_237[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_311 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_238[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_238[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_312 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_239[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_239[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_299 (Layer  (None, 8, 45)       90          ['multi_head_attention_310[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_300 (Layer  (None, 8, 45)       90          ['multi_head_attention_311[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_301 (Layer  (None, 11, 45)      90          ['multi_head_attention_312[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_484 (Dropout)          (None, 8, 45)        0           ['layer_normalization_299[0][0]']\n",
      "                                                                                                  \n",
      " dropout_485 (Dropout)          (None, 8, 45)        0           ['layer_normalization_300[0][0]']\n",
      "                                                                                                  \n",
      " dropout_486 (Dropout)          (None, 11, 45)       0           ['layer_normalization_301[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_244 (  (None, 45)          0           ['dropout_484[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_245 (  (None, 45)          0           ['dropout_485[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_246 (  (None, 45)          0           ['dropout_486[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_95 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_244[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_245[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_246[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_487 (Dropout)          (None, 135)          0           ['concatenate_95[0][0]']         \n",
      "                                                                                                  \n",
      " dense_208 (Dense)              (None, 128)          17408       ['dropout_487[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_488 (Dropout)          (None, 128)          0           ['dense_208[0][0]']              \n",
      "                                                                                                  \n",
      " dense_209 (Dense)              (None, 1)            129         ['dropout_488[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 14ms/step - loss: 0.1649 - accuracy: 0.9432 - val_loss: 0.0524 - val_accuracy: 0.9916\n",
      "Epoch 2/10\n",
      "310/938 [========>.....................] - ETA: 9s - loss: 0.0980 - accuracy: 0.9769\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_94\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_412 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_413 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_414 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_240 (TFOp  (None, 8, 45)       0           ['input_412[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_241 (TFOp  (None, 8, 45)       0           ['input_413[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_242 (TFOp  (None, 11, 45)      0           ['input_414[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_313 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_240[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_240[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_314 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_241[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_241[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_315 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_242[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_242[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_302 (Layer  (None, 8, 45)       90          ['multi_head_attention_313[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_303 (Layer  (None, 8, 45)       90          ['multi_head_attention_314[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_304 (Layer  (None, 11, 45)      90          ['multi_head_attention_315[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_489 (Dropout)          (None, 8, 45)        0           ['layer_normalization_302[0][0]']\n",
      "                                                                                                  \n",
      " dropout_490 (Dropout)          (None, 8, 45)        0           ['layer_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " dropout_491 (Dropout)          (None, 11, 45)       0           ['layer_normalization_304[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_247 (  (None, 45)          0           ['dropout_489[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_248 (  (None, 45)          0           ['dropout_490[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_249 (  (None, 45)          0           ['dropout_491[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_96 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_247[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_248[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_249[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_492 (Dropout)          (None, 135)          0           ['concatenate_96[0][0]']         \n",
      "                                                                                                  \n",
      " dense_210 (Dense)              (None, 128)          17408       ['dropout_492[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_493 (Dropout)          (None, 128)          0           ['dense_210[0][0]']              \n",
      "                                                                                                  \n",
      " dense_211 (Dense)              (None, 1)            129         ['dropout_493[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.2743 - accuracy: 0.8831 - val_loss: 0.1909 - val_accuracy: 0.8824\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1365 - accuracy: 0.9494 - val_loss: 0.0602 - val_accuracy: 0.9771\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1124 - accuracy: 0.9585 - val_loss: 0.0833 - val_accuracy: 0.9677\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1024 - accuracy: 0.9637 - val_loss: 0.0786 - val_accuracy: 0.9754\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0956 - accuracy: 0.9665 - val_loss: 0.0630 - val_accuracy: 0.9763\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0877 - accuracy: 0.9694 - val_loss: 0.0773 - val_accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "615/938 [==================>...........] - ETA: 4s - loss: 0.0846 - accuracy: 0.9711\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_95\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_415 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_416 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_417 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_243 (TFOp  (None, 8, 45)       0           ['input_415[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_244 (TFOp  (None, 8, 45)       0           ['input_416[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_245 (TFOp  (None, 11, 45)      0           ['input_417[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_316 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_243[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_243[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_317 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_244[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_244[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_318 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_245[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_245[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_305 (Layer  (None, 8, 45)       90          ['multi_head_attention_316[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_306 (Layer  (None, 8, 45)       90          ['multi_head_attention_317[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_307 (Layer  (None, 11, 45)      90          ['multi_head_attention_318[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_494 (Dropout)          (None, 8, 45)        0           ['layer_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      " dropout_495 (Dropout)          (None, 8, 45)        0           ['layer_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " dropout_496 (Dropout)          (None, 11, 45)       0           ['layer_normalization_307[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_250 (  (None, 45)          0           ['dropout_494[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_251 (  (None, 45)          0           ['dropout_495[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_252 (  (None, 45)          0           ['dropout_496[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_97 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_250[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_251[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_252[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_497 (Dropout)          (None, 135)          0           ['concatenate_97[0][0]']         \n",
      "                                                                                                  \n",
      " dense_212 (Dense)              (None, 128)          17408       ['dropout_497[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_498 (Dropout)          (None, 128)          0           ['dense_212[0][0]']              \n",
      "                                                                                                  \n",
      " dense_213 (Dense)              (None, 1)            129         ['dropout_498[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1930 - accuracy: 0.9169 - val_loss: 0.0275 - val_accuracy: 0.9912\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0623 - accuracy: 0.9805 - val_loss: 0.0223 - val_accuracy: 0.9921\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0494 - accuracy: 0.9851 - val_loss: 0.0211 - val_accuracy: 0.9926\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0369 - accuracy: 0.9883 - val_loss: 0.0951 - val_accuracy: 0.9656\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0352 - accuracy: 0.9888 - val_loss: 0.0181 - val_accuracy: 0.9938\n",
      "Epoch 6/10\n",
      "172/938 [====>.........................] - ETA: 10s - loss: 0.0325 - accuracy: 0.9884TRAIN resting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_96\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_418 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_419 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_420 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_246 (TFOp  (None, 8, 45)       0           ['input_418[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_247 (TFOp  (None, 8, 45)       0           ['input_419[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_248 (TFOp  (None, 11, 45)      0           ['input_420[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_319 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_246[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_246[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_320 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_247[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_247[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_321 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_248[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_248[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_308 (Layer  (None, 8, 45)       90          ['multi_head_attention_319[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_309 (Layer  (None, 8, 45)       90          ['multi_head_attention_320[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_310 (Layer  (None, 11, 45)      90          ['multi_head_attention_321[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_499 (Dropout)          (None, 8, 45)        0           ['layer_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " dropout_500 (Dropout)          (None, 8, 45)        0           ['layer_normalization_309[0][0]']\n",
      "                                                                                                  \n",
      " dropout_501 (Dropout)          (None, 11, 45)       0           ['layer_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_253 (  (None, 45)          0           ['dropout_499[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_254 (  (None, 45)          0           ['dropout_500[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_255 (  (None, 45)          0           ['dropout_501[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_98 (Concatenate)   (None, 135)          0           ['global_average_pooling1d_253[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_254[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_255[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_502 (Dropout)          (None, 135)          0           ['concatenate_98[0][0]']         \n",
      "                                                                                                  \n",
      " dense_214 (Dense)              (None, 128)          17408       ['dropout_502[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_503 (Dropout)          (None, 128)          0           ['dense_214[0][0]']              \n",
      "                                                                                                  \n",
      " dense_215 (Dense)              (None, 1)            129         ['dropout_503[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.2806 - accuracy: 0.8618 - val_loss: 0.1093 - val_accuracy: 0.9462\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1346 - accuracy: 0.9442 - val_loss: 0.1256 - val_accuracy: 0.9400\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1154 - accuracy: 0.9536 - val_loss: 0.0783 - val_accuracy: 0.9713\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1028 - accuracy: 0.9588 - val_loss: 0.0525 - val_accuracy: 0.9783\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0947 - accuracy: 0.9635 - val_loss: 0.0462 - val_accuracy: 0.9842\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.2163 - accuracy: 0.9209 - val_loss: 0.0682 - val_accuracy: 0.9959\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1226 - accuracy: 0.9706 - val_loss: 0.0435 - val_accuracy: 0.9947\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1146 - accuracy: 0.9713 - val_loss: 0.0466 - val_accuracy: 0.9952\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1014 - accuracy: 0.9720 - val_loss: 0.0355 - val_accuracy: 0.9962\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0952 - accuracy: 0.9733 - val_loss: 0.0849 - val_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0642 - accuracy: 0.9811 - val_loss: 0.0358 - val_accuracy: 0.9895\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0523 - accuracy: 0.9848 - val_loss: 0.0416 - val_accuracy: 0.9909\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0453 - accuracy: 0.9864 - val_loss: 0.0650 - val_accuracy: 0.9852\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0401 - accuracy: 0.9883 - val_loss: 0.0430 - val_accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0547 - val_accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.0192 - val_accuracy: 0.9947\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0099 - val_accuracy: 0.9967\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0092 - accuracy: 0.9980 - val_loss: 0.0125 - val_accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0112 - accuracy: 0.9978 - val_loss: 0.0186 - val_accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0128 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0313 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.0081 - val_accuracy: 0.9971\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0116 - val_accuracy: 0.9971\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 0.0124 - val_accuracy: 0.9959\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0814 - accuracy: 0.9778 - val_loss: 0.0305 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0791 - accuracy: 0.9775 - val_loss: 0.0230 - val_accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0792 - accuracy: 0.9777 - val_loss: 0.0201 - val_accuracy: 0.9957\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0744 - accuracy: 0.9781 - val_loss: 0.0159 - val_accuracy: 0.9947\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_102\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_436 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_437 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_438 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_264 (TFOp  (None, 8, 45)       0           ['input_436[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_265 (TFOp  (None, 8, 45)       0           ['input_437[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_266 (TFOp  (None, 11, 45)      0           ['input_438[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_337 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_264[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_264[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_338 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_265[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_265[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_339 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_266[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_266[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_326 (Layer  (None, 8, 45)       90          ['multi_head_attention_337[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_327 (Layer  (None, 8, 45)       90          ['multi_head_attention_338[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_328 (Layer  (None, 11, 45)      90          ['multi_head_attention_339[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_529 (Dropout)          (None, 8, 45)        0           ['layer_normalization_326[0][0]']\n",
      "                                                                                                  \n",
      " dropout_530 (Dropout)          (None, 8, 45)        0           ['layer_normalization_327[0][0]']\n",
      "                                                                                                  \n",
      " dropout_531 (Dropout)          (None, 11, 45)       0           ['layer_normalization_328[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_271 (  (None, 45)          0           ['dropout_529[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_272 (  (None, 45)          0           ['dropout_530[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_273 (  (None, 45)          0           ['dropout_531[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_271[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_272[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_273[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_532 (Dropout)          (None, 135)          0           ['concatenate_104[0][0]']        \n",
      "                                                                                                  \n",
      " dense_226 (Dense)              (None, 128)          17408       ['dropout_532[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_533 (Dropout)          (None, 128)          0           ['dense_226[0][0]']              \n",
      "                                                                                                  \n",
      " dense_227 (Dense)              (None, 1)            129         ['dropout_533[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.2767 - accuracy: 0.8854 - val_loss: 0.1551 - val_accuracy: 0.9314\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1365 - accuracy: 0.9514 - val_loss: 0.0676 - val_accuracy: 0.9735\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1034 - accuracy: 0.9649 - val_loss: 0.0519 - val_accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0717 - accuracy: 0.9769 - val_loss: 0.0547 - val_accuracy: 0.9797\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0668 - accuracy: 0.9782 - val_loss: 0.0576 - val_accuracy: 0.9854\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0622 - accuracy: 0.9792 - val_loss: 0.0902 - val_accuracy: 0.9756\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 10 19932\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_103\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_439 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_440 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_441 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_267 (TFOp  (None, 8, 45)       0           ['input_439[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_268 (TFOp  (None, 8, 45)       0           ['input_440[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_269 (TFOp  (None, 11, 45)      0           ['input_441[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_340 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_267[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_267[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_341 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_268[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_268[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_342 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_269[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_269[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_329 (Layer  (None, 8, 45)       90          ['multi_head_attention_340[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_330 (Layer  (None, 8, 45)       90          ['multi_head_attention_341[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_331 (Layer  (None, 11, 45)      90          ['multi_head_attention_342[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_534 (Dropout)          (None, 8, 45)        0           ['layer_normalization_329[0][0]']\n",
      "                                                                                                  \n",
      " dropout_535 (Dropout)          (None, 8, 45)        0           ['layer_normalization_330[0][0]']\n",
      "                                                                                                  \n",
      " dropout_536 (Dropout)          (None, 11, 45)       0           ['layer_normalization_331[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_274 (  (None, 45)          0           ['dropout_534[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_275 (  (None, 45)          0           ['dropout_535[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_276 (  (None, 45)          0           ['dropout_536[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_105 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_274[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_275[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_276[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_537 (Dropout)          (None, 135)          0           ['concatenate_105[0][0]']        \n",
      "                                                                                                  \n",
      " dense_228 (Dense)              (None, 128)          17408       ['dropout_537[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_538 (Dropout)          (None, 128)          0           ['dense_228[0][0]']              \n",
      "                                                                                                  \n",
      " dense_229 (Dense)              (None, 1)            129         ['dropout_538[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.2049 - accuracy: 0.9114 - val_loss: 0.0771 - val_accuracy: 0.9768\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0676 - accuracy: 0.9782 - val_loss: 0.0338 - val_accuracy: 0.9885\n",
      "Epoch 3/10\n",
      "544/938 [================>.............] - ETA: 5s - loss: 0.0494 - accuracy: 0.9836\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_104\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_442 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_443 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_444 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_270 (TFOp  (None, 8, 45)       0           ['input_442[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_271 (TFOp  (None, 8, 45)       0           ['input_443[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_272 (TFOp  (None, 11, 45)      0           ['input_444[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_343 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_270[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_270[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_344 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_271[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_271[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_345 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_272[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_272[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_332 (Layer  (None, 8, 45)       90          ['multi_head_attention_343[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_333 (Layer  (None, 8, 45)       90          ['multi_head_attention_344[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_334 (Layer  (None, 11, 45)      90          ['multi_head_attention_345[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_539 (Dropout)          (None, 8, 45)        0           ['layer_normalization_332[0][0]']\n",
      "                                                                                                  \n",
      " dropout_540 (Dropout)          (None, 8, 45)        0           ['layer_normalization_333[0][0]']\n",
      "                                                                                                  \n",
      " dropout_541 (Dropout)          (None, 11, 45)       0           ['layer_normalization_334[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_277 (  (None, 45)          0           ['dropout_539[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_278 (  (None, 45)          0           ['dropout_540[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_279 (  (None, 45)          0           ['dropout_541[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_106 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_277[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_278[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_279[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_542 (Dropout)          (None, 135)          0           ['concatenate_106[0][0]']        \n",
      "                                                                                                  \n",
      " dense_230 (Dense)              (None, 128)          17408       ['dropout_542[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_543 (Dropout)          (None, 128)          0           ['dense_230[0][0]']              \n",
      "                                                                                                  \n",
      " dense_231 (Dense)              (None, 1)            129         ['dropout_543[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2891 - accuracy: 0.8584 - val_loss: 0.0987 - val_accuracy: 0.9682\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1370 - accuracy: 0.9443 - val_loss: 0.1290 - val_accuracy: 0.9341\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1190 - accuracy: 0.9507 - val_loss: 0.1115 - val_accuracy: 0.9632\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1088 - accuracy: 0.9563 - val_loss: 0.1124 - val_accuracy: 0.9606\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1006 - accuracy: 0.9574 - val_loss: 0.0906 - val_accuracy: 0.9732\n",
      "Epoch 6/10\n",
      " 31/938 [..............................] - ETA: 13s - loss: 0.0881 - accuracy: 0.9677\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_105\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_445 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_446 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_447 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_273 (TFOp  (None, 8, 45)       0           ['input_445[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_274 (TFOp  (None, 8, 45)       0           ['input_446[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_275 (TFOp  (None, 11, 45)      0           ['input_447[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_346 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_273[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_273[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_347 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_274[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_274[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_348 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_275[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_275[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_335 (Layer  (None, 8, 45)       90          ['multi_head_attention_346[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_336 (Layer  (None, 8, 45)       90          ['multi_head_attention_347[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_337 (Layer  (None, 11, 45)      90          ['multi_head_attention_348[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_544 (Dropout)          (None, 8, 45)        0           ['layer_normalization_335[0][0]']\n",
      "                                                                                                  \n",
      " dropout_545 (Dropout)          (None, 8, 45)        0           ['layer_normalization_336[0][0]']\n",
      "                                                                                                  \n",
      " dropout_546 (Dropout)          (None, 11, 45)       0           ['layer_normalization_337[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_280 (  (None, 45)          0           ['dropout_544[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_281 (  (None, 45)          0           ['dropout_545[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_282 (  (None, 45)          0           ['dropout_546[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_107 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_280[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_281[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_282[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_547 (Dropout)          (None, 135)          0           ['concatenate_107[0][0]']        \n",
      "                                                                                                  \n",
      " dense_232 (Dense)              (None, 128)          17408       ['dropout_547[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_548 (Dropout)          (None, 128)          0           ['dense_232[0][0]']              \n",
      "                                                                                                  \n",
      " dense_233 (Dense)              (None, 1)            129         ['dropout_548[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 14ms/step - loss: 0.2265 - accuracy: 0.9175 - val_loss: 0.0418 - val_accuracy: 0.9964\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1298 - accuracy: 0.9684 - val_loss: 0.0284 - val_accuracy: 0.9957\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1157 - accuracy: 0.9714 - val_loss: 0.0462 - val_accuracy: 0.9943\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1073 - accuracy: 0.9724 - val_loss: 0.0277 - val_accuracy: 0.9969\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0988 - accuracy: 0.9732 - val_loss: 0.0634 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "  9/938 [..............................] - ETA: 12s - loss: 0.0832 - accuracy: 0.9757TRAIN cooking 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_106\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_448 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_449 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_450 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_276 (TFOp  (None, 8, 45)       0           ['input_448[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_277 (TFOp  (None, 8, 45)       0           ['input_449[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_278 (TFOp  (None, 11, 45)      0           ['input_450[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_349 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_276[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_276[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_350 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_277[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_277[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_351 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_278[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_278[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_338 (Layer  (None, 8, 45)       90          ['multi_head_attention_349[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_339 (Layer  (None, 8, 45)       90          ['multi_head_attention_350[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_340 (Layer  (None, 11, 45)      90          ['multi_head_attention_351[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_549 (Dropout)          (None, 8, 45)        0           ['layer_normalization_338[0][0]']\n",
      "                                                                                                  \n",
      " dropout_550 (Dropout)          (None, 8, 45)        0           ['layer_normalization_339[0][0]']\n",
      "                                                                                                  \n",
      " dropout_551 (Dropout)          (None, 11, 45)       0           ['layer_normalization_340[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_283 (  (None, 45)          0           ['dropout_549[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_284 (  (None, 45)          0           ['dropout_550[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_285 (  (None, 45)          0           ['dropout_551[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_108 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_283[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_284[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_285[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_552 (Dropout)          (None, 135)          0           ['concatenate_108[0][0]']        \n",
      "                                                                                                  \n",
      " dense_234 (Dense)              (None, 128)          17408       ['dropout_552[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_553 (Dropout)          (None, 128)          0           ['dense_234[0][0]']              \n",
      "                                                                                                  \n",
      " dense_235 (Dense)              (None, 1)            129         ['dropout_553[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1831 - accuracy: 0.9174 - val_loss: 0.0458 - val_accuracy: 0.9876\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0594 - accuracy: 0.9815 - val_loss: 0.0171 - val_accuracy: 0.9959\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0525 - accuracy: 0.9840 - val_loss: 0.0211 - val_accuracy: 0.9952\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0442 - accuracy: 0.9867 - val_loss: 0.0115 - val_accuracy: 0.9959\n",
      "Epoch 5/10\n",
      "816/938 [=========================>....] - ETA: 1s - loss: 0.0394 - accuracy: 0.9875TRAIN shower 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_107\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_451 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_452 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_453 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_279 (TFOp  (None, 8, 45)       0           ['input_451[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_280 (TFOp  (None, 8, 45)       0           ['input_452[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_281 (TFOp  (None, 11, 45)      0           ['input_453[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_352 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_279[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_279[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_353 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_280[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_280[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_354 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_281[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_281[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_341 (Layer  (None, 8, 45)       90          ['multi_head_attention_352[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_342 (Layer  (None, 8, 45)       90          ['multi_head_attention_353[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_343 (Layer  (None, 11, 45)      90          ['multi_head_attention_354[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_554 (Dropout)          (None, 8, 45)        0           ['layer_normalization_341[0][0]']\n",
      "                                                                                                  \n",
      " dropout_555 (Dropout)          (None, 8, 45)        0           ['layer_normalization_342[0][0]']\n",
      "                                                                                                  \n",
      " dropout_556 (Dropout)          (None, 11, 45)       0           ['layer_normalization_343[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_286 (  (None, 45)          0           ['dropout_554[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_287 (  (None, 45)          0           ['dropout_555[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_288 (  (None, 45)          0           ['dropout_556[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_109 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_286[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_287[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_288[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_557 (Dropout)          (None, 135)          0           ['concatenate_109[0][0]']        \n",
      "                                                                                                  \n",
      " dense_236 (Dense)              (None, 128)          17408       ['dropout_557[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_558 (Dropout)          (None, 128)          0           ['dense_236[0][0]']              \n",
      "                                                                                                  \n",
      " dense_237 (Dense)              (None, 1)            129         ['dropout_558[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1012 - accuracy: 0.9584 - val_loss: 0.0569 - val_accuracy: 0.9878\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0180 - accuracy: 0.9961 - val_loss: 0.0503 - val_accuracy: 0.9947\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.0573 - val_accuracy: 0.9952\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0094 - accuracy: 0.9982 - val_loss: 0.0520 - val_accuracy: 0.9931\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1159 - accuracy: 0.9573 - val_loss: 0.0626 - val_accuracy: 0.9849\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0232 - accuracy: 0.9954 - val_loss: 0.0055 - val_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0215 - accuracy: 0.9956 - val_loss: 0.0128 - val_accuracy: 0.9962\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.0107 - val_accuracy: 0.9969\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1015 - accuracy: 0.9746 - val_loss: 0.0542 - val_accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0926 - accuracy: 0.9760 - val_loss: 0.0505 - val_accuracy: 0.9878\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0901 - accuracy: 0.9754 - val_loss: 0.0533 - val_accuracy: 0.9878\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0887 - accuracy: 0.9767 - val_loss: 0.0591 - val_accuracy: 0.9914\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0844 - accuracy: 0.9707 - val_loss: 0.0722 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0783 - accuracy: 0.9738 - val_loss: 0.0991 - val_accuracy: 0.9591\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0745 - accuracy: 0.9736 - val_loss: 0.0598 - val_accuracy: 0.9728\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0720 - accuracy: 0.9748 - val_loss: 0.0671 - val_accuracy: 0.9728\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0659 - accuracy: 0.9770 - val_loss: 0.0871 - val_accuracy: 0.9646\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.0345 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.0319 - val_accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0258 - accuracy: 0.9906 - val_loss: 0.0238 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0276 - accuracy: 0.9901 - val_loss: 0.0293 - val_accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.0138 - val_accuracy: 0.9957\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN resting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_112\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_466 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_467 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_468 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_294 (TFOp  (None, 8, 45)       0           ['input_466[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_295 (TFOp  (None, 8, 45)       0           ['input_467[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_296 (TFOp  (None, 11, 45)      0           ['input_468[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_367 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_294[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_294[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_368 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_295[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_295[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_369 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_296[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_296[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_356 (Layer  (None, 8, 45)       90          ['multi_head_attention_367[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_357 (Layer  (None, 8, 45)       90          ['multi_head_attention_368[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_358 (Layer  (None, 11, 45)      90          ['multi_head_attention_369[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_579 (Dropout)          (None, 8, 45)        0           ['layer_normalization_356[0][0]']\n",
      "                                                                                                  \n",
      " dropout_580 (Dropout)          (None, 8, 45)        0           ['layer_normalization_357[0][0]']\n",
      "                                                                                                  \n",
      " dropout_581 (Dropout)          (None, 11, 45)       0           ['layer_normalization_358[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_301 (  (None, 45)          0           ['dropout_579[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_302 (  (None, 45)          0           ['dropout_580[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_303 (  (None, 45)          0           ['dropout_581[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_114 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_301[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_302[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_303[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_582 (Dropout)          (None, 135)          0           ['concatenate_114[0][0]']        \n",
      "                                                                                                  \n",
      " dense_246 (Dense)              (None, 128)          17408       ['dropout_582[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_583 (Dropout)          (None, 128)          0           ['dense_246[0][0]']              \n",
      "                                                                                                  \n",
      " dense_247 (Dense)              (None, 1)            129         ['dropout_583[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0854 - accuracy: 0.9653 - val_loss: 0.0743 - val_accuracy: 0.9744\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0794 - accuracy: 0.9670 - val_loss: 0.0900 - val_accuracy: 0.9668\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0775 - accuracy: 0.9692 - val_loss: 0.1217 - val_accuracy: 0.9565\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN exit 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_113\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_469 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_470 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_471 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_297 (TFOp  (None, 8, 45)       0           ['input_469[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_298 (TFOp  (None, 8, 45)       0           ['input_470[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_299 (TFOp  (None, 11, 45)      0           ['input_471[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_370 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_297[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_297[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_371 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_298[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_298[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_372 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_299[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_299[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_359 (Layer  (None, 8, 45)       90          ['multi_head_attention_370[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_360 (Layer  (None, 8, 45)       90          ['multi_head_attention_371[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_361 (Layer  (None, 11, 45)      90          ['multi_head_attention_372[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_584 (Dropout)          (None, 8, 45)        0           ['layer_normalization_359[0][0]']\n",
      "                                                                                                  \n",
      " dropout_585 (Dropout)          (None, 8, 45)        0           ['layer_normalization_360[0][0]']\n",
      "                                                                                                  \n",
      " dropout_586 (Dropout)          (None, 11, 45)       0           ['layer_normalization_361[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_304 (  (None, 45)          0           ['dropout_584[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_305 (  (None, 45)          0           ['dropout_585[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_306 (  (None, 45)          0           ['dropout_586[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_115 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_304[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_305[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_306[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_587 (Dropout)          (None, 135)          0           ['concatenate_115[0][0]']        \n",
      "                                                                                                  \n",
      " dense_248 (Dense)              (None, 128)          17408       ['dropout_587[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_588 (Dropout)          (None, 128)          0           ['dense_248[0][0]']              \n",
      "                                                                                                  \n",
      " dense_249 (Dense)              (None, 1)            129         ['dropout_588[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.2148 - accuracy: 0.9198 - val_loss: 0.0595 - val_accuracy: 0.9859\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1164 - accuracy: 0.9712 - val_loss: 0.0563 - val_accuracy: 0.9869\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0649 - accuracy: 0.9767 - val_loss: 0.0522 - val_accuracy: 0.9876\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN cooking 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_114\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_472 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_473 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_474 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_300 (TFOp  (None, 8, 45)       0           ['input_472[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_301 (TFOp  (None, 8, 45)       0           ['input_473[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_302 (TFOp  (None, 11, 45)      0           ['input_474[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_373 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_300[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_300[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_374 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_301[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_301[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_375 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_302[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_302[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_362 (Layer  (None, 8, 45)       90          ['multi_head_attention_373[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_363 (Layer  (None, 8, 45)       90          ['multi_head_attention_374[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_364 (Layer  (None, 11, 45)      90          ['multi_head_attention_375[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_589 (Dropout)          (None, 8, 45)        0           ['layer_normalization_362[0][0]']\n",
      "                                                                                                  \n",
      " dropout_590 (Dropout)          (None, 8, 45)        0           ['layer_normalization_363[0][0]']\n",
      "                                                                                                  \n",
      " dropout_591 (Dropout)          (None, 11, 45)       0           ['layer_normalization_364[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_307 (  (None, 45)          0           ['dropout_589[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_308 (  (None, 45)          0           ['dropout_590[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_309 (  (None, 45)          0           ['dropout_591[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_116 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_307[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_308[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_309[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_592 (Dropout)          (None, 135)          0           ['concatenate_116[0][0]']        \n",
      "                                                                                                  \n",
      " dense_250 (Dense)              (None, 128)          17408       ['dropout_592[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_593 (Dropout)          (None, 128)          0           ['dense_250[0][0]']              \n",
      "                                                                                                  \n",
      " dense_251 (Dense)              (None, 1)            129         ['dropout_593[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1905 - accuracy: 0.9140 - val_loss: 0.0232 - val_accuracy: 0.9943\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0654 - accuracy: 0.9808 - val_loss: 0.0242 - val_accuracy: 0.9945\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0583 - accuracy: 0.9827 - val_loss: 0.0718 - val_accuracy: 0.9830\n",
      "Epoch 4/10\n",
      "648/938 [===================>..........] - ETA: 4s - loss: 0.0499 - accuracy: 0.9849\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN shower 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_115\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_475 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_476 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_477 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_303 (TFOp  (None, 8, 45)       0           ['input_475[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_304 (TFOp  (None, 8, 45)       0           ['input_476[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_305 (TFOp  (None, 11, 45)      0           ['input_477[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_376 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_303[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_303[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_377 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_304[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_304[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_378 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_305[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_305[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_365 (Layer  (None, 8, 45)       90          ['multi_head_attention_376[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_366 (Layer  (None, 8, 45)       90          ['multi_head_attention_377[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_367 (Layer  (None, 11, 45)      90          ['multi_head_attention_378[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_594 (Dropout)          (None, 8, 45)        0           ['layer_normalization_365[0][0]']\n",
      "                                                                                                  \n",
      " dropout_595 (Dropout)          (None, 8, 45)        0           ['layer_normalization_366[0][0]']\n",
      "                                                                                                  \n",
      " dropout_596 (Dropout)          (None, 11, 45)       0           ['layer_normalization_367[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_310 (  (None, 45)          0           ['dropout_594[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_311 (  (None, 45)          0           ['dropout_595[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_312 (  (None, 45)          0           ['dropout_596[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_117 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_310[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_311[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_312[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_597 (Dropout)          (None, 135)          0           ['concatenate_117[0][0]']        \n",
      "                                                                                                  \n",
      " dense_252 (Dense)              (None, 128)          17408       ['dropout_597[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_598 (Dropout)          (None, 128)          0           ['dense_252[0][0]']              \n",
      "                                                                                                  \n",
      " dense_253 (Dense)              (None, 1)            129         ['dropout_598[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.0912 - accuracy: 0.9627 - val_loss: 0.0230 - val_accuracy: 0.9945\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.0276 - val_accuracy: 0.9943\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0207 - val_accuracy: 0.9955\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0231 - val_accuracy: 0.9962\n",
      "Epoch 5/10\n",
      "507/938 [===============>..............] - ETA: 5s - loss: 0.0038 - accuracy: 0.9994\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN pc 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_116\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_478 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_479 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_480 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_306 (TFOp  (None, 8, 45)       0           ['input_478[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_307 (TFOp  (None, 8, 45)       0           ['input_479[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_308 (TFOp  (None, 11, 45)      0           ['input_480[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_379 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_306[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_306[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_380 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_307[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_307[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_381 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_308[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_308[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_368 (Layer  (None, 8, 45)       90          ['multi_head_attention_379[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_369 (Layer  (None, 8, 45)       90          ['multi_head_attention_380[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_370 (Layer  (None, 11, 45)      90          ['multi_head_attention_381[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_599 (Dropout)          (None, 8, 45)        0           ['layer_normalization_368[0][0]']\n",
      "                                                                                                  \n",
      " dropout_600 (Dropout)          (None, 8, 45)        0           ['layer_normalization_369[0][0]']\n",
      "                                                                                                  \n",
      " dropout_601 (Dropout)          (None, 11, 45)       0           ['layer_normalization_370[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_313 (  (None, 45)          0           ['dropout_599[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_314 (  (None, 45)          0           ['dropout_600[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_315 (  (None, 45)          0           ['dropout_601[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_118 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_313[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_314[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_315[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_602 (Dropout)          (None, 135)          0           ['concatenate_118[0][0]']        \n",
      "                                                                                                  \n",
      " dense_254 (Dense)              (None, 128)          17408       ['dropout_602[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_603 (Dropout)          (None, 128)          0           ['dense_254[0][0]']              \n",
      "                                                                                                  \n",
      " dense_255 (Dense)              (None, 1)            129         ['dropout_603[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1143 - accuracy: 0.9571 - val_loss: 0.0411 - val_accuracy: 0.9902\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0228 - accuracy: 0.9955 - val_loss: 0.0747 - val_accuracy: 0.9897\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0190 - accuracy: 0.9963 - val_loss: 0.0844 - val_accuracy: 0.9907\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.0401 - val_accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "263/938 [=======>......................] - ETA: 10s - loss: 0.0119 - accuracy: 0.9980\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN sleep 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_117\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_481 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_482 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_483 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_309 (TFOp  (None, 8, 45)       0           ['input_481[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_310 (TFOp  (None, 8, 45)       0           ['input_482[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_311 (TFOp  (None, 11, 45)      0           ['input_483[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_382 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_309[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_309[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_383 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_310[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_310[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_384 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_311[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_311[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_371 (Layer  (None, 8, 45)       90          ['multi_head_attention_382[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_372 (Layer  (None, 8, 45)       90          ['multi_head_attention_383[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_373 (Layer  (None, 11, 45)      90          ['multi_head_attention_384[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_604 (Dropout)          (None, 8, 45)        0           ['layer_normalization_371[0][0]']\n",
      "                                                                                                  \n",
      " dropout_605 (Dropout)          (None, 8, 45)        0           ['layer_normalization_372[0][0]']\n",
      "                                                                                                  \n",
      " dropout_606 (Dropout)          (None, 11, 45)       0           ['layer_normalization_373[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_316 (  (None, 45)          0           ['dropout_604[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_317 (  (None, 45)          0           ['dropout_605[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_318 (  (None, 45)          0           ['dropout_606[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_119 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_316[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_317[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_318[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_607 (Dropout)          (None, 135)          0           ['concatenate_119[0][0]']        \n",
      "                                                                                                  \n",
      " dense_256 (Dense)              (None, 128)          17408       ['dropout_607[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_608 (Dropout)          (None, 128)          0           ['dense_256[0][0]']              \n",
      "                                                                                                  \n",
      " dense_257 (Dense)              (None, 1)            129         ['dropout_608[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1718 - accuracy: 0.9400 - val_loss: 0.0237 - val_accuracy: 0.9947\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1001 - accuracy: 0.9756 - val_loss: 0.0296 - val_accuracy: 0.9928\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0934 - accuracy: 0.9759 - val_loss: 0.0273 - val_accuracy: 0.9945\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0896 - accuracy: 0.9762 - val_loss: 0.0355 - val_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "202/938 [=====>........................] - ETA: 10s - loss: 0.0906 - accuracy: 0.9768TRAIN kitchen 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_118\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_484 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_485 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_486 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_312 (TFOp  (None, 8, 45)       0           ['input_484[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_313 (TFOp  (None, 8, 45)       0           ['input_485[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_314 (TFOp  (None, 11, 45)      0           ['input_486[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_385 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_312[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_312[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_386 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_313[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_313[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_387 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_314[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_314[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_374 (Layer  (None, 8, 45)       90          ['multi_head_attention_385[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_375 (Layer  (None, 8, 45)       90          ['multi_head_attention_386[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_376 (Layer  (None, 11, 45)      90          ['multi_head_attention_387[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_609 (Dropout)          (None, 8, 45)        0           ['layer_normalization_374[0][0]']\n",
      "                                                                                                  \n",
      " dropout_610 (Dropout)          (None, 8, 45)        0           ['layer_normalization_375[0][0]']\n",
      "                                                                                                  \n",
      " dropout_611 (Dropout)          (None, 11, 45)       0           ['layer_normalization_376[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_319 (  (None, 45)          0           ['dropout_609[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_320 (  (None, 45)          0           ['dropout_610[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_321 (  (None, 45)          0           ['dropout_611[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_120 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_319[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_320[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_321[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_612 (Dropout)          (None, 135)          0           ['concatenate_120[0][0]']        \n",
      "                                                                                                  \n",
      " dense_258 (Dense)              (None, 128)          17408       ['dropout_612[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_613 (Dropout)          (None, 128)          0           ['dense_258[0][0]']              \n",
      "                                                                                                  \n",
      " dense_259 (Dense)              (None, 1)            129         ['dropout_613[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.2683 - accuracy: 0.8881 - val_loss: 0.1002 - val_accuracy: 0.9491\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1351 - accuracy: 0.9501 - val_loss: 0.0601 - val_accuracy: 0.9766\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1094 - accuracy: 0.9620 - val_loss: 0.0717 - val_accuracy: 0.9737\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0983 - accuracy: 0.9665 - val_loss: 0.0691 - val_accuracy: 0.9756\n",
      "Epoch 5/10\n",
      "248/938 [======>.......................] - ETA: 9s - loss: 0.0949 - accuracy: 0.9677TRAIN toileting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_119\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_487 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_488 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_489 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_315 (TFOp  (None, 8, 45)       0           ['input_487[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_316 (TFOp  (None, 8, 45)       0           ['input_488[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_317 (TFOp  (None, 11, 45)      0           ['input_489[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_388 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_315[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_315[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_389 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_316[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_316[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_390 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_317[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_317[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_377 (Layer  (None, 8, 45)       90          ['multi_head_attention_388[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_378 (Layer  (None, 8, 45)       90          ['multi_head_attention_389[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_379 (Layer  (None, 11, 45)      90          ['multi_head_attention_390[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_614 (Dropout)          (None, 8, 45)        0           ['layer_normalization_377[0][0]']\n",
      "                                                                                                  \n",
      " dropout_615 (Dropout)          (None, 8, 45)        0           ['layer_normalization_378[0][0]']\n",
      "                                                                                                  \n",
      " dropout_616 (Dropout)          (None, 11, 45)       0           ['layer_normalization_379[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_322 (  (None, 45)          0           ['dropout_614[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_323 (  (None, 45)          0           ['dropout_615[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_324 (  (None, 45)          0           ['dropout_616[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_121 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_322[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_323[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_324[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_617 (Dropout)          (None, 135)          0           ['concatenate_121[0][0]']        \n",
      "                                                                                                  \n",
      " dense_260 (Dense)              (None, 128)          17408       ['dropout_617[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_618 (Dropout)          (None, 128)          0           ['dense_260[0][0]']              \n",
      "                                                                                                  \n",
      " dense_261 (Dense)              (None, 1)            129         ['dropout_618[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.2051 - accuracy: 0.9090 - val_loss: 0.0621 - val_accuracy: 0.9859\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0718 - accuracy: 0.9782 - val_loss: 0.0167 - val_accuracy: 0.9950\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0549 - accuracy: 0.9822 - val_loss: 0.0349 - val_accuracy: 0.9895\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0445 - accuracy: 0.9859 - val_loss: 0.0557 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1291 - accuracy: 0.9461 - val_loss: 0.0902 - val_accuracy: 0.9515\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1111 - accuracy: 0.9533 - val_loss: 0.1057 - val_accuracy: 0.9434\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1007 - accuracy: 0.9593 - val_loss: 0.0978 - val_accuracy: 0.9472\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0941 - accuracy: 0.9636 - val_loss: 0.0945 - val_accuracy: 0.9486\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0867 - accuracy: 0.9652 - val_loss: 0.0930 - val_accuracy: 0.9441\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0976 - accuracy: 0.9734 - val_loss: 0.0196 - val_accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0934 - accuracy: 0.9736 - val_loss: 0.0179 - val_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0886 - accuracy: 0.9740 - val_loss: 0.0867 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 0.0482 - val_accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0748 - accuracy: 0.9748 - val_loss: 0.0517 - val_accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0239 - val_accuracy: 0.9919\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.0375 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0289 - accuracy: 0.9913 - val_loss: 0.0299 - val_accuracy: 0.9919\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN shower 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_123\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_499 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_500 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_501 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_327 (TFOp  (None, 8, 45)       0           ['input_499[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_328 (TFOp  (None, 8, 45)       0           ['input_500[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_329 (TFOp  (None, 11, 45)      0           ['input_501[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_400 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_327[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_327[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_401 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_328[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_328[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_402 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_329[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_329[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_389 (Layer  (None, 8, 45)       90          ['multi_head_attention_400[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_390 (Layer  (None, 8, 45)       90          ['multi_head_attention_401[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_391 (Layer  (None, 11, 45)      90          ['multi_head_attention_402[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_634 (Dropout)          (None, 8, 45)        0           ['layer_normalization_389[0][0]']\n",
      "                                                                                                  \n",
      " dropout_635 (Dropout)          (None, 8, 45)        0           ['layer_normalization_390[0][0]']\n",
      "                                                                                                  \n",
      " dropout_636 (Dropout)          (None, 11, 45)       0           ['layer_normalization_391[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_334 (  (None, 45)          0           ['dropout_634[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_335 (  (None, 45)          0           ['dropout_635[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_336 (  (None, 45)          0           ['dropout_636[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_125 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_334[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_335[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_336[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_637 (Dropout)          (None, 135)          0           ['concatenate_125[0][0]']        \n",
      "                                                                                                  \n",
      " dense_268 (Dense)              (None, 128)          17408       ['dropout_637[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_638 (Dropout)          (None, 128)          0           ['dense_268[0][0]']              \n",
      "                                                                                                  \n",
      " dense_269 (Dense)              (None, 1)            129         ['dropout_638[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1067 - accuracy: 0.9522 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 5.4794e-08 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0234 - val_accuracy: 0.9940\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN pc 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_124\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_502 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_503 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_504 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_330 (TFOp  (None, 8, 45)       0           ['input_502[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_331 (TFOp  (None, 8, 45)       0           ['input_503[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_332 (TFOp  (None, 11, 45)      0           ['input_504[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_403 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_330[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_330[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_404 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_331[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_331[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_405 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_332[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_332[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_392 (Layer  (None, 8, 45)       90          ['multi_head_attention_403[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_393 (Layer  (None, 8, 45)       90          ['multi_head_attention_404[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_394 (Layer  (None, 11, 45)      90          ['multi_head_attention_405[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_639 (Dropout)          (None, 8, 45)        0           ['layer_normalization_392[0][0]']\n",
      "                                                                                                  \n",
      " dropout_640 (Dropout)          (None, 8, 45)        0           ['layer_normalization_393[0][0]']\n",
      "                                                                                                  \n",
      " dropout_641 (Dropout)          (None, 11, 45)       0           ['layer_normalization_394[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_337 (  (None, 45)          0           ['dropout_639[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_338 (  (None, 45)          0           ['dropout_640[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_339 (  (None, 45)          0           ['dropout_641[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_126 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_337[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_338[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_339[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_642 (Dropout)          (None, 135)          0           ['concatenate_126[0][0]']        \n",
      "                                                                                                  \n",
      " dense_270 (Dense)              (None, 128)          17408       ['dropout_642[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_643 (Dropout)          (None, 128)          0           ['dense_270[0][0]']              \n",
      "                                                                                                  \n",
      " dense_271 (Dense)              (None, 1)            129         ['dropout_643[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1133 - accuracy: 0.9577 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.0026 - val_accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 7.1917e-04 - val_accuracy: 0.9998\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN sleep 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_125\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_505 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_506 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_507 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_333 (TFOp  (None, 8, 45)       0           ['input_505[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_334 (TFOp  (None, 8, 45)       0           ['input_506[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_335 (TFOp  (None, 11, 45)      0           ['input_507[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_406 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_333[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_333[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_407 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_334[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_334[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_408 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_335[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_335[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_395 (Layer  (None, 8, 45)       90          ['multi_head_attention_406[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_396 (Layer  (None, 8, 45)       90          ['multi_head_attention_407[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_397 (Layer  (None, 11, 45)      90          ['multi_head_attention_408[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_644 (Dropout)          (None, 8, 45)        0           ['layer_normalization_395[0][0]']\n",
      "                                                                                                  \n",
      " dropout_645 (Dropout)          (None, 8, 45)        0           ['layer_normalization_396[0][0]']\n",
      "                                                                                                  \n",
      " dropout_646 (Dropout)          (None, 11, 45)       0           ['layer_normalization_397[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_340 (  (None, 45)          0           ['dropout_644[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_341 (  (None, 45)          0           ['dropout_645[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_342 (  (None, 45)          0           ['dropout_646[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_127 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_340[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_341[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_342[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_647 (Dropout)          (None, 135)          0           ['concatenate_127[0][0]']        \n",
      "                                                                                                  \n",
      " dense_272 (Dense)              (None, 128)          17408       ['dropout_647[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_648 (Dropout)          (None, 128)          0           ['dense_272[0][0]']              \n",
      "                                                                                                  \n",
      " dense_273 (Dense)              (None, 1)            129         ['dropout_648[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1758 - accuracy: 0.9363 - val_loss: 0.0242 - val_accuracy: 0.9943\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1010 - accuracy: 0.9764 - val_loss: 0.0294 - val_accuracy: 0.9959\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0949 - accuracy: 0.9758 - val_loss: 0.0226 - val_accuracy: 0.9957\n",
      "Epoch 4/10\n",
      "637/938 [===================>..........] - ETA: 4s - loss: 0.0874 - accuracy: 0.9777\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN kitchen 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_126\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_508 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_509 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_510 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_336 (TFOp  (None, 8, 45)       0           ['input_508[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_337 (TFOp  (None, 8, 45)       0           ['input_509[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_338 (TFOp  (None, 11, 45)      0           ['input_510[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_409 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_336[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_336[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_410 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_337[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_337[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_411 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_338[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_338[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_398 (Layer  (None, 8, 45)       90          ['multi_head_attention_409[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_399 (Layer  (None, 8, 45)       90          ['multi_head_attention_410[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_400 (Layer  (None, 11, 45)      90          ['multi_head_attention_411[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_649 (Dropout)          (None, 8, 45)        0           ['layer_normalization_398[0][0]']\n",
      "                                                                                                  \n",
      " dropout_650 (Dropout)          (None, 8, 45)        0           ['layer_normalization_399[0][0]']\n",
      "                                                                                                  \n",
      " dropout_651 (Dropout)          (None, 11, 45)       0           ['layer_normalization_400[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_343 (  (None, 45)          0           ['dropout_649[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_344 (  (None, 45)          0           ['dropout_650[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_345 (  (None, 45)          0           ['dropout_651[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_128 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_343[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_344[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_345[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_652 (Dropout)          (None, 135)          0           ['concatenate_128[0][0]']        \n",
      "                                                                                                  \n",
      " dense_274 (Dense)              (None, 128)          17408       ['dropout_652[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_653 (Dropout)          (None, 128)          0           ['dense_274[0][0]']              \n",
      "                                                                                                  \n",
      " dense_275 (Dense)              (None, 1)            129         ['dropout_653[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.2755 - accuracy: 0.8830 - val_loss: 0.2190 - val_accuracy: 0.8889\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1365 - accuracy: 0.9498 - val_loss: 0.1106 - val_accuracy: 0.9577\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1092 - accuracy: 0.9617 - val_loss: 0.0892 - val_accuracy: 0.9682\n",
      "Epoch 4/10\n",
      "902/938 [===========================>..] - ETA: 0s - loss: 0.1009 - accuracy: 0.9634\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN toileting 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_127\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_511 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_512 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_513 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_339 (TFOp  (None, 8, 45)       0           ['input_511[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_340 (TFOp  (None, 8, 45)       0           ['input_512[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_341 (TFOp  (None, 11, 45)      0           ['input_513[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_412 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_339[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_339[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_413 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_340[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_340[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_414 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_341[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_341[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_401 (Layer  (None, 8, 45)       90          ['multi_head_attention_412[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_402 (Layer  (None, 8, 45)       90          ['multi_head_attention_413[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_403 (Layer  (None, 11, 45)      90          ['multi_head_attention_414[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_654 (Dropout)          (None, 8, 45)        0           ['layer_normalization_401[0][0]']\n",
      "                                                                                                  \n",
      " dropout_655 (Dropout)          (None, 8, 45)        0           ['layer_normalization_402[0][0]']\n",
      "                                                                                                  \n",
      " dropout_656 (Dropout)          (None, 11, 45)       0           ['layer_normalization_403[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_346 (  (None, 45)          0           ['dropout_654[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_347 (  (None, 45)          0           ['dropout_655[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_348 (  (None, 45)          0           ['dropout_656[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_129 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_346[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_347[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_348[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_657 (Dropout)          (None, 135)          0           ['concatenate_129[0][0]']        \n",
      "                                                                                                  \n",
      " dense_276 (Dense)              (None, 128)          17408       ['dropout_657[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_658 (Dropout)          (None, 128)          0           ['dense_276[0][0]']              \n",
      "                                                                                                  \n",
      " dense_277 (Dense)              (None, 1)            129         ['dropout_658[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2151 - accuracy: 0.9050 - val_loss: 0.0403 - val_accuracy: 0.9888\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0715 - accuracy: 0.9755 - val_loss: 0.0326 - val_accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.0245 - val_accuracy: 0.9912\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0446 - accuracy: 0.9839 - val_loss: 0.0199 - val_accuracy: 0.9935\n",
      "Epoch 5/10\n",
      " 68/938 [=>............................] - ETA: 11s - loss: 0.0381 - accuracy: 0.9903TRAIN resting 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_128\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_514 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_515 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_516 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_342 (TFOp  (None, 8, 45)       0           ['input_514[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_343 (TFOp  (None, 8, 45)       0           ['input_515[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_344 (TFOp  (None, 11, 45)      0           ['input_516[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_415 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_342[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_342[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_416 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_343[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_343[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_417 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_344[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_344[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_404 (Layer  (None, 8, 45)       90          ['multi_head_attention_415[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_405 (Layer  (None, 8, 45)       90          ['multi_head_attention_416[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_406 (Layer  (None, 11, 45)      90          ['multi_head_attention_417[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_659 (Dropout)          (None, 8, 45)        0           ['layer_normalization_404[0][0]']\n",
      "                                                                                                  \n",
      " dropout_660 (Dropout)          (None, 8, 45)        0           ['layer_normalization_405[0][0]']\n",
      "                                                                                                  \n",
      " dropout_661 (Dropout)          (None, 11, 45)       0           ['layer_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_349 (  (None, 45)          0           ['dropout_659[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_350 (  (None, 45)          0           ['dropout_660[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_351 (  (None, 45)          0           ['dropout_661[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_130 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_349[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_350[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_351[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_662 (Dropout)          (None, 135)          0           ['concatenate_130[0][0]']        \n",
      "                                                                                                  \n",
      " dense_278 (Dense)              (None, 128)          17408       ['dropout_662[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_663 (Dropout)          (None, 128)          0           ['dense_278[0][0]']              \n",
      "                                                                                                  \n",
      " dense_279 (Dense)              (None, 1)            129         ['dropout_663[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2655 - accuracy: 0.8710 - val_loss: 0.1014 - val_accuracy: 0.9711\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1258 - accuracy: 0.9468 - val_loss: 0.0834 - val_accuracy: 0.9735\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1068 - accuracy: 0.9573 - val_loss: 0.0917 - val_accuracy: 0.9706\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0969 - accuracy: 0.9626 - val_loss: 0.0725 - val_accuracy: 0.9763\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1019 - accuracy: 0.9730 - val_loss: 0.0863 - val_accuracy: 0.9857\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0957 - accuracy: 0.9741 - val_loss: 0.0525 - val_accuracy: 0.9881\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0955 - accuracy: 0.9730 - val_loss: 0.0548 - val_accuracy: 0.9849\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0835 - accuracy: 0.9750 - val_loss: 0.0624 - val_accuracy: 0.9849\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 0.0411 - val_accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0298 - accuracy: 0.9910 - val_loss: 0.0635 - val_accuracy: 0.9852\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0317 - accuracy: 0.9904 - val_loss: 0.0602 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.0672 - val_accuracy: 0.9864\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0127 - val_accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0305 - val_accuracy: 0.9947\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0150 - val_accuracy: 0.9976\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN pc 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_132\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_526 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_527 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_528 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_354 (TFOp  (None, 8, 45)       0           ['input_526[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_355 (TFOp  (None, 8, 45)       0           ['input_527[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_356 (TFOp  (None, 11, 45)      0           ['input_528[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_427 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_354[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_354[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_428 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_355[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_355[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_429 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_356[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_356[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_416 (Layer  (None, 8, 45)       90          ['multi_head_attention_427[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_417 (Layer  (None, 8, 45)       90          ['multi_head_attention_428[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_418 (Layer  (None, 11, 45)      90          ['multi_head_attention_429[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_679 (Dropout)          (None, 8, 45)        0           ['layer_normalization_416[0][0]']\n",
      "                                                                                                  \n",
      " dropout_680 (Dropout)          (None, 8, 45)        0           ['layer_normalization_417[0][0]']\n",
      "                                                                                                  \n",
      " dropout_681 (Dropout)          (None, 11, 45)       0           ['layer_normalization_418[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_361 (  (None, 45)          0           ['dropout_679[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_362 (  (None, 45)          0           ['dropout_680[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_363 (  (None, 45)          0           ['dropout_681[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_134 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_361[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_362[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_363[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_682 (Dropout)          (None, 135)          0           ['concatenate_134[0][0]']        \n",
      "                                                                                                  \n",
      " dense_286 (Dense)              (None, 128)          17408       ['dropout_682[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_683 (Dropout)          (None, 128)          0           ['dense_286[0][0]']              \n",
      "                                                                                                  \n",
      " dense_287 (Dense)              (None, 1)            129         ['dropout_683[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.1115 - accuracy: 0.9573 - val_loss: 9.9377e-04 - val_accuracy: 0.9998\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0011 - val_accuracy: 0.9998\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN sleep 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_133\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_529 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_530 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_531 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_357 (TFOp  (None, 8, 45)       0           ['input_529[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_358 (TFOp  (None, 8, 45)       0           ['input_530[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_359 (TFOp  (None, 11, 45)      0           ['input_531[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_430 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_357[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_357[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_431 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_358[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_358[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_432 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_359[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_359[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_419 (Layer  (None, 8, 45)       90          ['multi_head_attention_430[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_420 (Layer  (None, 8, 45)       90          ['multi_head_attention_431[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_421 (Layer  (None, 11, 45)      90          ['multi_head_attention_432[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_684 (Dropout)          (None, 8, 45)        0           ['layer_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " dropout_685 (Dropout)          (None, 8, 45)        0           ['layer_normalization_420[0][0]']\n",
      "                                                                                                  \n",
      " dropout_686 (Dropout)          (None, 11, 45)       0           ['layer_normalization_421[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_364 (  (None, 45)          0           ['dropout_684[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_365 (  (None, 45)          0           ['dropout_685[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_366 (  (None, 45)          0           ['dropout_686[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_135 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_364[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_365[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_366[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_687 (Dropout)          (None, 135)          0           ['concatenate_135[0][0]']        \n",
      "                                                                                                  \n",
      " dense_288 (Dense)              (None, 128)          17408       ['dropout_687[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_688 (Dropout)          (None, 128)          0           ['dense_288[0][0]']              \n",
      "                                                                                                  \n",
      " dense_289 (Dense)              (None, 1)            129         ['dropout_688[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.1825 - accuracy: 0.9320 - val_loss: 0.0278 - val_accuracy: 0.9919\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1040 - accuracy: 0.9737 - val_loss: 0.0283 - val_accuracy: 0.9938\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0976 - accuracy: 0.9745 - val_loss: 0.0314 - val_accuracy: 0.9943\n",
      "Epoch 4/10\n",
      "384/938 [===========>..................] - ETA: 7s - loss: 0.0967 - accuracy: 0.9750\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN kitchen 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_134\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_532 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_533 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_534 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_360 (TFOp  (None, 8, 45)       0           ['input_532[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_361 (TFOp  (None, 8, 45)       0           ['input_533[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_362 (TFOp  (None, 11, 45)      0           ['input_534[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_433 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_360[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_360[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_434 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_361[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_361[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_435 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_362[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_362[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_422 (Layer  (None, 8, 45)       90          ['multi_head_attention_433[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_423 (Layer  (None, 8, 45)       90          ['multi_head_attention_434[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_424 (Layer  (None, 11, 45)      90          ['multi_head_attention_435[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_689 (Dropout)          (None, 8, 45)        0           ['layer_normalization_422[0][0]']\n",
      "                                                                                                  \n",
      " dropout_690 (Dropout)          (None, 8, 45)        0           ['layer_normalization_423[0][0]']\n",
      "                                                                                                  \n",
      " dropout_691 (Dropout)          (None, 11, 45)       0           ['layer_normalization_424[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_367 (  (None, 45)          0           ['dropout_689[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_368 (  (None, 45)          0           ['dropout_690[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_369 (  (None, 45)          0           ['dropout_691[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_136 (Concatenate)  (None, 135)          0           ['global_average_pooling1d_367[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_368[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_369[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_692 (Dropout)          (None, 135)          0           ['concatenate_136[0][0]']        \n",
      "                                                                                                  \n",
      " dense_290 (Dense)              (None, 128)          17408       ['dropout_692[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_693 (Dropout)          (None, 128)          0           ['dense_290[0][0]']              \n",
      "                                                                                                  \n",
      " dense_291 (Dense)              (None, 1)            129         ['dropout_693[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 215,582\n",
      "Trainable params: 215,582\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.2540 - accuracy: 0.8953 - val_loss: 0.0916 - val_accuracy: 0.9532\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1397 - accuracy: 0.9497 - val_loss: 0.1356 - val_accuracy: 0.9410\n",
      "Epoch 3/10\n",
      "587/938 [=================>............] - ETA: 5s - loss: 0.1117 - accuracy: 0.9618"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "SizeTrainOk=4000\n",
    "SizeTrainKo=6000\n",
    "\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    print(\"\\t\",dx,day)\n",
    "    other_dx= [other for other in range(0,len(days)) if other != dx]\n",
    "\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    \n",
    "    for ax,activity in enumerate(activities):\n",
    "            print(ax,activity)\n",
    "            \n",
    "            ##TRAING DATA\n",
    "            L1=[]\n",
    "            L2=[]\n",
    "            S=[]\n",
    "            Y=[]\n",
    "            for ux,user in enumerate(users):\n",
    "                    print(\"\\t\\t\",ux,user)\n",
    "                    other_ux= [other for other in range(0,len(users)) if other != ux]\n",
    "                    print(day,user,other_dx,other_ux)\n",
    "\n",
    "                    #OK act\n",
    "                    for ix in range(0,SizeTrainOk):\n",
    "                        #print(\"SizeTrainOk\",ix,\"vs\",SizeTrainOk)\n",
    "                        filtered_elements = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 1)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            #print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                            X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        Ss=[]\n",
    "                        for sx, sensor in enumerate(sensors):\n",
    "                            Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                        L1.append(X1s)\n",
    "                        L2.append(X2s)\n",
    "                        S.append(Ss)\n",
    "                        Y.append(user_activity[index])\n",
    "                        \n",
    "                    #KO act\n",
    "                    ix=0\n",
    "                    while ix < SizeTrainKo:\n",
    "                        #print(\"SizeTrainKo\",ix,\"vs\",SizeTrainKo)\n",
    "                        filtered_elements_specific = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 0)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        none=True\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            #if(ax2==ax):\n",
    "                                r=np.random.rand()\n",
    "                                #print(\" removing loc?:\",loc_user[ax2][iu][idy][tt],r)\n",
    "                                if(r<loc_user[ax2][iu][idy][tt]+0.05):\n",
    "                                    #print(\"NOT  removing loc:\",loc_user[ax2][iu][idy][tt])\n",
    "                                    none=False\n",
    "                                    \n",
    "                                X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                                X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        if not none:\n",
    "                            L1.append(X1s)\n",
    "                            L2.append(X2s)\n",
    "                            Ss=[]\n",
    "                            for sx, sensor in enumerate(sensors):\n",
    "                                Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                            S.append(Ss)\n",
    "                            Y.append(user_activity[index])       \n",
    "                            ix=ix+1\n",
    "\n",
    "            L1=np.array(L1)        \n",
    "            L2=np.array(L2)        \n",
    "            S=np.array(S)\n",
    "            Y=np.array(Y)\n",
    "            print(\"TRAIN\",activity,day,L1.shape,L2.shape,S.shape,Y.shape)\n",
    "            \n",
    "            \n",
    "            model=getModelHAR()\n",
    "            model.summary()\n",
    "            \n",
    "            ##TEST DATA\n",
    "            TL1=[]\n",
    "            TL2=[]\n",
    "            TS=[]\n",
    "            TY=[]\n",
    "            \n",
    "            \n",
    "            (t0,tN)=t0N_days[day]\n",
    "            ts=list(range(TWA,sizeT(t0,tN)-TWB))\n",
    "            \n",
    "            for ux2,user2 in enumerate(users):\n",
    "                other_ux2= [other for other in range(0,len(users)) if other != ux2]\n",
    "\n",
    "                for tx in ts:\n",
    "\n",
    "                    Ss=[]\n",
    "                    for sx, sensor in enumerate(sensors):\n",
    "                        Ss.append(act_sensors[sx][dx][tx-TWA:tx+TWB])\n",
    "                    \n",
    "                    X1s=[]\n",
    "                    X2s=[]\n",
    "                    for ax2,activity2 in enumerate(activities):\n",
    "                        X1s.append(loc_user[ax2][ux2][dx][tx-TWA:tx+TWB])\n",
    "                        X2s.append(np.amax(loc_user[ax2,other_ux2,dx,tx-TWA:tx+TWB],axis=0))\n",
    "\n",
    "\n",
    "                    TL1.append(X1s)\n",
    "                    TL2.append(X2s)\n",
    "                    TS.append(Ss)\n",
    "                    TY.append(user_activity[ax, ux2, dx, tx])\n",
    "                        \n",
    "            TL1=np.array(TL1)        \n",
    "            TL2=np.array(TL2)        \n",
    "            TS=np.array(TS)\n",
    "            TY=np.array(TY)\n",
    "            print(\"EVAL\",activity,day,TL1.shape,TL2.shape,TS.shape,TY.shape)\n",
    "            \n",
    "            history = model.fit([L1,L2,S] , Y, shuffle=True, batch_size=32,epochs=10, validation_data = ([TL1,TL2,TS], TY))\n",
    "            YT_prediction = model.predict([TL1,TL2,TS])\n",
    "            print(YT_prediction.shape)\n",
    "            \n",
    "            ix=0\n",
    "            for ux2,user2 in enumerate(users):\n",
    "                with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/PREDICTION-TRANS-ENC-DEC-POS-30+15.\"+user2+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                    for tx in (ts):\n",
    "                        tt=tx*time_step2+t0\n",
    "                        #print(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0]))\n",
    "                        file.write(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0])+\"\\n\")\n",
    "                        \n",
    "                        ix=ix+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fc952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
