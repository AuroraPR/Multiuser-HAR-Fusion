{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934b764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2024-07-05': ['0001', '3d57', 'ed9c'], '2024-07-06': ['0001', '3d57', 'ed9c'], '2024-07-07': ['0001', '3d57', 'ed9c'], '2024-07-18': ['16fe', 'f02e', 'ed9c'], '2024-07-19': ['16fe', 'f02e', 'ed9c'], '2024-07-20': ['16fe', 'f02e', 'ed9c'], '2024-07-24': ['16fe', '5b66', 'ed9c'], '2024-07-25': ['16fe', '5b66', 'ed9c'], '2024-07-26': ['16fe', '5b66', 'ed9c'], '2024-07-27': ['16fe', '5b66', 'ed9c'], '2024-07-28': ['16fe', '5b66', 'ed9c'], '2024-07-29': ['16fe', '5b66', 'ed9c'], '2024-07-30': ['16fe', '5b66', 'ed9c'], '2024-07-31': ['16fe', '5b66', 'ed9c']}\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('agg-config.txt')\n",
    "\n",
    "\n",
    "time_step = int(config.get('Configuration', 'time_step'))\n",
    "time_step2 = int(config.get('Configuration', 'time_step2'))\n",
    "\n",
    "window_size = int(config.get('Configuration', 'window_size'))\n",
    "processed_data_folder = config.get('Configuration', 'processed_data_folder')\n",
    "raw_data_folder = config.get('Configuration', 'raw_data_folder')\n",
    "\n",
    "ini_date = config.get('Configuration', 'ini_date')\n",
    "end_date = config.get('Configuration', 'end_date')\n",
    "\n",
    "\n",
    "activities=config.get('Configuration', 'learn_activities')\n",
    "activities = [(item.strip()) for item in activities.split(',')]\n",
    "\n",
    "cross_days=config.get('Configuration', 'cross_days')\n",
    "cross_days = [(item.strip()) for item in cross_days.split(',')]\n",
    "\n",
    "sensors=config.get('Configuration', 'sensors')\n",
    "sensors = [(item.strip()) for item in sensors.split(',')]\n",
    "\n",
    "w = int(config.get('Configuration', 'w'))\n",
    "h = int(config.get('Configuration', 'h'))\n",
    "\n",
    "users_day={}\n",
    "for cross_day in cross_days:\n",
    "    users_day[cross_day]=config.get('Configuration', cross_day)\n",
    "    users_day[cross_day] = [(item.strip()) for item in users_day[cross_day].split(',')]\n",
    "print(users_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ea50ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv    \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "off_zone=60*60*2\n",
    "\n",
    "def day_time(t0,tN,ti):\n",
    "    return int((int)((ti+off_zone)/(60*60*24)))\n",
    "\n",
    "\n",
    "def time2str(t0,tN,tt):\n",
    "    return datetime.fromtimestamp(tt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def day_time0(t0,tN,ti):\n",
    "    return day_time(ti)-day_time(t0)+1\n",
    "\n",
    "def relT(t0,tN,ti):\n",
    "    return (int)((ti-t0)/time_step2)\n",
    "\n",
    "def sizeT(t0,tN):\n",
    "    return relT(t0,tN,tN)+1\n",
    "\n",
    "\n",
    "def initTime(ini_date,end_date):\n",
    "    tN = (int)(datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "\n",
    "    t0 = (int)(datetime.strptime(ini_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    print (ini_date,\"Init date is\", t0, \"day:\",day_time(t0,tN,t0), time2str(t0,tN,t0))\n",
    "    print (end_date,\"End date is\", tN, \"day:\",day_time(t0,tN,tN), time2str(t0,tN,tN))\n",
    "\n",
    "    day=list(range(day_time(t0,tN,t0),day_time(t0,tN,tN)+1))[0]\n",
    "    return day,t0,tN\n",
    "    \n",
    "initTime(ini_date,end_date)\n",
    "\n",
    "\n",
    "def getStrDatefrom(day_number):\n",
    "    # Reference date (1970-01-01)\n",
    "    reference_date = datetime(1970, 1, 1)\n",
    "    \n",
    "    # Compute the date corresponding to the day number\n",
    "    resulting_date = reference_date + timedelta(days=day_number)\n",
    "    \n",
    "    return resulting_date.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeeab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ed8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-05\n",
      "New ini_date: 2024-07-05 02:00:00\n",
      "New end_date: 2024-07-06 01:59:59\n",
      "2024-07-05 02:00:00 Init date is 1720137600 day: 19909 2024-07-05 02:00:00\n",
      "2024-07-06 01:59:59 End date is 1720223999 day: 19910 2024-07-06 01:59:59\n",
      "2024-07-06\n",
      "New ini_date: 2024-07-06 02:00:00\n",
      "New end_date: 2024-07-07 01:59:59\n",
      "2024-07-06 02:00:00 Init date is 1720224000 day: 19910 2024-07-06 02:00:00\n",
      "2024-07-07 01:59:59 End date is 1720310399 day: 19911 2024-07-07 01:59:59\n",
      "2024-07-07\n",
      "New ini_date: 2024-07-07 02:00:00\n",
      "New end_date: 2024-07-08 01:59:59\n",
      "2024-07-07 02:00:00 Init date is 1720310400 day: 19911 2024-07-07 02:00:00\n",
      "2024-07-08 01:59:59 End date is 1720396799 day: 19912 2024-07-08 01:59:59\n",
      "2024-07-18\n",
      "New ini_date: 2024-07-18 02:00:00\n",
      "New end_date: 2024-07-19 01:59:59\n",
      "2024-07-18 02:00:00 Init date is 1721260800 day: 19922 2024-07-18 02:00:00\n",
      "2024-07-19 01:59:59 End date is 1721347199 day: 19923 2024-07-19 01:59:59\n",
      "2024-07-19\n",
      "New ini_date: 2024-07-19 02:00:00\n",
      "New end_date: 2024-07-20 01:59:59\n",
      "2024-07-19 02:00:00 Init date is 1721347200 day: 19923 2024-07-19 02:00:00\n",
      "2024-07-20 01:59:59 End date is 1721433599 day: 19924 2024-07-20 01:59:59\n",
      "2024-07-20\n",
      "New ini_date: 2024-07-20 02:00:00\n",
      "New end_date: 2024-07-21 01:59:59\n",
      "2024-07-20 02:00:00 Init date is 1721433600 day: 19924 2024-07-20 02:00:00\n",
      "2024-07-21 01:59:59 End date is 1721519999 day: 19925 2024-07-21 01:59:59\n",
      "2024-07-24\n",
      "New ini_date: 2024-07-24 02:00:00\n",
      "New end_date: 2024-07-25 01:59:59\n",
      "2024-07-24 02:00:00 Init date is 1721779200 day: 19928 2024-07-24 02:00:00\n",
      "2024-07-25 01:59:59 End date is 1721865599 day: 19929 2024-07-25 01:59:59\n",
      "2024-07-25\n",
      "New ini_date: 2024-07-25 02:00:00\n",
      "New end_date: 2024-07-26 01:59:59\n",
      "2024-07-25 02:00:00 Init date is 1721865600 day: 19929 2024-07-25 02:00:00\n",
      "2024-07-26 01:59:59 End date is 1721951999 day: 19930 2024-07-26 01:59:59\n",
      "2024-07-26\n",
      "New ini_date: 2024-07-26 02:00:00\n",
      "New end_date: 2024-07-27 01:59:59\n",
      "2024-07-26 02:00:00 Init date is 1721952000 day: 19930 2024-07-26 02:00:00\n",
      "2024-07-27 01:59:59 End date is 1722038399 day: 19931 2024-07-27 01:59:59\n",
      "2024-07-27\n",
      "New ini_date: 2024-07-27 02:00:00\n",
      "New end_date: 2024-07-28 01:59:59\n",
      "2024-07-27 02:00:00 Init date is 1722038400 day: 19931 2024-07-27 02:00:00\n",
      "2024-07-28 01:59:59 End date is 1722124799 day: 19932 2024-07-28 01:59:59\n",
      "2024-07-28\n",
      "New ini_date: 2024-07-28 02:00:00\n",
      "New end_date: 2024-07-29 01:59:59\n",
      "2024-07-28 02:00:00 Init date is 1722124800 day: 19932 2024-07-28 02:00:00\n",
      "2024-07-29 01:59:59 End date is 1722211199 day: 19933 2024-07-29 01:59:59\n",
      "2024-07-29\n",
      "New ini_date: 2024-07-29 02:00:00\n",
      "New end_date: 2024-07-30 01:59:59\n",
      "2024-07-29 02:00:00 Init date is 1722211200 day: 19933 2024-07-29 02:00:00\n",
      "2024-07-30 01:59:59 End date is 1722297599 day: 19934 2024-07-30 01:59:59\n",
      "2024-07-30\n",
      "New ini_date: 2024-07-30 02:00:00\n",
      "New end_date: 2024-07-31 01:59:59\n",
      "2024-07-30 02:00:00 Init date is 1722297600 day: 19934 2024-07-30 02:00:00\n",
      "2024-07-31 01:59:59 End date is 1722383999 day: 19935 2024-07-31 01:59:59\n",
      "2024-07-31\n",
      "New ini_date: 2024-07-31 02:00:00\n",
      "New end_date: 2024-08-01 01:59:59\n",
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n",
      "[19909, 19910, 19911, 19922, 19923, 19924, 19928, 19929, 19930, 19931, 19932, 19933, 19934, 19935]\n",
      "{19909: (1720137600, 1720223999), 19910: (1720224000, 1720310399), 19911: (1720310400, 1720396799), 19922: (1721260800, 1721347199), 19923: (1721347200, 1721433599), 19924: (1721433600, 1721519999), 19928: (1721779200, 1721865599), 19929: (1721865600, 1721951999), 19930: (1721952000, 1722038399), 19931: (1722038400, 1722124799), 19932: (1722124800, 1722211199), 19933: (1722211200, 1722297599), 19934: (1722297600, 1722383999), 19935: (1722384000, 1722470399)}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "days=[]\n",
    "t0N_days={}\n",
    "\n",
    "for cross_day in cross_days:\n",
    "    print(cross_day)\n",
    "    # Convertir las fechas a objetos datetime\n",
    "    ini_date_dt = datetime.strptime(ini_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    cross_day_dt = datetime.strptime(cross_day, \"%Y-%m-%d\")\n",
    "\n",
    "    # Reemplazar el d√≠a manteniendo la hora original\n",
    "    new_ini_date = cross_day_dt.replace(hour=ini_date_dt.hour, minute=ini_date_dt.minute, second=ini_date_dt.second)\n",
    "    new_end_date = cross_day_dt.replace(hour=end_date_dt.hour, minute=end_date_dt.minute, second=end_date_dt.second) + timedelta(days=1)\n",
    "\n",
    "    # Convertir las fechas de nuevo a cadena si es necesario\n",
    "    new_ini_date_str = new_ini_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    new_end_date_str = new_end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    print(f\"New ini_date: {new_ini_date_str}\")\n",
    "    print(f\"New end_date: {new_end_date_str}\")\n",
    "    day,t0,tN=initTime(new_ini_date_str,new_end_date_str)\n",
    "    days.append(day)\n",
    "    t0N_days[day]=(t0,tN)\n",
    "    \n",
    "\n",
    "print(days)\n",
    "print(t0N_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 14, 1440)\n",
      "\t toileting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.toileting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.toileting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.toileting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.toileting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.toileting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.toileting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.toileting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.toileting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.toileting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.toileting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.toileting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.toileting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.toileting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.toileting.tsv\n",
      "19935 (1440,)\n",
      "\t resting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.resting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.resting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.resting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.resting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.resting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.resting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.resting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.resting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.resting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.resting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.resting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.resting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.resting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.resting.tsv\n",
      "19935 (1440,)\n",
      "\t exit\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.exit.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.exit.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.exit.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.exit.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.exit.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.exit.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.exit.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.exit.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.exit.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.exit.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.exit.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.exit.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.exit.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.exit.tsv\n",
      "19935 (1440,)\n",
      "\t cooking\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.cooking.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.cooking.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.cooking.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.cooking.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.cooking.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.cooking.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.cooking.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.cooking.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.cooking.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.cooking.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.cooking.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.cooking.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.cooking.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.cooking.tsv\n",
      "19935 (1440,)\n",
      "\t shower\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.shower.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.shower.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.shower.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.shower.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.shower.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.shower.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.shower.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.shower.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.shower.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.shower.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.shower.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.shower.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.shower.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.shower.tsv\n",
      "19935 (1440,)\n",
      "\t pc\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.pc.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.pc.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.pc.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.pc.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.pc.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.pc.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.pc.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.pc.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.pc.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.pc.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.pc.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.pc.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.pc.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.pc.tsv\n",
      "19935 (1440,)\n",
      "\t sleep\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.sleep.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.sleep.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.sleep.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.sleep.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.sleep.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.sleep.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.sleep.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.sleep.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.sleep.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.sleep.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.sleep.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.sleep.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.sleep.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.sleep.tsv\n",
      "19935 (1440,)\n",
      "\t kitchen\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.kitchen.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.kitchen.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.kitchen.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.kitchen.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.kitchen.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.kitchen.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.kitchen.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.kitchen.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.kitchen.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.kitchen.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.kitchen.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.kitchen.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.kitchen.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.kitchen.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "len_users=3\n",
    "loc_user=np.zeros((len(activities),len_users,len(days),sizeT(t0,tN)))\n",
    "print(loc_user.shape)\n",
    "for ax,activity in enumerate(activities):\n",
    "    print(\"\\t\",activity)\n",
    "    for dx,day in enumerate(days):\n",
    "        day_str=getStrDatefrom(day)\n",
    "        users=users_day[day_str]\n",
    "        print(day,users)\n",
    "        for ux,user in enumerate(users):\n",
    "            print(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\")\n",
    "            series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"loc\"])\n",
    "            series=series[\"loc\"].values\n",
    "            print(day,series.shape)\n",
    "            loc_user[ax][ux][dx]=series\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9631e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 14, 1440)\n",
      "\t fridge_13\n",
      "./data-har//DAY_19909/object_sensor/fridge_13.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/fridge_13.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/fridge_13.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/fridge_13.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/fridge_13.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/fridge_13.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/fridge_13.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/fridge_13.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/fridge_13.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/fridge_13.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/fridge_13.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/fridge_13.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/fridge_13.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/fridge_13.tsv\n",
      "19935 (1440,)\n",
      "\t tap_22\n",
      "./data-har//DAY_19909/object_sensor/tap_22.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/tap_22.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/tap_22.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/tap_22.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/tap_22.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/tap_22.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/tap_22.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/tap_22.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/tap_22.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/tap_22.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/tap_22.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/tap_22.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/tap_22.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/tap_22.tsv\n",
      "19935 (1440,)\n",
      "\t micro_5\n",
      "./data-har//DAY_19909/object_sensor/micro_5.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/micro_5.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/micro_5.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/micro_5.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/micro_5.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/micro_5.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/micro_5.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/micro_5.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/micro_5.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/micro_5.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/micro_5.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/micro_5.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/micro_5.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/micro_5.tsv\n",
      "19935 (1440,)\n",
      "\t pans_8\n",
      "./data-har//DAY_19909/object_sensor/pans_8.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pans_8.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pans_8.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pans_8.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pans_8.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pans_8.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pans_8.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pans_8.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pans_8.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pans_8.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pans_8.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pans_8.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pans_8.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pans_8.tsv\n",
      "19935 (1440,)\n",
      "\t dishes_9\n",
      "./data-har//DAY_19909/object_sensor/dishes_9.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/dishes_9.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/dishes_9.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/dishes_9.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/dishes_9.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/dishes_9.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/dishes_9.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/dishes_9.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/dishes_9.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/dishes_9.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/dishes_9.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/dishes_9.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/dishes_9.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/dishes_9.tsv\n",
      "19935 (1440,)\n",
      "\t shower_24_apertura\n",
      "./data-har//DAY_19909/object_sensor/shower_24_apertura.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_24_apertura.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_24_apertura.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_24_apertura.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_24_apertura.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_24_apertura.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_24_apertura.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_24_apertura.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_24_apertura.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_24_apertura.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_24_apertura.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_24_apertura.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_24_apertura.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_24_apertura.tsv\n",
      "19935 (1440,)\n",
      "\t hum_shower_25\n",
      "./data-har//DAY_19909/object_sensor/hum_shower_25.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/hum_shower_25.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/hum_shower_25.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/hum_shower_25.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/hum_shower_25.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/hum_shower_25.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/hum_shower_25.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/hum_shower_25.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/hum_shower_25.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/hum_shower_25.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/hum_shower_25.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/hum_shower_25.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/hum_shower_25.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/hum_shower_25.tsv\n",
      "19935 (1440,)\n",
      "\t shower_31\n",
      "./data-har//DAY_19909/object_sensor/shower_31.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_31.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_31.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_31.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_31.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_31.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_31.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_31.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_31.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_31.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_31.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_31.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_31.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_31.tsv\n",
      "19935 (1440,)\n",
      "\t wc_17\n",
      "./data-har//DAY_19909/object_sensor/wc_17.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/wc_17.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/wc_17.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/wc_17.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/wc_17.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/wc_17.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/wc_17.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/wc_17.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/wc_17.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/wc_17.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/wc_17.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/wc_17.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/wc_17.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/wc_17.tsv\n",
      "19935 (1440,)\n",
      "\t sink_21\n",
      "./data-har//DAY_19909/object_sensor/sink_21.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/sink_21.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/sink_21.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/sink_21.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/sink_21.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/sink_21.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/sink_21.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/sink_21.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/sink_21.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/sink_21.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/sink_21.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/sink_21.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/sink_21.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/sink_21.tsv\n",
      "19935 (1440,)\n",
      "\t pc_1_current_consumption\n",
      "./data-har//DAY_19909/object_sensor/pc_1_current_consumption.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pc_1_current_consumption.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pc_1_current_consumption.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pc_1_current_consumption.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pc_1_current_consumption.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pc_1_current_consumption.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pc_1_current_consumption.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pc_1_current_consumption.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pc_1_current_consumption.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pc_1_current_consumption.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pc_1_current_consumption.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pc_1_current_consumption.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pc_1_current_consumption.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pc_1_current_consumption.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "act_sensors=np.zeros((len(sensors),len(days),sizeT(t0,tN)))\n",
    "print(act_sensors.shape)\n",
    "for sx,sensor in enumerate(sensors):\n",
    "    print(\"\\t\",sensor)\n",
    "    for dx,day in enumerate(days):\n",
    "        print(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\")\n",
    "        series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"status\"])\n",
    "        series=series[\"status\"].values\n",
    "        print(day,series.shape)\n",
    "        act_sensors[sx][dx]=series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n"
     ]
    }
   ],
   "source": [
    "user_activity=np.zeros((len(activities),len(users),len(days),sizeT(t0,tN)))\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            df_total=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/INTERVAL.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"ix\",\"d0\",\"dN\"])\n",
    "            #print(df_total)\n",
    "            #print(pd.to_datetime(df_total['d0']))\n",
    "            df_total['d0'] = pd.to_datetime(df_total['d0'])\n",
    "            df_total['dN'] = pd.to_datetime(df_total['dN'])\n",
    "            #print(df_total)\n",
    "\n",
    "            for tx,tt in enumerate(ts):\n",
    "                ttt=pd.to_datetime(time2str(t0,tN,tt))\n",
    "#                print(ttt)\n",
    "                row = df_total[(df_total['d0'] <= ttt) & (df_total['dN'] >= ttt)]\n",
    "#                print(\"df_in#tervalo\",row)\n",
    "                if(row.size>0):\n",
    "                    user_activity[ax][ux][dx][tx]=1\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "            \n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/LABEL3.\"+user+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                for tx,tt in enumerate(ts):\n",
    "                    file.write(time2str(t0,tN,tt)+\"\\t\"+str(user_activity[ax][ux][dx][tx])+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b92a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 00:02:50.724951: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 00:02:50.849647: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 00:02:51.714590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-11-27 00:02:53.257164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.429133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.429173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.434555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.434596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.434613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.751146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.751264: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.751275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-27 00:02:53.751301: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-27 00:02:53.751378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 45, 8)        0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 45, 8)        0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 45, 11)       0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 45, 8)       2248        ['reshape[0][0]',                \n",
      " dAttention)                                                      'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 45, 8)       2248        ['reshape_1[0][0]',              \n",
      " eadAttention)                                                    'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 45, 11)      4147        ['reshape_2[0][0]',              \n",
      " eadAttention)                                                    'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 45, 8)       16          ['multi_head_attention[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 45, 8)       16          ['multi_head_attention_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 45, 11)      22          ['multi_head_attention_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 45, 8)        0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 45, 8)        0           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 45, 11)       0           ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 45, 27)       0           ['dropout[0][0]',                \n",
      "                                                                  'dropout_1[0][0]',              \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 27)          0           ['concatenate[0][0]']            \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 27)           0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 27)        0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 1, 27)       24003       ['tf.expand_dims[0][0]',         \n",
      " eadAttention)                                                    'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 27)          0           ['multi_head_attention_3[0][0]'] \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 27)          54          ['tf.compat.v1.squeeze[0][0]']   \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 27)           0           ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         28672       ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          131200      ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            129         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, concatenate, GRU, TimeDistributed, Attention, Add, Dropout,Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv1D, TimeDistributed, Flatten, Dropout, GRU, Attention, Add, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, Concatenate, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, MultiHeadAttention, LayerNormalization, Dropout, Dense, Reshape, Concatenate, GlobalAveragePooling1D\n",
    "\n",
    "\n",
    "N1 = len(activities)\n",
    "N2 = len(activities)\n",
    "N3 = len(sensors)\n",
    "\n",
    "TWA = 45\n",
    "TWB = 0\n",
    "T = TWA + TWB\n",
    "\n",
    "def getModelHAR():\n",
    "    # Define inputs\n",
    "    input1 = Input(shape=(N1, T, 1))\n",
    "    input2 = Input(shape=(N2, T, 1))\n",
    "    input3 = Input(shape=(N3, T, 1))\n",
    "\n",
    "    # Reshape inputs for the attention mechanism \n",
    "    reshaped1 = Reshape((T, N1))(input1)\n",
    "    reshaped2 = Reshape((T, N2))(input2)\n",
    "    reshaped3 = Reshape((T, N3))(input3)\n",
    "\n",
    "    # Encoder for the first sequence\n",
    "    encoder1 = MultiHeadAttention(num_heads=8, key_dim=N1)(reshaped1, reshaped1)\n",
    "    encoder1 = LayerNormalization()(encoder1)\n",
    "    encoder1 = Dropout(0.5)(encoder1)\n",
    "\n",
    "    # Encoder for the second sequence\n",
    "    encoder2 = MultiHeadAttention(num_heads=8, key_dim=N2)(reshaped2, reshaped2)\n",
    "    encoder2 = LayerNormalization()(encoder2)\n",
    "    encoder2 = Dropout(0.5)(encoder2)\n",
    "\n",
    "    # Encoder for the third sequence\n",
    "    encoder3 = MultiHeadAttention(num_heads=8, key_dim=N3)(reshaped3, reshaped3)\n",
    "    encoder3 = LayerNormalization()(encoder3)\n",
    "    encoder3 = Dropout(0.5)(encoder3)\n",
    "\n",
    "    # Concatenation of the encoded sequences\n",
    "    merged_encoded = Concatenate(axis=-1)([encoder1, encoder2, encoder3]) \n",
    "\n",
    "    # Bottleneck layer (latent representation)\n",
    "    bottleneck = GlobalAveragePooling1D()(merged_encoded) # Pooling for classification\n",
    "    bottleneck = Dropout(0.5)(bottleneck)\n",
    "\n",
    "    # Expand dimensions for attention\n",
    "    bottleneck_expanded = tf.expand_dims(bottleneck, axis=1)  # Add temporal dimension\n",
    "\n",
    "    # Single Decoder with Multi-head Attention\n",
    "    decoder = MultiHeadAttention(num_heads=8, key_dim=bottleneck_expanded.shape[-1])(bottleneck_expanded, bottleneck_expanded)\n",
    "    decoder = tf.squeeze(decoder, axis=1)  # Remove the added temporal dimension\n",
    "    decoder = LayerNormalization()(decoder)\n",
    "    decoder = Dropout(0.5)(decoder)\n",
    "\n",
    "    # Dense layers for classification\n",
    "    dense = Dense(1024, activation='relu')(decoder)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(128, activation='relu')(dense)\n",
    "    output = Dense(1, activation='sigmoid')(dense) # Binary classification\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=[input1, input2, input3], outputs=output)\n",
    "\n",
    "    # Compile the model - binary crossentropy for classification\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "    return model\n",
    "\n",
    "# Instanciaci√≥n del modelo\n",
    "model = getModelHAR()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "386cb41e-bb1e-4043-b002-ea2c550f5dbd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a216fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 19909\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 45, 8)        0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 45, 8)        0           ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 45, 11)       0           ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 45, 8)       2248        ['reshape_3[0][0]',              \n",
      " eadAttention)                                                    'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 45, 8)       2248        ['reshape_4[0][0]',              \n",
      " eadAttention)                                                    'reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 45, 11)      4147        ['reshape_5[0][0]',              \n",
      " eadAttention)                                                    'reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 45, 8)       16          ['multi_head_attention_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 45, 8)       16          ['multi_head_attention_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 45, 11)      22          ['multi_head_attention_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 45, 8)        0           ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 45, 8)        0           ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 45, 11)       0           ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 45, 27)       0           ['dropout_6[0][0]',              \n",
      "                                                                  'dropout_7[0][0]',              \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 27)          0           ['concatenate_1[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 27)           0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 1, 27)        0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 1, 27)       24003       ['tf.expand_dims_1[0][0]',       \n",
      " eadAttention)                                                    'tf.expand_dims_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_1 (TFOpLa  (None, 27)          0           ['multi_head_attention_7[0][0]'] \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 27)          54          ['tf.compat.v1.squeeze_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 27)           0           ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1024)         28672       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 1024)         0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          131200      ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            129         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 00:04:06.062931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-11-27 00:04:06.115834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-11-27 00:04:06.186802: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f1b90f912f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-27 00:04:06.186869: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-11-27 00:04:06.192414: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-27 00:04:06.349350: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 20s 15ms/step - loss: 0.6103 - accuracy: 0.6474 - val_loss: 0.6058 - val_accuracy: 0.5477\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.5466 - accuracy: 0.7314 - val_loss: 0.3965 - val_accuracy: 0.7983\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4934 - accuracy: 0.7738 - val_loss: 0.3373 - val_accuracy: 0.8385\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4821 - accuracy: 0.7823 - val_loss: 0.4028 - val_accuracy: 0.7876\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4747 - accuracy: 0.7848 - val_loss: 0.3509 - val_accuracy: 0.8045\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4712 - accuracy: 0.7856 - val_loss: 0.3858 - val_accuracy: 0.8234\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4655 - accuracy: 0.7907 - val_loss: 0.3481 - val_accuracy: 0.8327\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4587 - accuracy: 0.7931 - val_loss: 0.3462 - val_accuracy: 0.8327\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4563 - accuracy: 0.7976 - val_loss: 0.3785 - val_accuracy: 0.8308\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4450 - accuracy: 0.8018 - val_loss: 0.3586 - val_accuracy: 0.8084\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 45, 8)        0           ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 45, 8)        0           ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 45, 11)       0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 45, 8)       2248        ['reshape_6[0][0]',              \n",
      " eadAttention)                                                    'reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 45, 8)       2248        ['reshape_7[0][0]',              \n",
      " eadAttention)                                                    'reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 45, 11)      4147        ['reshape_8[0][0]',              \n",
      " HeadAttention)                                                   'reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 45, 8)       16          ['multi_head_attention_8[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 45, 8)       16          ['multi_head_attention_9[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 45, 11)      22          ['multi_head_attention_10[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 45, 8)        0           ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 45, 8)        0           ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 45, 11)       0           ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 45, 27)       0           ['dropout_12[0][0]',             \n",
      "                                                                  'dropout_13[0][0]',             \n",
      "                                                                  'dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 27)          0           ['concatenate_2[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 27)           0           ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 1, 27)        0           ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_2[0][0]',       \n",
      " HeadAttention)                                                   'tf.expand_dims_2[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_2 (TFOpLa  (None, 27)          0           ['multi_head_attention_11[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_2[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 27)           0           ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 1024)         28672       ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 1024)         0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          131200      ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            129         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5132 - accuracy: 0.7425 - val_loss: 0.4467 - val_accuracy: 0.6803\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4152 - accuracy: 0.8000 - val_loss: 0.5132 - val_accuracy: 0.7226\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4029 - accuracy: 0.8024 - val_loss: 0.3750 - val_accuracy: 0.7240\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3796 - accuracy: 0.8176 - val_loss: 0.4090 - val_accuracy: 0.7556\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3671 - accuracy: 0.8275 - val_loss: 0.3435 - val_accuracy: 0.7783\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3508 - accuracy: 0.8351 - val_loss: 0.3229 - val_accuracy: 0.8578\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3311 - accuracy: 0.8453 - val_loss: 0.3676 - val_accuracy: 0.8270\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3175 - accuracy: 0.8543 - val_loss: 0.4880 - val_accuracy: 0.7902\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3019 - accuracy: 0.8622 - val_loss: 0.4068 - val_accuracy: 0.8378\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2976 - accuracy: 0.8695 - val_loss: 0.4734 - val_accuracy: 0.8464\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 45, 8)        0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_10 (Reshape)           (None, 45, 8)        0           ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_11 (Reshape)           (None, 45, 11)       0           ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 45, 8)       2248        ['reshape_9[0][0]',              \n",
      " HeadAttention)                                                   'reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 45, 8)       2248        ['reshape_10[0][0]',             \n",
      " HeadAttention)                                                   'reshape_10[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 45, 11)      4147        ['reshape_11[0][0]',             \n",
      " HeadAttention)                                                   'reshape_11[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 45, 8)       16          ['multi_head_attention_12[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 45, 8)       16          ['multi_head_attention_13[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 45, 11)      22          ['multi_head_attention_14[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 45, 8)        0           ['layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 45, 8)        0           ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 45, 11)       0           ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 45, 27)       0           ['dropout_18[0][0]',             \n",
      "                                                                  'dropout_19[0][0]',             \n",
      "                                                                  'dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 27)          0           ['concatenate_3[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 27)           0           ['global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 1, 27)        0           ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_3[0][0]',       \n",
      " HeadAttention)                                                   'tf.expand_dims_3[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_3 (TFOpLa  (None, 27)          0           ['multi_head_attention_15[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_3[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 27)           0           ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1024)         28672       ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 1024)         0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          131200      ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            129         ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 14ms/step - loss: 0.3861 - accuracy: 0.8426 - val_loss: 0.3102 - val_accuracy: 0.9051\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2585 - accuracy: 0.9206 - val_loss: 0.1966 - val_accuracy: 0.9429\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2369 - accuracy: 0.9298 - val_loss: 0.1867 - val_accuracy: 0.9520\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2303 - accuracy: 0.9309 - val_loss: 0.1691 - val_accuracy: 0.9558\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2269 - accuracy: 0.9311 - val_loss: 0.1502 - val_accuracy: 0.9570\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2172 - accuracy: 0.9349 - val_loss: 0.1538 - val_accuracy: 0.9568\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2113 - accuracy: 0.9357 - val_loss: 0.1542 - val_accuracy: 0.9575\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2053 - accuracy: 0.9391 - val_loss: 0.1710 - val_accuracy: 0.9503\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.1953 - accuracy: 0.9415 - val_loss: 0.1468 - val_accuracy: 0.9613\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.1998 - accuracy: 0.9409 - val_loss: 0.1433 - val_accuracy: 0.9618\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_12 (Reshape)           (None, 45, 8)        0           ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_13 (Reshape)           (None, 45, 8)        0           ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_14 (Reshape)           (None, 45, 11)       0           ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 45, 8)       2248        ['reshape_12[0][0]',             \n",
      " HeadAttention)                                                   'reshape_12[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 45, 8)       2248        ['reshape_13[0][0]',             \n",
      " HeadAttention)                                                   'reshape_13[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 45, 11)      4147        ['reshape_14[0][0]',             \n",
      " HeadAttention)                                                   'reshape_14[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 45, 8)       16          ['multi_head_attention_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 45, 8)       16          ['multi_head_attention_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 45, 11)      22          ['multi_head_attention_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 45, 8)        0           ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 45, 8)        0           ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 45, 11)       0           ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 45, 27)       0           ['dropout_24[0][0]',             \n",
      "                                                                  'dropout_25[0][0]',             \n",
      "                                                                  'dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 27)          0           ['concatenate_4[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 27)           0           ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 1, 27)        0           ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_4[0][0]',       \n",
      " HeadAttention)                                                   'tf.expand_dims_4[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_4 (TFOpLa  (None, 27)          0           ['multi_head_attention_19[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_4[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 27)           0           ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 1024)         28672       ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 1024)         0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 128)          131200      ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1)            129         ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 14ms/step - loss: 0.4958 - accuracy: 0.7803 - val_loss: 0.2656 - val_accuracy: 0.9023\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4195 - accuracy: 0.8260 - val_loss: 0.3302 - val_accuracy: 0.7897\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3883 - accuracy: 0.8360 - val_loss: 0.2393 - val_accuracy: 0.8973\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 13ms/step - loss: 0.3849 - accuracy: 0.8391 - val_loss: 0.3424 - val_accuracy: 0.8179\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3752 - accuracy: 0.8405 - val_loss: 0.3056 - val_accuracy: 0.8753\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3742 - accuracy: 0.8395 - val_loss: 0.2159 - val_accuracy: 0.8920\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.3700 - accuracy: 0.8434 - val_loss: 0.2337 - val_accuracy: 0.8815\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3659 - accuracy: 0.8419 - val_loss: 0.3055 - val_accuracy: 0.8519\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3628 - accuracy: 0.8434 - val_loss: 0.2543 - val_accuracy: 0.9111\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3620 - accuracy: 0.8450 - val_loss: 0.2924 - val_accuracy: 0.8669\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_17 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_15 (Reshape)           (None, 45, 8)        0           ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_16 (Reshape)           (None, 45, 8)        0           ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_17 (Reshape)           (None, 45, 11)       0           ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 45, 8)       2248        ['reshape_15[0][0]',             \n",
      " HeadAttention)                                                   'reshape_15[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 45, 8)       2248        ['reshape_16[0][0]',             \n",
      " HeadAttention)                                                   'reshape_16[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 45, 11)      4147        ['reshape_17[0][0]',             \n",
      " HeadAttention)                                                   'reshape_17[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 45, 8)       16          ['multi_head_attention_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 45, 8)       16          ['multi_head_attention_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 45, 11)      22          ['multi_head_attention_22[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 45, 8)        0           ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 45, 8)        0           ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 45, 11)       0           ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 45, 27)       0           ['dropout_30[0][0]',             \n",
      "                                                                  'dropout_31[0][0]',             \n",
      "                                                                  'dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 27)          0           ['concatenate_5[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 27)           0           ['global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLambda)  (None, 1, 27)        0           ['dropout_33[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_5[0][0]',       \n",
      " HeadAttention)                                                   'tf.expand_dims_5[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_5 (TFOpLa  (None, 27)          0           ['multi_head_attention_23[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_5[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 27)           0           ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1024)         28672       ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 1024)         0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          131200      ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            129         ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 14ms/step - loss: 0.3711 - accuracy: 0.8219 - val_loss: 0.2225 - val_accuracy: 0.8385\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2585 - accuracy: 0.8979 - val_loss: 0.2334 - val_accuracy: 0.8636\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2124 - accuracy: 0.9209 - val_loss: 0.2363 - val_accuracy: 0.8774\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1693 - accuracy: 0.9408 - val_loss: 0.1674 - val_accuracy: 0.9202\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1495 - accuracy: 0.9486 - val_loss: 0.1699 - val_accuracy: 0.9137\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1378 - accuracy: 0.9523 - val_loss: 0.1292 - val_accuracy: 0.9352\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1250 - accuracy: 0.9575 - val_loss: 0.1655 - val_accuracy: 0.9214\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1250 - accuracy: 0.9574 - val_loss: 0.1369 - val_accuracy: 0.9343\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1185 - accuracy: 0.9608 - val_loss: 0.1855 - val_accuracy: 0.9183\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1122 - accuracy: 0.9616 - val_loss: 0.1358 - val_accuracy: 0.9331\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_18 (Reshape)           (None, 45, 8)        0           ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_19 (Reshape)           (None, 45, 8)        0           ['input_20[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_20 (Reshape)           (None, 45, 11)       0           ['input_21[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 45, 8)       2248        ['reshape_18[0][0]',             \n",
      " HeadAttention)                                                   'reshape_18[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 45, 8)       2248        ['reshape_19[0][0]',             \n",
      " HeadAttention)                                                   'reshape_19[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 45, 11)      4147        ['reshape_20[0][0]',             \n",
      " HeadAttention)                                                   'reshape_20[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 45, 8)       16          ['multi_head_attention_24[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 45, 8)       16          ['multi_head_attention_25[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 45, 11)      22          ['multi_head_attention_26[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 45, 8)        0           ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 45, 8)        0           ['layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 45, 11)       0           ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 45, 27)       0           ['dropout_36[0][0]',             \n",
      "                                                                  'dropout_37[0][0]',             \n",
      "                                                                  'dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 27)          0           ['concatenate_6[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 27)           0           ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLambda)  (None, 1, 27)        0           ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_6[0][0]',       \n",
      " HeadAttention)                                                   'tf.expand_dims_6[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_6 (TFOpLa  (None, 27)          0           ['multi_head_attention_27[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_6[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 27)           0           ['layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1024)         28672       ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 1024)         0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 128)          131200      ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 1)            129         ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 14ms/step - loss: 0.3827 - accuracy: 0.8218 - val_loss: 0.4007 - val_accuracy: 0.7008\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3252 - accuracy: 0.8560 - val_loss: 0.2120 - val_accuracy: 0.9207\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2434 - accuracy: 0.9077 - val_loss: 0.3014 - val_accuracy: 0.8631\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2212 - accuracy: 0.9151 - val_loss: 0.1935 - val_accuracy: 0.9211\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2015 - accuracy: 0.9254 - val_loss: 0.1171 - val_accuracy: 0.9527\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1792 - accuracy: 0.9351 - val_loss: 0.2641 - val_accuracy: 0.8999\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1630 - accuracy: 0.9434 - val_loss: 0.1988 - val_accuracy: 0.9257\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1439 - accuracy: 0.9514 - val_loss: 0.1085 - val_accuracy: 0.9625\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1309 - accuracy: 0.9567 - val_loss: 0.0996 - val_accuracy: 0.9618\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1217 - accuracy: 0.9591 - val_loss: 0.0846 - val_accuracy: 0.9687\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_21 (Reshape)           (None, 45, 8)        0           ['input_22[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_22 (Reshape)           (None, 45, 8)        0           ['input_23[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_23 (Reshape)           (None, 45, 11)       0           ['input_24[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 45, 8)       2248        ['reshape_21[0][0]',             \n",
      " HeadAttention)                                                   'reshape_21[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 45, 8)       2248        ['reshape_22[0][0]',             \n",
      " HeadAttention)                                                   'reshape_22[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (Multi  (None, 45, 11)      4147        ['reshape_23[0][0]',             \n",
      " HeadAttention)                                                   'reshape_23[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 45, 8)       16          ['multi_head_attention_28[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 45, 8)       16          ['multi_head_attention_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 45, 11)      22          ['multi_head_attention_30[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 45, 8)        0           ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 45, 8)        0           ['layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 45, 11)       0           ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 45, 27)       0           ['dropout_42[0][0]',             \n",
      "                                                                  'dropout_43[0][0]',             \n",
      "                                                                  'dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 27)          0           ['concatenate_7[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 27)           0           ['global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLambda)  (None, 1, 27)        0           ['dropout_45[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_31 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_7[0][0]',       \n",
      " HeadAttention)                                                   'tf.expand_dims_7[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_7 (TFOpLa  (None, 27)          0           ['multi_head_attention_31[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_7[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 27)           0           ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1024)         28672       ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 1024)         0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 128)          131200      ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            129         ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3605 - accuracy: 0.8508 - val_loss: 0.1954 - val_accuracy: 0.9384\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2394 - accuracy: 0.9217 - val_loss: 0.1431 - val_accuracy: 0.9553\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2105 - accuracy: 0.9349 - val_loss: 0.1403 - val_accuracy: 0.9517\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2035 - accuracy: 0.9375 - val_loss: 0.1411 - val_accuracy: 0.9548\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1997 - accuracy: 0.9372 - val_loss: 0.1255 - val_accuracy: 0.9489\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1942 - accuracy: 0.9389 - val_loss: 0.1135 - val_accuracy: 0.9620\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1890 - accuracy: 0.9401 - val_loss: 0.1194 - val_accuracy: 0.9611\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1905 - accuracy: 0.9389 - val_loss: 0.1196 - val_accuracy: 0.9575\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1833 - accuracy: 0.9410 - val_loss: 0.1141 - val_accuracy: 0.9627\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1821 - accuracy: 0.9411 - val_loss: 0.1292 - val_accuracy: 0.9536\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_24 (Reshape)           (None, 45, 8)        0           ['input_25[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_25 (Reshape)           (None, 45, 8)        0           ['input_26[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_26 (Reshape)           (None, 45, 11)       0           ['input_27[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_32 (Multi  (None, 45, 8)       2248        ['reshape_24[0][0]',             \n",
      " HeadAttention)                                                   'reshape_24[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_33 (Multi  (None, 45, 8)       2248        ['reshape_25[0][0]',             \n",
      " HeadAttention)                                                   'reshape_25[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_34 (Multi  (None, 45, 11)      4147        ['reshape_26[0][0]',             \n",
      " HeadAttention)                                                   'reshape_26[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 45, 8)       16          ['multi_head_attention_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 45, 8)       16          ['multi_head_attention_33[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 45, 11)      22          ['multi_head_attention_34[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 45, 8)        0           ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 45, 8)        0           ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 45, 11)       0           ['layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 45, 27)       0           ['dropout_48[0][0]',             \n",
      "                                                                  'dropout_49[0][0]',             \n",
      "                                                                  'dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 27)          0           ['concatenate_8[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 27)           0           ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_8 (TFOpLambda)  (None, 1, 27)        0           ['dropout_51[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_35 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_8[0][0]',       \n",
      " HeadAttention)                                                   'tf.expand_dims_8[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_8 (TFOpLa  (None, 27)          0           ['multi_head_attention_35[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_8[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 27)           0           ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 1024)         28672       ['dropout_52[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 1024)         0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          131200      ['dropout_53[0][0]']             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 1)            129         ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.4365 - accuracy: 0.8055 - val_loss: 0.2588 - val_accuracy: 0.8724\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3529 - accuracy: 0.8562 - val_loss: 0.2380 - val_accuracy: 0.8781\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3359 - accuracy: 0.8590 - val_loss: 0.4086 - val_accuracy: 0.8461\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3256 - accuracy: 0.8633 - val_loss: 0.2614 - val_accuracy: 0.8717\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3198 - accuracy: 0.8654 - val_loss: 0.2195 - val_accuracy: 0.8872\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3157 - accuracy: 0.8672 - val_loss: 0.2439 - val_accuracy: 0.8726\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3036 - accuracy: 0.8724 - val_loss: 0.2596 - val_accuracy: 0.8631\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3006 - accuracy: 0.8744 - val_loss: 0.3039 - val_accuracy: 0.8621\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2938 - accuracy: 0.8781 - val_loss: 0.2714 - val_accuracy: 0.8664\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2861 - accuracy: 0.8795 - val_loss: 0.2430 - val_accuracy: 0.8886\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 1 19910\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_27 (Reshape)           (None, 45, 8)        0           ['input_28[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_28 (Reshape)           (None, 45, 8)        0           ['input_29[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_29 (Reshape)           (None, 45, 11)       0           ['input_30[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_36 (Multi  (None, 45, 8)       2248        ['reshape_27[0][0]',             \n",
      " HeadAttention)                                                   'reshape_27[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_37 (Multi  (None, 45, 8)       2248        ['reshape_28[0][0]',             \n",
      " HeadAttention)                                                   'reshape_28[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_38 (Multi  (None, 45, 11)      4147        ['reshape_29[0][0]',             \n",
      " HeadAttention)                                                   'reshape_29[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 45, 8)       16          ['multi_head_attention_36[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 45, 8)       16          ['multi_head_attention_37[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 45, 11)      22          ['multi_head_attention_38[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 45, 8)        0           ['layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 45, 8)        0           ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 45, 11)       0           ['layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 45, 27)       0           ['dropout_54[0][0]',             \n",
      "                                                                  'dropout_55[0][0]',             \n",
      "                                                                  'dropout_56[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 27)          0           ['concatenate_9[0][0]']          \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 27)           0           ['global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_9 (TFOpLambda)  (None, 1, 27)        0           ['dropout_57[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_39 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_9[0][0]',       \n",
      " HeadAttention)                                                   'tf.expand_dims_9[0][0]']       \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_9 (TFOpLa  (None, 27)          0           ['multi_head_attention_39[0][0]']\n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_9[0][0]'] \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 27)           0           ['layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1024)         28672       ['dropout_58[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 1024)         0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          131200      ['dropout_59[0][0]']             \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            129         ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5882 - accuracy: 0.6872 - val_loss: 0.2879 - val_accuracy: 0.8609\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.5093 - accuracy: 0.7573 - val_loss: 0.2628 - val_accuracy: 0.8695\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4899 - accuracy: 0.7714 - val_loss: 0.3353 - val_accuracy: 0.8215\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4803 - accuracy: 0.7732 - val_loss: 0.3003 - val_accuracy: 0.8464\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4748 - accuracy: 0.7793 - val_loss: 0.2692 - val_accuracy: 0.8418\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4676 - accuracy: 0.7818 - val_loss: 0.2407 - val_accuracy: 0.8726\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4545 - accuracy: 0.7909 - val_loss: 0.2216 - val_accuracy: 0.8798\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4468 - accuracy: 0.7970 - val_loss: 0.2151 - val_accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4469 - accuracy: 0.7982 - val_loss: 0.2116 - val_accuracy: 0.9054\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4381 - accuracy: 0.8044 - val_loss: 0.2304 - val_accuracy: 0.8994\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_30 (Reshape)           (None, 45, 8)        0           ['input_31[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_31 (Reshape)           (None, 45, 8)        0           ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_32 (Reshape)           (None, 45, 11)       0           ['input_33[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_40 (Multi  (None, 45, 8)       2248        ['reshape_30[0][0]',             \n",
      " HeadAttention)                                                   'reshape_30[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_41 (Multi  (None, 45, 8)       2248        ['reshape_31[0][0]',             \n",
      " HeadAttention)                                                   'reshape_31[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_42 (Multi  (None, 45, 11)      4147        ['reshape_32[0][0]',             \n",
      " HeadAttention)                                                   'reshape_32[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 45, 8)       16          ['multi_head_attention_40[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 45, 8)       16          ['multi_head_attention_41[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 45, 11)      22          ['multi_head_attention_42[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 45, 8)        0           ['layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 45, 8)        0           ['layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 45, 11)       0           ['layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 45, 27)       0           ['dropout_60[0][0]',             \n",
      "                                                                  'dropout_61[0][0]',             \n",
      "                                                                  'dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 27)          0           ['concatenate_10[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 27)           0           ['global_average_pooling1d_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_10 (TFOpLambda)  (None, 1, 27)       0           ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_43 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_10[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_10[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_10 (TFOpL  (None, 27)          0           ['multi_head_attention_43[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_10[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 27)           0           ['layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 1024)         28672       ['dropout_64[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)           (None, 1024)         0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 128)          131200      ['dropout_65[0][0]']             \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 1)            129         ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5351 - accuracy: 0.7218 - val_loss: 0.4354 - val_accuracy: 0.6294\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4344 - accuracy: 0.7834 - val_loss: 0.1695 - val_accuracy: 0.8793\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4079 - accuracy: 0.7978 - val_loss: 0.2622 - val_accuracy: 0.8559\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3700 - accuracy: 0.8214 - val_loss: 0.2110 - val_accuracy: 0.9042\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3551 - accuracy: 0.8313 - val_loss: 0.1801 - val_accuracy: 0.9188\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3341 - accuracy: 0.8452 - val_loss: 0.1832 - val_accuracy: 0.9085\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3265 - accuracy: 0.8530 - val_loss: 0.2147 - val_accuracy: 0.9063\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3131 - accuracy: 0.8606 - val_loss: 0.2080 - val_accuracy: 0.9059\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3050 - accuracy: 0.8642 - val_loss: 0.2096 - val_accuracy: 0.9209\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2976 - accuracy: 0.8685 - val_loss: 0.1807 - val_accuracy: 0.9197\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_34 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_33 (Reshape)           (None, 45, 8)        0           ['input_34[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_34 (Reshape)           (None, 45, 8)        0           ['input_35[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_35 (Reshape)           (None, 45, 11)       0           ['input_36[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_44 (Multi  (None, 45, 8)       2248        ['reshape_33[0][0]',             \n",
      " HeadAttention)                                                   'reshape_33[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_45 (Multi  (None, 45, 8)       2248        ['reshape_34[0][0]',             \n",
      " HeadAttention)                                                   'reshape_34[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_46 (Multi  (None, 45, 11)      4147        ['reshape_35[0][0]',             \n",
      " HeadAttention)                                                   'reshape_35[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 45, 8)       16          ['multi_head_attention_44[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 45, 8)       16          ['multi_head_attention_45[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 45, 11)      22          ['multi_head_attention_46[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 45, 8)        0           ['layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 45, 8)        0           ['layer_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_68 (Dropout)           (None, 45, 11)       0           ['layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 45, 27)       0           ['dropout_66[0][0]',             \n",
      "                                                                  'dropout_67[0][0]',             \n",
      "                                                                  'dropout_68[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_11 (G  (None, 27)          0           ['concatenate_11[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 27)           0           ['global_average_pooling1d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_11 (TFOpLambda)  (None, 1, 27)       0           ['dropout_69[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_47 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_11[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_11[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_11 (TFOpL  (None, 27)          0           ['multi_head_attention_47[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_11[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_70 (Dropout)           (None, 27)           0           ['layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 1024)         28672       ['dropout_70[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 1024)         0           ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          131200      ['dropout_71[0][0]']             \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 1)            129         ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3610 - accuracy: 0.8466 - val_loss: 0.4876 - val_accuracy: 0.8466\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2276 - accuracy: 0.9308 - val_loss: 0.5097 - val_accuracy: 0.8528\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2127 - accuracy: 0.9350 - val_loss: 0.4677 - val_accuracy: 0.8554\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2035 - accuracy: 0.9389 - val_loss: 0.4707 - val_accuracy: 0.8516\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1960 - accuracy: 0.9406 - val_loss: 0.4284 - val_accuracy: 0.8533\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1899 - accuracy: 0.9427 - val_loss: 0.4844 - val_accuracy: 0.8593\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1812 - accuracy: 0.9465 - val_loss: 0.4176 - val_accuracy: 0.8590\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1812 - accuracy: 0.9464 - val_loss: 0.4834 - val_accuracy: 0.8595\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1761 - accuracy: 0.9483 - val_loss: 0.5421 - val_accuracy: 0.8595\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1745 - accuracy: 0.9493 - val_loss: 0.5032 - val_accuracy: 0.8612\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_38 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_39 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_36 (Reshape)           (None, 45, 8)        0           ['input_37[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_37 (Reshape)           (None, 45, 8)        0           ['input_38[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_38 (Reshape)           (None, 45, 11)       0           ['input_39[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_48 (Multi  (None, 45, 8)       2248        ['reshape_36[0][0]',             \n",
      " HeadAttention)                                                   'reshape_36[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_49 (Multi  (None, 45, 8)       2248        ['reshape_37[0][0]',             \n",
      " HeadAttention)                                                   'reshape_37[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_50 (Multi  (None, 45, 11)      4147        ['reshape_38[0][0]',             \n",
      " HeadAttention)                                                   'reshape_38[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_48 (LayerN  (None, 45, 8)       16          ['multi_head_attention_48[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 45, 8)       16          ['multi_head_attention_49[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 45, 11)      22          ['multi_head_attention_50[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 45, 8)        0           ['layer_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 45, 8)        0           ['layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 45, 11)       0           ['layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 45, 27)       0           ['dropout_72[0][0]',             \n",
      "                                                                  'dropout_73[0][0]',             \n",
      "                                                                  'dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_12 (G  (None, 27)          0           ['concatenate_12[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 27)           0           ['global_average_pooling1d_12[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_12 (TFOpLambda)  (None, 1, 27)       0           ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_51 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_12[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_12[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_12 (TFOpL  (None, 27)          0           ['multi_head_attention_51[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_12[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)           (None, 27)           0           ['layer_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 1024)         28672       ['dropout_76[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 1024)         0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 128)          131200      ['dropout_77[0][0]']             \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 1)            129         ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.5065 - accuracy: 0.7683 - val_loss: 0.4934 - val_accuracy: 0.7460\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4127 - accuracy: 0.8298 - val_loss: 0.2393 - val_accuracy: 0.9087\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3962 - accuracy: 0.8382 - val_loss: 0.2427 - val_accuracy: 0.9075\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3909 - accuracy: 0.8384 - val_loss: 0.1840 - val_accuracy: 0.9228\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3852 - accuracy: 0.8412 - val_loss: 0.2424 - val_accuracy: 0.9211\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3825 - accuracy: 0.8408 - val_loss: 0.2900 - val_accuracy: 0.9094\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3769 - accuracy: 0.8401 - val_loss: 0.1977 - val_accuracy: 0.9364\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3732 - accuracy: 0.8397 - val_loss: 0.2796 - val_accuracy: 0.9157\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3697 - accuracy: 0.8422 - val_loss: 0.2538 - val_accuracy: 0.9262\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3651 - accuracy: 0.8461 - val_loss: 0.2053 - val_accuracy: 0.9259\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_40 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_41 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_42 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_39 (Reshape)           (None, 45, 8)        0           ['input_40[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_40 (Reshape)           (None, 45, 8)        0           ['input_41[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_41 (Reshape)           (None, 45, 11)       0           ['input_42[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_52 (Multi  (None, 45, 8)       2248        ['reshape_39[0][0]',             \n",
      " HeadAttention)                                                   'reshape_39[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_53 (Multi  (None, 45, 8)       2248        ['reshape_40[0][0]',             \n",
      " HeadAttention)                                                   'reshape_40[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_54 (Multi  (None, 45, 11)      4147        ['reshape_41[0][0]',             \n",
      " HeadAttention)                                                   'reshape_41[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 45, 8)       16          ['multi_head_attention_52[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 45, 8)       16          ['multi_head_attention_53[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 45, 11)      22          ['multi_head_attention_54[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 45, 8)        0           ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)           (None, 45, 8)        0           ['layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 45, 11)       0           ['layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 45, 27)       0           ['dropout_78[0][0]',             \n",
      "                                                                  'dropout_79[0][0]',             \n",
      "                                                                  'dropout_80[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_13 (G  (None, 27)          0           ['concatenate_13[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_81 (Dropout)           (None, 27)           0           ['global_average_pooling1d_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_13 (TFOpLambda)  (None, 1, 27)       0           ['dropout_81[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_55 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_13[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_13[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_13 (TFOpL  (None, 27)          0           ['multi_head_attention_55[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_13[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_82 (Dropout)           (None, 27)           0           ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 1024)         28672       ['dropout_82[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_83 (Dropout)           (None, 1024)         0           ['dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 128)          131200      ['dropout_83[0][0]']             \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 1)            129         ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3907 - accuracy: 0.8072 - val_loss: 0.1549 - val_accuracy: 0.9116\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2497 - accuracy: 0.9034 - val_loss: 0.1402 - val_accuracy: 0.9312\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2098 - accuracy: 0.9212 - val_loss: 0.1322 - val_accuracy: 0.9446\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1919 - accuracy: 0.9299 - val_loss: 0.1173 - val_accuracy: 0.9515\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1696 - accuracy: 0.9404 - val_loss: 0.1154 - val_accuracy: 0.9350\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1470 - accuracy: 0.9491 - val_loss: 0.1450 - val_accuracy: 0.9474\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1267 - accuracy: 0.9577 - val_loss: 0.0892 - val_accuracy: 0.9599\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1242 - accuracy: 0.9563 - val_loss: 0.0769 - val_accuracy: 0.9661\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1154 - accuracy: 0.9608 - val_loss: 0.0803 - val_accuracy: 0.9646\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1101 - accuracy: 0.9639 - val_loss: 0.0483 - val_accuracy: 0.9778\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_43 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_44 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_45 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_42 (Reshape)           (None, 45, 8)        0           ['input_43[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_43 (Reshape)           (None, 45, 8)        0           ['input_44[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_44 (Reshape)           (None, 45, 11)       0           ['input_45[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_56 (Multi  (None, 45, 8)       2248        ['reshape_42[0][0]',             \n",
      " HeadAttention)                                                   'reshape_42[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_57 (Multi  (None, 45, 8)       2248        ['reshape_43[0][0]',             \n",
      " HeadAttention)                                                   'reshape_43[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_58 (Multi  (None, 45, 11)      4147        ['reshape_44[0][0]',             \n",
      " HeadAttention)                                                   'reshape_44[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 45, 8)       16          ['multi_head_attention_56[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 45, 8)       16          ['multi_head_attention_57[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_58 (LayerN  (None, 45, 11)      22          ['multi_head_attention_58[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_84 (Dropout)           (None, 45, 8)        0           ['layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_85 (Dropout)           (None, 45, 8)        0           ['layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_86 (Dropout)           (None, 45, 11)       0           ['layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 45, 27)       0           ['dropout_84[0][0]',             \n",
      "                                                                  'dropout_85[0][0]',             \n",
      "                                                                  'dropout_86[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_14 (G  (None, 27)          0           ['concatenate_14[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_87 (Dropout)           (None, 27)           0           ['global_average_pooling1d_14[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_14 (TFOpLambda)  (None, 1, 27)       0           ['dropout_87[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_59 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_14[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_14[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_14 (TFOpL  (None, 27)          0           ['multi_head_attention_59[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_59 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_14[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 27)           0           ['layer_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 1024)         28672       ['dropout_88[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 1024)         0           ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 128)          131200      ['dropout_89[0][0]']             \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 1)            129         ['dense_43[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.3257 - accuracy: 0.8555 - val_loss: 0.3268 - val_accuracy: 0.9123\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2754 - accuracy: 0.8742 - val_loss: 0.3067 - val_accuracy: 0.9369\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2200 - accuracy: 0.9158 - val_loss: 0.1964 - val_accuracy: 0.9453\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1795 - accuracy: 0.9375 - val_loss: 0.1901 - val_accuracy: 0.9441\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1494 - accuracy: 0.9509 - val_loss: 0.1495 - val_accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1315 - accuracy: 0.9578 - val_loss: 0.1612 - val_accuracy: 0.9424\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1249 - accuracy: 0.9613 - val_loss: 0.1556 - val_accuracy: 0.9455\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1191 - accuracy: 0.9632 - val_loss: 0.1830 - val_accuracy: 0.9458\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1172 - accuracy: 0.9643 - val_loss: 0.1464 - val_accuracy: 0.9477\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1121 - accuracy: 0.9658 - val_loss: 0.2342 - val_accuracy: 0.9379\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_46 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_47 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_48 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_45 (Reshape)           (None, 45, 8)        0           ['input_46[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_46 (Reshape)           (None, 45, 8)        0           ['input_47[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_47 (Reshape)           (None, 45, 11)       0           ['input_48[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_60 (Multi  (None, 45, 8)       2248        ['reshape_45[0][0]',             \n",
      " HeadAttention)                                                   'reshape_45[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_61 (Multi  (None, 45, 8)       2248        ['reshape_46[0][0]',             \n",
      " HeadAttention)                                                   'reshape_46[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_62 (Multi  (None, 45, 11)      4147        ['reshape_47[0][0]',             \n",
      " HeadAttention)                                                   'reshape_47[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_60 (LayerN  (None, 45, 8)       16          ['multi_head_attention_60[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_61 (LayerN  (None, 45, 8)       16          ['multi_head_attention_61[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_62 (LayerN  (None, 45, 11)      22          ['multi_head_attention_62[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_90 (Dropout)           (None, 45, 8)        0           ['layer_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)           (None, 45, 8)        0           ['layer_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)           (None, 45, 11)       0           ['layer_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 45, 27)       0           ['dropout_90[0][0]',             \n",
      "                                                                  'dropout_91[0][0]',             \n",
      "                                                                  'dropout_92[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 27)          0           ['concatenate_15[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)           (None, 27)           0           ['global_average_pooling1d_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_15 (TFOpLambda)  (None, 1, 27)       0           ['dropout_93[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_63 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_15[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_15[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_15 (TFOpL  (None, 27)          0           ['multi_head_attention_63[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_63 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_15[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)           (None, 27)           0           ['layer_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 1024)         28672       ['dropout_94[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)           (None, 1024)         0           ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 128)          131200      ['dropout_95[0][0]']             \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 1)            129         ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3344 - accuracy: 0.8693 - val_loss: 0.4241 - val_accuracy: 0.8227\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2166 - accuracy: 0.9317 - val_loss: 0.4563 - val_accuracy: 0.8466\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1897 - accuracy: 0.9410 - val_loss: 0.5076 - val_accuracy: 0.8461\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1793 - accuracy: 0.9447 - val_loss: 0.5074 - val_accuracy: 0.8507\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1736 - accuracy: 0.9451 - val_loss: 0.4292 - val_accuracy: 0.8550\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1717 - accuracy: 0.9456 - val_loss: 0.5212 - val_accuracy: 0.8542\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1667 - accuracy: 0.9481 - val_loss: 0.5065 - val_accuracy: 0.8540\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1631 - accuracy: 0.9479 - val_loss: 0.4908 - val_accuracy: 0.8535\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1570 - accuracy: 0.9497 - val_loss: 0.5225 - val_accuracy: 0.8464\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1544 - accuracy: 0.9500 - val_loss: 0.4332 - val_accuracy: 0.8557\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_49 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_50 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_51 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_48 (Reshape)           (None, 45, 8)        0           ['input_49[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_49 (Reshape)           (None, 45, 8)        0           ['input_50[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_50 (Reshape)           (None, 45, 11)       0           ['input_51[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_64 (Multi  (None, 45, 8)       2248        ['reshape_48[0][0]',             \n",
      " HeadAttention)                                                   'reshape_48[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_65 (Multi  (None, 45, 8)       2248        ['reshape_49[0][0]',             \n",
      " HeadAttention)                                                   'reshape_49[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_66 (Multi  (None, 45, 11)      4147        ['reshape_50[0][0]',             \n",
      " HeadAttention)                                                   'reshape_50[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_64 (LayerN  (None, 45, 8)       16          ['multi_head_attention_64[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_65 (LayerN  (None, 45, 8)       16          ['multi_head_attention_65[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_66 (LayerN  (None, 45, 11)      22          ['multi_head_attention_66[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_96 (Dropout)           (None, 45, 8)        0           ['layer_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_97 (Dropout)           (None, 45, 8)        0           ['layer_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_98 (Dropout)           (None, 45, 11)       0           ['layer_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 45, 27)       0           ['dropout_96[0][0]',             \n",
      "                                                                  'dropout_97[0][0]',             \n",
      "                                                                  'dropout_98[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_16 (G  (None, 27)          0           ['concatenate_16[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_99 (Dropout)           (None, 27)           0           ['global_average_pooling1d_16[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_16 (TFOpLambda)  (None, 1, 27)       0           ['dropout_99[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_67 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_16[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_16[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_16 (TFOpL  (None, 27)          0           ['multi_head_attention_67[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_67 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_100 (Dropout)          (None, 27)           0           ['layer_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 1024)         28672       ['dropout_100[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_101 (Dropout)          (None, 1024)         0           ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 128)          131200      ['dropout_101[0][0]']            \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 1)            129         ['dense_49[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4422 - accuracy: 0.8015 - val_loss: 0.2950 - val_accuracy: 0.7871\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3710 - accuracy: 0.8420 - val_loss: 0.2316 - val_accuracy: 0.8970\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3388 - accuracy: 0.8602 - val_loss: 0.2317 - val_accuracy: 0.9202\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3216 - accuracy: 0.8686 - val_loss: 0.2341 - val_accuracy: 0.8932\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3137 - accuracy: 0.8706 - val_loss: 0.2148 - val_accuracy: 0.8951\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3062 - accuracy: 0.8728 - val_loss: 0.3361 - val_accuracy: 0.8719\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3003 - accuracy: 0.8750 - val_loss: 0.1819 - val_accuracy: 0.9051\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3015 - accuracy: 0.8738 - val_loss: 0.2027 - val_accuracy: 0.8970\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2919 - accuracy: 0.8807 - val_loss: 0.1925 - val_accuracy: 0.8975\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2888 - accuracy: 0.8803 - val_loss: 0.1637 - val_accuracy: 0.9233\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 2 19911\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_52 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_53 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_54 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_51 (Reshape)           (None, 45, 8)        0           ['input_52[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_52 (Reshape)           (None, 45, 8)        0           ['input_53[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_53 (Reshape)           (None, 45, 11)       0           ['input_54[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_68 (Multi  (None, 45, 8)       2248        ['reshape_51[0][0]',             \n",
      " HeadAttention)                                                   'reshape_51[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_69 (Multi  (None, 45, 8)       2248        ['reshape_52[0][0]',             \n",
      " HeadAttention)                                                   'reshape_52[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_70 (Multi  (None, 45, 11)      4147        ['reshape_53[0][0]',             \n",
      " HeadAttention)                                                   'reshape_53[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_68 (LayerN  (None, 45, 8)       16          ['multi_head_attention_68[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_69 (LayerN  (None, 45, 8)       16          ['multi_head_attention_69[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_70 (LayerN  (None, 45, 11)      22          ['multi_head_attention_70[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_102 (Dropout)          (None, 45, 8)        0           ['layer_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_103 (Dropout)          (None, 45, 8)        0           ['layer_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_104 (Dropout)          (None, 45, 11)       0           ['layer_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 45, 27)       0           ['dropout_102[0][0]',            \n",
      "                                                                  'dropout_103[0][0]',            \n",
      "                                                                  'dropout_104[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_17 (G  (None, 27)          0           ['concatenate_17[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_105 (Dropout)          (None, 27)           0           ['global_average_pooling1d_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_17 (TFOpLambda)  (None, 1, 27)       0           ['dropout_105[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_71 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_17[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_17[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_17 (TFOpL  (None, 27)          0           ['multi_head_attention_71[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_71 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_106 (Dropout)          (None, 27)           0           ['layer_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 1024)         28672       ['dropout_106[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_107 (Dropout)          (None, 1024)         0           ['dense_51[0][0]']               \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 128)          131200      ['dropout_107[0][0]']            \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 1)            129         ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 15ms/step - loss: 0.5994 - accuracy: 0.6730 - val_loss: 0.5042 - val_accuracy: 0.7453\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.5188 - accuracy: 0.7565 - val_loss: 0.4365 - val_accuracy: 0.7804\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4825 - accuracy: 0.7811 - val_loss: 0.5018 - val_accuracy: 0.7622\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4731 - accuracy: 0.7868 - val_loss: 0.4025 - val_accuracy: 0.7959\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4631 - accuracy: 0.7898 - val_loss: 0.3516 - val_accuracy: 0.8292\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4580 - accuracy: 0.7935 - val_loss: 0.3723 - val_accuracy: 0.8292\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4552 - accuracy: 0.7947 - val_loss: 0.3595 - val_accuracy: 0.8296\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4524 - accuracy: 0.7979 - val_loss: 0.3551 - val_accuracy: 0.8399\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4459 - accuracy: 0.8006 - val_loss: 0.3553 - val_accuracy: 0.8440\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4413 - accuracy: 0.8035 - val_loss: 0.4045 - val_accuracy: 0.8346\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_55 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_56 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_57 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_54 (Reshape)           (None, 45, 8)        0           ['input_55[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_55 (Reshape)           (None, 45, 8)        0           ['input_56[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_56 (Reshape)           (None, 45, 11)       0           ['input_57[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_72 (Multi  (None, 45, 8)       2248        ['reshape_54[0][0]',             \n",
      " HeadAttention)                                                   'reshape_54[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_73 (Multi  (None, 45, 8)       2248        ['reshape_55[0][0]',             \n",
      " HeadAttention)                                                   'reshape_55[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_74 (Multi  (None, 45, 11)      4147        ['reshape_56[0][0]',             \n",
      " HeadAttention)                                                   'reshape_56[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_72 (LayerN  (None, 45, 8)       16          ['multi_head_attention_72[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_73 (LayerN  (None, 45, 8)       16          ['multi_head_attention_73[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_74 (LayerN  (None, 45, 11)      22          ['multi_head_attention_74[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_108 (Dropout)          (None, 45, 8)        0           ['layer_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_109 (Dropout)          (None, 45, 8)        0           ['layer_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_110 (Dropout)          (None, 45, 11)       0           ['layer_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 45, 27)       0           ['dropout_108[0][0]',            \n",
      "                                                                  'dropout_109[0][0]',            \n",
      "                                                                  'dropout_110[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_18 (G  (None, 27)          0           ['concatenate_18[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_111 (Dropout)          (None, 27)           0           ['global_average_pooling1d_18[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_18 (TFOpLambda)  (None, 1, 27)       0           ['dropout_111[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_75 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_18[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_18[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_18 (TFOpL  (None, 27)          0           ['multi_head_attention_75[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_75 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_112 (Dropout)          (None, 27)           0           ['layer_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 1024)         28672       ['dropout_112[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_113 (Dropout)          (None, 1024)         0           ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 128)          131200      ['dropout_113[0][0]']            \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 1)            129         ['dense_55[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5167 - accuracy: 0.7418 - val_loss: 0.3452 - val_accuracy: 0.7869\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4091 - accuracy: 0.8057 - val_loss: 0.3363 - val_accuracy: 0.8167\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3725 - accuracy: 0.8271 - val_loss: 0.2942 - val_accuracy: 0.8664\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3504 - accuracy: 0.8323 - val_loss: 0.2792 - val_accuracy: 0.8839\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3338 - accuracy: 0.8429 - val_loss: 0.2622 - val_accuracy: 0.8886\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3295 - accuracy: 0.8429 - val_loss: 0.2473 - val_accuracy: 0.8925\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3206 - accuracy: 0.8496 - val_loss: 0.2606 - val_accuracy: 0.8600\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3090 - accuracy: 0.8582 - val_loss: 0.2407 - val_accuracy: 0.8736\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3011 - accuracy: 0.8609 - val_loss: 0.2122 - val_accuracy: 0.9097\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2935 - accuracy: 0.8663 - val_loss: 0.2213 - val_accuracy: 0.9051\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_58 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_59 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_60 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_57 (Reshape)           (None, 45, 8)        0           ['input_58[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_58 (Reshape)           (None, 45, 8)        0           ['input_59[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_59 (Reshape)           (None, 45, 11)       0           ['input_60[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_76 (Multi  (None, 45, 8)       2248        ['reshape_57[0][0]',             \n",
      " HeadAttention)                                                   'reshape_57[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_77 (Multi  (None, 45, 8)       2248        ['reshape_58[0][0]',             \n",
      " HeadAttention)                                                   'reshape_58[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_78 (Multi  (None, 45, 11)      4147        ['reshape_59[0][0]',             \n",
      " HeadAttention)                                                   'reshape_59[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_76 (LayerN  (None, 45, 8)       16          ['multi_head_attention_76[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_77 (LayerN  (None, 45, 8)       16          ['multi_head_attention_77[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_78 (LayerN  (None, 45, 11)      22          ['multi_head_attention_78[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_114 (Dropout)          (None, 45, 8)        0           ['layer_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_115 (Dropout)          (None, 45, 8)        0           ['layer_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)          (None, 45, 11)       0           ['layer_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 45, 27)       0           ['dropout_114[0][0]',            \n",
      "                                                                  'dropout_115[0][0]',            \n",
      "                                                                  'dropout_116[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_19 (G  (None, 27)          0           ['concatenate_19[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)          (None, 27)           0           ['global_average_pooling1d_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_19 (TFOpLambda)  (None, 1, 27)       0           ['dropout_117[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_79 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_19[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_19[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_19 (TFOpL  (None, 27)          0           ['multi_head_attention_79[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_79 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_118 (Dropout)          (None, 27)           0           ['layer_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 1024)         28672       ['dropout_118[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_119 (Dropout)          (None, 1024)         0           ['dense_57[0][0]']               \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 128)          131200      ['dropout_119[0][0]']            \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 1)            129         ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3389 - accuracy: 0.8642 - val_loss: 0.5012 - val_accuracy: 0.8194\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2105 - accuracy: 0.9398 - val_loss: 0.5163 - val_accuracy: 0.8294\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2062 - accuracy: 0.9406 - val_loss: 0.5558 - val_accuracy: 0.8337\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1943 - accuracy: 0.9447 - val_loss: 0.6033 - val_accuracy: 0.8335\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1938 - accuracy: 0.9424 - val_loss: 0.5432 - val_accuracy: 0.8280\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1879 - accuracy: 0.9442 - val_loss: 0.5291 - val_accuracy: 0.8308\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1791 - accuracy: 0.9483 - val_loss: 0.5132 - val_accuracy: 0.8287\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1755 - accuracy: 0.9478 - val_loss: 0.6148 - val_accuracy: 0.8277\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1707 - accuracy: 0.9502 - val_loss: 0.5420 - val_accuracy: 0.8327\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1681 - accuracy: 0.9503 - val_loss: 0.5090 - val_accuracy: 0.8361\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_61 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_62 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_63 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_60 (Reshape)           (None, 45, 8)        0           ['input_61[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_61 (Reshape)           (None, 45, 8)        0           ['input_62[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_62 (Reshape)           (None, 45, 11)       0           ['input_63[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_80 (Multi  (None, 45, 8)       2248        ['reshape_60[0][0]',             \n",
      " HeadAttention)                                                   'reshape_60[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_81 (Multi  (None, 45, 8)       2248        ['reshape_61[0][0]',             \n",
      " HeadAttention)                                                   'reshape_61[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_82 (Multi  (None, 45, 11)      4147        ['reshape_62[0][0]',             \n",
      " HeadAttention)                                                   'reshape_62[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_80 (LayerN  (None, 45, 8)       16          ['multi_head_attention_80[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_81 (LayerN  (None, 45, 8)       16          ['multi_head_attention_81[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_82 (LayerN  (None, 45, 11)      22          ['multi_head_attention_82[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_120 (Dropout)          (None, 45, 8)        0           ['layer_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_121 (Dropout)          (None, 45, 8)        0           ['layer_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_122 (Dropout)          (None, 45, 11)       0           ['layer_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 45, 27)       0           ['dropout_120[0][0]',            \n",
      "                                                                  'dropout_121[0][0]',            \n",
      "                                                                  'dropout_122[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_20 (G  (None, 27)          0           ['concatenate_20[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_123 (Dropout)          (None, 27)           0           ['global_average_pooling1d_20[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_20 (TFOpLambda)  (None, 1, 27)       0           ['dropout_123[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_83 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_20[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_20[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_20 (TFOpL  (None, 27)          0           ['multi_head_attention_83[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_83 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_124 (Dropout)          (None, 27)           0           ['layer_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 1024)         28672       ['dropout_124[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_125 (Dropout)          (None, 1024)         0           ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 128)          131200      ['dropout_125[0][0]']            \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 1)            129         ['dense_61[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5032 - accuracy: 0.7678 - val_loss: 0.3244 - val_accuracy: 0.8901\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4197 - accuracy: 0.8255 - val_loss: 0.3120 - val_accuracy: 0.8466\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4103 - accuracy: 0.8319 - val_loss: 0.4119 - val_accuracy: 0.8165\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4020 - accuracy: 0.8325 - val_loss: 0.3119 - val_accuracy: 0.8507\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4003 - accuracy: 0.8352 - val_loss: 0.3276 - val_accuracy: 0.8124\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3935 - accuracy: 0.8310 - val_loss: 0.2677 - val_accuracy: 0.8593\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3910 - accuracy: 0.8344 - val_loss: 0.2540 - val_accuracy: 0.8695\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3858 - accuracy: 0.8358 - val_loss: 0.3147 - val_accuracy: 0.8683\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3832 - accuracy: 0.8383 - val_loss: 0.3232 - val_accuracy: 0.8645\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3812 - accuracy: 0.8380 - val_loss: 0.3018 - val_accuracy: 0.8628\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_64 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_65 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_66 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_63 (Reshape)           (None, 45, 8)        0           ['input_64[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_64 (Reshape)           (None, 45, 8)        0           ['input_65[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_65 (Reshape)           (None, 45, 11)       0           ['input_66[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_84 (Multi  (None, 45, 8)       2248        ['reshape_63[0][0]',             \n",
      " HeadAttention)                                                   'reshape_63[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_85 (Multi  (None, 45, 8)       2248        ['reshape_64[0][0]',             \n",
      " HeadAttention)                                                   'reshape_64[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_86 (Multi  (None, 45, 11)      4147        ['reshape_65[0][0]',             \n",
      " HeadAttention)                                                   'reshape_65[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_84 (LayerN  (None, 45, 8)       16          ['multi_head_attention_84[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_85 (LayerN  (None, 45, 8)       16          ['multi_head_attention_85[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_86 (LayerN  (None, 45, 11)      22          ['multi_head_attention_86[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_126 (Dropout)          (None, 45, 8)        0           ['layer_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_127 (Dropout)          (None, 45, 8)        0           ['layer_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_128 (Dropout)          (None, 45, 11)       0           ['layer_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 45, 27)       0           ['dropout_126[0][0]',            \n",
      "                                                                  'dropout_127[0][0]',            \n",
      "                                                                  'dropout_128[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_21 (G  (None, 27)          0           ['concatenate_21[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_129 (Dropout)          (None, 27)           0           ['global_average_pooling1d_21[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_21 (TFOpLambda)  (None, 1, 27)       0           ['dropout_129[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_87 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_21[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_21[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_21 (TFOpL  (None, 27)          0           ['multi_head_attention_87[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_87 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_130 (Dropout)          (None, 27)           0           ['layer_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 1024)         28672       ['dropout_130[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, 1024)         0           ['dense_63[0][0]']               \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 128)          131200      ['dropout_131[0][0]']            \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 1)            129         ['dense_64[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 17ms/step - loss: 0.3668 - accuracy: 0.8254 - val_loss: 0.2733 - val_accuracy: 0.8480\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2629 - accuracy: 0.8970 - val_loss: 0.2084 - val_accuracy: 0.8841\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2035 - accuracy: 0.9235 - val_loss: 0.1884 - val_accuracy: 0.9090\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1684 - accuracy: 0.9383 - val_loss: 0.1554 - val_accuracy: 0.9190\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1467 - accuracy: 0.9461 - val_loss: 0.1670 - val_accuracy: 0.9204\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1363 - accuracy: 0.9497 - val_loss: 0.0943 - val_accuracy: 0.9570\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1247 - accuracy: 0.9563 - val_loss: 0.0900 - val_accuracy: 0.9556\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1100 - accuracy: 0.9619 - val_loss: 0.0904 - val_accuracy: 0.9625\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1099 - accuracy: 0.9627 - val_loss: 0.1465 - val_accuracy: 0.9415\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0952 - accuracy: 0.9684 - val_loss: 0.0752 - val_accuracy: 0.9704\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_67 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_68 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_69 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_66 (Reshape)           (None, 45, 8)        0           ['input_67[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_67 (Reshape)           (None, 45, 8)        0           ['input_68[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_68 (Reshape)           (None, 45, 11)       0           ['input_69[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_88 (Multi  (None, 45, 8)       2248        ['reshape_66[0][0]',             \n",
      " HeadAttention)                                                   'reshape_66[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_89 (Multi  (None, 45, 8)       2248        ['reshape_67[0][0]',             \n",
      " HeadAttention)                                                   'reshape_67[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_90 (Multi  (None, 45, 11)      4147        ['reshape_68[0][0]',             \n",
      " HeadAttention)                                                   'reshape_68[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_88 (LayerN  (None, 45, 8)       16          ['multi_head_attention_88[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_89 (LayerN  (None, 45, 8)       16          ['multi_head_attention_89[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_90 (LayerN  (None, 45, 11)      22          ['multi_head_attention_90[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_132 (Dropout)          (None, 45, 8)        0           ['layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_133 (Dropout)          (None, 45, 8)        0           ['layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_134 (Dropout)          (None, 45, 11)       0           ['layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 45, 27)       0           ['dropout_132[0][0]',            \n",
      "                                                                  'dropout_133[0][0]',            \n",
      "                                                                  'dropout_134[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_22 (G  (None, 27)          0           ['concatenate_22[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_135 (Dropout)          (None, 27)           0           ['global_average_pooling1d_22[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_22 (TFOpLambda)  (None, 1, 27)       0           ['dropout_135[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_91 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_22[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_22[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_22 (TFOpL  (None, 27)          0           ['multi_head_attention_91[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_91 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_22[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 27)           0           ['layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 1024)         28672       ['dropout_136[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 1024)         0           ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 128)          131200      ['dropout_137[0][0]']            \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 1)            129         ['dense_67[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 15ms/step - loss: 0.3652 - accuracy: 0.8210 - val_loss: 0.3606 - val_accuracy: 0.6459\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3115 - accuracy: 0.8396 - val_loss: 0.5576 - val_accuracy: 0.7472\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2688 - accuracy: 0.8842 - val_loss: 0.2304 - val_accuracy: 0.9039\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2260 - accuracy: 0.9138 - val_loss: 0.2513 - val_accuracy: 0.9240\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2127 - accuracy: 0.9194 - val_loss: 0.1866 - val_accuracy: 0.9508\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2067 - accuracy: 0.9250 - val_loss: 0.2746 - val_accuracy: 0.9238\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1939 - accuracy: 0.9296 - val_loss: 0.2141 - val_accuracy: 0.9422\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1827 - accuracy: 0.9339 - val_loss: 0.2126 - val_accuracy: 0.9348\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1654 - accuracy: 0.9390 - val_loss: 0.1637 - val_accuracy: 0.9520\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1558 - accuracy: 0.9450 - val_loss: 0.1504 - val_accuracy: 0.9431\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_70 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_71 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_72 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_69 (Reshape)           (None, 45, 8)        0           ['input_70[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_70 (Reshape)           (None, 45, 8)        0           ['input_71[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_71 (Reshape)           (None, 45, 11)       0           ['input_72[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_92 (Multi  (None, 45, 8)       2248        ['reshape_69[0][0]',             \n",
      " HeadAttention)                                                   'reshape_69[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_93 (Multi  (None, 45, 8)       2248        ['reshape_70[0][0]',             \n",
      " HeadAttention)                                                   'reshape_70[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_94 (Multi  (None, 45, 11)      4147        ['reshape_71[0][0]',             \n",
      " HeadAttention)                                                   'reshape_71[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_92 (LayerN  (None, 45, 8)       16          ['multi_head_attention_92[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_93 (LayerN  (None, 45, 8)       16          ['multi_head_attention_93[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_94 (LayerN  (None, 45, 11)      22          ['multi_head_attention_94[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 45, 8)        0           ['layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 45, 8)        0           ['layer_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 45, 11)       0           ['layer_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 45, 27)       0           ['dropout_138[0][0]',            \n",
      "                                                                  'dropout_139[0][0]',            \n",
      "                                                                  'dropout_140[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_23 (G  (None, 27)          0           ['concatenate_23[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 27)           0           ['global_average_pooling1d_23[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_23 (TFOpLambda)  (None, 1, 27)       0           ['dropout_141[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_95 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_23[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_23[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_23 (TFOpL  (None, 27)          0           ['multi_head_attention_95[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_95 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_23[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 27)           0           ['layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " dense_69 (Dense)               (None, 1024)         28672       ['dropout_142[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 1024)         0           ['dense_69[0][0]']               \n",
      "                                                                                                  \n",
      " dense_70 (Dense)               (None, 128)          131200      ['dropout_143[0][0]']            \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 1)            129         ['dense_70[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.3427 - accuracy: 0.8668 - val_loss: 0.4705 - val_accuracy: 0.7983\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2264 - accuracy: 0.9269 - val_loss: 0.4750 - val_accuracy: 0.8354\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1925 - accuracy: 0.9410 - val_loss: 0.5330 - val_accuracy: 0.8399\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1847 - accuracy: 0.9428 - val_loss: 0.5724 - val_accuracy: 0.8349\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1821 - accuracy: 0.9425 - val_loss: 0.4949 - val_accuracy: 0.8401\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1741 - accuracy: 0.9458 - val_loss: 0.5443 - val_accuracy: 0.8354\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1708 - accuracy: 0.9452 - val_loss: 0.4503 - val_accuracy: 0.8421\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1695 - accuracy: 0.9460 - val_loss: 0.6159 - val_accuracy: 0.8368\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1674 - accuracy: 0.9467 - val_loss: 0.5507 - val_accuracy: 0.8057\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1631 - accuracy: 0.9478 - val_loss: 0.5235 - val_accuracy: 0.8389\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_73 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_74 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_75 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_72 (Reshape)           (None, 45, 8)        0           ['input_73[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_73 (Reshape)           (None, 45, 8)        0           ['input_74[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_74 (Reshape)           (None, 45, 11)       0           ['input_75[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_96 (Multi  (None, 45, 8)       2248        ['reshape_72[0][0]',             \n",
      " HeadAttention)                                                   'reshape_72[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_97 (Multi  (None, 45, 8)       2248        ['reshape_73[0][0]',             \n",
      " HeadAttention)                                                   'reshape_73[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_98 (Multi  (None, 45, 11)      4147        ['reshape_74[0][0]',             \n",
      " HeadAttention)                                                   'reshape_74[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_96 (LayerN  (None, 45, 8)       16          ['multi_head_attention_96[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_97 (LayerN  (None, 45, 8)       16          ['multi_head_attention_97[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_98 (LayerN  (None, 45, 11)      22          ['multi_head_attention_98[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_144 (Dropout)          (None, 45, 8)        0           ['layer_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_145 (Dropout)          (None, 45, 8)        0           ['layer_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 45, 11)       0           ['layer_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 45, 27)       0           ['dropout_144[0][0]',            \n",
      "                                                                  'dropout_145[0][0]',            \n",
      "                                                                  'dropout_146[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_24 (G  (None, 27)          0           ['concatenate_24[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 27)           0           ['global_average_pooling1d_24[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_24 (TFOpLambda)  (None, 1, 27)       0           ['dropout_147[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_99 (Multi  (None, 1, 27)       24003       ['tf.expand_dims_24[0][0]',      \n",
      " HeadAttention)                                                   'tf.expand_dims_24[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_24 (TFOpL  (None, 27)          0           ['multi_head_attention_99[0][0]']\n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " layer_normalization_99 (LayerN  (None, 27)          54          ['tf.compat.v1.squeeze_24[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_148 (Dropout)          (None, 27)           0           ['layer_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " dense_72 (Dense)               (None, 1024)         28672       ['dropout_148[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_149 (Dropout)          (None, 1024)         0           ['dense_72[0][0]']               \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 128)          131200      ['dropout_149[0][0]']            \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 1)            129         ['dense_73[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4613 - accuracy: 0.7837 - val_loss: 0.3718 - val_accuracy: 0.7529\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3604 - accuracy: 0.8478 - val_loss: 0.3369 - val_accuracy: 0.8272\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3406 - accuracy: 0.8596 - val_loss: 0.2530 - val_accuracy: 0.8521\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3169 - accuracy: 0.8708 - val_loss: 0.2594 - val_accuracy: 0.8404\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3131 - accuracy: 0.8719 - val_loss: 0.2655 - val_accuracy: 0.8401\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3033 - accuracy: 0.8754 - val_loss: 0.2771 - val_accuracy: 0.8526\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2997 - accuracy: 0.8772 - val_loss: 0.3143 - val_accuracy: 0.8542\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2952 - accuracy: 0.8765 - val_loss: 0.2852 - val_accuracy: 0.8303\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2914 - accuracy: 0.8796 - val_loss: 0.2198 - val_accuracy: 0.8712\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2887 - accuracy: 0.8794 - val_loss: 0.2763 - val_accuracy: 0.8335\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 3 19922\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_76 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_77 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_78 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_75 (Reshape)           (None, 45, 8)        0           ['input_76[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_76 (Reshape)           (None, 45, 8)        0           ['input_77[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_77 (Reshape)           (None, 45, 11)       0           ['input_78[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_100 (Mult  (None, 45, 8)       2248        ['reshape_75[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_75[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_101 (Mult  (None, 45, 8)       2248        ['reshape_76[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_76[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_102 (Mult  (None, 45, 11)      4147        ['reshape_77[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_77[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_100 (Layer  (None, 45, 8)       16          ['multi_head_attention_100[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_101 (Layer  (None, 45, 8)       16          ['multi_head_attention_101[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_102 (Layer  (None, 45, 11)      22          ['multi_head_attention_102[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_150 (Dropout)          (None, 45, 8)        0           ['layer_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " dropout_151 (Dropout)          (None, 45, 8)        0           ['layer_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " dropout_152 (Dropout)          (None, 45, 11)       0           ['layer_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 45, 27)       0           ['dropout_150[0][0]',            \n",
      "                                                                  'dropout_151[0][0]',            \n",
      "                                                                  'dropout_152[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_25 (G  (None, 27)          0           ['concatenate_25[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_153 (Dropout)          (None, 27)           0           ['global_average_pooling1d_25[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_25 (TFOpLambda)  (None, 1, 27)       0           ['dropout_153[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_103 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_25[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_25[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_25 (TFOpL  (None, 27)          0           ['multi_head_attention_103[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_103 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_25[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_154 (Dropout)          (None, 27)           0           ['layer_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 1024)         28672       ['dropout_154[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_155 (Dropout)          (None, 1024)         0           ['dense_75[0][0]']               \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 128)          131200      ['dropout_155[0][0]']            \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 1)            129         ['dense_76[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5974 - accuracy: 0.6777 - val_loss: 0.4955 - val_accuracy: 0.7508\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.5033 - accuracy: 0.7659 - val_loss: 0.4127 - val_accuracy: 0.7639\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4769 - accuracy: 0.7785 - val_loss: 0.4853 - val_accuracy: 0.7374\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4703 - accuracy: 0.7839 - val_loss: 0.4962 - val_accuracy: 0.7223\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4649 - accuracy: 0.7832 - val_loss: 0.4064 - val_accuracy: 0.8055\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4606 - accuracy: 0.7878 - val_loss: 0.4563 - val_accuracy: 0.7372\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4542 - accuracy: 0.7924 - val_loss: 0.4463 - val_accuracy: 0.7515\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4490 - accuracy: 0.7923 - val_loss: 0.4447 - val_accuracy: 0.7642\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.4466 - accuracy: 0.7956 - val_loss: 0.3900 - val_accuracy: 0.7778\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4422 - accuracy: 0.7987 - val_loss: 0.3799 - val_accuracy: 0.8198\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_79 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_80 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_81 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_78 (Reshape)           (None, 45, 8)        0           ['input_79[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_79 (Reshape)           (None, 45, 8)        0           ['input_80[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_80 (Reshape)           (None, 45, 11)       0           ['input_81[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_104 (Mult  (None, 45, 8)       2248        ['reshape_78[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_78[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_105 (Mult  (None, 45, 8)       2248        ['reshape_79[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_79[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_106 (Mult  (None, 45, 11)      4147        ['reshape_80[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_80[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_104 (Layer  (None, 45, 8)       16          ['multi_head_attention_104[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_105 (Layer  (None, 45, 8)       16          ['multi_head_attention_105[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_106 (Layer  (None, 45, 11)      22          ['multi_head_attention_106[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_156 (Dropout)          (None, 45, 8)        0           ['layer_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " dropout_157 (Dropout)          (None, 45, 8)        0           ['layer_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " dropout_158 (Dropout)          (None, 45, 11)       0           ['layer_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 45, 27)       0           ['dropout_156[0][0]',            \n",
      "                                                                  'dropout_157[0][0]',            \n",
      "                                                                  'dropout_158[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_26 (G  (None, 27)          0           ['concatenate_26[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_159 (Dropout)          (None, 27)           0           ['global_average_pooling1d_26[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_26 (TFOpLambda)  (None, 1, 27)       0           ['dropout_159[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_107 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_26[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_26[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_26 (TFOpL  (None, 27)          0           ['multi_head_attention_107[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_107 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_26[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_160 (Dropout)          (None, 27)           0           ['layer_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 1024)         28672       ['dropout_160[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_161 (Dropout)          (None, 1024)         0           ['dense_78[0][0]']               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 128)          131200      ['dropout_161[0][0]']            \n",
      "                                                                                                  \n",
      " dense_80 (Dense)               (None, 1)            129         ['dense_79[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5565 - accuracy: 0.7108 - val_loss: 0.3849 - val_accuracy: 0.7749\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4050 - accuracy: 0.8139 - val_loss: 0.4029 - val_accuracy: 0.7582\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3531 - accuracy: 0.8403 - val_loss: 0.3668 - val_accuracy: 0.8103\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3349 - accuracy: 0.8486 - val_loss: 0.3686 - val_accuracy: 0.8170\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3217 - accuracy: 0.8532 - val_loss: 0.4267 - val_accuracy: 0.7560\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3106 - accuracy: 0.8613 - val_loss: 0.4161 - val_accuracy: 0.7558\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3066 - accuracy: 0.8665 - val_loss: 0.4168 - val_accuracy: 0.7551\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2973 - accuracy: 0.8716 - val_loss: 0.4167 - val_accuracy: 0.7563\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2852 - accuracy: 0.8755 - val_loss: 0.3991 - val_accuracy: 0.7835\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2833 - accuracy: 0.8770 - val_loss: 0.4187 - val_accuracy: 0.7570\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_82 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_83 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_84 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_81 (Reshape)           (None, 45, 8)        0           ['input_82[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_82 (Reshape)           (None, 45, 8)        0           ['input_83[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_83 (Reshape)           (None, 45, 11)       0           ['input_84[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_108 (Mult  (None, 45, 8)       2248        ['reshape_81[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_81[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_109 (Mult  (None, 45, 8)       2248        ['reshape_82[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_82[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_110 (Mult  (None, 45, 11)      4147        ['reshape_83[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_83[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_108 (Layer  (None, 45, 8)       16          ['multi_head_attention_108[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_109 (Layer  (None, 45, 8)       16          ['multi_head_attention_109[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_110 (Layer  (None, 45, 11)      22          ['multi_head_attention_110[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_162 (Dropout)          (None, 45, 8)        0           ['layer_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " dropout_163 (Dropout)          (None, 45, 8)        0           ['layer_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " dropout_164 (Dropout)          (None, 45, 11)       0           ['layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 45, 27)       0           ['dropout_162[0][0]',            \n",
      "                                                                  'dropout_163[0][0]',            \n",
      "                                                                  'dropout_164[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_27 (G  (None, 27)          0           ['concatenate_27[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_165 (Dropout)          (None, 27)           0           ['global_average_pooling1d_27[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_27 (TFOpLambda)  (None, 1, 27)       0           ['dropout_165[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_111 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_27[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_27[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_27 (TFOpL  (None, 27)          0           ['multi_head_attention_111[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_111 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_27[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_166 (Dropout)          (None, 27)           0           ['layer_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 1024)         28672       ['dropout_166[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_167 (Dropout)          (None, 1024)         0           ['dense_81[0][0]']               \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 128)          131200      ['dropout_167[0][0]']            \n",
      "                                                                                                  \n",
      " dense_83 (Dense)               (None, 1)            129         ['dense_82[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.3871 - accuracy: 0.8319 - val_loss: 0.1843 - val_accuracy: 0.9591\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2456 - accuracy: 0.9267 - val_loss: 0.1841 - val_accuracy: 0.9589\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2332 - accuracy: 0.9305 - val_loss: 0.1715 - val_accuracy: 0.9661\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2306 - accuracy: 0.9327 - val_loss: 0.1610 - val_accuracy: 0.9673\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2257 - accuracy: 0.9334 - val_loss: 0.1635 - val_accuracy: 0.9651\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2204 - accuracy: 0.9354 - val_loss: 0.1308 - val_accuracy: 0.9685\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2214 - accuracy: 0.9343 - val_loss: 0.1324 - val_accuracy: 0.9665\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2129 - accuracy: 0.9373 - val_loss: 0.1380 - val_accuracy: 0.9680\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2083 - accuracy: 0.9385 - val_loss: 0.1264 - val_accuracy: 0.9670\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2078 - accuracy: 0.9396 - val_loss: 0.1409 - val_accuracy: 0.9634\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_85 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_86 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_87 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_84 (Reshape)           (None, 45, 8)        0           ['input_85[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_85 (Reshape)           (None, 45, 8)        0           ['input_86[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_86 (Reshape)           (None, 45, 11)       0           ['input_87[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_112 (Mult  (None, 45, 8)       2248        ['reshape_84[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_84[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_113 (Mult  (None, 45, 8)       2248        ['reshape_85[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_85[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_114 (Mult  (None, 45, 11)      4147        ['reshape_86[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_86[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_112 (Layer  (None, 45, 8)       16          ['multi_head_attention_112[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_113 (Layer  (None, 45, 8)       16          ['multi_head_attention_113[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_114 (Layer  (None, 45, 11)      22          ['multi_head_attention_114[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_168 (Dropout)          (None, 45, 8)        0           ['layer_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " dropout_169 (Dropout)          (None, 45, 8)        0           ['layer_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " dropout_170 (Dropout)          (None, 45, 11)       0           ['layer_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 45, 27)       0           ['dropout_168[0][0]',            \n",
      "                                                                  'dropout_169[0][0]',            \n",
      "                                                                  'dropout_170[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_28 (G  (None, 27)          0           ['concatenate_28[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_171 (Dropout)          (None, 27)           0           ['global_average_pooling1d_28[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_28 (TFOpLambda)  (None, 1, 27)       0           ['dropout_171[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_115 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_28[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_28[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_28 (TFOpL  (None, 27)          0           ['multi_head_attention_115[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_115 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_28[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_172 (Dropout)          (None, 27)           0           ['layer_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " dense_84 (Dense)               (None, 1024)         28672       ['dropout_172[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_173 (Dropout)          (None, 1024)         0           ['dense_84[0][0]']               \n",
      "                                                                                                  \n",
      " dense_85 (Dense)               (None, 128)          131200      ['dropout_173[0][0]']            \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 1)            129         ['dense_85[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4919 - accuracy: 0.7810 - val_loss: 0.3104 - val_accuracy: 0.8535\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4036 - accuracy: 0.8358 - val_loss: 0.2992 - val_accuracy: 0.8502\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3923 - accuracy: 0.8385 - val_loss: 0.3868 - val_accuracy: 0.8499\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3847 - accuracy: 0.8405 - val_loss: 0.3909 - val_accuracy: 0.8115\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3816 - accuracy: 0.8419 - val_loss: 0.3430 - val_accuracy: 0.8743\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3750 - accuracy: 0.8441 - val_loss: 0.3434 - val_accuracy: 0.8621\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3693 - accuracy: 0.8457 - val_loss: 0.3616 - val_accuracy: 0.8165\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3681 - accuracy: 0.8475 - val_loss: 0.2915 - val_accuracy: 0.8829\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3666 - accuracy: 0.8451 - val_loss: 0.3143 - val_accuracy: 0.8910\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3610 - accuracy: 0.8487 - val_loss: 0.2955 - val_accuracy: 0.8777\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_88 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_89 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_90 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_87 (Reshape)           (None, 45, 8)        0           ['input_88[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_88 (Reshape)           (None, 45, 8)        0           ['input_89[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_89 (Reshape)           (None, 45, 11)       0           ['input_90[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_116 (Mult  (None, 45, 8)       2248        ['reshape_87[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_87[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_117 (Mult  (None, 45, 8)       2248        ['reshape_88[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_88[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_118 (Mult  (None, 45, 11)      4147        ['reshape_89[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_89[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_116 (Layer  (None, 45, 8)       16          ['multi_head_attention_116[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_117 (Layer  (None, 45, 8)       16          ['multi_head_attention_117[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_118 (Layer  (None, 45, 11)      22          ['multi_head_attention_118[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_174 (Dropout)          (None, 45, 8)        0           ['layer_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " dropout_175 (Dropout)          (None, 45, 8)        0           ['layer_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " dropout_176 (Dropout)          (None, 45, 11)       0           ['layer_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 45, 27)       0           ['dropout_174[0][0]',            \n",
      "                                                                  'dropout_175[0][0]',            \n",
      "                                                                  'dropout_176[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_29 (G  (None, 27)          0           ['concatenate_29[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_177 (Dropout)          (None, 27)           0           ['global_average_pooling1d_29[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_29 (TFOpLambda)  (None, 1, 27)       0           ['dropout_177[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_119 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_29[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_29[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_29 (TFOpL  (None, 27)          0           ['multi_head_attention_119[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_119 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_29[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_178 (Dropout)          (None, 27)           0           ['layer_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " dense_87 (Dense)               (None, 1024)         28672       ['dropout_178[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_179 (Dropout)          (None, 1024)         0           ['dense_87[0][0]']               \n",
      "                                                                                                  \n",
      " dense_88 (Dense)               (None, 128)          131200      ['dropout_179[0][0]']            \n",
      "                                                                                                  \n",
      " dense_89 (Dense)               (None, 1)            129         ['dense_88[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.3644 - accuracy: 0.8265 - val_loss: 0.2715 - val_accuracy: 0.8449\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2512 - accuracy: 0.9041 - val_loss: 0.1893 - val_accuracy: 0.8714\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2057 - accuracy: 0.9259 - val_loss: 0.2292 - val_accuracy: 0.8805\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1761 - accuracy: 0.9365 - val_loss: 0.2157 - val_accuracy: 0.9145\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1680 - accuracy: 0.9389 - val_loss: 0.1933 - val_accuracy: 0.9097\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1464 - accuracy: 0.9504 - val_loss: 0.2364 - val_accuracy: 0.9039\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1279 - accuracy: 0.9576 - val_loss: 0.1850 - val_accuracy: 0.9350\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1129 - accuracy: 0.9630 - val_loss: 0.1429 - val_accuracy: 0.9443\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1035 - accuracy: 0.9666 - val_loss: 0.1571 - val_accuracy: 0.9367\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0944 - accuracy: 0.9705 - val_loss: 0.0957 - val_accuracy: 0.9582\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_91 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_92 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_93 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_90 (Reshape)           (None, 45, 8)        0           ['input_91[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_91 (Reshape)           (None, 45, 8)        0           ['input_92[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_92 (Reshape)           (None, 45, 11)       0           ['input_93[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_120 (Mult  (None, 45, 8)       2248        ['reshape_90[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_90[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_121 (Mult  (None, 45, 8)       2248        ['reshape_91[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_91[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_122 (Mult  (None, 45, 11)      4147        ['reshape_92[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_92[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_120 (Layer  (None, 45, 8)       16          ['multi_head_attention_120[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_121 (Layer  (None, 45, 8)       16          ['multi_head_attention_121[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_122 (Layer  (None, 45, 11)      22          ['multi_head_attention_122[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_180 (Dropout)          (None, 45, 8)        0           ['layer_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " dropout_181 (Dropout)          (None, 45, 8)        0           ['layer_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " dropout_182 (Dropout)          (None, 45, 11)       0           ['layer_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 45, 27)       0           ['dropout_180[0][0]',            \n",
      "                                                                  'dropout_181[0][0]',            \n",
      "                                                                  'dropout_182[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_30 (G  (None, 27)          0           ['concatenate_30[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_183 (Dropout)          (None, 27)           0           ['global_average_pooling1d_30[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_30 (TFOpLambda)  (None, 1, 27)       0           ['dropout_183[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_123 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_30[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_30[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_30 (TFOpL  (None, 27)          0           ['multi_head_attention_123[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_123 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_30[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_184 (Dropout)          (None, 27)           0           ['layer_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " dense_90 (Dense)               (None, 1024)         28672       ['dropout_184[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_185 (Dropout)          (None, 1024)         0           ['dense_90[0][0]']               \n",
      "                                                                                                  \n",
      " dense_91 (Dense)               (None, 128)          131200      ['dropout_185[0][0]']            \n",
      "                                                                                                  \n",
      " dense_92 (Dense)               (None, 1)            129         ['dense_91[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.3570 - accuracy: 0.8237 - val_loss: 0.4183 - val_accuracy: 0.8777\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3004 - accuracy: 0.8532 - val_loss: 0.4130 - val_accuracy: 0.8946\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2715 - accuracy: 0.8767 - val_loss: 0.3748 - val_accuracy: 0.8755\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2119 - accuracy: 0.9192 - val_loss: 0.2872 - val_accuracy: 0.9006\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2021 - accuracy: 0.9240 - val_loss: 0.3056 - val_accuracy: 0.9106\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1932 - accuracy: 0.9266 - val_loss: 0.2354 - val_accuracy: 0.9367\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1849 - accuracy: 0.9313 - val_loss: 0.2737 - val_accuracy: 0.9288\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1786 - accuracy: 0.9344 - val_loss: 0.3015 - val_accuracy: 0.9161\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1734 - accuracy: 0.9369 - val_loss: 0.3300 - val_accuracy: 0.9090\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1665 - accuracy: 0.9415 - val_loss: 0.2892 - val_accuracy: 0.9245\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_94 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_95 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_96 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_93 (Reshape)           (None, 45, 8)        0           ['input_94[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_94 (Reshape)           (None, 45, 8)        0           ['input_95[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_95 (Reshape)           (None, 45, 11)       0           ['input_96[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_124 (Mult  (None, 45, 8)       2248        ['reshape_93[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_93[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_125 (Mult  (None, 45, 8)       2248        ['reshape_94[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_94[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_126 (Mult  (None, 45, 11)      4147        ['reshape_95[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_95[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_124 (Layer  (None, 45, 8)       16          ['multi_head_attention_124[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_125 (Layer  (None, 45, 8)       16          ['multi_head_attention_125[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_126 (Layer  (None, 45, 11)      22          ['multi_head_attention_126[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_186 (Dropout)          (None, 45, 8)        0           ['layer_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " dropout_187 (Dropout)          (None, 45, 8)        0           ['layer_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " dropout_188 (Dropout)          (None, 45, 11)       0           ['layer_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 45, 27)       0           ['dropout_186[0][0]',            \n",
      "                                                                  'dropout_187[0][0]',            \n",
      "                                                                  'dropout_188[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_31 (G  (None, 27)          0           ['concatenate_31[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_189 (Dropout)          (None, 27)           0           ['global_average_pooling1d_31[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_31 (TFOpLambda)  (None, 1, 27)       0           ['dropout_189[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_127 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_31[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_31[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_31 (TFOpL  (None, 27)          0           ['multi_head_attention_127[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_127 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_31[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_190 (Dropout)          (None, 27)           0           ['layer_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " dense_93 (Dense)               (None, 1024)         28672       ['dropout_190[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_191 (Dropout)          (None, 1024)         0           ['dense_93[0][0]']               \n",
      "                                                                                                  \n",
      " dense_94 (Dense)               (None, 128)          131200      ['dropout_191[0][0]']            \n",
      "                                                                                                  \n",
      " dense_95 (Dense)               (None, 1)            129         ['dense_94[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3550 - accuracy: 0.8606 - val_loss: 0.2234 - val_accuracy: 0.9197\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2557 - accuracy: 0.9140 - val_loss: 0.1060 - val_accuracy: 0.9682\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2121 - accuracy: 0.9325 - val_loss: 0.1027 - val_accuracy: 0.9754\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2029 - accuracy: 0.9357 - val_loss: 0.0960 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1997 - accuracy: 0.9371 - val_loss: 0.0920 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1957 - accuracy: 0.9365 - val_loss: 0.0932 - val_accuracy: 0.9761\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1944 - accuracy: 0.9377 - val_loss: 0.0830 - val_accuracy: 0.9797\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1911 - accuracy: 0.9393 - val_loss: 0.0727 - val_accuracy: 0.9780\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1884 - accuracy: 0.9399 - val_loss: 0.0810 - val_accuracy: 0.9785\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1865 - accuracy: 0.9391 - val_loss: 0.0802 - val_accuracy: 0.9785\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_97 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_98 (InputLayer)          [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_99 (InputLayer)          [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_96 (Reshape)           (None, 45, 8)        0           ['input_97[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_97 (Reshape)           (None, 45, 8)        0           ['input_98[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_98 (Reshape)           (None, 45, 11)       0           ['input_99[0][0]']               \n",
      "                                                                                                  \n",
      " multi_head_attention_128 (Mult  (None, 45, 8)       2248        ['reshape_96[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_96[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_129 (Mult  (None, 45, 8)       2248        ['reshape_97[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_97[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_130 (Mult  (None, 45, 11)      4147        ['reshape_98[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_98[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_128 (Layer  (None, 45, 8)       16          ['multi_head_attention_128[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_129 (Layer  (None, 45, 8)       16          ['multi_head_attention_129[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_130 (Layer  (None, 45, 11)      22          ['multi_head_attention_130[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_192 (Dropout)          (None, 45, 8)        0           ['layer_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " dropout_193 (Dropout)          (None, 45, 8)        0           ['layer_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " dropout_194 (Dropout)          (None, 45, 11)       0           ['layer_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 45, 27)       0           ['dropout_192[0][0]',            \n",
      "                                                                  'dropout_193[0][0]',            \n",
      "                                                                  'dropout_194[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_32 (G  (None, 27)          0           ['concatenate_32[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_195 (Dropout)          (None, 27)           0           ['global_average_pooling1d_32[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_32 (TFOpLambda)  (None, 1, 27)       0           ['dropout_195[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_131 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_32[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_32[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_32 (TFOpL  (None, 27)          0           ['multi_head_attention_131[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_131 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_32[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_196 (Dropout)          (None, 27)           0           ['layer_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " dense_96 (Dense)               (None, 1024)         28672       ['dropout_196[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_197 (Dropout)          (None, 1024)         0           ['dense_96[0][0]']               \n",
      "                                                                                                  \n",
      " dense_97 (Dense)               (None, 128)          131200      ['dropout_197[0][0]']            \n",
      "                                                                                                  \n",
      " dense_98 (Dense)               (None, 1)            129         ['dense_97[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4449 - accuracy: 0.7968 - val_loss: 0.3972 - val_accuracy: 0.7231\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3707 - accuracy: 0.8464 - val_loss: 0.4211 - val_accuracy: 0.7556\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3463 - accuracy: 0.8602 - val_loss: 0.3450 - val_accuracy: 0.8017\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3314 - accuracy: 0.8674 - val_loss: 0.3534 - val_accuracy: 0.8098\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3174 - accuracy: 0.8697 - val_loss: 0.3324 - val_accuracy: 0.8203\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3090 - accuracy: 0.8752 - val_loss: 0.3837 - val_accuracy: 0.8246\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3008 - accuracy: 0.8787 - val_loss: 0.3753 - val_accuracy: 0.8167\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2972 - accuracy: 0.8797 - val_loss: 0.3454 - val_accuracy: 0.8335\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2957 - accuracy: 0.8803 - val_loss: 0.3632 - val_accuracy: 0.8335\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2881 - accuracy: 0.8828 - val_loss: 0.3663 - val_accuracy: 0.8103\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 4 19923\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_100 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_101 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_102 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_99 (Reshape)           (None, 45, 8)        0           ['input_100[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_100 (Reshape)          (None, 45, 8)        0           ['input_101[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_101 (Reshape)          (None, 45, 11)       0           ['input_102[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_132 (Mult  (None, 45, 8)       2248        ['reshape_99[0][0]',             \n",
      " iHeadAttention)                                                  'reshape_99[0][0]']             \n",
      "                                                                                                  \n",
      " multi_head_attention_133 (Mult  (None, 45, 8)       2248        ['reshape_100[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_100[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_134 (Mult  (None, 45, 11)      4147        ['reshape_101[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_101[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_132 (Layer  (None, 45, 8)       16          ['multi_head_attention_132[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_133 (Layer  (None, 45, 8)       16          ['multi_head_attention_133[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_134 (Layer  (None, 45, 11)      22          ['multi_head_attention_134[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_198 (Dropout)          (None, 45, 8)        0           ['layer_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " dropout_199 (Dropout)          (None, 45, 8)        0           ['layer_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " dropout_200 (Dropout)          (None, 45, 11)       0           ['layer_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 45, 27)       0           ['dropout_198[0][0]',            \n",
      "                                                                  'dropout_199[0][0]',            \n",
      "                                                                  'dropout_200[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_33 (G  (None, 27)          0           ['concatenate_33[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_201 (Dropout)          (None, 27)           0           ['global_average_pooling1d_33[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_33 (TFOpLambda)  (None, 1, 27)       0           ['dropout_201[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_135 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_33[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_33[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_33 (TFOpL  (None, 27)          0           ['multi_head_attention_135[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_135 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_33[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_202 (Dropout)          (None, 27)           0           ['layer_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " dense_99 (Dense)               (None, 1024)         28672       ['dropout_202[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_203 (Dropout)          (None, 1024)         0           ['dense_99[0][0]']               \n",
      "                                                                                                  \n",
      " dense_100 (Dense)              (None, 128)          131200      ['dropout_203[0][0]']            \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 1)            129         ['dense_100[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5916 - accuracy: 0.6807 - val_loss: 0.4522 - val_accuracy: 0.7374\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.5024 - accuracy: 0.7738 - val_loss: 0.5669 - val_accuracy: 0.6996\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4703 - accuracy: 0.7905 - val_loss: 0.4959 - val_accuracy: 0.7744\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4590 - accuracy: 0.7969 - val_loss: 0.4297 - val_accuracy: 0.7916\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4491 - accuracy: 0.8008 - val_loss: 0.4163 - val_accuracy: 0.7814\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4425 - accuracy: 0.8031 - val_loss: 0.3556 - val_accuracy: 0.8112\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4355 - accuracy: 0.8064 - val_loss: 0.2995 - val_accuracy: 0.8354\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4345 - accuracy: 0.8059 - val_loss: 0.4413 - val_accuracy: 0.7990\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4300 - accuracy: 0.8088 - val_loss: 0.3274 - val_accuracy: 0.8167\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4248 - accuracy: 0.8101 - val_loss: 0.3572 - val_accuracy: 0.8237\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_103 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_104 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_105 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_102 (Reshape)          (None, 45, 8)        0           ['input_103[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_103 (Reshape)          (None, 45, 8)        0           ['input_104[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_104 (Reshape)          (None, 45, 11)       0           ['input_105[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_136 (Mult  (None, 45, 8)       2248        ['reshape_102[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_102[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_137 (Mult  (None, 45, 8)       2248        ['reshape_103[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_103[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_138 (Mult  (None, 45, 11)      4147        ['reshape_104[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_104[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_136 (Layer  (None, 45, 8)       16          ['multi_head_attention_136[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_137 (Layer  (None, 45, 8)       16          ['multi_head_attention_137[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_138 (Layer  (None, 45, 11)      22          ['multi_head_attention_138[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_204 (Dropout)          (None, 45, 8)        0           ['layer_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " dropout_205 (Dropout)          (None, 45, 8)        0           ['layer_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " dropout_206 (Dropout)          (None, 45, 11)       0           ['layer_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 45, 27)       0           ['dropout_204[0][0]',            \n",
      "                                                                  'dropout_205[0][0]',            \n",
      "                                                                  'dropout_206[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_34 (G  (None, 27)          0           ['concatenate_34[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_207 (Dropout)          (None, 27)           0           ['global_average_pooling1d_34[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_34 (TFOpLambda)  (None, 1, 27)       0           ['dropout_207[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_139 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_34[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_34[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_34 (TFOpL  (None, 27)          0           ['multi_head_attention_139[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_139 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_34[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_208 (Dropout)          (None, 27)           0           ['layer_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " dense_102 (Dense)              (None, 1024)         28672       ['dropout_208[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_209 (Dropout)          (None, 1024)         0           ['dense_102[0][0]']              \n",
      "                                                                                                  \n",
      " dense_103 (Dense)              (None, 128)          131200      ['dropout_209[0][0]']            \n",
      "                                                                                                  \n",
      " dense_104 (Dense)              (None, 1)            129         ['dense_103[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5441 - accuracy: 0.7267 - val_loss: 0.5249 - val_accuracy: 0.7023\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4225 - accuracy: 0.7999 - val_loss: 0.3748 - val_accuracy: 0.7584\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3955 - accuracy: 0.8109 - val_loss: 0.4419 - val_accuracy: 0.7059\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3751 - accuracy: 0.8254 - val_loss: 0.4534 - val_accuracy: 0.7135\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3572 - accuracy: 0.8332 - val_loss: 0.3035 - val_accuracy: 0.8478\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3383 - accuracy: 0.8449 - val_loss: 0.4129 - val_accuracy: 0.7632\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3309 - accuracy: 0.8483 - val_loss: 0.3274 - val_accuracy: 0.8507\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3226 - accuracy: 0.8535 - val_loss: 0.3625 - val_accuracy: 0.8050\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3148 - accuracy: 0.8586 - val_loss: 0.3163 - val_accuracy: 0.8645\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.3081 - accuracy: 0.8601 - val_loss: 0.2913 - val_accuracy: 0.8896\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_106 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_107 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_108 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_105 (Reshape)          (None, 45, 8)        0           ['input_106[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_106 (Reshape)          (None, 45, 8)        0           ['input_107[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_107 (Reshape)          (None, 45, 11)       0           ['input_108[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_140 (Mult  (None, 45, 8)       2248        ['reshape_105[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_105[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_141 (Mult  (None, 45, 8)       2248        ['reshape_106[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_106[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_142 (Mult  (None, 45, 11)      4147        ['reshape_107[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_107[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_140 (Layer  (None, 45, 8)       16          ['multi_head_attention_140[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_141 (Layer  (None, 45, 8)       16          ['multi_head_attention_141[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_142 (Layer  (None, 45, 11)      22          ['multi_head_attention_142[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_210 (Dropout)          (None, 45, 8)        0           ['layer_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " dropout_211 (Dropout)          (None, 45, 8)        0           ['layer_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " dropout_212 (Dropout)          (None, 45, 11)       0           ['layer_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 45, 27)       0           ['dropout_210[0][0]',            \n",
      "                                                                  'dropout_211[0][0]',            \n",
      "                                                                  'dropout_212[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_35 (G  (None, 27)          0           ['concatenate_35[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_213 (Dropout)          (None, 27)           0           ['global_average_pooling1d_35[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_35 (TFOpLambda)  (None, 1, 27)       0           ['dropout_213[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_143 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_35[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_35[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_35 (TFOpL  (None, 27)          0           ['multi_head_attention_143[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_143 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_35[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_214 (Dropout)          (None, 27)           0           ['layer_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " dense_105 (Dense)              (None, 1024)         28672       ['dropout_214[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_215 (Dropout)          (None, 1024)         0           ['dense_105[0][0]']              \n",
      "                                                                                                  \n",
      " dense_106 (Dense)              (None, 128)          131200      ['dropout_215[0][0]']            \n",
      "                                                                                                  \n",
      " dense_107 (Dense)              (None, 1)            129         ['dense_106[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3822 - accuracy: 0.8306 - val_loss: 0.1936 - val_accuracy: 0.9491\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2310 - accuracy: 0.9344 - val_loss: 0.1667 - val_accuracy: 0.9489\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2229 - accuracy: 0.9357 - val_loss: 0.1613 - val_accuracy: 0.9603\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2158 - accuracy: 0.9387 - val_loss: 0.1633 - val_accuracy: 0.9613\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2152 - accuracy: 0.9392 - val_loss: 0.1565 - val_accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2128 - accuracy: 0.9382 - val_loss: 0.1758 - val_accuracy: 0.9625\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2073 - accuracy: 0.9402 - val_loss: 0.1472 - val_accuracy: 0.9601\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2036 - accuracy: 0.9424 - val_loss: 0.1504 - val_accuracy: 0.9642\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1987 - accuracy: 0.9419 - val_loss: 0.1386 - val_accuracy: 0.9615\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1970 - accuracy: 0.9428 - val_loss: 0.1802 - val_accuracy: 0.9520\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_109 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_110 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_111 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_108 (Reshape)          (None, 45, 8)        0           ['input_109[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_109 (Reshape)          (None, 45, 8)        0           ['input_110[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_110 (Reshape)          (None, 45, 11)       0           ['input_111[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_144 (Mult  (None, 45, 8)       2248        ['reshape_108[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_108[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_145 (Mult  (None, 45, 8)       2248        ['reshape_109[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_109[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_146 (Mult  (None, 45, 11)      4147        ['reshape_110[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_110[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_144 (Layer  (None, 45, 8)       16          ['multi_head_attention_144[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_145 (Layer  (None, 45, 8)       16          ['multi_head_attention_145[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_146 (Layer  (None, 45, 11)      22          ['multi_head_attention_146[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_216 (Dropout)          (None, 45, 8)        0           ['layer_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " dropout_217 (Dropout)          (None, 45, 8)        0           ['layer_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " dropout_218 (Dropout)          (None, 45, 11)       0           ['layer_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, 45, 27)       0           ['dropout_216[0][0]',            \n",
      "                                                                  'dropout_217[0][0]',            \n",
      "                                                                  'dropout_218[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_36 (G  (None, 27)          0           ['concatenate_36[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_219 (Dropout)          (None, 27)           0           ['global_average_pooling1d_36[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_36 (TFOpLambda)  (None, 1, 27)       0           ['dropout_219[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_147 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_36[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_36[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_36 (TFOpL  (None, 27)          0           ['multi_head_attention_147[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_147 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_36[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_220 (Dropout)          (None, 27)           0           ['layer_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " dense_108 (Dense)              (None, 1024)         28672       ['dropout_220[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_221 (Dropout)          (None, 1024)         0           ['dense_108[0][0]']              \n",
      "                                                                                                  \n",
      " dense_109 (Dense)              (None, 128)          131200      ['dropout_221[0][0]']            \n",
      "                                                                                                  \n",
      " dense_110 (Dense)              (None, 1)            129         ['dense_109[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4945 - accuracy: 0.7787 - val_loss: 0.4262 - val_accuracy: 0.7728\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4155 - accuracy: 0.8327 - val_loss: 0.3277 - val_accuracy: 0.8492\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3925 - accuracy: 0.8431 - val_loss: 0.2529 - val_accuracy: 0.8669\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3878 - accuracy: 0.8453 - val_loss: 0.3338 - val_accuracy: 0.8229\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3801 - accuracy: 0.8480 - val_loss: 0.3344 - val_accuracy: 0.8354\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3752 - accuracy: 0.8497 - val_loss: 0.2649 - val_accuracy: 0.8726\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3722 - accuracy: 0.8484 - val_loss: 0.3207 - val_accuracy: 0.8643\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3689 - accuracy: 0.8502 - val_loss: 0.2538 - val_accuracy: 0.8784\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3632 - accuracy: 0.8517 - val_loss: 0.2762 - val_accuracy: 0.8820\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3562 - accuracy: 0.8530 - val_loss: 0.3406 - val_accuracy: 0.8781\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_112 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_113 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_114 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_111 (Reshape)          (None, 45, 8)        0           ['input_112[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_112 (Reshape)          (None, 45, 8)        0           ['input_113[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_113 (Reshape)          (None, 45, 11)       0           ['input_114[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_148 (Mult  (None, 45, 8)       2248        ['reshape_111[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_111[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_149 (Mult  (None, 45, 8)       2248        ['reshape_112[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_112[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_150 (Mult  (None, 45, 11)      4147        ['reshape_113[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_113[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_148 (Layer  (None, 45, 8)       16          ['multi_head_attention_148[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_149 (Layer  (None, 45, 8)       16          ['multi_head_attention_149[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_150 (Layer  (None, 45, 11)      22          ['multi_head_attention_150[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_222 (Dropout)          (None, 45, 8)        0           ['layer_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " dropout_223 (Dropout)          (None, 45, 8)        0           ['layer_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " dropout_224 (Dropout)          (None, 45, 11)       0           ['layer_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, 45, 27)       0           ['dropout_222[0][0]',            \n",
      "                                                                  'dropout_223[0][0]',            \n",
      "                                                                  'dropout_224[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_37 (G  (None, 27)          0           ['concatenate_37[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_225 (Dropout)          (None, 27)           0           ['global_average_pooling1d_37[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_37 (TFOpLambda)  (None, 1, 27)       0           ['dropout_225[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_151 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_37[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_37[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_37 (TFOpL  (None, 27)          0           ['multi_head_attention_151[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_151 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_37[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_226 (Dropout)          (None, 27)           0           ['layer_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " dense_111 (Dense)              (None, 1024)         28672       ['dropout_226[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_227 (Dropout)          (None, 1024)         0           ['dense_111[0][0]']              \n",
      "                                                                                                  \n",
      " dense_112 (Dense)              (None, 128)          131200      ['dropout_227[0][0]']            \n",
      "                                                                                                  \n",
      " dense_113 (Dense)              (None, 1)            129         ['dense_112[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3550 - accuracy: 0.8319 - val_loss: 0.2595 - val_accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2199 - accuracy: 0.9137 - val_loss: 0.1603 - val_accuracy: 0.8980\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1790 - accuracy: 0.9333 - val_loss: 0.2483 - val_accuracy: 0.8449\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1580 - accuracy: 0.9429 - val_loss: 0.1539 - val_accuracy: 0.9257\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1438 - accuracy: 0.9499 - val_loss: 0.1427 - val_accuracy: 0.9278\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1295 - accuracy: 0.9547 - val_loss: 0.1894 - val_accuracy: 0.8980\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1233 - accuracy: 0.9581 - val_loss: 0.1932 - val_accuracy: 0.9116\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1136 - accuracy: 0.9632 - val_loss: 0.1899 - val_accuracy: 0.9137\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1100 - accuracy: 0.9633 - val_loss: 0.1459 - val_accuracy: 0.9424\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1025 - accuracy: 0.9659 - val_loss: 0.1149 - val_accuracy: 0.9539\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_115 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_116 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_117 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_114 (Reshape)          (None, 45, 8)        0           ['input_115[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_115 (Reshape)          (None, 45, 8)        0           ['input_116[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_116 (Reshape)          (None, 45, 11)       0           ['input_117[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_152 (Mult  (None, 45, 8)       2248        ['reshape_114[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_114[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_153 (Mult  (None, 45, 8)       2248        ['reshape_115[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_115[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_154 (Mult  (None, 45, 11)      4147        ['reshape_116[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_116[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_152 (Layer  (None, 45, 8)       16          ['multi_head_attention_152[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_153 (Layer  (None, 45, 8)       16          ['multi_head_attention_153[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_154 (Layer  (None, 45, 11)      22          ['multi_head_attention_154[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_228 (Dropout)          (None, 45, 8)        0           ['layer_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " dropout_229 (Dropout)          (None, 45, 8)        0           ['layer_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " dropout_230 (Dropout)          (None, 45, 11)       0           ['layer_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, 45, 27)       0           ['dropout_228[0][0]',            \n",
      "                                                                  'dropout_229[0][0]',            \n",
      "                                                                  'dropout_230[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_38 (G  (None, 27)          0           ['concatenate_38[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_231 (Dropout)          (None, 27)           0           ['global_average_pooling1d_38[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_38 (TFOpLambda)  (None, 1, 27)       0           ['dropout_231[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_155 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_38[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_38[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_38 (TFOpL  (None, 27)          0           ['multi_head_attention_155[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_155 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_38[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_232 (Dropout)          (None, 27)           0           ['layer_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " dense_114 (Dense)              (None, 1024)         28672       ['dropout_232[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_233 (Dropout)          (None, 1024)         0           ['dense_114[0][0]']              \n",
      "                                                                                                  \n",
      " dense_115 (Dense)              (None, 128)          131200      ['dropout_233[0][0]']            \n",
      "                                                                                                  \n",
      " dense_116 (Dense)              (None, 1)            129         ['dense_115[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3663 - accuracy: 0.8271 - val_loss: 0.3149 - val_accuracy: 0.9104\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3062 - accuracy: 0.8562 - val_loss: 0.3837 - val_accuracy: 0.8777\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2730 - accuracy: 0.8829 - val_loss: 0.3823 - val_accuracy: 0.8664\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2349 - accuracy: 0.9130 - val_loss: 0.1835 - val_accuracy: 0.9271\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2198 - accuracy: 0.9218 - val_loss: 0.2401 - val_accuracy: 0.9104\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2067 - accuracy: 0.9268 - val_loss: 0.1958 - val_accuracy: 0.9436\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1972 - accuracy: 0.9317 - val_loss: 0.2465 - val_accuracy: 0.9319\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1937 - accuracy: 0.9324 - val_loss: 0.2688 - val_accuracy: 0.9329\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1845 - accuracy: 0.9373 - val_loss: 0.2056 - val_accuracy: 0.9460\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1770 - accuracy: 0.9382 - val_loss: 0.1951 - val_accuracy: 0.9446\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_118 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_119 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_120 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_117 (Reshape)          (None, 45, 8)        0           ['input_118[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_118 (Reshape)          (None, 45, 8)        0           ['input_119[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_119 (Reshape)          (None, 45, 11)       0           ['input_120[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_156 (Mult  (None, 45, 8)       2248        ['reshape_117[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_117[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_157 (Mult  (None, 45, 8)       2248        ['reshape_118[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_118[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_158 (Mult  (None, 45, 11)      4147        ['reshape_119[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_119[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_156 (Layer  (None, 45, 8)       16          ['multi_head_attention_156[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_157 (Layer  (None, 45, 8)       16          ['multi_head_attention_157[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_158 (Layer  (None, 45, 11)      22          ['multi_head_attention_158[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_234 (Dropout)          (None, 45, 8)        0           ['layer_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " dropout_235 (Dropout)          (None, 45, 8)        0           ['layer_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " dropout_236 (Dropout)          (None, 45, 11)       0           ['layer_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, 45, 27)       0           ['dropout_234[0][0]',            \n",
      "                                                                  'dropout_235[0][0]',            \n",
      "                                                                  'dropout_236[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_39 (G  (None, 27)          0           ['concatenate_39[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_237 (Dropout)          (None, 27)           0           ['global_average_pooling1d_39[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_39 (TFOpLambda)  (None, 1, 27)       0           ['dropout_237[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_159 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_39[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_39[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_39 (TFOpL  (None, 27)          0           ['multi_head_attention_159[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_159 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_39[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_238 (Dropout)          (None, 27)           0           ['layer_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " dense_117 (Dense)              (None, 1024)         28672       ['dropout_238[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_239 (Dropout)          (None, 1024)         0           ['dense_117[0][0]']              \n",
      "                                                                                                  \n",
      " dense_118 (Dense)              (None, 128)          131200      ['dropout_239[0][0]']            \n",
      "                                                                                                  \n",
      " dense_119 (Dense)              (None, 1)            129         ['dense_118[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3313 - accuracy: 0.8705 - val_loss: 0.1419 - val_accuracy: 0.9563\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2171 - accuracy: 0.9311 - val_loss: 0.1160 - val_accuracy: 0.9632\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2046 - accuracy: 0.9346 - val_loss: 0.1256 - val_accuracy: 0.9608\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1939 - accuracy: 0.9386 - val_loss: 0.1387 - val_accuracy: 0.9651\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1908 - accuracy: 0.9386 - val_loss: 0.1165 - val_accuracy: 0.9654\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1861 - accuracy: 0.9407 - val_loss: 0.1059 - val_accuracy: 0.9673\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1841 - accuracy: 0.9409 - val_loss: 0.1167 - val_accuracy: 0.9599\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1842 - accuracy: 0.9415 - val_loss: 0.1027 - val_accuracy: 0.9649\n",
      "Epoch 9/10\n",
      "138/938 [===>..........................] - ETA: 11s - loss: 0.1792 - accuracy: 0.9432TRAIN resting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_127 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_128 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_129 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_126 (Reshape)          (None, 45, 8)        0           ['input_127[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_127 (Reshape)          (None, 45, 8)        0           ['input_128[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_128 (Reshape)          (None, 45, 11)       0           ['input_129[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_168 (Mult  (None, 45, 8)       2248        ['reshape_126[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_126[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_169 (Mult  (None, 45, 8)       2248        ['reshape_127[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_127[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_170 (Mult  (None, 45, 11)      4147        ['reshape_128[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_128[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_168 (Layer  (None, 45, 8)       16          ['multi_head_attention_168[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_169 (Layer  (None, 45, 8)       16          ['multi_head_attention_169[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_170 (Layer  (None, 45, 11)      22          ['multi_head_attention_170[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_252 (Dropout)          (None, 45, 8)        0           ['layer_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " dropout_253 (Dropout)          (None, 45, 8)        0           ['layer_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " dropout_254 (Dropout)          (None, 45, 11)       0           ['layer_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenate)   (None, 45, 27)       0           ['dropout_252[0][0]',            \n",
      "                                                                  'dropout_253[0][0]',            \n",
      "                                                                  'dropout_254[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_42 (G  (None, 27)          0           ['concatenate_42[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_255 (Dropout)          (None, 27)           0           ['global_average_pooling1d_42[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_42 (TFOpLambda)  (None, 1, 27)       0           ['dropout_255[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_171 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_42[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_42[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_42 (TFOpL  (None, 27)          0           ['multi_head_attention_171[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_171 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_42[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_256 (Dropout)          (None, 27)           0           ['layer_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " dense_126 (Dense)              (None, 1024)         28672       ['dropout_256[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_257 (Dropout)          (None, 1024)         0           ['dense_126[0][0]']              \n",
      "                                                                                                  \n",
      " dense_127 (Dense)              (None, 128)          131200      ['dropout_257[0][0]']            \n",
      "                                                                                                  \n",
      " dense_128 (Dense)              (None, 1)            129         ['dense_127[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.5357 - accuracy: 0.7254 - val_loss: 0.3863 - val_accuracy: 0.7142\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4025 - accuracy: 0.8076 - val_loss: 0.3999 - val_accuracy: 0.7391\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3707 - accuracy: 0.8268 - val_loss: 0.2130 - val_accuracy: 0.9137\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3525 - accuracy: 0.8359 - val_loss: 0.2834 - val_accuracy: 0.8915\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3371 - accuracy: 0.8447 - val_loss: 0.2692 - val_accuracy: 0.9059\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3283 - accuracy: 0.8503 - val_loss: 0.2569 - val_accuracy: 0.9252\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3174 - accuracy: 0.8537 - val_loss: 0.2716 - val_accuracy: 0.9025\n",
      "Epoch 8/10\n",
      "458/938 [=============>................] - ETA: 6s - loss: 0.3172 - accuracy: 0.8560\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_130 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_131 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_132 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_129 (Reshape)          (None, 45, 8)        0           ['input_130[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_130 (Reshape)          (None, 45, 8)        0           ['input_131[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_131 (Reshape)          (None, 45, 11)       0           ['input_132[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_172 (Mult  (None, 45, 8)       2248        ['reshape_129[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_129[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_173 (Mult  (None, 45, 8)       2248        ['reshape_130[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_130[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_174 (Mult  (None, 45, 11)      4147        ['reshape_131[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_131[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_172 (Layer  (None, 45, 8)       16          ['multi_head_attention_172[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_173 (Layer  (None, 45, 8)       16          ['multi_head_attention_173[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_174 (Layer  (None, 45, 11)      22          ['multi_head_attention_174[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_258 (Dropout)          (None, 45, 8)        0           ['layer_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " dropout_259 (Dropout)          (None, 45, 8)        0           ['layer_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " dropout_260 (Dropout)          (None, 45, 11)       0           ['layer_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenate)   (None, 45, 27)       0           ['dropout_258[0][0]',            \n",
      "                                                                  'dropout_259[0][0]',            \n",
      "                                                                  'dropout_260[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_43 (G  (None, 27)          0           ['concatenate_43[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_261 (Dropout)          (None, 27)           0           ['global_average_pooling1d_43[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_43 (TFOpLambda)  (None, 1, 27)       0           ['dropout_261[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_175 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_43[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_43[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_43 (TFOpL  (None, 27)          0           ['multi_head_attention_175[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_175 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_43[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_262 (Dropout)          (None, 27)           0           ['layer_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " dense_129 (Dense)              (None, 1024)         28672       ['dropout_262[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_263 (Dropout)          (None, 1024)         0           ['dense_129[0][0]']              \n",
      "                                                                                                  \n",
      " dense_130 (Dense)              (None, 128)          131200      ['dropout_263[0][0]']            \n",
      "                                                                                                  \n",
      " dense_131 (Dense)              (None, 1)            129         ['dense_130[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3863 - accuracy: 0.8452 - val_loss: 0.2112 - val_accuracy: 0.9374\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2661 - accuracy: 0.9181 - val_loss: 0.2002 - val_accuracy: 0.9536\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2371 - accuracy: 0.9296 - val_loss: 0.1997 - val_accuracy: 0.9470\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2272 - accuracy: 0.9334 - val_loss: 0.1611 - val_accuracy: 0.9551\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2260 - accuracy: 0.9337 - val_loss: 0.1736 - val_accuracy: 0.9570\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2198 - accuracy: 0.9356 - val_loss: 0.1603 - val_accuracy: 0.9622\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2193 - accuracy: 0.9357 - val_loss: 0.1786 - val_accuracy: 0.9558\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2154 - accuracy: 0.9381 - val_loss: 0.1602 - val_accuracy: 0.9615\n",
      "Epoch 9/10\n",
      "820/938 [=========================>....] - ETA: 1s - loss: 0.2096 - accuracy: 0.9377\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_133 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_134 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_135 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_132 (Reshape)          (None, 45, 8)        0           ['input_133[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_133 (Reshape)          (None, 45, 8)        0           ['input_134[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_134 (Reshape)          (None, 45, 11)       0           ['input_135[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_176 (Mult  (None, 45, 8)       2248        ['reshape_132[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_132[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_177 (Mult  (None, 45, 8)       2248        ['reshape_133[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_133[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_178 (Mult  (None, 45, 11)      4147        ['reshape_134[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_134[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_176 (Layer  (None, 45, 8)       16          ['multi_head_attention_176[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_177 (Layer  (None, 45, 8)       16          ['multi_head_attention_177[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_178 (Layer  (None, 45, 11)      22          ['multi_head_attention_178[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_264 (Dropout)          (None, 45, 8)        0           ['layer_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " dropout_265 (Dropout)          (None, 45, 8)        0           ['layer_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " dropout_266 (Dropout)          (None, 45, 11)       0           ['layer_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenate)   (None, 45, 27)       0           ['dropout_264[0][0]',            \n",
      "                                                                  'dropout_265[0][0]',            \n",
      "                                                                  'dropout_266[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_44 (G  (None, 27)          0           ['concatenate_44[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_267 (Dropout)          (None, 27)           0           ['global_average_pooling1d_44[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_44 (TFOpLambda)  (None, 1, 27)       0           ['dropout_267[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_179 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_44[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_44[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_44 (TFOpL  (None, 27)          0           ['multi_head_attention_179[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_179 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_44[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_268 (Dropout)          (None, 27)           0           ['layer_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " dense_132 (Dense)              (None, 1024)         28672       ['dropout_268[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_269 (Dropout)          (None, 1024)         0           ['dense_132[0][0]']              \n",
      "                                                                                                  \n",
      " dense_133 (Dense)              (None, 128)          131200      ['dropout_269[0][0]']            \n",
      "                                                                                                  \n",
      " dense_134 (Dense)              (None, 1)            129         ['dense_133[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4844 - accuracy: 0.7887 - val_loss: 0.2362 - val_accuracy: 0.8894\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4075 - accuracy: 0.8317 - val_loss: 0.2316 - val_accuracy: 0.9004\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3951 - accuracy: 0.8395 - val_loss: 0.2451 - val_accuracy: 0.8937\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3886 - accuracy: 0.8418 - val_loss: 0.3128 - val_accuracy: 0.8497\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3819 - accuracy: 0.8424 - val_loss: 0.3062 - val_accuracy: 0.8898\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3762 - accuracy: 0.8445 - val_loss: 0.2471 - val_accuracy: 0.9056\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3701 - accuracy: 0.8483 - val_loss: 0.2488 - val_accuracy: 0.9106\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.2202 - accuracy: 0.9161 - val_loss: 0.1824 - val_accuracy: 0.9157\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1689 - accuracy: 0.9378 - val_loss: 0.1329 - val_accuracy: 0.9372\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1406 - accuracy: 0.9501 - val_loss: 0.1795 - val_accuracy: 0.9099\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1332 - accuracy: 0.9537 - val_loss: 0.0751 - val_accuracy: 0.9656\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1190 - accuracy: 0.9600 - val_loss: 0.1011 - val_accuracy: 0.9481\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1130 - accuracy: 0.9632 - val_loss: 0.0554 - val_accuracy: 0.9730\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0987 - accuracy: 0.9679 - val_loss: 0.0769 - val_accuracy: 0.9639\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2279 - accuracy: 0.9086 - val_loss: 0.1214 - val_accuracy: 0.9627\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2173 - accuracy: 0.9161 - val_loss: 0.0994 - val_accuracy: 0.9735\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2012 - accuracy: 0.9232 - val_loss: 0.0826 - val_accuracy: 0.9785\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1838 - accuracy: 0.9313 - val_loss: 0.0863 - val_accuracy: 0.9579\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1609 - accuracy: 0.9423 - val_loss: 0.1093 - val_accuracy: 0.9477\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1523 - accuracy: 0.9474 - val_loss: 0.0636 - val_accuracy: 0.9730\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1434 - accuracy: 0.9524 - val_loss: 0.0469 - val_accuracy: 0.9802\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_142 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_143 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_144 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_141 (Reshape)          (None, 45, 8)        0           ['input_142[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_142 (Reshape)          (None, 45, 8)        0           ['input_143[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_143 (Reshape)          (None, 45, 11)       0           ['input_144[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_188 (Mult  (None, 45, 8)       2248        ['reshape_141[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_141[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_189 (Mult  (None, 45, 8)       2248        ['reshape_142[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_142[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_190 (Mult  (None, 45, 11)      4147        ['reshape_143[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_143[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_188 (Layer  (None, 45, 8)       16          ['multi_head_attention_188[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_189 (Layer  (None, 45, 8)       16          ['multi_head_attention_189[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_190 (Layer  (None, 45, 11)      22          ['multi_head_attention_190[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_282 (Dropout)          (None, 45, 8)        0           ['layer_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " dropout_283 (Dropout)          (None, 45, 8)        0           ['layer_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " dropout_284 (Dropout)          (None, 45, 11)       0           ['layer_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 45, 27)       0           ['dropout_282[0][0]',            \n",
      "                                                                  'dropout_283[0][0]',            \n",
      "                                                                  'dropout_284[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_47 (G  (None, 27)          0           ['concatenate_47[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_285 (Dropout)          (None, 27)           0           ['global_average_pooling1d_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_47 (TFOpLambda)  (None, 1, 27)       0           ['dropout_285[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_191 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_47[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_47[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_47 (TFOpL  (None, 27)          0           ['multi_head_attention_191[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_191 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_47[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_286 (Dropout)          (None, 27)           0           ['layer_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " dense_141 (Dense)              (None, 1024)         28672       ['dropout_286[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_287 (Dropout)          (None, 1024)         0           ['dense_141[0][0]']              \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 128)          131200      ['dropout_287[0][0]']            \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 1)            129         ['dense_142[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1948 - accuracy: 0.9367 - val_loss: 0.1744 - val_accuracy: 0.9491\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1930 - accuracy: 0.9388 - val_loss: 0.1632 - val_accuracy: 0.9520\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1862 - accuracy: 0.9404 - val_loss: 0.1822 - val_accuracy: 0.9465\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1856 - accuracy: 0.9397 - val_loss: 0.1618 - val_accuracy: 0.9532\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1802 - accuracy: 0.9418 - val_loss: 0.1634 - val_accuracy: 0.9539\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1772 - accuracy: 0.9423 - val_loss: 0.1635 - val_accuracy: 0.9517\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_145 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_146 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_147 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_144 (Reshape)          (None, 45, 8)        0           ['input_145[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_145 (Reshape)          (None, 45, 8)        0           ['input_146[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_146 (Reshape)          (None, 45, 11)       0           ['input_147[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_192 (Mult  (None, 45, 8)       2248        ['reshape_144[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_144[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_193 (Mult  (None, 45, 8)       2248        ['reshape_145[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_145[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_194 (Mult  (None, 45, 11)      4147        ['reshape_146[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_146[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_192 (Layer  (None, 45, 8)       16          ['multi_head_attention_192[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_193 (Layer  (None, 45, 8)       16          ['multi_head_attention_193[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_194 (Layer  (None, 45, 11)      22          ['multi_head_attention_194[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_288 (Dropout)          (None, 45, 8)        0           ['layer_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " dropout_289 (Dropout)          (None, 45, 8)        0           ['layer_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " dropout_290 (Dropout)          (None, 45, 11)       0           ['layer_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 45, 27)       0           ['dropout_288[0][0]',            \n",
      "                                                                  'dropout_289[0][0]',            \n",
      "                                                                  'dropout_290[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_48 (G  (None, 27)          0           ['concatenate_48[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_291 (Dropout)          (None, 27)           0           ['global_average_pooling1d_48[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_48 (TFOpLambda)  (None, 1, 27)       0           ['dropout_291[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_195 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_48[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_48[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_48 (TFOpL  (None, 27)          0           ['multi_head_attention_195[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_195 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_48[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_292 (Dropout)          (None, 27)           0           ['layer_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " dense_144 (Dense)              (None, 1024)         28672       ['dropout_292[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_293 (Dropout)          (None, 1024)         0           ['dense_144[0][0]']              \n",
      "                                                                                                  \n",
      " dense_145 (Dense)              (None, 128)          131200      ['dropout_293[0][0]']            \n",
      "                                                                                                  \n",
      " dense_146 (Dense)              (None, 1)            129         ['dense_145[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4498 - accuracy: 0.7914 - val_loss: 0.2679 - val_accuracy: 0.8385\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3632 - accuracy: 0.8514 - val_loss: 0.2342 - val_accuracy: 0.8858\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3023 - accuracy: 0.8772 - val_loss: 0.2558 - val_accuracy: 0.8662\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2994 - accuracy: 0.8775 - val_loss: 0.2769 - val_accuracy: 0.8707\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2940 - accuracy: 0.8785 - val_loss: 0.3016 - val_accuracy: 0.8671\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 6 19928\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_148 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_149 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_150 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_147 (Reshape)          (None, 45, 8)        0           ['input_148[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_148 (Reshape)          (None, 45, 8)        0           ['input_149[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_149 (Reshape)          (None, 45, 11)       0           ['input_150[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_196 (Mult  (None, 45, 8)       2248        ['reshape_147[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_147[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_197 (Mult  (None, 45, 8)       2248        ['reshape_148[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_148[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_198 (Mult  (None, 45, 11)      4147        ['reshape_149[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_149[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_196 (Layer  (None, 45, 8)       16          ['multi_head_attention_196[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_197 (Layer  (None, 45, 8)       16          ['multi_head_attention_197[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_198 (Layer  (None, 45, 11)      22          ['multi_head_attention_198[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_294 (Dropout)          (None, 45, 8)        0           ['layer_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " dropout_295 (Dropout)          (None, 45, 8)        0           ['layer_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " dropout_296 (Dropout)          (None, 45, 11)       0           ['layer_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 45, 27)       0           ['dropout_294[0][0]',            \n",
      "                                                                  'dropout_295[0][0]',            \n",
      "                                                                  'dropout_296[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_49 (G  (None, 27)          0           ['concatenate_49[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_297 (Dropout)          (None, 27)           0           ['global_average_pooling1d_49[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_49 (TFOpLambda)  (None, 1, 27)       0           ['dropout_297[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_199 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_49[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_49[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_49 (TFOpL  (None, 27)          0           ['multi_head_attention_199[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_199 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_49[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_298 (Dropout)          (None, 27)           0           ['layer_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " dense_147 (Dense)              (None, 1024)         28672       ['dropout_298[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_299 (Dropout)          (None, 1024)         0           ['dense_147[0][0]']              \n",
      "                                                                                                  \n",
      " dense_148 (Dense)              (None, 128)          131200      ['dropout_299[0][0]']            \n",
      "                                                                                                  \n",
      " dense_149 (Dense)              (None, 1)            129         ['dense_148[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5982 - accuracy: 0.6821 - val_loss: 0.4089 - val_accuracy: 0.8258\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.5111 - accuracy: 0.7621 - val_loss: 0.3060 - val_accuracy: 0.8215\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4880 - accuracy: 0.7732 - val_loss: 0.5033 - val_accuracy: 0.7372\n",
      "Epoch 4/10\n",
      "308/938 [========>.....................] - ETA: 8s - loss: 0.4867 - accuracy: 0.7698\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_151 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_152 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_153 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_150 (Reshape)          (None, 45, 8)        0           ['input_151[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_151 (Reshape)          (None, 45, 8)        0           ['input_152[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_152 (Reshape)          (None, 45, 11)       0           ['input_153[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_200 (Mult  (None, 45, 8)       2248        ['reshape_150[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_150[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_201 (Mult  (None, 45, 8)       2248        ['reshape_151[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_151[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_202 (Mult  (None, 45, 11)      4147        ['reshape_152[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_152[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_200 (Layer  (None, 45, 8)       16          ['multi_head_attention_200[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_201 (Layer  (None, 45, 8)       16          ['multi_head_attention_201[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_202 (Layer  (None, 45, 11)      22          ['multi_head_attention_202[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_300 (Dropout)          (None, 45, 8)        0           ['layer_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " dropout_301 (Dropout)          (None, 45, 8)        0           ['layer_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " dropout_302 (Dropout)          (None, 45, 11)       0           ['layer_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_50 (Concatenate)   (None, 45, 27)       0           ['dropout_300[0][0]',            \n",
      "                                                                  'dropout_301[0][0]',            \n",
      "                                                                  'dropout_302[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_50 (G  (None, 27)          0           ['concatenate_50[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_303 (Dropout)          (None, 27)           0           ['global_average_pooling1d_50[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_50 (TFOpLambda)  (None, 1, 27)       0           ['dropout_303[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_203 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_50[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_50[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_50 (TFOpL  (None, 27)          0           ['multi_head_attention_203[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_203 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_50[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_304 (Dropout)          (None, 27)           0           ['layer_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " dense_150 (Dense)              (None, 1024)         28672       ['dropout_304[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_305 (Dropout)          (None, 1024)         0           ['dense_150[0][0]']              \n",
      "                                                                                                  \n",
      " dense_151 (Dense)              (None, 128)          131200      ['dropout_305[0][0]']            \n",
      "                                                                                                  \n",
      " dense_152 (Dense)              (None, 1)            129         ['dense_151[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5477 - accuracy: 0.7175 - val_loss: 0.4484 - val_accuracy: 0.6698\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.4229 - accuracy: 0.7903 - val_loss: 0.3879 - val_accuracy: 0.6958\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4062 - accuracy: 0.7993 - val_loss: 0.3695 - val_accuracy: 0.7011\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4001 - accuracy: 0.8009 - val_loss: 0.3921 - val_accuracy: 0.7018\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3795 - accuracy: 0.8136 - val_loss: 0.3603 - val_accuracy: 0.7417\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3589 - accuracy: 0.8260 - val_loss: 0.2559 - val_accuracy: 0.8829\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3331 - accuracy: 0.8393 - val_loss: 0.2386 - val_accuracy: 0.8984\n",
      "Epoch 8/10\n",
      "829/938 [=========================>....] - ETA: 1s - loss: 0.3221 - accuracy: 0.8465\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_154 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_155 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_156 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_153 (Reshape)          (None, 45, 8)        0           ['input_154[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_154 (Reshape)          (None, 45, 8)        0           ['input_155[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_155 (Reshape)          (None, 45, 11)       0           ['input_156[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_204 (Mult  (None, 45, 8)       2248        ['reshape_153[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_153[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_205 (Mult  (None, 45, 8)       2248        ['reshape_154[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_154[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_206 (Mult  (None, 45, 11)      4147        ['reshape_155[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_155[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_204 (Layer  (None, 45, 8)       16          ['multi_head_attention_204[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_205 (Layer  (None, 45, 8)       16          ['multi_head_attention_205[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_206 (Layer  (None, 45, 11)      22          ['multi_head_attention_206[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_306 (Dropout)          (None, 45, 8)        0           ['layer_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " dropout_307 (Dropout)          (None, 45, 8)        0           ['layer_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " dropout_308 (Dropout)          (None, 45, 11)       0           ['layer_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_51 (Concatenate)   (None, 45, 27)       0           ['dropout_306[0][0]',            \n",
      "                                                                  'dropout_307[0][0]',            \n",
      "                                                                  'dropout_308[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_51 (G  (None, 27)          0           ['concatenate_51[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_309 (Dropout)          (None, 27)           0           ['global_average_pooling1d_51[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_51 (TFOpLambda)  (None, 1, 27)       0           ['dropout_309[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_207 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_51[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_51[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_51 (TFOpL  (None, 27)          0           ['multi_head_attention_207[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_207 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_51[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_310 (Dropout)          (None, 27)           0           ['layer_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " dense_153 (Dense)              (None, 1024)         28672       ['dropout_310[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_311 (Dropout)          (None, 1024)         0           ['dense_153[0][0]']              \n",
      "                                                                                                  \n",
      " dense_154 (Dense)              (None, 128)          131200      ['dropout_311[0][0]']            \n",
      "                                                                                                  \n",
      " dense_155 (Dense)              (None, 1)            129         ['dense_154[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4496 - accuracy: 0.7868 - val_loss: 0.1684 - val_accuracy: 0.9534\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2670 - accuracy: 0.9151 - val_loss: 0.1626 - val_accuracy: 0.9670\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2337 - accuracy: 0.9308 - val_loss: 0.1269 - val_accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2258 - accuracy: 0.9329 - val_loss: 0.1207 - val_accuracy: 0.9737\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2194 - accuracy: 0.9347 - val_loss: 0.1142 - val_accuracy: 0.9740\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2163 - accuracy: 0.9367 - val_loss: 0.1268 - val_accuracy: 0.9675\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4072 - accuracy: 0.8344 - val_loss: 0.3083 - val_accuracy: 0.8404\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3952 - accuracy: 0.8381 - val_loss: 0.3622 - val_accuracy: 0.8511\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3863 - accuracy: 0.8414 - val_loss: 0.3278 - val_accuracy: 0.8805\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3839 - accuracy: 0.8426 - val_loss: 0.3032 - val_accuracy: 0.8540\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3773 - accuracy: 0.8438 - val_loss: 0.2768 - val_accuracy: 0.8810\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3780 - accuracy: 0.8426 - val_loss: 0.3132 - val_accuracy: 0.8449\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2014 - accuracy: 0.9233 - val_loss: 0.1774 - val_accuracy: 0.9228\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1574 - accuracy: 0.9419 - val_loss: 0.2244 - val_accuracy: 0.9018\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1427 - accuracy: 0.9491 - val_loss: 0.1405 - val_accuracy: 0.9290\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1291 - accuracy: 0.9550 - val_loss: 0.1637 - val_accuracy: 0.9247\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1233 - accuracy: 0.9572 - val_loss: 0.1561 - val_accuracy: 0.9321\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1170 - accuracy: 0.9597 - val_loss: 0.1495 - val_accuracy: 0.9161\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1099 - accuracy: 0.9629 - val_loss: 0.1322 - val_accuracy: 0.9441\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2163 - accuracy: 0.9152 - val_loss: 0.2040 - val_accuracy: 0.9431\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2032 - accuracy: 0.9194 - val_loss: 0.1820 - val_accuracy: 0.9427\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1963 - accuracy: 0.9240 - val_loss: 0.1670 - val_accuracy: 0.9522\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1836 - accuracy: 0.9290 - val_loss: 0.1890 - val_accuracy: 0.9274\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1730 - accuracy: 0.9340 - val_loss: 0.1134 - val_accuracy: 0.9553\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1577 - accuracy: 0.9430 - val_loss: 0.1318 - val_accuracy: 0.9453\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_55\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_166 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_167 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_168 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_165 (Reshape)          (None, 45, 8)        0           ['input_166[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_166 (Reshape)          (None, 45, 8)        0           ['input_167[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_167 (Reshape)          (None, 45, 11)       0           ['input_168[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_220 (Mult  (None, 45, 8)       2248        ['reshape_165[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_165[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_221 (Mult  (None, 45, 8)       2248        ['reshape_166[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_166[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_222 (Mult  (None, 45, 11)      4147        ['reshape_167[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_167[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_220 (Layer  (None, 45, 8)       16          ['multi_head_attention_220[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_221 (Layer  (None, 45, 8)       16          ['multi_head_attention_221[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_222 (Layer  (None, 45, 11)      22          ['multi_head_attention_222[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_330 (Dropout)          (None, 45, 8)        0           ['layer_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " dropout_331 (Dropout)          (None, 45, 8)        0           ['layer_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " dropout_332 (Dropout)          (None, 45, 11)       0           ['layer_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_55 (Concatenate)   (None, 45, 27)       0           ['dropout_330[0][0]',            \n",
      "                                                                  'dropout_331[0][0]',            \n",
      "                                                                  'dropout_332[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_55 (G  (None, 27)          0           ['concatenate_55[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_333 (Dropout)          (None, 27)           0           ['global_average_pooling1d_55[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_55 (TFOpLambda)  (None, 1, 27)       0           ['dropout_333[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_223 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_55[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_55[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_55 (TFOpL  (None, 27)          0           ['multi_head_attention_223[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_223 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_55[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_334 (Dropout)          (None, 27)           0           ['layer_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " dense_165 (Dense)              (None, 1024)         28672       ['dropout_334[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_335 (Dropout)          (None, 1024)         0           ['dense_165[0][0]']              \n",
      "                                                                                                  \n",
      " dense_166 (Dense)              (None, 128)          131200      ['dropout_335[0][0]']            \n",
      "                                                                                                  \n",
      " dense_167 (Dense)              (None, 1)            129         ['dense_166[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3504 - accuracy: 0.8618 - val_loss: 0.2854 - val_accuracy: 0.8679\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2564 - accuracy: 0.9152 - val_loss: 0.1189 - val_accuracy: 0.9706\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1901 - accuracy: 0.9390 - val_loss: 0.0937 - val_accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1855 - accuracy: 0.9402 - val_loss: 0.1195 - val_accuracy: 0.9682\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1858 - accuracy: 0.9406 - val_loss: 0.0924 - val_accuracy: 0.9713\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1793 - accuracy: 0.9415 - val_loss: 0.1284 - val_accuracy: 0.9661\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_169 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_170 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_171 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_168 (Reshape)          (None, 45, 8)        0           ['input_169[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_169 (Reshape)          (None, 45, 8)        0           ['input_170[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_170 (Reshape)          (None, 45, 11)       0           ['input_171[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_224 (Mult  (None, 45, 8)       2248        ['reshape_168[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_168[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_225 (Mult  (None, 45, 8)       2248        ['reshape_169[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_169[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_226 (Mult  (None, 45, 11)      4147        ['reshape_170[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_170[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_224 (Layer  (None, 45, 8)       16          ['multi_head_attention_224[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_225 (Layer  (None, 45, 8)       16          ['multi_head_attention_225[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_226 (Layer  (None, 45, 11)      22          ['multi_head_attention_226[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_336 (Dropout)          (None, 45, 8)        0           ['layer_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " dropout_337 (Dropout)          (None, 45, 8)        0           ['layer_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " dropout_338 (Dropout)          (None, 45, 11)       0           ['layer_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_56 (Concatenate)   (None, 45, 27)       0           ['dropout_336[0][0]',            \n",
      "                                                                  'dropout_337[0][0]',            \n",
      "                                                                  'dropout_338[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_56 (G  (None, 27)          0           ['concatenate_56[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_339 (Dropout)          (None, 27)           0           ['global_average_pooling1d_56[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_56 (TFOpLambda)  (None, 1, 27)       0           ['dropout_339[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_227 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_56[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_56[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_56 (TFOpL  (None, 27)          0           ['multi_head_attention_227[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_227 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_56[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_340 (Dropout)          (None, 27)           0           ['layer_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " dense_168 (Dense)              (None, 1024)         28672       ['dropout_340[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_341 (Dropout)          (None, 1024)         0           ['dense_168[0][0]']              \n",
      "                                                                                                  \n",
      " dense_169 (Dense)              (None, 128)          131200      ['dropout_341[0][0]']            \n",
      "                                                                                                  \n",
      " dense_170 (Dense)              (None, 1)            129         ['dense_169[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4469 - accuracy: 0.7977 - val_loss: 0.3141 - val_accuracy: 0.8272\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3604 - accuracy: 0.8531 - val_loss: 0.2166 - val_accuracy: 0.8736\n",
      "Epoch 3/10\n",
      "392/938 [===========>..................] - ETA: 8s - loss: 0.3507 - accuracy: 0.8553\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_172 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_173 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_174 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_171 (Reshape)          (None, 45, 8)        0           ['input_172[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_172 (Reshape)          (None, 45, 8)        0           ['input_173[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_173 (Reshape)          (None, 45, 11)       0           ['input_174[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_228 (Mult  (None, 45, 8)       2248        ['reshape_171[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_171[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_229 (Mult  (None, 45, 8)       2248        ['reshape_172[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_172[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_230 (Mult  (None, 45, 11)      4147        ['reshape_173[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_173[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_228 (Layer  (None, 45, 8)       16          ['multi_head_attention_228[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_229 (Layer  (None, 45, 8)       16          ['multi_head_attention_229[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_230 (Layer  (None, 45, 11)      22          ['multi_head_attention_230[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_342 (Dropout)          (None, 45, 8)        0           ['layer_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " dropout_343 (Dropout)          (None, 45, 8)        0           ['layer_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " dropout_344 (Dropout)          (None, 45, 11)       0           ['layer_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_57 (Concatenate)   (None, 45, 27)       0           ['dropout_342[0][0]',            \n",
      "                                                                  'dropout_343[0][0]',            \n",
      "                                                                  'dropout_344[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_57 (G  (None, 27)          0           ['concatenate_57[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_345 (Dropout)          (None, 27)           0           ['global_average_pooling1d_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_57 (TFOpLambda)  (None, 1, 27)       0           ['dropout_345[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_231 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_57[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_57[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_57 (TFOpL  (None, 27)          0           ['multi_head_attention_231[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_231 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_57[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_346 (Dropout)          (None, 27)           0           ['layer_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " dense_171 (Dense)              (None, 1024)         28672       ['dropout_346[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_347 (Dropout)          (None, 1024)         0           ['dense_171[0][0]']              \n",
      "                                                                                                  \n",
      " dense_172 (Dense)              (None, 128)          131200      ['dropout_347[0][0]']            \n",
      "                                                                                                  \n",
      " dense_173 (Dense)              (None, 1)            129         ['dense_172[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5760 - accuracy: 0.7044 - val_loss: 0.4923 - val_accuracy: 0.7584\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.5041 - accuracy: 0.7648 - val_loss: 0.3989 - val_accuracy: 0.8043\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4830 - accuracy: 0.7754 - val_loss: 0.4330 - val_accuracy: 0.7744\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4697 - accuracy: 0.7833 - val_loss: 0.3312 - val_accuracy: 0.8093\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.4595 - accuracy: 0.7870 - val_loss: 0.3574 - val_accuracy: 0.8091\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4570 - accuracy: 0.7901 - val_loss: 0.4167 - val_accuracy: 0.7730\n",
      "Epoch 7/10\n",
      "806/938 [========================>.....] - ETA: 2s - loss: 0.4515 - accuracy: 0.7925\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_175 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_176 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_177 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_174 (Reshape)          (None, 45, 8)        0           ['input_175[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_175 (Reshape)          (None, 45, 8)        0           ['input_176[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_176 (Reshape)          (None, 45, 11)       0           ['input_177[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_232 (Mult  (None, 45, 8)       2248        ['reshape_174[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_174[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_233 (Mult  (None, 45, 8)       2248        ['reshape_175[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_175[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_234 (Mult  (None, 45, 11)      4147        ['reshape_176[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_176[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_232 (Layer  (None, 45, 8)       16          ['multi_head_attention_232[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_233 (Layer  (None, 45, 8)       16          ['multi_head_attention_233[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_234 (Layer  (None, 45, 11)      22          ['multi_head_attention_234[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_348 (Dropout)          (None, 45, 8)        0           ['layer_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " dropout_349 (Dropout)          (None, 45, 8)        0           ['layer_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " dropout_350 (Dropout)          (None, 45, 11)       0           ['layer_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_58 (Concatenate)   (None, 45, 27)       0           ['dropout_348[0][0]',            \n",
      "                                                                  'dropout_349[0][0]',            \n",
      "                                                                  'dropout_350[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_58 (G  (None, 27)          0           ['concatenate_58[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_351 (Dropout)          (None, 27)           0           ['global_average_pooling1d_58[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_58 (TFOpLambda)  (None, 1, 27)       0           ['dropout_351[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_235 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_58[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_58[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_58 (TFOpL  (None, 27)          0           ['multi_head_attention_235[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_235 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_58[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_352 (Dropout)          (None, 27)           0           ['layer_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " dense_174 (Dense)              (None, 1024)         28672       ['dropout_352[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_353 (Dropout)          (None, 1024)         0           ['dense_174[0][0]']              \n",
      "                                                                                                  \n",
      " dense_175 (Dense)              (None, 128)          131200      ['dropout_353[0][0]']            \n",
      "                                                                                                  \n",
      " dense_176 (Dense)              (None, 1)            129         ['dense_175[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5481 - accuracy: 0.7146 - val_loss: 0.3604 - val_accuracy: 0.7214\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4294 - accuracy: 0.7871 - val_loss: 0.3469 - val_accuracy: 0.7219\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4034 - accuracy: 0.8050 - val_loss: 0.3588 - val_accuracy: 0.7601\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3704 - accuracy: 0.8249 - val_loss: 0.2799 - val_accuracy: 0.8827\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3507 - accuracy: 0.8366 - val_loss: 0.3790 - val_accuracy: 0.8203\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3915 - accuracy: 0.8337 - val_loss: 0.1478 - val_accuracy: 0.9603\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2466 - accuracy: 0.9263 - val_loss: 0.2520 - val_accuracy: 0.9159\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2339 - accuracy: 0.9321 - val_loss: 0.1540 - val_accuracy: 0.9668\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2280 - accuracy: 0.9334 - val_loss: 0.1583 - val_accuracy: 0.9694\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2217 - accuracy: 0.9348 - val_loss: 0.1255 - val_accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.2193 - accuracy: 0.9334 - val_loss: 0.1255 - val_accuracy: 0.9744\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.5041 - accuracy: 0.7674 - val_loss: 0.4847 - val_accuracy: 0.7422\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4279 - accuracy: 0.8231 - val_loss: 0.3742 - val_accuracy: 0.8065\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3903 - accuracy: 0.8384 - val_loss: 0.3432 - val_accuracy: 0.8545\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3827 - accuracy: 0.8384 - val_loss: 0.3180 - val_accuracy: 0.8573\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3793 - accuracy: 0.8416 - val_loss: 0.3745 - val_accuracy: 0.8332\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3734 - accuracy: 0.8428 - val_loss: 0.2936 - val_accuracy: 0.8843\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2732 - accuracy: 0.8837 - val_loss: 0.2320 - val_accuracy: 0.8332\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2348 - accuracy: 0.9025 - val_loss: 0.2205 - val_accuracy: 0.8808\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1892 - accuracy: 0.9274 - val_loss: 0.1875 - val_accuracy: 0.9099\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1562 - accuracy: 0.9420 - val_loss: 0.1791 - val_accuracy: 0.9209\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1481 - accuracy: 0.9486 - val_loss: 0.1039 - val_accuracy: 0.9405\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1306 - accuracy: 0.9542 - val_loss: 0.1357 - val_accuracy: 0.9369\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2177 - accuracy: 0.9143 - val_loss: 0.2186 - val_accuracy: 0.9197\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2061 - accuracy: 0.9207 - val_loss: 0.1288 - val_accuracy: 0.9615\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1971 - accuracy: 0.9229 - val_loss: 0.1889 - val_accuracy: 0.9243\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1811 - accuracy: 0.9297 - val_loss: 0.1419 - val_accuracy: 0.9493\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1591 - accuracy: 0.9409 - val_loss: 0.1074 - val_accuracy: 0.9529\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1481 - accuracy: 0.9464 - val_loss: 0.0882 - val_accuracy: 0.9675\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1918 - accuracy: 0.9397 - val_loss: 0.1473 - val_accuracy: 0.9505\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1867 - accuracy: 0.9430 - val_loss: 0.1504 - val_accuracy: 0.9481\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1874 - accuracy: 0.9416 - val_loss: 0.1464 - val_accuracy: 0.9491\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1810 - accuracy: 0.9432 - val_loss: 0.1565 - val_accuracy: 0.9489\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1836 - accuracy: 0.9429 - val_loss: 0.1553 - val_accuracy: 0.9496\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_64\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_193 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_194 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_195 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_192 (Reshape)          (None, 45, 8)        0           ['input_193[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_193 (Reshape)          (None, 45, 8)        0           ['input_194[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_194 (Reshape)          (None, 45, 11)       0           ['input_195[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_256 (Mult  (None, 45, 8)       2248        ['reshape_192[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_192[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_257 (Mult  (None, 45, 8)       2248        ['reshape_193[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_193[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_258 (Mult  (None, 45, 11)      4147        ['reshape_194[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_194[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_256 (Layer  (None, 45, 8)       16          ['multi_head_attention_256[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_257 (Layer  (None, 45, 8)       16          ['multi_head_attention_257[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_258 (Layer  (None, 45, 11)      22          ['multi_head_attention_258[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_384 (Dropout)          (None, 45, 8)        0           ['layer_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " dropout_385 (Dropout)          (None, 45, 8)        0           ['layer_normalization_257[0][0]']\n",
      "                                                                                                  \n",
      " dropout_386 (Dropout)          (None, 45, 11)       0           ['layer_normalization_258[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_64 (Concatenate)   (None, 45, 27)       0           ['dropout_384[0][0]',            \n",
      "                                                                  'dropout_385[0][0]',            \n",
      "                                                                  'dropout_386[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_64 (G  (None, 27)          0           ['concatenate_64[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_387 (Dropout)          (None, 27)           0           ['global_average_pooling1d_64[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_64 (TFOpLambda)  (None, 1, 27)       0           ['dropout_387[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_259 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_64[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_64[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_64 (TFOpL  (None, 27)          0           ['multi_head_attention_259[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_259 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_64[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_388 (Dropout)          (None, 27)           0           ['layer_normalization_259[0][0]']\n",
      "                                                                                                  \n",
      " dense_192 (Dense)              (None, 1024)         28672       ['dropout_388[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_389 (Dropout)          (None, 1024)         0           ['dense_192[0][0]']              \n",
      "                                                                                                  \n",
      " dense_193 (Dense)              (None, 128)          131200      ['dropout_389[0][0]']            \n",
      "                                                                                                  \n",
      " dense_194 (Dense)              (None, 1)            129         ['dense_193[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 16ms/step - loss: 0.4704 - accuracy: 0.7764 - val_loss: 0.2853 - val_accuracy: 0.8119\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3800 - accuracy: 0.8403 - val_loss: 0.2247 - val_accuracy: 0.8628\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3164 - accuracy: 0.8709 - val_loss: 0.2985 - val_accuracy: 0.8643\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3139 - accuracy: 0.8719 - val_loss: 0.3210 - val_accuracy: 0.8497\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3080 - accuracy: 0.8736 - val_loss: 0.2210 - val_accuracy: 0.8963\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3011 - accuracy: 0.8780 - val_loss: 0.2255 - val_accuracy: 0.8829\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 8 19930\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_65\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_196 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_197 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_198 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_195 (Reshape)          (None, 45, 8)        0           ['input_196[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_196 (Reshape)          (None, 45, 8)        0           ['input_197[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_197 (Reshape)          (None, 45, 11)       0           ['input_198[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_260 (Mult  (None, 45, 8)       2248        ['reshape_195[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_195[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_261 (Mult  (None, 45, 8)       2248        ['reshape_196[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_196[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_262 (Mult  (None, 45, 11)      4147        ['reshape_197[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_197[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_260 (Layer  (None, 45, 8)       16          ['multi_head_attention_260[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_261 (Layer  (None, 45, 8)       16          ['multi_head_attention_261[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_262 (Layer  (None, 45, 11)      22          ['multi_head_attention_262[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_390 (Dropout)          (None, 45, 8)        0           ['layer_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " dropout_391 (Dropout)          (None, 45, 8)        0           ['layer_normalization_261[0][0]']\n",
      "                                                                                                  \n",
      " dropout_392 (Dropout)          (None, 45, 11)       0           ['layer_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_65 (Concatenate)   (None, 45, 27)       0           ['dropout_390[0][0]',            \n",
      "                                                                  'dropout_391[0][0]',            \n",
      "                                                                  'dropout_392[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_65 (G  (None, 27)          0           ['concatenate_65[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_393 (Dropout)          (None, 27)           0           ['global_average_pooling1d_65[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_65 (TFOpLambda)  (None, 1, 27)       0           ['dropout_393[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_263 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_65[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_65[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_65 (TFOpL  (None, 27)          0           ['multi_head_attention_263[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_263 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_65[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_394 (Dropout)          (None, 27)           0           ['layer_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " dense_195 (Dense)              (None, 1024)         28672       ['dropout_394[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_395 (Dropout)          (None, 1024)         0           ['dense_195[0][0]']              \n",
      "                                                                                                  \n",
      " dense_196 (Dense)              (None, 128)          131200      ['dropout_395[0][0]']            \n",
      "                                                                                                  \n",
      " dense_197 (Dense)              (None, 1)            129         ['dense_196[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.6007 - accuracy: 0.6611 - val_loss: 0.5993 - val_accuracy: 0.6731\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.5137 - accuracy: 0.7563 - val_loss: 0.5135 - val_accuracy: 0.6863\n",
      "Epoch 3/10\n",
      " 65/938 [=>............................] - ETA: 12s - loss: 0.4912 - accuracy: 0.7659\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_66\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_199 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_200 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_201 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_198 (Reshape)          (None, 45, 8)        0           ['input_199[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_199 (Reshape)          (None, 45, 8)        0           ['input_200[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_200 (Reshape)          (None, 45, 11)       0           ['input_201[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_264 (Mult  (None, 45, 8)       2248        ['reshape_198[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_198[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_265 (Mult  (None, 45, 8)       2248        ['reshape_199[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_199[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_266 (Mult  (None, 45, 11)      4147        ['reshape_200[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_200[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_264 (Layer  (None, 45, 8)       16          ['multi_head_attention_264[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_265 (Layer  (None, 45, 8)       16          ['multi_head_attention_265[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_266 (Layer  (None, 45, 11)      22          ['multi_head_attention_266[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_396 (Dropout)          (None, 45, 8)        0           ['layer_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " dropout_397 (Dropout)          (None, 45, 8)        0           ['layer_normalization_265[0][0]']\n",
      "                                                                                                  \n",
      " dropout_398 (Dropout)          (None, 45, 11)       0           ['layer_normalization_266[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_66 (Concatenate)   (None, 45, 27)       0           ['dropout_396[0][0]',            \n",
      "                                                                  'dropout_397[0][0]',            \n",
      "                                                                  'dropout_398[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_66 (G  (None, 27)          0           ['concatenate_66[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_399 (Dropout)          (None, 27)           0           ['global_average_pooling1d_66[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_66 (TFOpLambda)  (None, 1, 27)       0           ['dropout_399[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_267 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_66[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_66[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_66 (TFOpL  (None, 27)          0           ['multi_head_attention_267[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_267 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_66[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_400 (Dropout)          (None, 27)           0           ['layer_normalization_267[0][0]']\n",
      "                                                                                                  \n",
      " dense_198 (Dense)              (None, 1024)         28672       ['dropout_400[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_401 (Dropout)          (None, 1024)         0           ['dense_198[0][0]']              \n",
      "                                                                                                  \n",
      " dense_199 (Dense)              (None, 128)          131200      ['dropout_401[0][0]']            \n",
      "                                                                                                  \n",
      " dense_200 (Dense)              (None, 1)            129         ['dense_199[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5421 - accuracy: 0.7231 - val_loss: 0.3866 - val_accuracy: 0.7505\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4070 - accuracy: 0.8049 - val_loss: 0.3943 - val_accuracy: 0.7178\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3715 - accuracy: 0.8229 - val_loss: 0.2878 - val_accuracy: 0.8203\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3494 - accuracy: 0.8318 - val_loss: 0.2930 - val_accuracy: 0.8504\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3373 - accuracy: 0.8409 - val_loss: 0.3801 - val_accuracy: 0.7888\n",
      "Epoch 6/10\n",
      "200/938 [=====>........................] - ETA: 10s - loss: 0.3321 - accuracy: 0.8411\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_67\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_202 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_203 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_204 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_201 (Reshape)          (None, 45, 8)        0           ['input_202[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_202 (Reshape)          (None, 45, 8)        0           ['input_203[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_203 (Reshape)          (None, 45, 11)       0           ['input_204[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_268 (Mult  (None, 45, 8)       2248        ['reshape_201[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_201[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_269 (Mult  (None, 45, 8)       2248        ['reshape_202[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_202[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_270 (Mult  (None, 45, 11)      4147        ['reshape_203[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_203[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_268 (Layer  (None, 45, 8)       16          ['multi_head_attention_268[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_269 (Layer  (None, 45, 8)       16          ['multi_head_attention_269[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_270 (Layer  (None, 45, 11)      22          ['multi_head_attention_270[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_402 (Dropout)          (None, 45, 8)        0           ['layer_normalization_268[0][0]']\n",
      "                                                                                                  \n",
      " dropout_403 (Dropout)          (None, 45, 8)        0           ['layer_normalization_269[0][0]']\n",
      "                                                                                                  \n",
      " dropout_404 (Dropout)          (None, 45, 11)       0           ['layer_normalization_270[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_67 (Concatenate)   (None, 45, 27)       0           ['dropout_402[0][0]',            \n",
      "                                                                  'dropout_403[0][0]',            \n",
      "                                                                  'dropout_404[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_67 (G  (None, 27)          0           ['concatenate_67[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_405 (Dropout)          (None, 27)           0           ['global_average_pooling1d_67[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_67 (TFOpLambda)  (None, 1, 27)       0           ['dropout_405[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_271 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_67[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_67[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_67 (TFOpL  (None, 27)          0           ['multi_head_attention_271[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_271 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_67[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_406 (Dropout)          (None, 27)           0           ['layer_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " dense_201 (Dense)              (None, 1024)         28672       ['dropout_406[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_407 (Dropout)          (None, 1024)         0           ['dense_201[0][0]']              \n",
      "                                                                                                  \n",
      " dense_202 (Dense)              (None, 128)          131200      ['dropout_407[0][0]']            \n",
      "                                                                                                  \n",
      " dense_203 (Dense)              (None, 1)            129         ['dense_202[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3802 - accuracy: 0.8440 - val_loss: 0.2429 - val_accuracy: 0.9441\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2420 - accuracy: 0.9279 - val_loss: 0.1585 - val_accuracy: 0.9654\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2256 - accuracy: 0.9338 - val_loss: 0.1379 - val_accuracy: 0.9673\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2209 - accuracy: 0.9341 - val_loss: 0.1350 - val_accuracy: 0.9685\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2185 - accuracy: 0.9358 - val_loss: 0.1909 - val_accuracy: 0.9670\n",
      "Epoch 6/10\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_68\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_205 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_206 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_207 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_204 (Reshape)          (None, 45, 8)        0           ['input_205[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_205 (Reshape)          (None, 45, 8)        0           ['input_206[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_206 (Reshape)          (None, 45, 11)       0           ['input_207[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_272 (Mult  (None, 45, 8)       2248        ['reshape_204[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_204[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_273 (Mult  (None, 45, 8)       2248        ['reshape_205[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_205[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_274 (Mult  (None, 45, 11)      4147        ['reshape_206[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_206[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_272 (Layer  (None, 45, 8)       16          ['multi_head_attention_272[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_273 (Layer  (None, 45, 8)       16          ['multi_head_attention_273[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_274 (Layer  (None, 45, 11)      22          ['multi_head_attention_274[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_408 (Dropout)          (None, 45, 8)        0           ['layer_normalization_272[0][0]']\n",
      "                                                                                                  \n",
      " dropout_409 (Dropout)          (None, 45, 8)        0           ['layer_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " dropout_410 (Dropout)          (None, 45, 11)       0           ['layer_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_68 (Concatenate)   (None, 45, 27)       0           ['dropout_408[0][0]',            \n",
      "                                                                  'dropout_409[0][0]',            \n",
      "                                                                  'dropout_410[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_68 (G  (None, 27)          0           ['concatenate_68[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_411 (Dropout)          (None, 27)           0           ['global_average_pooling1d_68[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_68 (TFOpLambda)  (None, 1, 27)       0           ['dropout_411[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_275 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_68[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_68[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_68 (TFOpL  (None, 27)          0           ['multi_head_attention_275[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_275 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_68[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_412 (Dropout)          (None, 27)           0           ['layer_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " dense_204 (Dense)              (None, 1024)         28672       ['dropout_412[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_413 (Dropout)          (None, 1024)         0           ['dense_204[0][0]']              \n",
      "                                                                                                  \n",
      " dense_205 (Dense)              (None, 128)          131200      ['dropout_413[0][0]']            \n",
      "                                                                                                  \n",
      " dense_206 (Dense)              (None, 1)            129         ['dense_205[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4956 - accuracy: 0.7795 - val_loss: 0.4847 - val_accuracy: 0.8029\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4163 - accuracy: 0.8265 - val_loss: 0.4300 - val_accuracy: 0.7940\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3931 - accuracy: 0.8320 - val_loss: 0.2889 - val_accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3863 - accuracy: 0.8364 - val_loss: 0.4223 - val_accuracy: 0.8454\n",
      "Epoch 5/10\n",
      "845/938 [==========================>...] - ETA: 1s - loss: 0.3824 - accuracy: 0.8395\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_69\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_208 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_209 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_210 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_207 (Reshape)          (None, 45, 8)        0           ['input_208[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_208 (Reshape)          (None, 45, 8)        0           ['input_209[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_209 (Reshape)          (None, 45, 11)       0           ['input_210[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_276 (Mult  (None, 45, 8)       2248        ['reshape_207[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_207[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_277 (Mult  (None, 45, 8)       2248        ['reshape_208[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_208[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_278 (Mult  (None, 45, 11)      4147        ['reshape_209[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_209[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_276 (Layer  (None, 45, 8)       16          ['multi_head_attention_276[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_277 (Layer  (None, 45, 8)       16          ['multi_head_attention_277[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_278 (Layer  (None, 45, 11)      22          ['multi_head_attention_278[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_414 (Dropout)          (None, 45, 8)        0           ['layer_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " dropout_415 (Dropout)          (None, 45, 8)        0           ['layer_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " dropout_416 (Dropout)          (None, 45, 11)       0           ['layer_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_69 (Concatenate)   (None, 45, 27)       0           ['dropout_414[0][0]',            \n",
      "                                                                  'dropout_415[0][0]',            \n",
      "                                                                  'dropout_416[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_69 (G  (None, 27)          0           ['concatenate_69[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_417 (Dropout)          (None, 27)           0           ['global_average_pooling1d_69[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_69 (TFOpLambda)  (None, 1, 27)       0           ['dropout_417[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_279 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_69[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_69[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_69 (TFOpL  (None, 27)          0           ['multi_head_attention_279[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_279 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_69[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_418 (Dropout)          (None, 27)           0           ['layer_normalization_279[0][0]']\n",
      "                                                                                                  \n",
      " dense_207 (Dense)              (None, 1024)         28672       ['dropout_418[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_419 (Dropout)          (None, 1024)         0           ['dense_207[0][0]']              \n",
      "                                                                                                  \n",
      " dense_208 (Dense)              (None, 128)          131200      ['dropout_419[0][0]']            \n",
      "                                                                                                  \n",
      " dense_209 (Dense)              (None, 1)            129         ['dense_208[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4127 - accuracy: 0.7862 - val_loss: 0.1798 - val_accuracy: 0.8669\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2831 - accuracy: 0.8777 - val_loss: 0.2300 - val_accuracy: 0.7904\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2348 - accuracy: 0.9032 - val_loss: 0.1456 - val_accuracy: 0.9238\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1844 - accuracy: 0.9290 - val_loss: 0.1016 - val_accuracy: 0.9484\n",
      "Epoch 5/10\n",
      "831/938 [=========================>....] - ETA: 1s - loss: 0.1544 - accuracy: 0.9430TRAIN pc 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_70\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_211 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_212 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_213 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_210 (Reshape)          (None, 45, 8)        0           ['input_211[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_211 (Reshape)          (None, 45, 8)        0           ['input_212[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_212 (Reshape)          (None, 45, 11)       0           ['input_213[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_280 (Mult  (None, 45, 8)       2248        ['reshape_210[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_210[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_281 (Mult  (None, 45, 8)       2248        ['reshape_211[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_211[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_282 (Mult  (None, 45, 11)      4147        ['reshape_212[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_212[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_280 (Layer  (None, 45, 8)       16          ['multi_head_attention_280[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_281 (Layer  (None, 45, 8)       16          ['multi_head_attention_281[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_282 (Layer  (None, 45, 11)      22          ['multi_head_attention_282[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_420 (Dropout)          (None, 45, 8)        0           ['layer_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " dropout_421 (Dropout)          (None, 45, 8)        0           ['layer_normalization_281[0][0]']\n",
      "                                                                                                  \n",
      " dropout_422 (Dropout)          (None, 45, 11)       0           ['layer_normalization_282[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_70 (Concatenate)   (None, 45, 27)       0           ['dropout_420[0][0]',            \n",
      "                                                                  'dropout_421[0][0]',            \n",
      "                                                                  'dropout_422[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_70 (G  (None, 27)          0           ['concatenate_70[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_423 (Dropout)          (None, 27)           0           ['global_average_pooling1d_70[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_70 (TFOpLambda)  (None, 1, 27)       0           ['dropout_423[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_283 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_70[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_70[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_70 (TFOpL  (None, 27)          0           ['multi_head_attention_283[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_283 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_70[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_424 (Dropout)          (None, 27)           0           ['layer_normalization_283[0][0]']\n",
      "                                                                                                  \n",
      " dense_210 (Dense)              (None, 1024)         28672       ['dropout_424[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_425 (Dropout)          (None, 1024)         0           ['dense_210[0][0]']              \n",
      "                                                                                                  \n",
      " dense_211 (Dense)              (None, 128)          131200      ['dropout_425[0][0]']            \n",
      "                                                                                                  \n",
      " dense_212 (Dense)              (None, 1)            129         ['dense_211[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3909 - accuracy: 0.8159 - val_loss: 0.5291 - val_accuracy: 0.5744\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3133 - accuracy: 0.8582 - val_loss: 0.4570 - val_accuracy: 0.8354\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2306 - accuracy: 0.9120 - val_loss: 0.3497 - val_accuracy: 0.8545\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2141 - accuracy: 0.9202 - val_loss: 0.3580 - val_accuracy: 0.8836\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1999 - accuracy: 0.9289 - val_loss: 0.2549 - val_accuracy: 0.9312\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3621 - accuracy: 0.8525 - val_loss: 0.1985 - val_accuracy: 0.9415\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2439 - accuracy: 0.9164 - val_loss: 0.1983 - val_accuracy: 0.9271\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2085 - accuracy: 0.9355 - val_loss: 0.1344 - val_accuracy: 0.9611\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1989 - accuracy: 0.9377 - val_loss: 0.1293 - val_accuracy: 0.9608\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1949 - accuracy: 0.9384 - val_loss: 0.1258 - val_accuracy: 0.9639\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3745 - accuracy: 0.8403 - val_loss: 0.3349 - val_accuracy: 0.7599\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3483 - accuracy: 0.8566 - val_loss: 0.2663 - val_accuracy: 0.8824\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3262 - accuracy: 0.8655 - val_loss: 0.2797 - val_accuracy: 0.8774\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3183 - accuracy: 0.8709 - val_loss: 0.2925 - val_accuracy: 0.8552\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3162 - accuracy: 0.8728 - val_loss: 0.2684 - val_accuracy: 0.8765\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3118 - accuracy: 0.8732 - val_loss: 0.3811 - val_accuracy: 0.8466\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4673 - accuracy: 0.7895 - val_loss: 0.3966 - val_accuracy: 0.7943\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4633 - accuracy: 0.7918 - val_loss: 0.3462 - val_accuracy: 0.8487\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.4523 - accuracy: 0.7947 - val_loss: 0.3408 - val_accuracy: 0.8392\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4475 - accuracy: 0.7993 - val_loss: 0.3891 - val_accuracy: 0.8076\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4436 - accuracy: 0.8013 - val_loss: 0.4204 - val_accuracy: 0.7790\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4413 - accuracy: 0.8012 - val_loss: 0.2900 - val_accuracy: 0.8473\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3306 - accuracy: 0.8459 - val_loss: 0.2166 - val_accuracy: 0.9259\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3234 - accuracy: 0.8526 - val_loss: 0.1925 - val_accuracy: 0.9350\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3183 - accuracy: 0.8540 - val_loss: 0.1709 - val_accuracy: 0.9348\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3136 - accuracy: 0.8585 - val_loss: 0.1893 - val_accuracy: 0.9264\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_75\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_226 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_227 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_228 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_225 (Reshape)          (None, 45, 8)        0           ['input_226[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_226 (Reshape)          (None, 45, 8)        0           ['input_227[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_227 (Reshape)          (None, 45, 11)       0           ['input_228[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_300 (Mult  (None, 45, 8)       2248        ['reshape_225[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_225[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_301 (Mult  (None, 45, 8)       2248        ['reshape_226[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_226[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_302 (Mult  (None, 45, 11)      4147        ['reshape_227[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_227[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_300 (Layer  (None, 45, 8)       16          ['multi_head_attention_300[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_301 (Layer  (None, 45, 8)       16          ['multi_head_attention_301[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_302 (Layer  (None, 45, 11)      22          ['multi_head_attention_302[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_450 (Dropout)          (None, 45, 8)        0           ['layer_normalization_300[0][0]']\n",
      "                                                                                                  \n",
      " dropout_451 (Dropout)          (None, 45, 8)        0           ['layer_normalization_301[0][0]']\n",
      "                                                                                                  \n",
      " dropout_452 (Dropout)          (None, 45, 11)       0           ['layer_normalization_302[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_75 (Concatenate)   (None, 45, 27)       0           ['dropout_450[0][0]',            \n",
      "                                                                  'dropout_451[0][0]',            \n",
      "                                                                  'dropout_452[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_75 (G  (None, 27)          0           ['concatenate_75[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_453 (Dropout)          (None, 27)           0           ['global_average_pooling1d_75[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_75 (TFOpLambda)  (None, 1, 27)       0           ['dropout_453[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_303 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_75[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_75[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_75 (TFOpL  (None, 27)          0           ['multi_head_attention_303[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_303 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_75[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_454 (Dropout)          (None, 27)           0           ['layer_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " dense_225 (Dense)              (None, 1024)         28672       ['dropout_454[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_455 (Dropout)          (None, 1024)         0           ['dense_225[0][0]']              \n",
      "                                                                                                  \n",
      " dense_226 (Dense)              (None, 128)          131200      ['dropout_455[0][0]']            \n",
      "                                                                                                  \n",
      " dense_227 (Dense)              (None, 1)            129         ['dense_226[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.3875 - accuracy: 0.8429 - val_loss: 0.1923 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2085 - accuracy: 0.9382 - val_loss: 0.1017 - val_accuracy: 0.9756\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2037 - accuracy: 0.9406 - val_loss: 0.1087 - val_accuracy: 0.9768\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2023 - accuracy: 0.9405 - val_loss: 0.1116 - val_accuracy: 0.9761\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_76\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_229 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_230 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_231 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_228 (Reshape)          (None, 45, 8)        0           ['input_229[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_229 (Reshape)          (None, 45, 8)        0           ['input_230[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_230 (Reshape)          (None, 45, 11)       0           ['input_231[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_304 (Mult  (None, 45, 8)       2248        ['reshape_228[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_228[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_305 (Mult  (None, 45, 8)       2248        ['reshape_229[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_229[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_306 (Mult  (None, 45, 11)      4147        ['reshape_230[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_230[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_304 (Layer  (None, 45, 8)       16          ['multi_head_attention_304[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_305 (Layer  (None, 45, 8)       16          ['multi_head_attention_305[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_306 (Layer  (None, 45, 11)      22          ['multi_head_attention_306[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_456 (Dropout)          (None, 45, 8)        0           ['layer_normalization_304[0][0]']\n",
      "                                                                                                  \n",
      " dropout_457 (Dropout)          (None, 45, 8)        0           ['layer_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      " dropout_458 (Dropout)          (None, 45, 11)       0           ['layer_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_76 (Concatenate)   (None, 45, 27)       0           ['dropout_456[0][0]',            \n",
      "                                                                  'dropout_457[0][0]',            \n",
      "                                                                  'dropout_458[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_76 (G  (None, 27)          0           ['concatenate_76[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_459 (Dropout)          (None, 27)           0           ['global_average_pooling1d_76[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_76 (TFOpLambda)  (None, 1, 27)       0           ['dropout_459[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_307 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_76[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_76[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_76 (TFOpL  (None, 27)          0           ['multi_head_attention_307[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_307 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_76[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_460 (Dropout)          (None, 27)           0           ['layer_normalization_307[0][0]']\n",
      "                                                                                                  \n",
      " dense_228 (Dense)              (None, 1024)         28672       ['dropout_460[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_461 (Dropout)          (None, 1024)         0           ['dense_228[0][0]']              \n",
      "                                                                                                  \n",
      " dense_229 (Dense)              (None, 128)          131200      ['dropout_461[0][0]']            \n",
      "                                                                                                  \n",
      " dense_230 (Dense)              (None, 1)            129         ['dense_229[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4838 - accuracy: 0.7834 - val_loss: 0.2876 - val_accuracy: 0.8554\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4130 - accuracy: 0.8307 - val_loss: 0.1993 - val_accuracy: 0.8884\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.3992 - accuracy: 0.8357 - val_loss: 0.2690 - val_accuracy: 0.8982\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3907 - accuracy: 0.8379 - val_loss: 0.2962 - val_accuracy: 0.8863\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3734 - accuracy: 0.8429 - val_loss: 0.2203 - val_accuracy: 0.9018\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3669 - accuracy: 0.8460 - val_loss: 0.2075 - val_accuracy: 0.9030\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_77\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_232 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_233 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_234 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_231 (Reshape)          (None, 45, 8)        0           ['input_232[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_232 (Reshape)          (None, 45, 8)        0           ['input_233[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_233 (Reshape)          (None, 45, 11)       0           ['input_234[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_308 (Mult  (None, 45, 8)       2248        ['reshape_231[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_231[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_309 (Mult  (None, 45, 8)       2248        ['reshape_232[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_232[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_310 (Mult  (None, 45, 11)      4147        ['reshape_233[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_233[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_308 (Layer  (None, 45, 8)       16          ['multi_head_attention_308[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_309 (Layer  (None, 45, 8)       16          ['multi_head_attention_309[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_310 (Layer  (None, 45, 11)      22          ['multi_head_attention_310[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_462 (Dropout)          (None, 45, 8)        0           ['layer_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " dropout_463 (Dropout)          (None, 45, 8)        0           ['layer_normalization_309[0][0]']\n",
      "                                                                                                  \n",
      " dropout_464 (Dropout)          (None, 45, 11)       0           ['layer_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_77 (Concatenate)   (None, 45, 27)       0           ['dropout_462[0][0]',            \n",
      "                                                                  'dropout_463[0][0]',            \n",
      "                                                                  'dropout_464[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_77 (G  (None, 27)          0           ['concatenate_77[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_465 (Dropout)          (None, 27)           0           ['global_average_pooling1d_77[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_77 (TFOpLambda)  (None, 1, 27)       0           ['dropout_465[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_311 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_77[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_77[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_77 (TFOpL  (None, 27)          0           ['multi_head_attention_311[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_311 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_77[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_466 (Dropout)          (None, 27)           0           ['layer_normalization_311[0][0]']\n",
      "                                                                                                  \n",
      " dense_231 (Dense)              (None, 1024)         28672       ['dropout_466[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_467 (Dropout)          (None, 1024)         0           ['dense_231[0][0]']              \n",
      "                                                                                                  \n",
      " dense_232 (Dense)              (None, 128)          131200      ['dropout_467[0][0]']            \n",
      "                                                                                                  \n",
      " dense_233 (Dense)              (None, 1)            129         ['dense_232[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3801 - accuracy: 0.8123 - val_loss: 0.2156 - val_accuracy: 0.8662\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2653 - accuracy: 0.8886 - val_loss: 0.2263 - val_accuracy: 0.9056\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2343 - accuracy: 0.9028 - val_loss: 0.1810 - val_accuracy: 0.9288\n",
      "Epoch 4/10\n",
      "116/938 [==>...........................] - ETA: 11s - loss: 0.2119 - accuracy: 0.9168TRAIN pc 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_78\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_235 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_236 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_237 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_234 (Reshape)          (None, 45, 8)        0           ['input_235[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_235 (Reshape)          (None, 45, 8)        0           ['input_236[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_236 (Reshape)          (None, 45, 11)       0           ['input_237[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_312 (Mult  (None, 45, 8)       2248        ['reshape_234[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_234[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_313 (Mult  (None, 45, 8)       2248        ['reshape_235[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_235[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_314 (Mult  (None, 45, 11)      4147        ['reshape_236[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_236[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_312 (Layer  (None, 45, 8)       16          ['multi_head_attention_312[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_313 (Layer  (None, 45, 8)       16          ['multi_head_attention_313[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_314 (Layer  (None, 45, 11)      22          ['multi_head_attention_314[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_468 (Dropout)          (None, 45, 8)        0           ['layer_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " dropout_469 (Dropout)          (None, 45, 8)        0           ['layer_normalization_313[0][0]']\n",
      "                                                                                                  \n",
      " dropout_470 (Dropout)          (None, 45, 11)       0           ['layer_normalization_314[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_78 (Concatenate)   (None, 45, 27)       0           ['dropout_468[0][0]',            \n",
      "                                                                  'dropout_469[0][0]',            \n",
      "                                                                  'dropout_470[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_78 (G  (None, 27)          0           ['concatenate_78[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_471 (Dropout)          (None, 27)           0           ['global_average_pooling1d_78[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_78 (TFOpLambda)  (None, 1, 27)       0           ['dropout_471[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_315 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_78[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_78[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_78 (TFOpL  (None, 27)          0           ['multi_head_attention_315[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_315 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_78[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_472 (Dropout)          (None, 27)           0           ['layer_normalization_315[0][0]']\n",
      "                                                                                                  \n",
      " dense_234 (Dense)              (None, 1024)         28672       ['dropout_472[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_473 (Dropout)          (None, 1024)         0           ['dense_234[0][0]']              \n",
      "                                                                                                  \n",
      " dense_235 (Dense)              (None, 128)          131200      ['dropout_473[0][0]']            \n",
      "                                                                                                  \n",
      " dense_236 (Dense)              (None, 1)            129         ['dense_235[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3734 - accuracy: 0.8189 - val_loss: 0.2853 - val_accuracy: 0.9465\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2908 - accuracy: 0.8650 - val_loss: 0.2556 - val_accuracy: 0.9061\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2329 - accuracy: 0.9045 - val_loss: 0.1847 - val_accuracy: 0.9510\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2142 - accuracy: 0.9144 - val_loss: 0.1817 - val_accuracy: 0.9470\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3557 - accuracy: 0.8596 - val_loss: 0.2271 - val_accuracy: 0.9259\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2480 - accuracy: 0.9188 - val_loss: 0.1510 - val_accuracy: 0.9510\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2100 - accuracy: 0.9365 - val_loss: 0.1388 - val_accuracy: 0.9541\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2016 - accuracy: 0.9367 - val_loss: 0.1226 - val_accuracy: 0.9556\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1985 - accuracy: 0.9375 - val_loss: 0.1289 - val_accuracy: 0.9558\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3413 - accuracy: 0.8628 - val_loss: 0.2238 - val_accuracy: 0.8975\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3270 - accuracy: 0.8677 - val_loss: 0.2253 - val_accuracy: 0.9061\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3152 - accuracy: 0.8724 - val_loss: 0.2343 - val_accuracy: 0.8867\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3140 - accuracy: 0.8728 - val_loss: 0.2657 - val_accuracy: 0.8820\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3068 - accuracy: 0.8742 - val_loss: 0.2158 - val_accuracy: 0.9016\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4748 - accuracy: 0.7779 - val_loss: 0.3266 - val_accuracy: 0.8440\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4708 - accuracy: 0.7799 - val_loss: 0.3254 - val_accuracy: 0.8399\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4619 - accuracy: 0.7854 - val_loss: 0.2697 - val_accuracy: 0.8734\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4558 - accuracy: 0.7919 - val_loss: 0.2834 - val_accuracy: 0.8731\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4514 - accuracy: 0.7910 - val_loss: 0.3589 - val_accuracy: 0.8552\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4467 - accuracy: 0.7942 - val_loss: 0.2726 - val_accuracy: 0.8722\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_247 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_248 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_249 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_246 (Reshape)          (None, 45, 8)        0           ['input_247[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_247 (Reshape)          (None, 45, 8)        0           ['input_248[0][0]']              \n",
      "                                                                                                  \n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3193 - accuracy: 0.8605 - val_loss: 0.2932 - val_accuracy: 0.8614\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3124 - accuracy: 0.8664 - val_loss: 0.2633 - val_accuracy: 0.8741\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3001 - accuracy: 0.8682 - val_loss: 0.2544 - val_accuracy: 0.8691\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_83\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_250 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_251 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_252 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_249 (Reshape)          (None, 45, 8)        0           ['input_250[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_250 (Reshape)          (None, 45, 8)        0           ['input_251[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_251 (Reshape)          (None, 45, 11)       0           ['input_252[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_332 (Mult  (None, 45, 8)       2248        ['reshape_249[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_249[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_333 (Mult  (None, 45, 8)       2248        ['reshape_250[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_250[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_334 (Mult  (None, 45, 11)      4147        ['reshape_251[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_251[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_332 (Layer  (None, 45, 8)       16          ['multi_head_attention_332[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_333 (Layer  (None, 45, 8)       16          ['multi_head_attention_333[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_334 (Layer  (None, 45, 11)      22          ['multi_head_attention_334[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_498 (Dropout)          (None, 45, 8)        0           ['layer_normalization_332[0][0]']\n",
      "                                                                                                  \n",
      " dropout_499 (Dropout)          (None, 45, 8)        0           ['layer_normalization_333[0][0]']\n",
      "                                                                                                  \n",
      " dropout_500 (Dropout)          (None, 45, 11)       0           ['layer_normalization_334[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_83 (Concatenate)   (None, 45, 27)       0           ['dropout_498[0][0]',            \n",
      "                                                                  'dropout_499[0][0]',            \n",
      "                                                                  'dropout_500[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_83 (G  (None, 27)          0           ['concatenate_83[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_501 (Dropout)          (None, 27)           0           ['global_average_pooling1d_83[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_83 (TFOpLambda)  (None, 1, 27)       0           ['dropout_501[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_335 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_83[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_83[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_83 (TFOpL  (None, 27)          0           ['multi_head_attention_335[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_335 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_83[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_502 (Dropout)          (None, 27)           0           ['layer_normalization_335[0][0]']\n",
      "                                                                                                  \n",
      " dense_249 (Dense)              (None, 1024)         28672       ['dropout_502[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_503 (Dropout)          (None, 1024)         0           ['dense_249[0][0]']              \n",
      "                                                                                                  \n",
      " dense_250 (Dense)              (None, 128)          131200      ['dropout_503[0][0]']            \n",
      "                                                                                                  \n",
      " dense_251 (Dense)              (None, 1)            129         ['dense_250[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4097 - accuracy: 0.8257 - val_loss: 0.1214 - val_accuracy: 0.9763\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2143 - accuracy: 0.9372 - val_loss: 0.1351 - val_accuracy: 0.9790\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2123 - accuracy: 0.9372 - val_loss: 0.1032 - val_accuracy: 0.9795\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_84\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_253 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_254 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_255 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_252 (Reshape)          (None, 45, 8)        0           ['input_253[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_253 (Reshape)          (None, 45, 8)        0           ['input_254[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_254 (Reshape)          (None, 45, 11)       0           ['input_255[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_336 (Mult  (None, 45, 8)       2248        ['reshape_252[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_252[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_337 (Mult  (None, 45, 8)       2248        ['reshape_253[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_253[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_338 (Mult  (None, 45, 11)      4147        ['reshape_254[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_254[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_336 (Layer  (None, 45, 8)       16          ['multi_head_attention_336[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_337 (Layer  (None, 45, 8)       16          ['multi_head_attention_337[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_338 (Layer  (None, 45, 11)      22          ['multi_head_attention_338[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_504 (Dropout)          (None, 45, 8)        0           ['layer_normalization_336[0][0]']\n",
      "                                                                                                  \n",
      " dropout_505 (Dropout)          (None, 45, 8)        0           ['layer_normalization_337[0][0]']\n",
      "                                                                                                  \n",
      " dropout_506 (Dropout)          (None, 45, 11)       0           ['layer_normalization_338[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_84 (Concatenate)   (None, 45, 27)       0           ['dropout_504[0][0]',            \n",
      "                                                                  'dropout_505[0][0]',            \n",
      "                                                                  'dropout_506[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_84 (G  (None, 27)          0           ['concatenate_84[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_507 (Dropout)          (None, 27)           0           ['global_average_pooling1d_84[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_84 (TFOpLambda)  (None, 1, 27)       0           ['dropout_507[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_339 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_84[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_84[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_84 (TFOpL  (None, 27)          0           ['multi_head_attention_339[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_339 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_84[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_508 (Dropout)          (None, 27)           0           ['layer_normalization_339[0][0]']\n",
      "                                                                                                  \n",
      " dense_252 (Dense)              (None, 1024)         28672       ['dropout_508[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_509 (Dropout)          (None, 1024)         0           ['dense_252[0][0]']              \n",
      "                                                                                                  \n",
      " dense_253 (Dense)              (None, 128)          131200      ['dropout_509[0][0]']            \n",
      "                                                                                                  \n",
      " dense_254 (Dense)              (None, 1)            129         ['dense_253[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4966 - accuracy: 0.7787 - val_loss: 0.2606 - val_accuracy: 0.8714\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4089 - accuracy: 0.8334 - val_loss: 0.2423 - val_accuracy: 0.8444\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3858 - accuracy: 0.8448 - val_loss: 0.2072 - val_accuracy: 0.8741\n",
      "Epoch 4/10\n",
      " 67/938 [=>............................] - ETA: 13s - loss: 0.3927 - accuracy: 0.8410\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_85\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_256 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_257 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_258 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_255 (Reshape)          (None, 45, 8)        0           ['input_256[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_256 (Reshape)          (None, 45, 8)        0           ['input_257[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_257 (Reshape)          (None, 45, 11)       0           ['input_258[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_340 (Mult  (None, 45, 8)       2248        ['reshape_255[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_255[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_341 (Mult  (None, 45, 8)       2248        ['reshape_256[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_256[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_342 (Mult  (None, 45, 11)      4147        ['reshape_257[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_257[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_340 (Layer  (None, 45, 8)       16          ['multi_head_attention_340[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_341 (Layer  (None, 45, 8)       16          ['multi_head_attention_341[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_342 (Layer  (None, 45, 11)      22          ['multi_head_attention_342[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_510 (Dropout)          (None, 45, 8)        0           ['layer_normalization_340[0][0]']\n",
      "                                                                                                  \n",
      " dropout_511 (Dropout)          (None, 45, 8)        0           ['layer_normalization_341[0][0]']\n",
      "                                                                                                  \n",
      " dropout_512 (Dropout)          (None, 45, 11)       0           ['layer_normalization_342[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_85 (Concatenate)   (None, 45, 27)       0           ['dropout_510[0][0]',            \n",
      "                                                                  'dropout_511[0][0]',            \n",
      "                                                                  'dropout_512[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_85 (G  (None, 27)          0           ['concatenate_85[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_513 (Dropout)          (None, 27)           0           ['global_average_pooling1d_85[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_85 (TFOpLambda)  (None, 1, 27)       0           ['dropout_513[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_343 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_85[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_85[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_85 (TFOpL  (None, 27)          0           ['multi_head_attention_343[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_343 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_85[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_514 (Dropout)          (None, 27)           0           ['layer_normalization_343[0][0]']\n",
      "                                                                                                  \n",
      " dense_255 (Dense)              (None, 1024)         28672       ['dropout_514[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_515 (Dropout)          (None, 1024)         0           ['dense_255[0][0]']              \n",
      "                                                                                                  \n",
      " dense_256 (Dense)              (None, 128)          131200      ['dropout_515[0][0]']            \n",
      "                                                                                                  \n",
      " dense_257 (Dense)              (None, 1)            129         ['dense_256[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4002 - accuracy: 0.7978 - val_loss: 0.2122 - val_accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2536 - accuracy: 0.8971 - val_loss: 0.2087 - val_accuracy: 0.9018\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1884 - accuracy: 0.9306 - val_loss: 0.1250 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1546 - accuracy: 0.9450 - val_loss: 0.1609 - val_accuracy: 0.9223\n",
      "Epoch 5/10\n",
      "291/938 [========>.....................] - ETA: 9s - loss: 0.1474 - accuracy: 0.9494\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_86\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_259 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_260 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_261 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_258 (Reshape)          (None, 45, 8)        0           ['input_259[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_259 (Reshape)          (None, 45, 8)        0           ['input_260[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_260 (Reshape)          (None, 45, 11)       0           ['input_261[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_344 (Mult  (None, 45, 8)       2248        ['reshape_258[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_258[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_345 (Mult  (None, 45, 8)       2248        ['reshape_259[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_259[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_346 (Mult  (None, 45, 11)      4147        ['reshape_260[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_260[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_344 (Layer  (None, 45, 8)       16          ['multi_head_attention_344[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_345 (Layer  (None, 45, 8)       16          ['multi_head_attention_345[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_346 (Layer  (None, 45, 11)      22          ['multi_head_attention_346[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_516 (Dropout)          (None, 45, 8)        0           ['layer_normalization_344[0][0]']\n",
      "                                                                                                  \n",
      " dropout_517 (Dropout)          (None, 45, 8)        0           ['layer_normalization_345[0][0]']\n",
      "                                                                                                  \n",
      " dropout_518 (Dropout)          (None, 45, 11)       0           ['layer_normalization_346[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_86 (Concatenate)   (None, 45, 27)       0           ['dropout_516[0][0]',            \n",
      "                                                                  'dropout_517[0][0]',            \n",
      "                                                                  'dropout_518[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_86 (G  (None, 27)          0           ['concatenate_86[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_519 (Dropout)          (None, 27)           0           ['global_average_pooling1d_86[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_86 (TFOpLambda)  (None, 1, 27)       0           ['dropout_519[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_347 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_86[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_86[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_86 (TFOpL  (None, 27)          0           ['multi_head_attention_347[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_347 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_86[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_520 (Dropout)          (None, 27)           0           ['layer_normalization_347[0][0]']\n",
      "                                                                                                  \n",
      " dense_258 (Dense)              (None, 1024)         28672       ['dropout_520[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_521 (Dropout)          (None, 1024)         0           ['dense_258[0][0]']              \n",
      "                                                                                                  \n",
      " dense_259 (Dense)              (None, 128)          131200      ['dropout_521[0][0]']            \n",
      "                                                                                                  \n",
      " dense_260 (Dense)              (None, 1)            129         ['dense_259[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3777 - accuracy: 0.8116 - val_loss: 0.1699 - val_accuracy: 0.9427\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2701 - accuracy: 0.8876 - val_loss: 0.2167 - val_accuracy: 0.9073\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2326 - accuracy: 0.9117 - val_loss: 0.1073 - val_accuracy: 0.9620\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2160 - accuracy: 0.9188 - val_loss: 0.1132 - val_accuracy: 0.9510\n",
      "Epoch 5/10\n",
      "295/938 [========>.....................] - ETA: 9s - loss: 0.2080 - accuracy: 0.9211\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_87\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_262 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_263 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_264 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_261 (Reshape)          (None, 45, 8)        0           ['input_262[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_262 (Reshape)          (None, 45, 8)        0           ['input_263[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_263 (Reshape)          (None, 45, 11)       0           ['input_264[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_348 (Mult  (None, 45, 8)       2248        ['reshape_261[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_261[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_349 (Mult  (None, 45, 8)       2248        ['reshape_262[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_262[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_350 (Mult  (None, 45, 11)      4147        ['reshape_263[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_263[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_348 (Layer  (None, 45, 8)       16          ['multi_head_attention_348[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_349 (Layer  (None, 45, 8)       16          ['multi_head_attention_349[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_350 (Layer  (None, 45, 11)      22          ['multi_head_attention_350[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_522 (Dropout)          (None, 45, 8)        0           ['layer_normalization_348[0][0]']\n",
      "                                                                                                  \n",
      " dropout_523 (Dropout)          (None, 45, 8)        0           ['layer_normalization_349[0][0]']\n",
      "                                                                                                  \n",
      " dropout_524 (Dropout)          (None, 45, 11)       0           ['layer_normalization_350[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_87 (Concatenate)   (None, 45, 27)       0           ['dropout_522[0][0]',            \n",
      "                                                                  'dropout_523[0][0]',            \n",
      "                                                                  'dropout_524[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_87 (G  (None, 27)          0           ['concatenate_87[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_525 (Dropout)          (None, 27)           0           ['global_average_pooling1d_87[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_87 (TFOpLambda)  (None, 1, 27)       0           ['dropout_525[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_351 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_87[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_87[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_87 (TFOpL  (None, 27)          0           ['multi_head_attention_351[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_351 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_87[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_526 (Dropout)          (None, 27)           0           ['layer_normalization_351[0][0]']\n",
      "                                                                                                  \n",
      " dense_261 (Dense)              (None, 1024)         28672       ['dropout_526[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_527 (Dropout)          (None, 1024)         0           ['dense_261[0][0]']              \n",
      "                                                                                                  \n",
      " dense_262 (Dense)              (None, 128)          131200      ['dropout_527[0][0]']            \n",
      "                                                                                                  \n",
      " dense_263 (Dense)              (None, 1)            129         ['dense_262[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3330 - accuracy: 0.8689 - val_loss: 0.1815 - val_accuracy: 0.9386\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2361 - accuracy: 0.9241 - val_loss: 0.1594 - val_accuracy: 0.9467\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2100 - accuracy: 0.9336 - val_loss: 0.1428 - val_accuracy: 0.9520\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2013 - accuracy: 0.9381 - val_loss: 0.1533 - val_accuracy: 0.9489\n",
      "Epoch 5/10\n",
      "305/938 [========>.....................] - ETA: 8s - loss: 0.2054 - accuracy: 0.9361TRAIN kitchen 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_88\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_265 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_266 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_267 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_264 (Reshape)          (None, 45, 8)        0           ['input_265[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_265 (Reshape)          (None, 45, 8)        0           ['input_266[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_266 (Reshape)          (None, 45, 11)       0           ['input_267[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_352 (Mult  (None, 45, 8)       2248        ['reshape_264[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_264[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_353 (Mult  (None, 45, 8)       2248        ['reshape_265[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_265[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_354 (Mult  (None, 45, 11)      4147        ['reshape_266[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_266[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_352 (Layer  (None, 45, 8)       16          ['multi_head_attention_352[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_353 (Layer  (None, 45, 8)       16          ['multi_head_attention_353[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_354 (Layer  (None, 45, 11)      22          ['multi_head_attention_354[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_528 (Dropout)          (None, 45, 8)        0           ['layer_normalization_352[0][0]']\n",
      "                                                                                                  \n",
      " dropout_529 (Dropout)          (None, 45, 8)        0           ['layer_normalization_353[0][0]']\n",
      "                                                                                                  \n",
      " dropout_530 (Dropout)          (None, 45, 11)       0           ['layer_normalization_354[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_88 (Concatenate)   (None, 45, 27)       0           ['dropout_528[0][0]',            \n",
      "                                                                  'dropout_529[0][0]',            \n",
      "                                                                  'dropout_530[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_88 (G  (None, 27)          0           ['concatenate_88[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_531 (Dropout)          (None, 27)           0           ['global_average_pooling1d_88[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_88 (TFOpLambda)  (None, 1, 27)       0           ['dropout_531[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_355 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_88[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_88[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_88 (TFOpL  (None, 27)          0           ['multi_head_attention_355[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_355 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_88[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_532 (Dropout)          (None, 27)           0           ['layer_normalization_355[0][0]']\n",
      "                                                                                                  \n",
      " dense_264 (Dense)              (None, 1024)         28672       ['dropout_532[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_533 (Dropout)          (None, 1024)         0           ['dense_264[0][0]']              \n",
      "                                                                                                  \n",
      " dense_265 (Dense)              (None, 128)          131200      ['dropout_533[0][0]']            \n",
      "                                                                                                  \n",
      " dense_266 (Dense)              (None, 1)            129         ['dense_265[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4301 - accuracy: 0.8123 - val_loss: 0.2213 - val_accuracy: 0.8686\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3616 - accuracy: 0.8538 - val_loss: 0.2636 - val_accuracy: 0.8464\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3477 - accuracy: 0.8568 - val_loss: 0.1892 - val_accuracy: 0.8949\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3406 - accuracy: 0.8611 - val_loss: 0.1822 - val_accuracy: 0.9030\n",
      "Epoch 5/10\n",
      " 61/938 [>.............................] - ETA: 12s - loss: 0.3351 - accuracy: 0.8617TRAIN toileting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_89\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_268 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_269 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_270 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_267 (Reshape)          (None, 45, 8)        0           ['input_268[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_268 (Reshape)          (None, 45, 8)        0           ['input_269[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_269 (Reshape)          (None, 45, 11)       0           ['input_270[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_356 (Mult  (None, 45, 8)       2248        ['reshape_267[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_267[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_357 (Mult  (None, 45, 8)       2248        ['reshape_268[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_268[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_358 (Mult  (None, 45, 11)      4147        ['reshape_269[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_269[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_356 (Layer  (None, 45, 8)       16          ['multi_head_attention_356[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_357 (Layer  (None, 45, 8)       16          ['multi_head_attention_357[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_358 (Layer  (None, 45, 11)      22          ['multi_head_attention_358[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_534 (Dropout)          (None, 45, 8)        0           ['layer_normalization_356[0][0]']\n",
      "                                                                                                  \n",
      " dropout_535 (Dropout)          (None, 45, 8)        0           ['layer_normalization_357[0][0]']\n",
      "                                                                                                  \n",
      " dropout_536 (Dropout)          (None, 45, 11)       0           ['layer_normalization_358[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_89 (Concatenate)   (None, 45, 27)       0           ['dropout_534[0][0]',            \n",
      "                                                                  'dropout_535[0][0]',            \n",
      "                                                                  'dropout_536[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_89 (G  (None, 27)          0           ['concatenate_89[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_537 (Dropout)          (None, 27)           0           ['global_average_pooling1d_89[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_89 (TFOpLambda)  (None, 1, 27)       0           ['dropout_537[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_359 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_89[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_89[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_89 (TFOpL  (None, 27)          0           ['multi_head_attention_359[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_359 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_89[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_538 (Dropout)          (None, 27)           0           ['layer_normalization_359[0][0]']\n",
      "                                                                                                  \n",
      " dense_267 (Dense)              (None, 1024)         28672       ['dropout_538[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_539 (Dropout)          (None, 1024)         0           ['dense_267[0][0]']              \n",
      "                                                                                                  \n",
      " dense_268 (Dense)              (None, 128)          131200      ['dropout_539[0][0]']            \n",
      "                                                                                                  \n",
      " dense_269 (Dense)              (None, 1)            129         ['dense_268[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5957 - accuracy: 0.6713 - val_loss: 0.5935 - val_accuracy: 0.6327\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.5000 - accuracy: 0.7677 - val_loss: 0.3717 - val_accuracy: 0.8043\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4723 - accuracy: 0.7824 - val_loss: 0.2921 - val_accuracy: 0.8346\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4627 - accuracy: 0.7890 - val_loss: 0.4202 - val_accuracy: 0.7646\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5530 - accuracy: 0.7075 - val_loss: 0.4763 - val_accuracy: 0.5816\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4271 - accuracy: 0.7877 - val_loss: 0.4317 - val_accuracy: 0.6239\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4071 - accuracy: 0.8020 - val_loss: 0.5119 - val_accuracy: 0.6162\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3978 - accuracy: 0.8076 - val_loss: 0.5157 - val_accuracy: 0.5993\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2345 - accuracy: 0.9322 - val_loss: 0.1325 - val_accuracy: 0.9685\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2287 - accuracy: 0.9334 - val_loss: 0.1502 - val_accuracy: 0.9656\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2211 - accuracy: 0.9353 - val_loss: 0.1613 - val_accuracy: 0.9682\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2161 - accuracy: 0.9366 - val_loss: 0.1165 - val_accuracy: 0.9694\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3835 - accuracy: 0.8410 - val_loss: 0.2310 - val_accuracy: 0.8784\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3793 - accuracy: 0.8431 - val_loss: 0.2383 - val_accuracy: 0.8796\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3784 - accuracy: 0.8424 - val_loss: 0.2953 - val_accuracy: 0.8686\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3713 - accuracy: 0.8452 - val_loss: 0.2950 - val_accuracy: 0.8502\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3700 - accuracy: 0.8458 - val_loss: 0.2725 - val_accuracy: 0.8643\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1237 - accuracy: 0.9566 - val_loss: 0.0811 - val_accuracy: 0.9587\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1127 - accuracy: 0.9614 - val_loss: 0.1176 - val_accuracy: 0.9453\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1052 - accuracy: 0.9643 - val_loss: 0.1041 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1032 - accuracy: 0.9646 - val_loss: 0.1004 - val_accuracy: 0.9568\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN pc 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_94\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_283 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_284 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_285 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_282 (Reshape)          (None, 45, 8)        0           ['input_283[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_283 (Reshape)          (None, 45, 8)        0           ['input_284[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_284 (Reshape)          (None, 45, 11)       0           ['input_285[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_376 (Mult  (None, 45, 8)       2248        ['reshape_282[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_282[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_377 (Mult  (None, 45, 8)       2248        ['reshape_283[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_283[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_378 (Mult  (None, 45, 11)      4147        ['reshape_284[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_284[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_376 (Layer  (None, 45, 8)       16          ['multi_head_attention_376[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_377 (Layer  (None, 45, 8)       16          ['multi_head_attention_377[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_378 (Layer  (None, 45, 11)      22          ['multi_head_attention_378[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_564 (Dropout)          (None, 45, 8)        0           ['layer_normalization_376[0][0]']\n",
      "                                                                                                  \n",
      " dropout_565 (Dropout)          (None, 45, 8)        0           ['layer_normalization_377[0][0]']\n",
      "                                                                                                  \n",
      " dropout_566 (Dropout)          (None, 45, 11)       0           ['layer_normalization_378[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_94 (Concatenate)   (None, 45, 27)       0           ['dropout_564[0][0]',            \n",
      "                                                                  'dropout_565[0][0]',            \n",
      "                                                                  'dropout_566[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_94 (G  (None, 27)          0           ['concatenate_94[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_567 (Dropout)          (None, 27)           0           ['global_average_pooling1d_94[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_94 (TFOpLambda)  (None, 1, 27)       0           ['dropout_567[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_379 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_94[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_94[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_94 (TFOpL  (None, 27)          0           ['multi_head_attention_379[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_379 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_94[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_568 (Dropout)          (None, 27)           0           ['layer_normalization_379[0][0]']\n",
      "                                                                                                  \n",
      " dense_282 (Dense)              (None, 1024)         28672       ['dropout_568[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_569 (Dropout)          (None, 1024)         0           ['dense_282[0][0]']              \n",
      "                                                                                                  \n",
      " dense_283 (Dense)              (None, 128)          131200      ['dropout_569[0][0]']            \n",
      "                                                                                                  \n",
      " dense_284 (Dense)              (None, 1)            129         ['dense_283[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1520 - accuracy: 0.9494 - val_loss: 0.0870 - val_accuracy: 0.9692\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1388 - accuracy: 0.9537 - val_loss: 0.1025 - val_accuracy: 0.9620\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN sleep 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_95\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_286 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_287 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_288 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_285 (Reshape)          (None, 45, 8)        0           ['input_286[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_286 (Reshape)          (None, 45, 8)        0           ['input_287[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_287 (Reshape)          (None, 45, 11)       0           ['input_288[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_380 (Mult  (None, 45, 8)       2248        ['reshape_285[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_285[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_381 (Mult  (None, 45, 8)       2248        ['reshape_286[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_286[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_382 (Mult  (None, 45, 11)      4147        ['reshape_287[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_287[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_380 (Layer  (None, 45, 8)       16          ['multi_head_attention_380[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_381 (Layer  (None, 45, 8)       16          ['multi_head_attention_381[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_382 (Layer  (None, 45, 11)      22          ['multi_head_attention_382[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_570 (Dropout)          (None, 45, 8)        0           ['layer_normalization_380[0][0]']\n",
      "                                                                                                  \n",
      " dropout_571 (Dropout)          (None, 45, 8)        0           ['layer_normalization_381[0][0]']\n",
      "                                                                                                  \n",
      " dropout_572 (Dropout)          (None, 45, 11)       0           ['layer_normalization_382[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_95 (Concatenate)   (None, 45, 27)       0           ['dropout_570[0][0]',            \n",
      "                                                                  'dropout_571[0][0]',            \n",
      "                                                                  'dropout_572[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_95 (G  (None, 27)          0           ['concatenate_95[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_573 (Dropout)          (None, 27)           0           ['global_average_pooling1d_95[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_95 (TFOpLambda)  (None, 1, 27)       0           ['dropout_573[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_383 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_95[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_95[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_95 (TFOpL  (None, 27)          0           ['multi_head_attention_383[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_383 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_95[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_574 (Dropout)          (None, 27)           0           ['layer_normalization_383[0][0]']\n",
      "                                                                                                  \n",
      " dense_285 (Dense)              (None, 1024)         28672       ['dropout_574[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_575 (Dropout)          (None, 1024)         0           ['dense_285[0][0]']              \n",
      "                                                                                                  \n",
      " dense_286 (Dense)              (None, 128)          131200      ['dropout_575[0][0]']            \n",
      "                                                                                                  \n",
      " dense_287 (Dense)              (None, 1)            129         ['dense_286[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3450 - accuracy: 0.8633 - val_loss: 0.3443 - val_accuracy: 0.8449\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2276 - accuracy: 0.9281 - val_loss: 0.1573 - val_accuracy: 0.9462\n",
      "Epoch 3/10\n",
      " 80/938 [=>............................] - ETA: 12s - loss: 0.2132 - accuracy: 0.9352\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_96\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_289 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_290 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_291 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_288 (Reshape)          (None, 45, 8)        0           ['input_289[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_289 (Reshape)          (None, 45, 8)        0           ['input_290[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_290 (Reshape)          (None, 45, 11)       0           ['input_291[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_384 (Mult  (None, 45, 8)       2248        ['reshape_288[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_288[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_385 (Mult  (None, 45, 8)       2248        ['reshape_289[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_289[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_386 (Mult  (None, 45, 11)      4147        ['reshape_290[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_290[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_384 (Layer  (None, 45, 8)       16          ['multi_head_attention_384[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_385 (Layer  (None, 45, 8)       16          ['multi_head_attention_385[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_386 (Layer  (None, 45, 11)      22          ['multi_head_attention_386[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_576 (Dropout)          (None, 45, 8)        0           ['layer_normalization_384[0][0]']\n",
      "                                                                                                  \n",
      " dropout_577 (Dropout)          (None, 45, 8)        0           ['layer_normalization_385[0][0]']\n",
      "                                                                                                  \n",
      " dropout_578 (Dropout)          (None, 45, 11)       0           ['layer_normalization_386[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_96 (Concatenate)   (None, 45, 27)       0           ['dropout_576[0][0]',            \n",
      "                                                                  'dropout_577[0][0]',            \n",
      "                                                                  'dropout_578[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_96 (G  (None, 27)          0           ['concatenate_96[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_579 (Dropout)          (None, 27)           0           ['global_average_pooling1d_96[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_96 (TFOpLambda)  (None, 1, 27)       0           ['dropout_579[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_387 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_96[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_96[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_96 (TFOpL  (None, 27)          0           ['multi_head_attention_387[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_387 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_96[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_580 (Dropout)          (None, 27)           0           ['layer_normalization_387[0][0]']\n",
      "                                                                                                  \n",
      " dense_288 (Dense)              (None, 1024)         28672       ['dropout_580[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_581 (Dropout)          (None, 1024)         0           ['dense_288[0][0]']              \n",
      "                                                                                                  \n",
      " dense_289 (Dense)              (None, 128)          131200      ['dropout_581[0][0]']            \n",
      "                                                                                                  \n",
      " dense_290 (Dense)              (None, 1)            129         ['dense_289[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4531 - accuracy: 0.7885 - val_loss: 0.3267 - val_accuracy: 0.8222\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3893 - accuracy: 0.8308 - val_loss: 0.2882 - val_accuracy: 0.8504\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3663 - accuracy: 0.8453 - val_loss: 0.2302 - val_accuracy: 0.8755\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3509 - accuracy: 0.8525 - val_loss: 0.2734 - val_accuracy: 0.8898\n",
      "Epoch 5/10\n",
      " 17/938 [..............................] - ETA: 12s - loss: 0.3520 - accuracy: 0.8585\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN toileting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_97\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_292 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_293 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_294 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_291 (Reshape)          (None, 45, 8)        0           ['input_292[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_292 (Reshape)          (None, 45, 8)        0           ['input_293[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_293 (Reshape)          (None, 45, 11)       0           ['input_294[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_388 (Mult  (None, 45, 8)       2248        ['reshape_291[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_291[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_389 (Mult  (None, 45, 8)       2248        ['reshape_292[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_292[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_390 (Mult  (None, 45, 11)      4147        ['reshape_293[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_293[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_388 (Layer  (None, 45, 8)       16          ['multi_head_attention_388[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_389 (Layer  (None, 45, 8)       16          ['multi_head_attention_389[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_390 (Layer  (None, 45, 11)      22          ['multi_head_attention_390[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_582 (Dropout)          (None, 45, 8)        0           ['layer_normalization_388[0][0]']\n",
      "                                                                                                  \n",
      " dropout_583 (Dropout)          (None, 45, 8)        0           ['layer_normalization_389[0][0]']\n",
      "                                                                                                  \n",
      " dropout_584 (Dropout)          (None, 45, 11)       0           ['layer_normalization_390[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_97 (Concatenate)   (None, 45, 27)       0           ['dropout_582[0][0]',            \n",
      "                                                                  'dropout_583[0][0]',            \n",
      "                                                                  'dropout_584[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_97 (G  (None, 27)          0           ['concatenate_97[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_585 (Dropout)          (None, 27)           0           ['global_average_pooling1d_97[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_97 (TFOpLambda)  (None, 1, 27)       0           ['dropout_585[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_391 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_97[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_97[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_97 (TFOpL  (None, 27)          0           ['multi_head_attention_391[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_391 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_97[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_586 (Dropout)          (None, 27)           0           ['layer_normalization_391[0][0]']\n",
      "                                                                                                  \n",
      " dense_291 (Dense)              (None, 1024)         28672       ['dropout_586[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_587 (Dropout)          (None, 1024)         0           ['dense_291[0][0]']              \n",
      "                                                                                                  \n",
      " dense_292 (Dense)              (None, 128)          131200      ['dropout_587[0][0]']            \n",
      "                                                                                                  \n",
      " dense_293 (Dense)              (None, 1)            129         ['dense_292[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.5798 - accuracy: 0.6970 - val_loss: 0.4851 - val_accuracy: 0.7498\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.5064 - accuracy: 0.7656 - val_loss: 0.4567 - val_accuracy: 0.7269\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4896 - accuracy: 0.7710 - val_loss: 0.3706 - val_accuracy: 0.8081\n",
      "Epoch 4/10\n",
      "691/938 [=====================>........] - ETA: 3s - loss: 0.4811 - accuracy: 0.7769\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN resting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_98\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_295 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_296 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_297 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_294 (Reshape)          (None, 45, 8)        0           ['input_295[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_295 (Reshape)          (None, 45, 8)        0           ['input_296[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_296 (Reshape)          (None, 45, 11)       0           ['input_297[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_392 (Mult  (None, 45, 8)       2248        ['reshape_294[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_294[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_393 (Mult  (None, 45, 8)       2248        ['reshape_295[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_295[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_394 (Mult  (None, 45, 11)      4147        ['reshape_296[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_296[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_392 (Layer  (None, 45, 8)       16          ['multi_head_attention_392[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_393 (Layer  (None, 45, 8)       16          ['multi_head_attention_393[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_394 (Layer  (None, 45, 11)      22          ['multi_head_attention_394[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_588 (Dropout)          (None, 45, 8)        0           ['layer_normalization_392[0][0]']\n",
      "                                                                                                  \n",
      " dropout_589 (Dropout)          (None, 45, 8)        0           ['layer_normalization_393[0][0]']\n",
      "                                                                                                  \n",
      " dropout_590 (Dropout)          (None, 45, 11)       0           ['layer_normalization_394[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_98 (Concatenate)   (None, 45, 27)       0           ['dropout_588[0][0]',            \n",
      "                                                                  'dropout_589[0][0]',            \n",
      "                                                                  'dropout_590[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_98 (G  (None, 27)          0           ['concatenate_98[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_591 (Dropout)          (None, 27)           0           ['global_average_pooling1d_98[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_98 (TFOpLambda)  (None, 1, 27)       0           ['dropout_591[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_395 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_98[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_98[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_98 (TFOpL  (None, 27)          0           ['multi_head_attention_395[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_395 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_98[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_592 (Dropout)          (None, 27)           0           ['layer_normalization_395[0][0]']\n",
      "                                                                                                  \n",
      " dense_294 (Dense)              (None, 1024)         28672       ['dropout_592[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_593 (Dropout)          (None, 1024)         0           ['dense_294[0][0]']              \n",
      "                                                                                                  \n",
      " dense_295 (Dense)              (None, 128)          131200      ['dropout_593[0][0]']            \n",
      "                                                                                                  \n",
      " dense_296 (Dense)              (None, 1)            129         ['dense_295[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 16ms/step - loss: 0.5337 - accuracy: 0.7179 - val_loss: 0.3556 - val_accuracy: 0.6973\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4234 - accuracy: 0.7888 - val_loss: 0.3642 - val_accuracy: 0.7278\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4058 - accuracy: 0.8009 - val_loss: 0.4088 - val_accuracy: 0.7157\n",
      "Epoch 4/10\n",
      "831/938 [=========================>....] - ETA: 1s - loss: 0.3996 - accuracy: 0.8045TRAIN exit 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_99\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_298 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_299 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_300 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_297 (Reshape)          (None, 45, 8)        0           ['input_298[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_298 (Reshape)          (None, 45, 8)        0           ['input_299[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_299 (Reshape)          (None, 45, 11)       0           ['input_300[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_396 (Mult  (None, 45, 8)       2248        ['reshape_297[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_297[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_397 (Mult  (None, 45, 8)       2248        ['reshape_298[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_298[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_398 (Mult  (None, 45, 11)      4147        ['reshape_299[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_299[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_396 (Layer  (None, 45, 8)       16          ['multi_head_attention_396[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_397 (Layer  (None, 45, 8)       16          ['multi_head_attention_397[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_398 (Layer  (None, 45, 11)      22          ['multi_head_attention_398[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_594 (Dropout)          (None, 45, 8)        0           ['layer_normalization_396[0][0]']\n",
      "                                                                                                  \n",
      " dropout_595 (Dropout)          (None, 45, 8)        0           ['layer_normalization_397[0][0]']\n",
      "                                                                                                  \n",
      " dropout_596 (Dropout)          (None, 45, 11)       0           ['layer_normalization_398[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_99 (Concatenate)   (None, 45, 27)       0           ['dropout_594[0][0]',            \n",
      "                                                                  'dropout_595[0][0]',            \n",
      "                                                                  'dropout_596[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_99 (G  (None, 27)          0           ['concatenate_99[0][0]']         \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_597 (Dropout)          (None, 27)           0           ['global_average_pooling1d_99[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " tf.expand_dims_99 (TFOpLambda)  (None, 1, 27)       0           ['dropout_597[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_399 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_99[0][0]',      \n",
      " iHeadAttention)                                                  'tf.expand_dims_99[0][0]']      \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_99 (TFOpL  (None, 27)          0           ['multi_head_attention_399[0][0]'\n",
      " ambda)                                                          ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_399 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_99[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout_598 (Dropout)          (None, 27)           0           ['layer_normalization_399[0][0]']\n",
      "                                                                                                  \n",
      " dense_297 (Dense)              (None, 1024)         28672       ['dropout_598[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_599 (Dropout)          (None, 1024)         0           ['dense_297[0][0]']              \n",
      "                                                                                                  \n",
      " dense_298 (Dense)              (None, 128)          131200      ['dropout_599[0][0]']            \n",
      "                                                                                                  \n",
      " dense_299 (Dense)              (None, 1)            129         ['dense_298[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4144 - accuracy: 0.8223 - val_loss: 0.2328 - val_accuracy: 0.9345\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2996 - accuracy: 0.9010 - val_loss: 0.1907 - val_accuracy: 0.9436\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2577 - accuracy: 0.9187 - val_loss: 0.1711 - val_accuracy: 0.9551\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 20s 17ms/step - loss: 0.5173 - accuracy: 0.7609 - val_loss: 0.2871 - val_accuracy: 0.8707\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4445 - accuracy: 0.8135 - val_loss: 0.2600 - val_accuracy: 0.8296\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4075 - accuracy: 0.8336 - val_loss: 0.2241 - val_accuracy: 0.8714\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3975 - accuracy: 0.8366 - val_loss: 0.3557 - val_accuracy: 0.8459\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2793 - accuracy: 0.8784 - val_loss: 0.1887 - val_accuracy: 0.8774\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2478 - accuracy: 0.8982 - val_loss: 0.1816 - val_accuracy: 0.9047\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1869 - accuracy: 0.9292 - val_loss: 0.1153 - val_accuracy: 0.9345\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1646 - accuracy: 0.9397 - val_loss: 0.1420 - val_accuracy: 0.9321\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1520 - accuracy: 0.9444 - val_loss: 0.1422 - val_accuracy: 0.9312\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1893 - accuracy: 0.9259 - val_loss: 0.0905 - val_accuracy: 0.9740\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1701 - accuracy: 0.9337 - val_loss: 0.0663 - val_accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1567 - accuracy: 0.9415 - val_loss: 0.0498 - val_accuracy: 0.9792\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1466 - accuracy: 0.9481 - val_loss: 0.0549 - val_accuracy: 0.9799\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1877 - accuracy: 0.9399 - val_loss: 0.1158 - val_accuracy: 0.9615\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1807 - accuracy: 0.9420 - val_loss: 0.1213 - val_accuracy: 0.9599\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1786 - accuracy: 0.9427 - val_loss: 0.1120 - val_accuracy: 0.9630\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN kitchen 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_104\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_313 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_314 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_315 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_312 (Reshape)          (None, 45, 8)        0           ['input_313[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_313 (Reshape)          (None, 45, 8)        0           ['input_314[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_314 (Reshape)          (None, 45, 11)       0           ['input_315[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_416 (Mult  (None, 45, 8)       2248        ['reshape_312[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_312[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_417 (Mult  (None, 45, 8)       2248        ['reshape_313[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_313[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_418 (Mult  (None, 45, 11)      4147        ['reshape_314[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_314[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_416 (Layer  (None, 45, 8)       16          ['multi_head_attention_416[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_417 (Layer  (None, 45, 8)       16          ['multi_head_attention_417[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_418 (Layer  (None, 45, 11)      22          ['multi_head_attention_418[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_624 (Dropout)          (None, 45, 8)        0           ['layer_normalization_416[0][0]']\n",
      "                                                                                                  \n",
      " dropout_625 (Dropout)          (None, 45, 8)        0           ['layer_normalization_417[0][0]']\n",
      "                                                                                                  \n",
      " dropout_626 (Dropout)          (None, 45, 11)       0           ['layer_normalization_418[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 45, 27)       0           ['dropout_624[0][0]',            \n",
      "                                                                  'dropout_625[0][0]',            \n",
      "                                                                  'dropout_626[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_104 (  (None, 27)          0           ['concatenate_104[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_627 (Dropout)          (None, 27)           0           ['global_average_pooling1d_104[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_104 (TFOpLambda  (None, 1, 27)       0           ['dropout_627[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_419 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_104[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_104[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_104 (TFOp  (None, 27)          0           ['multi_head_attention_419[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_419 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_104[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_628 (Dropout)          (None, 27)           0           ['layer_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " dense_312 (Dense)              (None, 1024)         28672       ['dropout_628[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_629 (Dropout)          (None, 1024)         0           ['dense_312[0][0]']              \n",
      "                                                                                                  \n",
      " dense_313 (Dense)              (None, 128)          131200      ['dropout_629[0][0]']            \n",
      "                                                                                                  \n",
      " dense_314 (Dense)              (None, 1)            129         ['dense_313[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4489 - accuracy: 0.7929 - val_loss: 0.3343 - val_accuracy: 0.8151\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2951 - accuracy: 0.8773 - val_loss: 0.2439 - val_accuracy: 0.8674\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2911 - accuracy: 0.8773 - val_loss: 0.2386 - val_accuracy: 0.8483\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 13 19935\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN toileting 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_105\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_316 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_317 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_318 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_315 (Reshape)          (None, 45, 8)        0           ['input_316[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_316 (Reshape)          (None, 45, 8)        0           ['input_317[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_317 (Reshape)          (None, 45, 11)       0           ['input_318[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_420 (Mult  (None, 45, 8)       2248        ['reshape_315[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_315[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_421 (Mult  (None, 45, 8)       2248        ['reshape_316[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_316[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_422 (Mult  (None, 45, 11)      4147        ['reshape_317[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_317[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_420 (Layer  (None, 45, 8)       16          ['multi_head_attention_420[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_421 (Layer  (None, 45, 8)       16          ['multi_head_attention_421[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_422 (Layer  (None, 45, 11)      22          ['multi_head_attention_422[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_630 (Dropout)          (None, 45, 8)        0           ['layer_normalization_420[0][0]']\n",
      "                                                                                                  \n",
      " dropout_631 (Dropout)          (None, 45, 8)        0           ['layer_normalization_421[0][0]']\n",
      "                                                                                                  \n",
      " dropout_632 (Dropout)          (None, 45, 11)       0           ['layer_normalization_422[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_105 (Concatenate)  (None, 45, 27)       0           ['dropout_630[0][0]',            \n",
      "                                                                  'dropout_631[0][0]',            \n",
      "                                                                  'dropout_632[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_105 (  (None, 27)          0           ['concatenate_105[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_633 (Dropout)          (None, 27)           0           ['global_average_pooling1d_105[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_105 (TFOpLambda  (None, 1, 27)       0           ['dropout_633[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_423 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_105[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_105[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_105 (TFOp  (None, 27)          0           ['multi_head_attention_423[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_423 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_105[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_634 (Dropout)          (None, 27)           0           ['layer_normalization_423[0][0]']\n",
      "                                                                                                  \n",
      " dense_315 (Dense)              (None, 1024)         28672       ['dropout_634[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_635 (Dropout)          (None, 1024)         0           ['dense_315[0][0]']              \n",
      "                                                                                                  \n",
      " dense_316 (Dense)              (None, 128)          131200      ['dropout_635[0][0]']            \n",
      "                                                                                                  \n",
      " dense_317 (Dense)              (None, 1)            129         ['dense_316[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5934 - accuracy: 0.6763 - val_loss: 0.2979 - val_accuracy: 0.8693\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.5163 - accuracy: 0.7541 - val_loss: 0.3365 - val_accuracy: 0.8072\n",
      "Epoch 3/10\n",
      "621/938 [==================>...........] - ETA: 4s - loss: 0.4828 - accuracy: 0.7747\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN resting 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_106\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_319 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_320 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_321 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_318 (Reshape)          (None, 45, 8)        0           ['input_319[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_319 (Reshape)          (None, 45, 8)        0           ['input_320[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_320 (Reshape)          (None, 45, 11)       0           ['input_321[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_424 (Mult  (None, 45, 8)       2248        ['reshape_318[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_318[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_425 (Mult  (None, 45, 8)       2248        ['reshape_319[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_319[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_426 (Mult  (None, 45, 11)      4147        ['reshape_320[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_320[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_424 (Layer  (None, 45, 8)       16          ['multi_head_attention_424[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_425 (Layer  (None, 45, 8)       16          ['multi_head_attention_425[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_426 (Layer  (None, 45, 11)      22          ['multi_head_attention_426[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_636 (Dropout)          (None, 45, 8)        0           ['layer_normalization_424[0][0]']\n",
      "                                                                                                  \n",
      " dropout_637 (Dropout)          (None, 45, 8)        0           ['layer_normalization_425[0][0]']\n",
      "                                                                                                  \n",
      " dropout_638 (Dropout)          (None, 45, 11)       0           ['layer_normalization_426[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_106 (Concatenate)  (None, 45, 27)       0           ['dropout_636[0][0]',            \n",
      "                                                                  'dropout_637[0][0]',            \n",
      "                                                                  'dropout_638[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_106 (  (None, 27)          0           ['concatenate_106[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_639 (Dropout)          (None, 27)           0           ['global_average_pooling1d_106[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_106 (TFOpLambda  (None, 1, 27)       0           ['dropout_639[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_427 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_106[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_106[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_106 (TFOp  (None, 27)          0           ['multi_head_attention_427[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_427 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_106[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_640 (Dropout)          (None, 27)           0           ['layer_normalization_427[0][0]']\n",
      "                                                                                                  \n",
      " dense_318 (Dense)              (None, 1024)         28672       ['dropout_640[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_641 (Dropout)          (None, 1024)         0           ['dense_318[0][0]']              \n",
      "                                                                                                  \n",
      " dense_319 (Dense)              (None, 128)          131200      ['dropout_641[0][0]']            \n",
      "                                                                                                  \n",
      " dense_320 (Dense)              (None, 1)            129         ['dense_319[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5217 - accuracy: 0.7347 - val_loss: 0.4194 - val_accuracy: 0.6633\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4161 - accuracy: 0.7988 - val_loss: 0.4443 - val_accuracy: 0.6839\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3941 - accuracy: 0.8113 - val_loss: 0.4699 - val_accuracy: 0.6736\n",
      "Epoch 4/10\n",
      "654/938 [===================>..........] - ETA: 4s - loss: 0.3640 - accuracy: 0.8263\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN exit 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_107\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_322 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_323 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_324 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_321 (Reshape)          (None, 45, 8)        0           ['input_322[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_322 (Reshape)          (None, 45, 8)        0           ['input_323[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_323 (Reshape)          (None, 45, 11)       0           ['input_324[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_428 (Mult  (None, 45, 8)       2248        ['reshape_321[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_321[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_429 (Mult  (None, 45, 8)       2248        ['reshape_322[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_322[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_430 (Mult  (None, 45, 11)      4147        ['reshape_323[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_323[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_428 (Layer  (None, 45, 8)       16          ['multi_head_attention_428[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_429 (Layer  (None, 45, 8)       16          ['multi_head_attention_429[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_430 (Layer  (None, 45, 11)      22          ['multi_head_attention_430[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_642 (Dropout)          (None, 45, 8)        0           ['layer_normalization_428[0][0]']\n",
      "                                                                                                  \n",
      " dropout_643 (Dropout)          (None, 45, 8)        0           ['layer_normalization_429[0][0]']\n",
      "                                                                                                  \n",
      " dropout_644 (Dropout)          (None, 45, 11)       0           ['layer_normalization_430[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_107 (Concatenate)  (None, 45, 27)       0           ['dropout_642[0][0]',            \n",
      "                                                                  'dropout_643[0][0]',            \n",
      "                                                                  'dropout_644[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_107 (  (None, 27)          0           ['concatenate_107[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_645 (Dropout)          (None, 27)           0           ['global_average_pooling1d_107[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_107 (TFOpLambda  (None, 1, 27)       0           ['dropout_645[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_431 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_107[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_107[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_107 (TFOp  (None, 27)          0           ['multi_head_attention_431[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_431 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_107[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_646 (Dropout)          (None, 27)           0           ['layer_normalization_431[0][0]']\n",
      "                                                                                                  \n",
      " dense_321 (Dense)              (None, 1024)         28672       ['dropout_646[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_647 (Dropout)          (None, 1024)         0           ['dense_321[0][0]']              \n",
      "                                                                                                  \n",
      " dense_322 (Dense)              (None, 128)          131200      ['dropout_647[0][0]']            \n",
      "                                                                                                  \n",
      " dense_323 (Dense)              (None, 1)            129         ['dense_322[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4153 - accuracy: 0.8136 - val_loss: 0.2850 - val_accuracy: 0.8906\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2757 - accuracy: 0.9116 - val_loss: 0.1992 - val_accuracy: 0.9403\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2397 - accuracy: 0.9289 - val_loss: 0.1920 - val_accuracy: 0.9427\n",
      "Epoch 4/10\n",
      "871/938 [==========================>...] - ETA: 0s - loss: 0.2292 - accuracy: 0.9327TRAIN cooking 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_108\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_325 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_326 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_327 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_324 (Reshape)          (None, 45, 8)        0           ['input_325[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_325 (Reshape)          (None, 45, 8)        0           ['input_326[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_326 (Reshape)          (None, 45, 11)       0           ['input_327[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_432 (Mult  (None, 45, 8)       2248        ['reshape_324[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_324[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_433 (Mult  (None, 45, 8)       2248        ['reshape_325[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_325[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_434 (Mult  (None, 45, 11)      4147        ['reshape_326[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_326[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_432 (Layer  (None, 45, 8)       16          ['multi_head_attention_432[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_433 (Layer  (None, 45, 8)       16          ['multi_head_attention_433[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_434 (Layer  (None, 45, 11)      22          ['multi_head_attention_434[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_648 (Dropout)          (None, 45, 8)        0           ['layer_normalization_432[0][0]']\n",
      "                                                                                                  \n",
      " dropout_649 (Dropout)          (None, 45, 8)        0           ['layer_normalization_433[0][0]']\n",
      "                                                                                                  \n",
      " dropout_650 (Dropout)          (None, 45, 11)       0           ['layer_normalization_434[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_108 (Concatenate)  (None, 45, 27)       0           ['dropout_648[0][0]',            \n",
      "                                                                  'dropout_649[0][0]',            \n",
      "                                                                  'dropout_650[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_108 (  (None, 27)          0           ['concatenate_108[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_651 (Dropout)          (None, 27)           0           ['global_average_pooling1d_108[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_108 (TFOpLambda  (None, 1, 27)       0           ['dropout_651[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_435 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_108[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_108[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_108 (TFOp  (None, 27)          0           ['multi_head_attention_435[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_435 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_108[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_652 (Dropout)          (None, 27)           0           ['layer_normalization_435[0][0]']\n",
      "                                                                                                  \n",
      " dense_324 (Dense)              (None, 1024)         28672       ['dropout_652[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_653 (Dropout)          (None, 1024)         0           ['dense_324[0][0]']              \n",
      "                                                                                                  \n",
      " dense_325 (Dense)              (None, 128)          131200      ['dropout_653[0][0]']            \n",
      "                                                                                                  \n",
      " dense_326 (Dense)              (None, 1)            129         ['dense_325[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4897 - accuracy: 0.7774 - val_loss: 0.2546 - val_accuracy: 0.8870\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4008 - accuracy: 0.8371 - val_loss: 0.3324 - val_accuracy: 0.8624\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3869 - accuracy: 0.8415 - val_loss: 0.3060 - val_accuracy: 0.8683\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4106 - accuracy: 0.7887 - val_loss: 0.2544 - val_accuracy: 0.8084\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2774 - accuracy: 0.8830 - val_loss: 0.2264 - val_accuracy: 0.8504\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2450 - accuracy: 0.9001 - val_loss: 0.2307 - val_accuracy: 0.8557\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2804 - accuracy: 0.8717 - val_loss: 0.2548 - val_accuracy: 0.9254\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2274 - accuracy: 0.9090 - val_loss: 0.1548 - val_accuracy: 0.9697\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2188 - accuracy: 0.9138 - val_loss: 0.1733 - val_accuracy: 0.9501\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2093 - accuracy: 0.9170 - val_loss: 0.1395 - val_accuracy: 0.9713\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1951 - accuracy: 0.9396 - val_loss: 0.1296 - val_accuracy: 0.9560\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1897 - accuracy: 0.9400 - val_loss: 0.1080 - val_accuracy: 0.9649\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1873 - accuracy: 0.9408 - val_loss: 0.1045 - val_accuracy: 0.9630\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2825 - accuracy: 0.8825 - val_loss: 0.2971 - val_accuracy: 0.8323\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2746 - accuracy: 0.8875 - val_loss: 0.2829 - val_accuracy: 0.8485\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gru_22 (GRU)                (None, 11, 128)              2261760   ['time_distributed_44[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 27, 128)              0         ['gru_20[0][0]',              \n",
      " )                                                                   'gru_21[0][0]',              \n",
      "                                                                     'gru_22[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, 27, 128)              0         ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " gru_23 (GRU)                (None, 27, 256)              296448    ['dropout_20[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)        (None, 27, 256)              0         ['gru_23[0][0]']              \n",
      "                                                                                                  \n",
      " gru_24 (GRU)                (None, 27, 512)              1182720   ['dropout_21[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)        (None, 27, 512)              0         ['gru_24[0][0]']              \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     (None, 27, 512)              0         ['dropout_22[0][0]',          \n",
      "                                                                     'dropout_22[0][0]']          \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 27, 512)              0         ['dropout_22[0][0]',          \n",
      "                                                                     'attention_4[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_19 (Flatten)        (None, 13824)                0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)        (None, 13824)                0         ['flatten_19[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 128)                  1769600   ['dropout_23[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)        (None, 128)                  0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 32)                   4128      ['dropout_24[0][0]']          \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 1)                    33        ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10113089 (38.58 MB)\n",
      "Trainable params: 10113089 (38.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 1919s 2s/step - loss: 0.1343 - accuracy: 0.9567 - val_loss: 0.0923 - val_accuracy: 0.9740\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 1937s 2s/step - loss: 0.0659 - accuracy: 0.9806 - val_loss: 0.0342 - val_accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 1927s 2s/step - loss: 0.0447 - accuracy: 0.9863 - val_loss: 0.0690 - val_accuracy: 0.9857\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 1873s 2s/step - loss: 0.0348 - accuracy: 0.9895 - val_loss: 0.0429 - val_accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 1894s 2s/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0315 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 1911s 2s/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.0167 - val_accuracy: 0.9940\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 1882s 2s/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.0215 - val_accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 1904s 2s/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0351 - val_accuracy: 0.9957\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 1901s 2s/step - loss: 0.0126 - accuracy: 0.9950 - val_loss: 0.0172 - val_accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 1919s 2s/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.0120 - val_accuracy: 0.9974\n",
      "131/131 [==============================] - 107s 806ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)       [(None, 8, 45, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " input_17 (InputLayer)       [(None, 8, 45, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)       [(None, 11, 45, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_45 (TimeD  (None, 8, 45, 64)            256       ['input_16[0][0]']            \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_48 (TimeD  (None, 8, 45, 64)            256       ['input_17[0][0]']            \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_51 (TimeD  (None, 11, 45, 64)           256       ['input_18[0][0]']            \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_46 (TimeD  (None, 8, 45, 128)           24704     ['time_distributed_45[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_49 (TimeD  (None, 8, 45, 128)           24704     ['time_distributed_48[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_52 (TimeD  (None, 11, 45, 128)          24704     ['time_distributed_51[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time_distributed_47 (TimeD  (None, 8, 5760)              0         ['time_distributed_46[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_50 (TimeD  (None, 8, 5760)              0         ['time_distributed_49[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_53 (TimeD  (None, 11, 5760)             0         ['time_distributed_52[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " gru_25 (GRU)                (None, 8, 128)               2261760   ['time_distributed_47[0][0]'] \n",
      "                                                                                                  \n",
      " gru_26 (GRU)                (None, 8, 128)               2261760   ['time_distributed_50[0][0]'] \n",
      "                                                                                                  \n",
      " gru_27 (GRU)                (None, 11, 128)              2261760   ['time_distributed_53[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 27, 128)              0         ['gru_25[0][0]',              \n",
      " )                                                                   'gru_26[0][0]',              \n",
      "                                                                     'gru_27[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)        (None, 27, 128)              0         ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " gru_28 (GRU)                (None, 27, 256)              296448    ['dropout_25[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)        (None, 27, 256)              0         ['gru_28[0][0]']              \n",
      "                                                                                                  \n",
      " gru_29 (GRU)                (None, 27, 512)              1182720   ['dropout_26[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)        (None, 27, 512)              0         ['gru_29[0][0]']              \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, 27, 512)              0         ['dropout_27[0][0]',          \n",
      "                                                                     'dropout_27[0][0]']          \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 27, 512)              0         ['dropout_27[0][0]',          \n",
      "                                                                     'attention_5[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_23 (Flatten)        (None, 13824)                0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)        (None, 13824)                0         ['flatten_23[0][0]']          \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 128)                  1769600   ['dropout_28[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)        (None, 128)                  0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 32)                   4128      ['dropout_29[0][0]']          \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 1)                    33        ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10113089 (38.58 MB)\n",
      "Trainable params: 10113089 (38.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 2195s 2s/step - loss: 0.0632 - accuracy: 0.9826 - val_loss: 0.0305 - val_accuracy: 0.9931\n",
      "Epoch 2/10\n",
      "434/938 [============>.................] - ETA: 17:11 - loss: 0.0409 - accuracy: 0.9936"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "SizeTrainOk=4000\n",
    "SizeTrainKo=6000\n",
    "\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    print(\"\\t\",dx,day)\n",
    "    other_dx= [other for other in range(0,len(days)) if other != dx]\n",
    "\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    \n",
    "    for ax,activity in enumerate(activities):\n",
    "            print(ax,activity)\n",
    "            \n",
    "            ##TRAING DATA\n",
    "            L1=[]\n",
    "            L2=[]\n",
    "            S=[]\n",
    "            Y=[]\n",
    "            for ux,user in enumerate(users):\n",
    "                    print(\"\\t\\t\",ux,user)\n",
    "                    other_ux= [other for other in range(0,len(users)) if other != ux]\n",
    "                    print(day,user,other_dx,other_ux)\n",
    "\n",
    "                    #OK act\n",
    "                    for ix in range(0,SizeTrainOk):\n",
    "                        #print(\"SizeTrainOk\",ix,\"vs\",SizeTrainOk)\n",
    "                        filtered_elements = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 1)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            #print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                            X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        Ss=[]\n",
    "                        for sx, sensor in enumerate(sensors):\n",
    "                            Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                        L1.append(X1s)\n",
    "                        L2.append(X2s)\n",
    "                        S.append(Ss)\n",
    "                        Y.append(user_activity[index])\n",
    "                        \n",
    "                    #KO act\n",
    "                    ix=0\n",
    "                    while ix < SizeTrainKo:\n",
    "                        #print(\"SizeTrainKo\",ix,\"vs\",SizeTrainKo)\n",
    "                        filtered_elements_specific = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 0)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        none=True\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            #if(ax2==ax):\n",
    "                                r=np.random.rand()\n",
    "                                #print(\" removing loc?:\",loc_user[ax2][iu][idy][tt],r)\n",
    "                                if(r<loc_user[ax2][iu][idy][tt]+0.05):\n",
    "                                    #print(\"NOT  removing loc:\",loc_user[ax2][iu][idy][tt])\n",
    "                                    none=False\n",
    "                                    \n",
    "                                X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                                X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        if not none:\n",
    "                            L1.append(X1s)\n",
    "                            L2.append(X2s)\n",
    "                            Ss=[]\n",
    "                            for sx, sensor in enumerate(sensors):\n",
    "                                Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                            S.append(Ss)\n",
    "                            Y.append(user_activity[index])       \n",
    "                            ix=ix+1\n",
    "\n",
    "            L1=np.array(L1)        \n",
    "            L2=np.array(L2)        \n",
    "            S=np.array(S)\n",
    "            Y=np.array(Y)\n",
    "            print(\"TRAIN\",activity,day,L1.shape,L2.shape,S.shape,Y.shape)\n",
    "            \n",
    "            \n",
    "            model=getModelHAR()\n",
    "            model.summary()\n",
    "            \n",
    "            ##TEST DATA\n",
    "            TL1=[]\n",
    "            TL2=[]\n",
    "            TS=[]\n",
    "            TY=[]\n",
    "            \n",
    "            \n",
    "            (t0,tN)=t0N_days[day]\n",
    "            ts=list(range(TWA,sizeT(t0,tN)-TWB))\n",
    "            \n",
    "            for ux2,user2 in enumerate(users):\n",
    "                other_ux2= [other for other in range(0,len(users)) if other != ux2]\n",
    "\n",
    "                for tx in ts:\n",
    "\n",
    "                    Ss=[]\n",
    "                    for sx, sensor in enumerate(sensors):\n",
    "                        Ss.append(act_sensors[sx][dx][tx-TWA:tx+TWB])\n",
    "                    \n",
    "                    X1s=[]\n",
    "                    X2s=[]\n",
    "                    for ax2,activity2 in enumerate(activities):\n",
    "                        X1s.append(loc_user[ax2][ux2][dx][tx-TWA:tx+TWB])\n",
    "                        X2s.append(np.amax(loc_user[ax2,other_ux2,dx,tx-TWA:tx+TWB],axis=0))\n",
    "\n",
    "\n",
    "                    TL1.append(X1s)\n",
    "                    TL2.append(X2s)\n",
    "                    TS.append(Ss)\n",
    "                    TY.append(user_activity[ax, ux2, dx, tx])\n",
    "                        \n",
    "            TL1=np.array(TL1)        \n",
    "            TL2=np.array(TL2)        \n",
    "            TS=np.array(TS)\n",
    "            TY=np.array(TY)\n",
    "            print(\"EVAL\",activity,day,TL1.shape,TL2.shape,TS.shape,TY.shape)\n",
    "            \n",
    "            history = model.fit([L1,L2,S] , Y, shuffle=True, batch_size=32,epochs=10, validation_data = ([TL1,TL2,TS], TY))\n",
    "            YT_prediction = model.predict([TL1,TL2,TS])\n",
    "            print(YT_prediction.shape)\n",
    "            \n",
    "            ix=0\n",
    "            for ux2,user2 in enumerate(users):\n",
    "                with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/PREDICTION-TRANS-ENC-DEC-1024-45+0.\"+user2+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                    for tx in (ts):\n",
    "                        tt=tx*time_step2+t0\n",
    "                        #print(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0]))\n",
    "                        file.write(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0])+\"\\n\")\n",
    "                        \n",
    "                        ix=ix+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fc952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
