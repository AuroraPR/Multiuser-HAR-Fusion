{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934b764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2024-07-05': ['0001', '3d57', 'ed9c'], '2024-07-06': ['0001', '3d57', 'ed9c'], '2024-07-07': ['0001', '3d57', 'ed9c'], '2024-07-18': ['16fe', 'f02e', 'ed9c'], '2024-07-19': ['16fe', 'f02e', 'ed9c'], '2024-07-20': ['16fe', 'f02e', 'ed9c'], '2024-07-24': ['16fe', '5b66', 'ed9c'], '2024-07-25': ['16fe', '5b66', 'ed9c'], '2024-07-26': ['16fe', '5b66', 'ed9c'], '2024-07-27': ['16fe', '5b66', 'ed9c'], '2024-07-28': ['16fe', '5b66', 'ed9c'], '2024-07-29': ['16fe', '5b66', 'ed9c'], '2024-07-30': ['16fe', '5b66', 'ed9c'], '2024-07-31': ['16fe', '5b66', 'ed9c']}\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('agg-config.txt')\n",
    "\n",
    "\n",
    "time_step = int(config.get('Configuration', 'time_step'))\n",
    "time_step2 = int(config.get('Configuration', 'time_step2'))\n",
    "\n",
    "window_size = int(config.get('Configuration', 'window_size'))\n",
    "processed_data_folder = config.get('Configuration', 'processed_data_folder')\n",
    "raw_data_folder = config.get('Configuration', 'raw_data_folder')\n",
    "\n",
    "ini_date = config.get('Configuration', 'ini_date')\n",
    "end_date = config.get('Configuration', 'end_date')\n",
    "\n",
    "\n",
    "activities=config.get('Configuration', 'learn_activities')\n",
    "activities = [(item.strip()) for item in activities.split(',')]\n",
    "\n",
    "cross_days=config.get('Configuration', 'cross_days')\n",
    "cross_days = [(item.strip()) for item in cross_days.split(',')]\n",
    "\n",
    "sensors=config.get('Configuration', 'sensors')\n",
    "sensors = [(item.strip()) for item in sensors.split(',')]\n",
    "\n",
    "w = int(config.get('Configuration', 'w'))\n",
    "h = int(config.get('Configuration', 'h'))\n",
    "\n",
    "users_day={}\n",
    "for cross_day in cross_days:\n",
    "    users_day[cross_day]=config.get('Configuration', cross_day)\n",
    "    users_day[cross_day] = [(item.strip()) for item in users_day[cross_day].split(',')]\n",
    "print(users_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ea50ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv    \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "off_zone=60*60*2\n",
    "\n",
    "def day_time(t0,tN,ti):\n",
    "    return int((int)((ti+off_zone)/(60*60*24)))\n",
    "\n",
    "\n",
    "def time2str(t0,tN,tt):\n",
    "    return datetime.fromtimestamp(tt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def day_time0(t0,tN,ti):\n",
    "    return day_time(ti)-day_time(t0)+1\n",
    "\n",
    "def relT(t0,tN,ti):\n",
    "    return (int)((ti-t0)/time_step2)\n",
    "\n",
    "def sizeT(t0,tN):\n",
    "    return relT(t0,tN,tN)+1\n",
    "\n",
    "\n",
    "def initTime(ini_date,end_date):\n",
    "    tN = (int)(datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "\n",
    "    t0 = (int)(datetime.strptime(ini_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    print (ini_date,\"Init date is\", t0, \"day:\",day_time(t0,tN,t0), time2str(t0,tN,t0))\n",
    "    print (end_date,\"End date is\", tN, \"day:\",day_time(t0,tN,tN), time2str(t0,tN,tN))\n",
    "\n",
    "    day=list(range(day_time(t0,tN,t0),day_time(t0,tN,tN)+1))[0]\n",
    "    return day,t0,tN\n",
    "    \n",
    "initTime(ini_date,end_date)\n",
    "\n",
    "\n",
    "def getStrDatefrom(day_number):\n",
    "    # Reference date (1970-01-01)\n",
    "    reference_date = datetime(1970, 1, 1)\n",
    "    \n",
    "    # Compute the date corresponding to the day number\n",
    "    resulting_date = reference_date + timedelta(days=day_number)\n",
    "    \n",
    "    return resulting_date.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeeab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ed8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-05\n",
      "New ini_date: 2024-07-05 02:00:00\n",
      "New end_date: 2024-07-06 01:59:59\n",
      "2024-07-05 02:00:00 Init date is 1720137600 day: 19909 2024-07-05 02:00:00\n",
      "2024-07-06 01:59:59 End date is 1720223999 day: 19910 2024-07-06 01:59:59\n",
      "2024-07-06\n",
      "New ini_date: 2024-07-06 02:00:00\n",
      "New end_date: 2024-07-07 01:59:59\n",
      "2024-07-06 02:00:00 Init date is 1720224000 day: 19910 2024-07-06 02:00:00\n",
      "2024-07-07 01:59:59 End date is 1720310399 day: 19911 2024-07-07 01:59:59\n",
      "2024-07-07\n",
      "New ini_date: 2024-07-07 02:00:00\n",
      "New end_date: 2024-07-08 01:59:59\n",
      "2024-07-07 02:00:00 Init date is 1720310400 day: 19911 2024-07-07 02:00:00\n",
      "2024-07-08 01:59:59 End date is 1720396799 day: 19912 2024-07-08 01:59:59\n",
      "2024-07-18\n",
      "New ini_date: 2024-07-18 02:00:00\n",
      "New end_date: 2024-07-19 01:59:59\n",
      "2024-07-18 02:00:00 Init date is 1721260800 day: 19922 2024-07-18 02:00:00\n",
      "2024-07-19 01:59:59 End date is 1721347199 day: 19923 2024-07-19 01:59:59\n",
      "2024-07-19\n",
      "New ini_date: 2024-07-19 02:00:00\n",
      "New end_date: 2024-07-20 01:59:59\n",
      "2024-07-19 02:00:00 Init date is 1721347200 day: 19923 2024-07-19 02:00:00\n",
      "2024-07-20 01:59:59 End date is 1721433599 day: 19924 2024-07-20 01:59:59\n",
      "2024-07-20\n",
      "New ini_date: 2024-07-20 02:00:00\n",
      "New end_date: 2024-07-21 01:59:59\n",
      "2024-07-20 02:00:00 Init date is 1721433600 day: 19924 2024-07-20 02:00:00\n",
      "2024-07-21 01:59:59 End date is 1721519999 day: 19925 2024-07-21 01:59:59\n",
      "2024-07-24\n",
      "New ini_date: 2024-07-24 02:00:00\n",
      "New end_date: 2024-07-25 01:59:59\n",
      "2024-07-24 02:00:00 Init date is 1721779200 day: 19928 2024-07-24 02:00:00\n",
      "2024-07-25 01:59:59 End date is 1721865599 day: 19929 2024-07-25 01:59:59\n",
      "2024-07-25\n",
      "New ini_date: 2024-07-25 02:00:00\n",
      "New end_date: 2024-07-26 01:59:59\n",
      "2024-07-25 02:00:00 Init date is 1721865600 day: 19929 2024-07-25 02:00:00\n",
      "2024-07-26 01:59:59 End date is 1721951999 day: 19930 2024-07-26 01:59:59\n",
      "2024-07-26\n",
      "New ini_date: 2024-07-26 02:00:00\n",
      "New end_date: 2024-07-27 01:59:59\n",
      "2024-07-26 02:00:00 Init date is 1721952000 day: 19930 2024-07-26 02:00:00\n",
      "2024-07-27 01:59:59 End date is 1722038399 day: 19931 2024-07-27 01:59:59\n",
      "2024-07-27\n",
      "New ini_date: 2024-07-27 02:00:00\n",
      "New end_date: 2024-07-28 01:59:59\n",
      "2024-07-27 02:00:00 Init date is 1722038400 day: 19931 2024-07-27 02:00:00\n",
      "2024-07-28 01:59:59 End date is 1722124799 day: 19932 2024-07-28 01:59:59\n",
      "2024-07-28\n",
      "New ini_date: 2024-07-28 02:00:00\n",
      "New end_date: 2024-07-29 01:59:59\n",
      "2024-07-28 02:00:00 Init date is 1722124800 day: 19932 2024-07-28 02:00:00\n",
      "2024-07-29 01:59:59 End date is 1722211199 day: 19933 2024-07-29 01:59:59\n",
      "2024-07-29\n",
      "New ini_date: 2024-07-29 02:00:00\n",
      "New end_date: 2024-07-30 01:59:59\n",
      "2024-07-29 02:00:00 Init date is 1722211200 day: 19933 2024-07-29 02:00:00\n",
      "2024-07-30 01:59:59 End date is 1722297599 day: 19934 2024-07-30 01:59:59\n",
      "2024-07-30\n",
      "New ini_date: 2024-07-30 02:00:00\n",
      "New end_date: 2024-07-31 01:59:59\n",
      "2024-07-30 02:00:00 Init date is 1722297600 day: 19934 2024-07-30 02:00:00\n",
      "2024-07-31 01:59:59 End date is 1722383999 day: 19935 2024-07-31 01:59:59\n",
      "2024-07-31\n",
      "New ini_date: 2024-07-31 02:00:00\n",
      "New end_date: 2024-08-01 01:59:59\n",
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n",
      "[19909, 19910, 19911, 19922, 19923, 19924, 19928, 19929, 19930, 19931, 19932, 19933, 19934, 19935]\n",
      "{19909: (1720137600, 1720223999), 19910: (1720224000, 1720310399), 19911: (1720310400, 1720396799), 19922: (1721260800, 1721347199), 19923: (1721347200, 1721433599), 19924: (1721433600, 1721519999), 19928: (1721779200, 1721865599), 19929: (1721865600, 1721951999), 19930: (1721952000, 1722038399), 19931: (1722038400, 1722124799), 19932: (1722124800, 1722211199), 19933: (1722211200, 1722297599), 19934: (1722297600, 1722383999), 19935: (1722384000, 1722470399)}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "days=[]\n",
    "t0N_days={}\n",
    "\n",
    "for cross_day in cross_days:\n",
    "    print(cross_day)\n",
    "    # Convertir las fechas a objetos datetime\n",
    "    ini_date_dt = datetime.strptime(ini_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    cross_day_dt = datetime.strptime(cross_day, \"%Y-%m-%d\")\n",
    "\n",
    "    # Reemplazar el día manteniendo la hora original\n",
    "    new_ini_date = cross_day_dt.replace(hour=ini_date_dt.hour, minute=ini_date_dt.minute, second=ini_date_dt.second)\n",
    "    new_end_date = cross_day_dt.replace(hour=end_date_dt.hour, minute=end_date_dt.minute, second=end_date_dt.second) + timedelta(days=1)\n",
    "\n",
    "    # Convertir las fechas de nuevo a cadena si es necesario\n",
    "    new_ini_date_str = new_ini_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    new_end_date_str = new_end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    print(f\"New ini_date: {new_ini_date_str}\")\n",
    "    print(f\"New end_date: {new_end_date_str}\")\n",
    "    day,t0,tN=initTime(new_ini_date_str,new_end_date_str)\n",
    "    days.append(day)\n",
    "    t0N_days[day]=(t0,tN)\n",
    "    \n",
    "\n",
    "print(days)\n",
    "print(t0N_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 14, 1440)\n",
      "\t toileting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.toileting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.toileting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.toileting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.toileting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.toileting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.toileting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.toileting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.toileting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.toileting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.toileting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.toileting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.toileting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.toileting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.toileting.tsv\n",
      "19935 (1440,)\n",
      "\t resting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.resting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.resting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.resting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.resting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.resting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.resting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.resting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.resting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.resting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.resting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.resting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.resting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.resting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.resting.tsv\n",
      "19935 (1440,)\n",
      "\t exit\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.exit.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.exit.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.exit.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.exit.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.exit.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.exit.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.exit.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.exit.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.exit.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.exit.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.exit.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.exit.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.exit.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.exit.tsv\n",
      "19935 (1440,)\n",
      "\t cooking\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.cooking.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.cooking.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.cooking.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.cooking.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.cooking.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.cooking.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.cooking.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.cooking.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.cooking.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.cooking.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.cooking.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.cooking.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.cooking.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.cooking.tsv\n",
      "19935 (1440,)\n",
      "\t shower\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.shower.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.shower.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.shower.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.shower.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.shower.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.shower.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.shower.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.shower.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.shower.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.shower.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.shower.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.shower.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.shower.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.shower.tsv\n",
      "19935 (1440,)\n",
      "\t pc\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.pc.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.pc.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.pc.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.pc.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.pc.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.pc.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.pc.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.pc.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.pc.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.pc.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.pc.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.pc.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.pc.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.pc.tsv\n",
      "19935 (1440,)\n",
      "\t sleep\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.sleep.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.sleep.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.sleep.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.sleep.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.sleep.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.sleep.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.sleep.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.sleep.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.sleep.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.sleep.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.sleep.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.sleep.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.sleep.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.sleep.tsv\n",
      "19935 (1440,)\n",
      "\t kitchen\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.kitchen.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.kitchen.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.kitchen.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.kitchen.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.kitchen.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.kitchen.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.kitchen.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.kitchen.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.kitchen.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.kitchen.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.kitchen.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.kitchen.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.kitchen.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.kitchen.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "len_users=3\n",
    "loc_user=np.zeros((len(activities),len_users,len(days),sizeT(t0,tN)))\n",
    "print(loc_user.shape)\n",
    "for ax,activity in enumerate(activities):\n",
    "    print(\"\\t\",activity)\n",
    "    for dx,day in enumerate(days):\n",
    "        day_str=getStrDatefrom(day)\n",
    "        users=users_day[day_str]\n",
    "        print(day,users)\n",
    "        for ux,user in enumerate(users):\n",
    "            print(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\")\n",
    "            series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"loc\"])\n",
    "            series=series[\"loc\"].values\n",
    "            print(day,series.shape)\n",
    "            loc_user[ax][ux][dx]=series\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9631e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 14, 1440)\n",
      "\t fridge_13\n",
      "./data-har//DAY_19909/object_sensor/fridge_13.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/fridge_13.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/fridge_13.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/fridge_13.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/fridge_13.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/fridge_13.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/fridge_13.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/fridge_13.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/fridge_13.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/fridge_13.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/fridge_13.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/fridge_13.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/fridge_13.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/fridge_13.tsv\n",
      "19935 (1440,)\n",
      "\t tap_22\n",
      "./data-har//DAY_19909/object_sensor/tap_22.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/tap_22.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/tap_22.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/tap_22.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/tap_22.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/tap_22.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/tap_22.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/tap_22.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/tap_22.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/tap_22.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/tap_22.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/tap_22.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/tap_22.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/tap_22.tsv\n",
      "19935 (1440,)\n",
      "\t micro_5\n",
      "./data-har//DAY_19909/object_sensor/micro_5.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/micro_5.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/micro_5.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/micro_5.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/micro_5.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/micro_5.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/micro_5.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/micro_5.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/micro_5.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/micro_5.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/micro_5.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/micro_5.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/micro_5.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/micro_5.tsv\n",
      "19935 (1440,)\n",
      "\t pans_8\n",
      "./data-har//DAY_19909/object_sensor/pans_8.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pans_8.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pans_8.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pans_8.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pans_8.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pans_8.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pans_8.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pans_8.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pans_8.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pans_8.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pans_8.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pans_8.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pans_8.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pans_8.tsv\n",
      "19935 (1440,)\n",
      "\t dishes_9\n",
      "./data-har//DAY_19909/object_sensor/dishes_9.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/dishes_9.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/dishes_9.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/dishes_9.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/dishes_9.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/dishes_9.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/dishes_9.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/dishes_9.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/dishes_9.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/dishes_9.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/dishes_9.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/dishes_9.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/dishes_9.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/dishes_9.tsv\n",
      "19935 (1440,)\n",
      "\t shower_24_apertura\n",
      "./data-har//DAY_19909/object_sensor/shower_24_apertura.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_24_apertura.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_24_apertura.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_24_apertura.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_24_apertura.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_24_apertura.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_24_apertura.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_24_apertura.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_24_apertura.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_24_apertura.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_24_apertura.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_24_apertura.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_24_apertura.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_24_apertura.tsv\n",
      "19935 (1440,)\n",
      "\t hum_shower_25\n",
      "./data-har//DAY_19909/object_sensor/hum_shower_25.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/hum_shower_25.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/hum_shower_25.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/hum_shower_25.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/hum_shower_25.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/hum_shower_25.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/hum_shower_25.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/hum_shower_25.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/hum_shower_25.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/hum_shower_25.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/hum_shower_25.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/hum_shower_25.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/hum_shower_25.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/hum_shower_25.tsv\n",
      "19935 (1440,)\n",
      "\t shower_31\n",
      "./data-har//DAY_19909/object_sensor/shower_31.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_31.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_31.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_31.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_31.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_31.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_31.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_31.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_31.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_31.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_31.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_31.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_31.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_31.tsv\n",
      "19935 (1440,)\n",
      "\t wc_17\n",
      "./data-har//DAY_19909/object_sensor/wc_17.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/wc_17.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/wc_17.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/wc_17.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/wc_17.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/wc_17.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/wc_17.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/wc_17.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/wc_17.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/wc_17.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/wc_17.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/wc_17.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/wc_17.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/wc_17.tsv\n",
      "19935 (1440,)\n",
      "\t sink_21\n",
      "./data-har//DAY_19909/object_sensor/sink_21.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/sink_21.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/sink_21.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/sink_21.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/sink_21.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/sink_21.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/sink_21.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/sink_21.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/sink_21.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/sink_21.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/sink_21.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/sink_21.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/sink_21.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/sink_21.tsv\n",
      "19935 (1440,)\n",
      "\t pc_1_current_consumption\n",
      "./data-har//DAY_19909/object_sensor/pc_1_current_consumption.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pc_1_current_consumption.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pc_1_current_consumption.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pc_1_current_consumption.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pc_1_current_consumption.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pc_1_current_consumption.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pc_1_current_consumption.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pc_1_current_consumption.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pc_1_current_consumption.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pc_1_current_consumption.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pc_1_current_consumption.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pc_1_current_consumption.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pc_1_current_consumption.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pc_1_current_consumption.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "act_sensors=np.zeros((len(sensors),len(days),sizeT(t0,tN)))\n",
    "print(act_sensors.shape)\n",
    "for sx,sensor in enumerate(sensors):\n",
    "    print(\"\\t\",sensor)\n",
    "    for dx,day in enumerate(days):\n",
    "        print(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\")\n",
    "        series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"status\"])\n",
    "        series=series[\"status\"].values\n",
    "        print(day,series.shape)\n",
    "        act_sensors[sx][dx]=series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n"
     ]
    }
   ],
   "source": [
    "user_activity=np.zeros((len(activities),len(users),len(days),sizeT(t0,tN)))\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            df_total=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/INTERVAL.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"ix\",\"d0\",\"dN\"])\n",
    "            #print(df_total)\n",
    "            #print(pd.to_datetime(df_total['d0']))\n",
    "            df_total['d0'] = pd.to_datetime(df_total['d0'])\n",
    "            df_total['dN'] = pd.to_datetime(df_total['dN'])\n",
    "            #print(df_total)\n",
    "\n",
    "            for tx,tt in enumerate(ts):\n",
    "                ttt=pd.to_datetime(time2str(t0,tN,tt))\n",
    "#                print(ttt)\n",
    "                row = df_total[(df_total['d0'] <= ttt) & (df_total['dN'] >= ttt)]\n",
    "#                print(\"df_in#tervalo\",row)\n",
    "                if(row.size>0):\n",
    "                    user_activity[ax][ux][dx][tx]=1\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "            \n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/LABEL3.\"+user+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                for tx,tt in enumerate(ts):\n",
    "                    file.write(time2str(t0,tN,tt)+\"\\t\"+str(user_activity[ax][ux][dx][tx])+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b92a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:03:41.421168: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 13:03:41.452841: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 13:03:41.909935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'activities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Reshape, MultiHeadAttention, LayerNormalization, Dropout, Concatenate, Dense, GlobalAveragePooling1D\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m----> 6\u001b[0m N1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mactivities\u001b[49m)\n\u001b[1;32m      7\u001b[0m N2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(activities)\n\u001b[1;32m      8\u001b[0m N3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sensors)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'activities' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, concatenate, GRU, TimeDistributed, Attention, Add, Dropout,Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv1D, TimeDistributed, Flatten, Dropout, GRU, Attention, Add, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D, Concatenate, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, MultiHeadAttention, LayerNormalization, Dropout, Dense, Reshape, Concatenate, GlobalAveragePooling1D\n",
    "\n",
    "\n",
    "N1 = len(activities)\n",
    "N2 = len(activities)\n",
    "N3 = len(sensors)\n",
    "\n",
    "TWA = 30\n",
    "TWB = 15\n",
    "T = TWA + TWB\n",
    "\n",
    "def getModelHAR():\n",
    "    # Define inputs\n",
    "    input1 = Input(shape=(N1, T, 1))\n",
    "    input2 = Input(shape=(N2, T, 1))\n",
    "    input3 = Input(shape=(N3, T, 1))\n",
    "\n",
    "    # Reshape inputs for the attention mechanism \n",
    "    reshaped1 = Reshape((T, N1))(input1)\n",
    "    reshaped2 = Reshape((T, N2))(input2)\n",
    "    reshaped3 = Reshape((T, N3))(input3)\n",
    "\n",
    "    # Encoder for the first sequence\n",
    "    encoder1 = MultiHeadAttention(num_heads=8, key_dim=N1)(reshaped1, reshaped1)\n",
    "    encoder1 = LayerNormalization()(encoder1)\n",
    "    encoder1 = Dropout(0.5)(encoder1)\n",
    "\n",
    "    # Encoder for the second sequence\n",
    "    encoder2 = MultiHeadAttention(num_heads=8, key_dim=N2)(reshaped2, reshaped2)\n",
    "    encoder2 = LayerNormalization()(encoder2)\n",
    "    encoder2 = Dropout(0.5)(encoder2)\n",
    "\n",
    "    # Encoder for the third sequence\n",
    "    encoder3 = MultiHeadAttention(num_heads=8, key_dim=N3)(reshaped3, reshaped3)\n",
    "    encoder3 = LayerNormalization()(encoder3)\n",
    "    encoder3 = Dropout(0.5)(encoder3)\n",
    "\n",
    "    # Concatenation of the encoded sequences\n",
    "    merged_encoded = Concatenate(axis=-1)([encoder1, encoder2, encoder3]) \n",
    "\n",
    "    # Bottleneck layer (latent representation)\n",
    "    bottleneck = GlobalAveragePooling1D()(merged_encoded) # Pooling for classification\n",
    "    bottleneck = Dropout(0.5)(bottleneck)\n",
    "\n",
    "    # Expand dimensions for attention\n",
    "    bottleneck_expanded = tf.expand_dims(bottleneck, axis=1)  # Add temporal dimension\n",
    "\n",
    "    # Single Decoder with Multi-head Attention\n",
    "    decoder = MultiHeadAttention(num_heads=8, key_dim=bottleneck_expanded.shape[-1])(bottleneck_expanded, bottleneck_expanded)\n",
    "    decoder = tf.squeeze(decoder, axis=1)  # Remove the added temporal dimension\n",
    "    decoder = LayerNormalization()(decoder)\n",
    "    decoder = Dropout(0.5)(decoder)\n",
    "\n",
    "    # Dense layers for classification\n",
    "    dense = Dense(1024, activation='relu')(decoder)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    dense = Dense(128, activation='relu')(dense)\n",
    "    output = Dense(1, activation='sigmoid')(dense) # Binary classification\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=[input1, input2, input3], outputs=output)\n",
    "\n",
    "    # Compile the model - binary crossentropy for classification\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "    return model\n",
    "\n",
    "# Instanciación del modelo\n",
    "model = getModelHAR()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "386cb41e-bb1e-4043-b002-ea2c550f5dbd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a216fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 19909\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_117\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_358 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_359 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_360 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_357 (Reshape)          (None, 45, 8)        0           ['input_358[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_358 (Reshape)          (None, 45, 8)        0           ['input_359[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_359 (Reshape)          (None, 45, 11)       0           ['input_360[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_476 (Mult  (None, 45, 8)       2248        ['reshape_357[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_357[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_477 (Mult  (None, 45, 8)       2248        ['reshape_358[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_358[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_478 (Mult  (None, 45, 11)      4147        ['reshape_359[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_359[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_474 (Layer  (None, 45, 8)       16          ['multi_head_attention_476[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_475 (Layer  (None, 45, 8)       16          ['multi_head_attention_477[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_476 (Layer  (None, 45, 11)      22          ['multi_head_attention_478[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_710 (Dropout)          (None, 45, 8)        0           ['layer_normalization_474[0][0]']\n",
      "                                                                                                  \n",
      " dropout_711 (Dropout)          (None, 45, 8)        0           ['layer_normalization_475[0][0]']\n",
      "                                                                                                  \n",
      " dropout_712 (Dropout)          (None, 45, 11)       0           ['layer_normalization_476[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_119 (Concatenate)  (None, 45, 27)       0           ['dropout_710[0][0]',            \n",
      "                                                                  'dropout_711[0][0]',            \n",
      "                                                                  'dropout_712[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_119 (  (None, 27)          0           ['concatenate_119[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_713 (Dropout)          (None, 27)           0           ['global_average_pooling1d_119[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_118 (TFOpLambda  (None, 1, 27)       0           ['dropout_713[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_479 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_118[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_118[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_116 (TFOp  (None, 27)          0           ['multi_head_attention_479[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_477 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_116[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_714 (Dropout)          (None, 27)           0           ['layer_normalization_477[0][0]']\n",
      "                                                                                                  \n",
      " dense_351 (Dense)              (None, 1024)         28672       ['dropout_714[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_715 (Dropout)          (None, 1024)         0           ['dense_351[0][0]']              \n",
      "                                                                                                  \n",
      " dense_352 (Dense)              (None, 128)          131200      ['dropout_715[0][0]']            \n",
      "                                                                                                  \n",
      " dense_353 (Dense)              (None, 1)            129         ['dense_352[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4821 - accuracy: 0.7447 - val_loss: 0.3241 - val_accuracy: 0.7680\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3866 - accuracy: 0.8269 - val_loss: 0.2861 - val_accuracy: 0.8129\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3678 - accuracy: 0.8399 - val_loss: 0.3278 - val_accuracy: 0.8244\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3538 - accuracy: 0.8461 - val_loss: 0.3688 - val_accuracy: 0.7754\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3409 - accuracy: 0.8504 - val_loss: 0.3810 - val_accuracy: 0.7582\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3389 - accuracy: 0.8532 - val_loss: 0.3233 - val_accuracy: 0.8151\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3345 - accuracy: 0.8537 - val_loss: 0.3761 - val_accuracy: 0.7811\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3225 - accuracy: 0.8618 - val_loss: 0.3605 - val_accuracy: 0.7914\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3215 - accuracy: 0.8624 - val_loss: 0.3351 - val_accuracy: 0.8084\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3147 - accuracy: 0.8668 - val_loss: 0.2728 - val_accuracy: 0.8392\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_118\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_361 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_362 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_363 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_360 (Reshape)          (None, 45, 8)        0           ['input_361[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_361 (Reshape)          (None, 45, 8)        0           ['input_362[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_362 (Reshape)          (None, 45, 11)       0           ['input_363[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_480 (Mult  (None, 45, 8)       2248        ['reshape_360[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_360[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_481 (Mult  (None, 45, 8)       2248        ['reshape_361[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_361[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_482 (Mult  (None, 45, 11)      4147        ['reshape_362[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_362[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_478 (Layer  (None, 45, 8)       16          ['multi_head_attention_480[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_479 (Layer  (None, 45, 8)       16          ['multi_head_attention_481[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_480 (Layer  (None, 45, 11)      22          ['multi_head_attention_482[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_716 (Dropout)          (None, 45, 8)        0           ['layer_normalization_478[0][0]']\n",
      "                                                                                                  \n",
      " dropout_717 (Dropout)          (None, 45, 8)        0           ['layer_normalization_479[0][0]']\n",
      "                                                                                                  \n",
      " dropout_718 (Dropout)          (None, 45, 11)       0           ['layer_normalization_480[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_120 (Concatenate)  (None, 45, 27)       0           ['dropout_716[0][0]',            \n",
      "                                                                  'dropout_717[0][0]',            \n",
      "                                                                  'dropout_718[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_120 (  (None, 27)          0           ['concatenate_120[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_719 (Dropout)          (None, 27)           0           ['global_average_pooling1d_120[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_119 (TFOpLambda  (None, 1, 27)       0           ['dropout_719[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_483 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_119[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_119[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_117 (TFOp  (None, 27)          0           ['multi_head_attention_483[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_481 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_117[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_720 (Dropout)          (None, 27)           0           ['layer_normalization_481[0][0]']\n",
      "                                                                                                  \n",
      " dense_354 (Dense)              (None, 1024)         28672       ['dropout_720[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_721 (Dropout)          (None, 1024)         0           ['dense_354[0][0]']              \n",
      "                                                                                                  \n",
      " dense_355 (Dense)              (None, 128)          131200      ['dropout_721[0][0]']            \n",
      "                                                                                                  \n",
      " dense_356 (Dense)              (None, 1)            129         ['dense_355[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5497 - accuracy: 0.7031 - val_loss: 0.3434 - val_accuracy: 0.7594\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.4034 - accuracy: 0.7975 - val_loss: 0.3206 - val_accuracy: 0.7718\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3933 - accuracy: 0.7999 - val_loss: 0.3578 - val_accuracy: 0.7677\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3818 - accuracy: 0.8052 - val_loss: 0.3062 - val_accuracy: 0.7787\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3714 - accuracy: 0.8096 - val_loss: 0.3857 - val_accuracy: 0.7082\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3662 - accuracy: 0.8092 - val_loss: 0.3422 - val_accuracy: 0.7546\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3528 - accuracy: 0.8201 - val_loss: 0.3215 - val_accuracy: 0.7773\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3466 - accuracy: 0.8156 - val_loss: 0.3890 - val_accuracy: 0.7486\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3389 - accuracy: 0.8305 - val_loss: 0.4156 - val_accuracy: 0.7197\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3234 - accuracy: 0.8431 - val_loss: 0.4006 - val_accuracy: 0.7587\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_119\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_364 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_365 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_366 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_363 (Reshape)          (None, 45, 8)        0           ['input_364[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_364 (Reshape)          (None, 45, 8)        0           ['input_365[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_365 (Reshape)          (None, 45, 11)       0           ['input_366[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_484 (Mult  (None, 45, 8)       2248        ['reshape_363[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_363[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_485 (Mult  (None, 45, 8)       2248        ['reshape_364[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_364[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_486 (Mult  (None, 45, 11)      4147        ['reshape_365[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_365[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_482 (Layer  (None, 45, 8)       16          ['multi_head_attention_484[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_483 (Layer  (None, 45, 8)       16          ['multi_head_attention_485[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_484 (Layer  (None, 45, 11)      22          ['multi_head_attention_486[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_722 (Dropout)          (None, 45, 8)        0           ['layer_normalization_482[0][0]']\n",
      "                                                                                                  \n",
      " dropout_723 (Dropout)          (None, 45, 8)        0           ['layer_normalization_483[0][0]']\n",
      "                                                                                                  \n",
      " dropout_724 (Dropout)          (None, 45, 11)       0           ['layer_normalization_484[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_121 (Concatenate)  (None, 45, 27)       0           ['dropout_722[0][0]',            \n",
      "                                                                  'dropout_723[0][0]',            \n",
      "                                                                  'dropout_724[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_121 (  (None, 27)          0           ['concatenate_121[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_725 (Dropout)          (None, 27)           0           ['global_average_pooling1d_121[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_120 (TFOpLambda  (None, 1, 27)       0           ['dropout_725[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_487 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_120[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_120[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_118 (TFOp  (None, 27)          0           ['multi_head_attention_487[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_485 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_118[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_726 (Dropout)          (None, 27)           0           ['layer_normalization_485[0][0]']\n",
      "                                                                                                  \n",
      " dense_357 (Dense)              (None, 1024)         28672       ['dropout_726[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_727 (Dropout)          (None, 1024)         0           ['dense_357[0][0]']              \n",
      "                                                                                                  \n",
      " dense_358 (Dense)              (None, 128)          131200      ['dropout_727[0][0]']            \n",
      "                                                                                                  \n",
      " dense_359 (Dense)              (None, 1)            129         ['dense_358[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.3568 - accuracy: 0.8531 - val_loss: 0.1976 - val_accuracy: 0.9384\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2460 - accuracy: 0.9193 - val_loss: 0.1725 - val_accuracy: 0.9434\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2212 - accuracy: 0.9291 - val_loss: 0.1279 - val_accuracy: 0.9577\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2057 - accuracy: 0.9345 - val_loss: 0.1259 - val_accuracy: 0.9589\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1931 - accuracy: 0.9391 - val_loss: 0.1209 - val_accuracy: 0.9608\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1820 - accuracy: 0.9436 - val_loss: 0.1015 - val_accuracy: 0.9677\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1740 - accuracy: 0.9461 - val_loss: 0.1100 - val_accuracy: 0.9677\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1690 - accuracy: 0.9479 - val_loss: 0.1080 - val_accuracy: 0.9699\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1657 - accuracy: 0.9496 - val_loss: 0.0879 - val_accuracy: 0.9718\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1635 - accuracy: 0.9495 - val_loss: 0.1303 - val_accuracy: 0.9603\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_120\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_367 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_368 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_369 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_366 (Reshape)          (None, 45, 8)        0           ['input_367[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_367 (Reshape)          (None, 45, 8)        0           ['input_368[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_368 (Reshape)          (None, 45, 11)       0           ['input_369[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_488 (Mult  (None, 45, 8)       2248        ['reshape_366[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_366[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_489 (Mult  (None, 45, 8)       2248        ['reshape_367[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_367[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_490 (Mult  (None, 45, 11)      4147        ['reshape_368[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_368[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_486 (Layer  (None, 45, 8)       16          ['multi_head_attention_488[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_487 (Layer  (None, 45, 8)       16          ['multi_head_attention_489[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_488 (Layer  (None, 45, 11)      22          ['multi_head_attention_490[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_728 (Dropout)          (None, 45, 8)        0           ['layer_normalization_486[0][0]']\n",
      "                                                                                                  \n",
      " dropout_729 (Dropout)          (None, 45, 8)        0           ['layer_normalization_487[0][0]']\n",
      "                                                                                                  \n",
      " dropout_730 (Dropout)          (None, 45, 11)       0           ['layer_normalization_488[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_122 (Concatenate)  (None, 45, 27)       0           ['dropout_728[0][0]',            \n",
      "                                                                  'dropout_729[0][0]',            \n",
      "                                                                  'dropout_730[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_122 (  (None, 27)          0           ['concatenate_122[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_731 (Dropout)          (None, 27)           0           ['global_average_pooling1d_122[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_121 (TFOpLambda  (None, 1, 27)       0           ['dropout_731[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_491 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_121[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_121[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_119 (TFOp  (None, 27)          0           ['multi_head_attention_491[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_489 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_119[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_732 (Dropout)          (None, 27)           0           ['layer_normalization_489[0][0]']\n",
      "                                                                                                  \n",
      " dense_360 (Dense)              (None, 1024)         28672       ['dropout_732[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_733 (Dropout)          (None, 1024)         0           ['dense_360[0][0]']              \n",
      "                                                                                                  \n",
      " dense_361 (Dense)              (None, 128)          131200      ['dropout_733[0][0]']            \n",
      "                                                                                                  \n",
      " dense_362 (Dense)              (None, 1)            129         ['dense_361[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4148 - accuracy: 0.8242 - val_loss: 0.4052 - val_accuracy: 0.8303\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3562 - accuracy: 0.8548 - val_loss: 0.3298 - val_accuracy: 0.8597\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3395 - accuracy: 0.8592 - val_loss: 0.2555 - val_accuracy: 0.8877\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3284 - accuracy: 0.8609 - val_loss: 0.2977 - val_accuracy: 0.8963\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3177 - accuracy: 0.8600 - val_loss: 0.2835 - val_accuracy: 0.8521\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3077 - accuracy: 0.8625 - val_loss: 0.2433 - val_accuracy: 0.8643\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3076 - accuracy: 0.8629 - val_loss: 0.2680 - val_accuracy: 0.8454\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3025 - accuracy: 0.8644 - val_loss: 0.3066 - val_accuracy: 0.8280\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2983 - accuracy: 0.8683 - val_loss: 0.2278 - val_accuracy: 0.8932\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2955 - accuracy: 0.8671 - val_loss: 0.2546 - val_accuracy: 0.8495\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_121\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_370 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_371 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_372 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_369 (Reshape)          (None, 45, 8)        0           ['input_370[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_370 (Reshape)          (None, 45, 8)        0           ['input_371[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_371 (Reshape)          (None, 45, 11)       0           ['input_372[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_492 (Mult  (None, 45, 8)       2248        ['reshape_369[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_369[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_493 (Mult  (None, 45, 8)       2248        ['reshape_370[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_370[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_494 (Mult  (None, 45, 11)      4147        ['reshape_371[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_371[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_490 (Layer  (None, 45, 8)       16          ['multi_head_attention_492[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_491 (Layer  (None, 45, 8)       16          ['multi_head_attention_493[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_492 (Layer  (None, 45, 11)      22          ['multi_head_attention_494[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_734 (Dropout)          (None, 45, 8)        0           ['layer_normalization_490[0][0]']\n",
      "                                                                                                  \n",
      " dropout_735 (Dropout)          (None, 45, 8)        0           ['layer_normalization_491[0][0]']\n",
      "                                                                                                  \n",
      " dropout_736 (Dropout)          (None, 45, 11)       0           ['layer_normalization_492[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_123 (Concatenate)  (None, 45, 27)       0           ['dropout_734[0][0]',            \n",
      "                                                                  'dropout_735[0][0]',            \n",
      "                                                                  'dropout_736[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_123 (  (None, 27)          0           ['concatenate_123[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_737 (Dropout)          (None, 27)           0           ['global_average_pooling1d_123[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_122 (TFOpLambda  (None, 1, 27)       0           ['dropout_737[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_495 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_122[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_122[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_120 (TFOp  (None, 27)          0           ['multi_head_attention_495[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_493 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_120[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_738 (Dropout)          (None, 27)           0           ['layer_normalization_493[0][0]']\n",
      "                                                                                                  \n",
      " dense_363 (Dense)              (None, 1024)         28672       ['dropout_738[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_739 (Dropout)          (None, 1024)         0           ['dense_363[0][0]']              \n",
      "                                                                                                  \n",
      " dense_364 (Dense)              (None, 128)          131200      ['dropout_739[0][0]']            \n",
      "                                                                                                  \n",
      " dense_365 (Dense)              (None, 1)            129         ['dense_364[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.2825 - accuracy: 0.8794 - val_loss: 0.1721 - val_accuracy: 0.9094\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1850 - accuracy: 0.9364 - val_loss: 0.1126 - val_accuracy: 0.9348\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1522 - accuracy: 0.9501 - val_loss: 0.0818 - val_accuracy: 0.9556\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1305 - accuracy: 0.9597 - val_loss: 0.0742 - val_accuracy: 0.9642\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1095 - accuracy: 0.9668 - val_loss: 0.0855 - val_accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1043 - accuracy: 0.9694 - val_loss: 0.0494 - val_accuracy: 0.9795\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1076 - accuracy: 0.9681 - val_loss: 0.0664 - val_accuracy: 0.9716\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0906 - accuracy: 0.9730 - val_loss: 0.0915 - val_accuracy: 0.9668\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0938 - accuracy: 0.9731 - val_loss: 0.0514 - val_accuracy: 0.9802\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0941 - accuracy: 0.9718 - val_loss: 0.0781 - val_accuracy: 0.9713\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_122\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_373 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_374 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_375 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_372 (Reshape)          (None, 45, 8)        0           ['input_373[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_373 (Reshape)          (None, 45, 8)        0           ['input_374[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_374 (Reshape)          (None, 45, 11)       0           ['input_375[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_496 (Mult  (None, 45, 8)       2248        ['reshape_372[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_372[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_497 (Mult  (None, 45, 8)       2248        ['reshape_373[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_373[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_498 (Mult  (None, 45, 11)      4147        ['reshape_374[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_374[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_494 (Layer  (None, 45, 8)       16          ['multi_head_attention_496[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_495 (Layer  (None, 45, 8)       16          ['multi_head_attention_497[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_496 (Layer  (None, 45, 11)      22          ['multi_head_attention_498[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_740 (Dropout)          (None, 45, 8)        0           ['layer_normalization_494[0][0]']\n",
      "                                                                                                  \n",
      " dropout_741 (Dropout)          (None, 45, 8)        0           ['layer_normalization_495[0][0]']\n",
      "                                                                                                  \n",
      " dropout_742 (Dropout)          (None, 45, 11)       0           ['layer_normalization_496[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_124 (Concatenate)  (None, 45, 27)       0           ['dropout_740[0][0]',            \n",
      "                                                                  'dropout_741[0][0]',            \n",
      "                                                                  'dropout_742[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_124 (  (None, 27)          0           ['concatenate_124[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_743 (Dropout)          (None, 27)           0           ['global_average_pooling1d_124[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_123 (TFOpLambda  (None, 1, 27)       0           ['dropout_743[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_499 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_123[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_123[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_121 (TFOp  (None, 27)          0           ['multi_head_attention_499[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_497 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_121[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_744 (Dropout)          (None, 27)           0           ['layer_normalization_497[0][0]']\n",
      "                                                                                                  \n",
      " dense_366 (Dense)              (None, 1024)         28672       ['dropout_744[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_745 (Dropout)          (None, 1024)         0           ['dense_366[0][0]']              \n",
      "                                                                                                  \n",
      " dense_367 (Dense)              (None, 128)          131200      ['dropout_745[0][0]']            \n",
      "                                                                                                  \n",
      " dense_368 (Dense)              (None, 1)            129         ['dense_367[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3032 - accuracy: 0.8761 - val_loss: 0.3902 - val_accuracy: 0.7094\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2713 - accuracy: 0.8923 - val_loss: 0.2089 - val_accuracy: 0.8707\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2524 - accuracy: 0.8967 - val_loss: 0.2090 - val_accuracy: 0.8746\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2034 - accuracy: 0.9183 - val_loss: 0.1152 - val_accuracy: 0.9503\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1700 - accuracy: 0.9315 - val_loss: 0.1564 - val_accuracy: 0.9231\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1524 - accuracy: 0.9415 - val_loss: 0.0876 - val_accuracy: 0.9608\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1262 - accuracy: 0.9562 - val_loss: 0.0656 - val_accuracy: 0.9718\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1127 - accuracy: 0.9613 - val_loss: 0.0580 - val_accuracy: 0.9775\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1074 - accuracy: 0.9647 - val_loss: 0.0425 - val_accuracy: 0.9809\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0964 - accuracy: 0.9688 - val_loss: 0.0678 - val_accuracy: 0.9747\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_123\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_376 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_377 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_378 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_375 (Reshape)          (None, 45, 8)        0           ['input_376[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_376 (Reshape)          (None, 45, 8)        0           ['input_377[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_377 (Reshape)          (None, 45, 11)       0           ['input_378[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_500 (Mult  (None, 45, 8)       2248        ['reshape_375[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_375[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_501 (Mult  (None, 45, 8)       2248        ['reshape_376[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_376[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_502 (Mult  (None, 45, 11)      4147        ['reshape_377[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_377[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_498 (Layer  (None, 45, 8)       16          ['multi_head_attention_500[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_499 (Layer  (None, 45, 8)       16          ['multi_head_attention_501[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_500 (Layer  (None, 45, 11)      22          ['multi_head_attention_502[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_746 (Dropout)          (None, 45, 8)        0           ['layer_normalization_498[0][0]']\n",
      "                                                                                                  \n",
      " dropout_747 (Dropout)          (None, 45, 8)        0           ['layer_normalization_499[0][0]']\n",
      "                                                                                                  \n",
      " dropout_748 (Dropout)          (None, 45, 11)       0           ['layer_normalization_500[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_125 (Concatenate)  (None, 45, 27)       0           ['dropout_746[0][0]',            \n",
      "                                                                  'dropout_747[0][0]',            \n",
      "                                                                  'dropout_748[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_125 (  (None, 27)          0           ['concatenate_125[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_749 (Dropout)          (None, 27)           0           ['global_average_pooling1d_125[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_124 (TFOpLambda  (None, 1, 27)       0           ['dropout_749[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_503 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_124[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_124[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_122 (TFOp  (None, 27)          0           ['multi_head_attention_503[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_501 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_122[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_750 (Dropout)          (None, 27)           0           ['layer_normalization_501[0][0]']\n",
      "                                                                                                  \n",
      " dense_369 (Dense)              (None, 1024)         28672       ['dropout_750[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_751 (Dropout)          (None, 1024)         0           ['dense_369[0][0]']              \n",
      "                                                                                                  \n",
      " dense_370 (Dense)              (None, 128)          131200      ['dropout_751[0][0]']            \n",
      "                                                                                                  \n",
      " dense_371 (Dense)              (None, 1)            129         ['dense_370[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3463 - accuracy: 0.8651 - val_loss: 0.1910 - val_accuracy: 0.9288\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2671 - accuracy: 0.9067 - val_loss: 0.1298 - val_accuracy: 0.9625\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2138 - accuracy: 0.9363 - val_loss: 0.1217 - val_accuracy: 0.9637\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1954 - accuracy: 0.9419 - val_loss: 0.1002 - val_accuracy: 0.9718\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1880 - accuracy: 0.9449 - val_loss: 0.0979 - val_accuracy: 0.9740\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1817 - accuracy: 0.9473 - val_loss: 0.0872 - val_accuracy: 0.9759\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1775 - accuracy: 0.9479 - val_loss: 0.1942 - val_accuracy: 0.9333\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1692 - accuracy: 0.9500 - val_loss: 0.0707 - val_accuracy: 0.9766\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1627 - accuracy: 0.9527 - val_loss: 0.0736 - val_accuracy: 0.9814\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1547 - accuracy: 0.9553 - val_loss: 0.0664 - val_accuracy: 0.9830\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_124\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_379 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_380 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_381 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_378 (Reshape)          (None, 45, 8)        0           ['input_379[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_379 (Reshape)          (None, 45, 8)        0           ['input_380[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_380 (Reshape)          (None, 45, 11)       0           ['input_381[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_504 (Mult  (None, 45, 8)       2248        ['reshape_378[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_378[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_505 (Mult  (None, 45, 8)       2248        ['reshape_379[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_379[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_506 (Mult  (None, 45, 11)      4147        ['reshape_380[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_380[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_502 (Layer  (None, 45, 8)       16          ['multi_head_attention_504[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_503 (Layer  (None, 45, 8)       16          ['multi_head_attention_505[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_504 (Layer  (None, 45, 11)      22          ['multi_head_attention_506[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_752 (Dropout)          (None, 45, 8)        0           ['layer_normalization_502[0][0]']\n",
      "                                                                                                  \n",
      " dropout_753 (Dropout)          (None, 45, 8)        0           ['layer_normalization_503[0][0]']\n",
      "                                                                                                  \n",
      " dropout_754 (Dropout)          (None, 45, 11)       0           ['layer_normalization_504[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_126 (Concatenate)  (None, 45, 27)       0           ['dropout_752[0][0]',            \n",
      "                                                                  'dropout_753[0][0]',            \n",
      "                                                                  'dropout_754[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_126 (  (None, 27)          0           ['concatenate_126[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_755 (Dropout)          (None, 27)           0           ['global_average_pooling1d_126[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_125 (TFOpLambda  (None, 1, 27)       0           ['dropout_755[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_507 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_125[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_125[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_123 (TFOp  (None, 27)          0           ['multi_head_attention_507[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_505 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_123[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_756 (Dropout)          (None, 27)           0           ['layer_normalization_505[0][0]']\n",
      "                                                                                                  \n",
      " dense_372 (Dense)              (None, 1024)         28672       ['dropout_756[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_757 (Dropout)          (None, 1024)         0           ['dense_372[0][0]']              \n",
      "                                                                                                  \n",
      " dense_373 (Dense)              (None, 128)          131200      ['dropout_757[0][0]']            \n",
      "                                                                                                  \n",
      " dense_374 (Dense)              (None, 1)            129         ['dense_373[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3742 - accuracy: 0.8459 - val_loss: 0.3588 - val_accuracy: 0.8131\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3142 - accuracy: 0.8827 - val_loss: 0.1992 - val_accuracy: 0.9133\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3020 - accuracy: 0.8898 - val_loss: 0.2179 - val_accuracy: 0.9013\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2940 - accuracy: 0.8919 - val_loss: 0.2051 - val_accuracy: 0.9042\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2871 - accuracy: 0.8936 - val_loss: 0.2877 - val_accuracy: 0.8937\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2830 - accuracy: 0.8942 - val_loss: 0.2002 - val_accuracy: 0.9104\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2776 - accuracy: 0.8951 - val_loss: 0.2618 - val_accuracy: 0.8996\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2752 - accuracy: 0.8956 - val_loss: 0.2084 - val_accuracy: 0.9066\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2764 - accuracy: 0.8939 - val_loss: 0.2389 - val_accuracy: 0.9047\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2744 - accuracy: 0.8934 - val_loss: 0.2003 - val_accuracy: 0.9137\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 1 19910\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_125\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_382 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_383 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_384 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_381 (Reshape)          (None, 45, 8)        0           ['input_382[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_382 (Reshape)          (None, 45, 8)        0           ['input_383[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_383 (Reshape)          (None, 45, 11)       0           ['input_384[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_508 (Mult  (None, 45, 8)       2248        ['reshape_381[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_381[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_509 (Mult  (None, 45, 8)       2248        ['reshape_382[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_382[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_510 (Mult  (None, 45, 11)      4147        ['reshape_383[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_383[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_506 (Layer  (None, 45, 8)       16          ['multi_head_attention_508[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_507 (Layer  (None, 45, 8)       16          ['multi_head_attention_509[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_508 (Layer  (None, 45, 11)      22          ['multi_head_attention_510[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_758 (Dropout)          (None, 45, 8)        0           ['layer_normalization_506[0][0]']\n",
      "                                                                                                  \n",
      " dropout_759 (Dropout)          (None, 45, 8)        0           ['layer_normalization_507[0][0]']\n",
      "                                                                                                  \n",
      " dropout_760 (Dropout)          (None, 45, 11)       0           ['layer_normalization_508[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_127 (Concatenate)  (None, 45, 27)       0           ['dropout_758[0][0]',            \n",
      "                                                                  'dropout_759[0][0]',            \n",
      "                                                                  'dropout_760[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_127 (  (None, 27)          0           ['concatenate_127[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_761 (Dropout)          (None, 27)           0           ['global_average_pooling1d_127[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_126 (TFOpLambda  (None, 1, 27)       0           ['dropout_761[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_511 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_126[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_126[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_124 (TFOp  (None, 27)          0           ['multi_head_attention_511[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_509 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_124[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_762 (Dropout)          (None, 27)           0           ['layer_normalization_509[0][0]']\n",
      "                                                                                                  \n",
      " dense_375 (Dense)              (None, 1024)         28672       ['dropout_762[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_763 (Dropout)          (None, 1024)         0           ['dense_375[0][0]']              \n",
      "                                                                                                  \n",
      " dense_376 (Dense)              (None, 128)          131200      ['dropout_763[0][0]']            \n",
      "                                                                                                  \n",
      " dense_377 (Dense)              (None, 1)            129         ['dense_376[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4814 - accuracy: 0.7496 - val_loss: 0.3049 - val_accuracy: 0.8557\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3795 - accuracy: 0.8330 - val_loss: 0.2449 - val_accuracy: 0.8731\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3624 - accuracy: 0.8444 - val_loss: 0.2258 - val_accuracy: 0.8595\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3513 - accuracy: 0.8481 - val_loss: 0.2800 - val_accuracy: 0.8507\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3448 - accuracy: 0.8514 - val_loss: 0.2605 - val_accuracy: 0.8382\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3375 - accuracy: 0.8556 - val_loss: 0.2033 - val_accuracy: 0.8753\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3312 - accuracy: 0.8575 - val_loss: 0.2325 - val_accuracy: 0.8691\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3265 - accuracy: 0.8603 - val_loss: 0.1759 - val_accuracy: 0.8848\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3201 - accuracy: 0.8643 - val_loss: 0.2369 - val_accuracy: 0.8576\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3150 - accuracy: 0.8665 - val_loss: 0.2208 - val_accuracy: 0.8714\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_126\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_385 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_386 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_387 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_384 (Reshape)          (None, 45, 8)        0           ['input_385[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_385 (Reshape)          (None, 45, 8)        0           ['input_386[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_386 (Reshape)          (None, 45, 11)       0           ['input_387[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_512 (Mult  (None, 45, 8)       2248        ['reshape_384[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_384[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_513 (Mult  (None, 45, 8)       2248        ['reshape_385[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_385[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_514 (Mult  (None, 45, 11)      4147        ['reshape_386[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_386[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_510 (Layer  (None, 45, 8)       16          ['multi_head_attention_512[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_511 (Layer  (None, 45, 8)       16          ['multi_head_attention_513[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_512 (Layer  (None, 45, 11)      22          ['multi_head_attention_514[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_764 (Dropout)          (None, 45, 8)        0           ['layer_normalization_510[0][0]']\n",
      "                                                                                                  \n",
      " dropout_765 (Dropout)          (None, 45, 8)        0           ['layer_normalization_511[0][0]']\n",
      "                                                                                                  \n",
      " dropout_766 (Dropout)          (None, 45, 11)       0           ['layer_normalization_512[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_128 (Concatenate)  (None, 45, 27)       0           ['dropout_764[0][0]',            \n",
      "                                                                  'dropout_765[0][0]',            \n",
      "                                                                  'dropout_766[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_128 (  (None, 27)          0           ['concatenate_128[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_767 (Dropout)          (None, 27)           0           ['global_average_pooling1d_128[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_127 (TFOpLambda  (None, 1, 27)       0           ['dropout_767[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_515 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_127[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_127[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_125 (TFOp  (None, 27)          0           ['multi_head_attention_515[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_513 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_125[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_768 (Dropout)          (None, 27)           0           ['layer_normalization_513[0][0]']\n",
      "                                                                                                  \n",
      " dense_378 (Dense)              (None, 1024)         28672       ['dropout_768[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_769 (Dropout)          (None, 1024)         0           ['dense_378[0][0]']              \n",
      "                                                                                                  \n",
      " dense_379 (Dense)              (None, 128)          131200      ['dropout_769[0][0]']            \n",
      "                                                                                                  \n",
      " dense_380 (Dense)              (None, 1)            129         ['dense_379[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.5478 - accuracy: 0.7065 - val_loss: 0.5087 - val_accuracy: 0.5955\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4340 - accuracy: 0.7819 - val_loss: 0.2053 - val_accuracy: 0.8320\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4158 - accuracy: 0.7875 - val_loss: 0.2216 - val_accuracy: 0.8246\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4019 - accuracy: 0.7937 - val_loss: 0.2107 - val_accuracy: 0.8440\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3917 - accuracy: 0.7974 - val_loss: 0.1559 - val_accuracy: 0.8836\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3577 - accuracy: 0.8203 - val_loss: 0.1836 - val_accuracy: 0.8829\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3384 - accuracy: 0.8291 - val_loss: 0.1978 - val_accuracy: 0.9118\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3240 - accuracy: 0.8416 - val_loss: 0.2467 - val_accuracy: 0.8846\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3140 - accuracy: 0.8450 - val_loss: 0.2020 - val_accuracy: 0.8956\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3108 - accuracy: 0.8504 - val_loss: 0.2840 - val_accuracy: 0.8898\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_127\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_388 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_389 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_390 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_387 (Reshape)          (None, 45, 8)        0           ['input_388[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_388 (Reshape)          (None, 45, 8)        0           ['input_389[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_389 (Reshape)          (None, 45, 11)       0           ['input_390[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_516 (Mult  (None, 45, 8)       2248        ['reshape_387[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_387[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_517 (Mult  (None, 45, 8)       2248        ['reshape_388[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_388[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_518 (Mult  (None, 45, 11)      4147        ['reshape_389[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_389[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_514 (Layer  (None, 45, 8)       16          ['multi_head_attention_516[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_515 (Layer  (None, 45, 8)       16          ['multi_head_attention_517[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_516 (Layer  (None, 45, 11)      22          ['multi_head_attention_518[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_770 (Dropout)          (None, 45, 8)        0           ['layer_normalization_514[0][0]']\n",
      "                                                                                                  \n",
      " dropout_771 (Dropout)          (None, 45, 8)        0           ['layer_normalization_515[0][0]']\n",
      "                                                                                                  \n",
      " dropout_772 (Dropout)          (None, 45, 11)       0           ['layer_normalization_516[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_129 (Concatenate)  (None, 45, 27)       0           ['dropout_770[0][0]',            \n",
      "                                                                  'dropout_771[0][0]',            \n",
      "                                                                  'dropout_772[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_129 (  (None, 27)          0           ['concatenate_129[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_773 (Dropout)          (None, 27)           0           ['global_average_pooling1d_129[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_128 (TFOpLambda  (None, 1, 27)       0           ['dropout_773[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_519 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_128[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_128[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_126 (TFOp  (None, 27)          0           ['multi_head_attention_519[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_517 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_126[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_774 (Dropout)          (None, 27)           0           ['layer_normalization_517[0][0]']\n",
      "                                                                                                  \n",
      " dense_381 (Dense)              (None, 1024)         28672       ['dropout_774[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_775 (Dropout)          (None, 1024)         0           ['dense_381[0][0]']              \n",
      "                                                                                                  \n",
      " dense_382 (Dense)              (None, 128)          131200      ['dropout_775[0][0]']            \n",
      "                                                                                                  \n",
      " dense_383 (Dense)              (None, 1)            129         ['dense_382[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.3542 - accuracy: 0.8500 - val_loss: 0.5699 - val_accuracy: 0.8468\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2380 - accuracy: 0.9176 - val_loss: 0.4751 - val_accuracy: 0.8478\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2006 - accuracy: 0.9332 - val_loss: 0.6081 - val_accuracy: 0.8588\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1779 - accuracy: 0.9427 - val_loss: 0.4156 - val_accuracy: 0.8631\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1600 - accuracy: 0.9497 - val_loss: 0.5724 - val_accuracy: 0.8636\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1550 - accuracy: 0.9508 - val_loss: 0.4893 - val_accuracy: 0.8688\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1502 - accuracy: 0.9531 - val_loss: 0.4984 - val_accuracy: 0.8607\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1460 - accuracy: 0.9531 - val_loss: 0.4625 - val_accuracy: 0.8631\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1433 - accuracy: 0.9551 - val_loss: 0.4680 - val_accuracy: 0.8710\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1390 - accuracy: 0.9570 - val_loss: 0.4744 - val_accuracy: 0.8726\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_128\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_391 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_392 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_393 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_390 (Reshape)          (None, 45, 8)        0           ['input_391[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_391 (Reshape)          (None, 45, 8)        0           ['input_392[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_392 (Reshape)          (None, 45, 11)       0           ['input_393[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_520 (Mult  (None, 45, 8)       2248        ['reshape_390[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_390[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_521 (Mult  (None, 45, 8)       2248        ['reshape_391[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_391[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_522 (Mult  (None, 45, 11)      4147        ['reshape_392[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_392[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_518 (Layer  (None, 45, 8)       16          ['multi_head_attention_520[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_519 (Layer  (None, 45, 8)       16          ['multi_head_attention_521[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_520 (Layer  (None, 45, 11)      22          ['multi_head_attention_522[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_776 (Dropout)          (None, 45, 8)        0           ['layer_normalization_518[0][0]']\n",
      "                                                                                                  \n",
      " dropout_777 (Dropout)          (None, 45, 8)        0           ['layer_normalization_519[0][0]']\n",
      "                                                                                                  \n",
      " dropout_778 (Dropout)          (None, 45, 11)       0           ['layer_normalization_520[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_130 (Concatenate)  (None, 45, 27)       0           ['dropout_776[0][0]',            \n",
      "                                                                  'dropout_777[0][0]',            \n",
      "                                                                  'dropout_778[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_130 (  (None, 27)          0           ['concatenate_130[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_779 (Dropout)          (None, 27)           0           ['global_average_pooling1d_130[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_129 (TFOpLambda  (None, 1, 27)       0           ['dropout_779[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_523 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_129[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_129[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_127 (TFOp  (None, 27)          0           ['multi_head_attention_523[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_521 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_127[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_780 (Dropout)          (None, 27)           0           ['layer_normalization_521[0][0]']\n",
      "                                                                                                  \n",
      " dense_384 (Dense)              (None, 1024)         28672       ['dropout_780[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_781 (Dropout)          (None, 1024)         0           ['dense_384[0][0]']              \n",
      "                                                                                                  \n",
      " dense_385 (Dense)              (None, 128)          131200      ['dropout_781[0][0]']            \n",
      "                                                                                                  \n",
      " dense_386 (Dense)              (None, 1)            129         ['dense_385[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4248 - accuracy: 0.8127 - val_loss: 0.3881 - val_accuracy: 0.8253\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3618 - accuracy: 0.8545 - val_loss: 0.2499 - val_accuracy: 0.9030\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3526 - accuracy: 0.8580 - val_loss: 0.2342 - val_accuracy: 0.9016\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3437 - accuracy: 0.8597 - val_loss: 0.2755 - val_accuracy: 0.8616\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3383 - accuracy: 0.8601 - val_loss: 0.2186 - val_accuracy: 0.8894\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3325 - accuracy: 0.8609 - val_loss: 0.2914 - val_accuracy: 0.8399\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3235 - accuracy: 0.8601 - val_loss: 0.3048 - val_accuracy: 0.8437\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3173 - accuracy: 0.8621 - val_loss: 0.2925 - val_accuracy: 0.8289\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.3122 - accuracy: 0.8634 - val_loss: 0.3132 - val_accuracy: 0.8294\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3105 - accuracy: 0.8646 - val_loss: 0.1716 - val_accuracy: 0.9047\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_129\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_394 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_395 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_396 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_393 (Reshape)          (None, 45, 8)        0           ['input_394[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_394 (Reshape)          (None, 45, 8)        0           ['input_395[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_395 (Reshape)          (None, 45, 11)       0           ['input_396[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_524 (Mult  (None, 45, 8)       2248        ['reshape_393[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_393[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_525 (Mult  (None, 45, 8)       2248        ['reshape_394[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_394[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_526 (Mult  (None, 45, 11)      4147        ['reshape_395[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_395[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_522 (Layer  (None, 45, 8)       16          ['multi_head_attention_524[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_523 (Layer  (None, 45, 8)       16          ['multi_head_attention_525[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_524 (Layer  (None, 45, 11)      22          ['multi_head_attention_526[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_782 (Dropout)          (None, 45, 8)        0           ['layer_normalization_522[0][0]']\n",
      "                                                                                                  \n",
      " dropout_783 (Dropout)          (None, 45, 8)        0           ['layer_normalization_523[0][0]']\n",
      "                                                                                                  \n",
      " dropout_784 (Dropout)          (None, 45, 11)       0           ['layer_normalization_524[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_131 (Concatenate)  (None, 45, 27)       0           ['dropout_782[0][0]',            \n",
      "                                                                  'dropout_783[0][0]',            \n",
      "                                                                  'dropout_784[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_131 (  (None, 27)          0           ['concatenate_131[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_785 (Dropout)          (None, 27)           0           ['global_average_pooling1d_131[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_130 (TFOpLambda  (None, 1, 27)       0           ['dropout_785[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_527 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_130[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_130[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_128 (TFOp  (None, 27)          0           ['multi_head_attention_527[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_525 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_128[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_786 (Dropout)          (None, 27)           0           ['layer_normalization_525[0][0]']\n",
      "                                                                                                  \n",
      " dense_387 (Dense)              (None, 1024)         28672       ['dropout_786[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_787 (Dropout)          (None, 1024)         0           ['dense_387[0][0]']              \n",
      "                                                                                                  \n",
      " dense_388 (Dense)              (None, 128)          131200      ['dropout_787[0][0]']            \n",
      "                                                                                                  \n",
      " dense_389 (Dense)              (None, 1)            129         ['dense_388[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3032 - accuracy: 0.8678 - val_loss: 0.2203 - val_accuracy: 0.8886\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2102 - accuracy: 0.9248 - val_loss: 0.1984 - val_accuracy: 0.8977\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1881 - accuracy: 0.9339 - val_loss: 0.1815 - val_accuracy: 0.9039\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1670 - accuracy: 0.9426 - val_loss: 0.1826 - val_accuracy: 0.9259\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1438 - accuracy: 0.9512 - val_loss: 0.1765 - val_accuracy: 0.9209\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1309 - accuracy: 0.9572 - val_loss: 0.1856 - val_accuracy: 0.9278\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1204 - accuracy: 0.9626 - val_loss: 0.2218 - val_accuracy: 0.9245\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1160 - accuracy: 0.9640 - val_loss: 0.1788 - val_accuracy: 0.9297\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1042 - accuracy: 0.9684 - val_loss: 0.2154 - val_accuracy: 0.9312\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1050 - accuracy: 0.9689 - val_loss: 0.1719 - val_accuracy: 0.9381\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_130\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_397 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_398 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_399 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_396 (Reshape)          (None, 45, 8)        0           ['input_397[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_397 (Reshape)          (None, 45, 8)        0           ['input_398[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_398 (Reshape)          (None, 45, 11)       0           ['input_399[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_528 (Mult  (None, 45, 8)       2248        ['reshape_396[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_396[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_529 (Mult  (None, 45, 8)       2248        ['reshape_397[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_397[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_530 (Mult  (None, 45, 11)      4147        ['reshape_398[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_398[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_526 (Layer  (None, 45, 8)       16          ['multi_head_attention_528[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_527 (Layer  (None, 45, 8)       16          ['multi_head_attention_529[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_528 (Layer  (None, 45, 11)      22          ['multi_head_attention_530[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_788 (Dropout)          (None, 45, 8)        0           ['layer_normalization_526[0][0]']\n",
      "                                                                                                  \n",
      " dropout_789 (Dropout)          (None, 45, 8)        0           ['layer_normalization_527[0][0]']\n",
      "                                                                                                  \n",
      " dropout_790 (Dropout)          (None, 45, 11)       0           ['layer_normalization_528[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_132 (Concatenate)  (None, 45, 27)       0           ['dropout_788[0][0]',            \n",
      "                                                                  'dropout_789[0][0]',            \n",
      "                                                                  'dropout_790[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_132 (  (None, 27)          0           ['concatenate_132[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_791 (Dropout)          (None, 27)           0           ['global_average_pooling1d_132[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_131 (TFOpLambda  (None, 1, 27)       0           ['dropout_791[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_531 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_131[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_131[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_129 (TFOp  (None, 27)          0           ['multi_head_attention_531[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_529 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_129[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_792 (Dropout)          (None, 27)           0           ['layer_normalization_529[0][0]']\n",
      "                                                                                                  \n",
      " dense_390 (Dense)              (None, 1024)         28672       ['dropout_792[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_793 (Dropout)          (None, 1024)         0           ['dense_390[0][0]']              \n",
      "                                                                                                  \n",
      " dense_391 (Dense)              (None, 128)          131200      ['dropout_793[0][0]']            \n",
      "                                                                                                  \n",
      " dense_392 (Dense)              (None, 1)            129         ['dense_391[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.2534 - accuracy: 0.8954 - val_loss: 0.3192 - val_accuracy: 0.6932\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2050 - accuracy: 0.9074 - val_loss: 0.3095 - val_accuracy: 0.6886\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1930 - accuracy: 0.9136 - val_loss: 0.3078 - val_accuracy: 0.6867\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1733 - accuracy: 0.9333 - val_loss: 0.1492 - val_accuracy: 0.9563\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1462 - accuracy: 0.9527 - val_loss: 0.1360 - val_accuracy: 0.9544\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1379 - accuracy: 0.9564 - val_loss: 0.1263 - val_accuracy: 0.9438\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1320 - accuracy: 0.9599 - val_loss: 0.1327 - val_accuracy: 0.9510\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1279 - accuracy: 0.9609 - val_loss: 0.1191 - val_accuracy: 0.9558\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1192 - accuracy: 0.9642 - val_loss: 0.1303 - val_accuracy: 0.9570\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1148 - accuracy: 0.9676 - val_loss: 0.1135 - val_accuracy: 0.9589\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_131\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_400 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_401 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_402 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_399 (Reshape)          (None, 45, 8)        0           ['input_400[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_400 (Reshape)          (None, 45, 8)        0           ['input_401[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_401 (Reshape)          (None, 45, 11)       0           ['input_402[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_532 (Mult  (None, 45, 8)       2248        ['reshape_399[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_399[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_533 (Mult  (None, 45, 8)       2248        ['reshape_400[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_400[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_534 (Mult  (None, 45, 11)      4147        ['reshape_401[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_401[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_530 (Layer  (None, 45, 8)       16          ['multi_head_attention_532[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_531 (Layer  (None, 45, 8)       16          ['multi_head_attention_533[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_532 (Layer  (None, 45, 11)      22          ['multi_head_attention_534[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_794 (Dropout)          (None, 45, 8)        0           ['layer_normalization_530[0][0]']\n",
      "                                                                                                  \n",
      " dropout_795 (Dropout)          (None, 45, 8)        0           ['layer_normalization_531[0][0]']\n",
      "                                                                                                  \n",
      " dropout_796 (Dropout)          (None, 45, 11)       0           ['layer_normalization_532[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_133 (Concatenate)  (None, 45, 27)       0           ['dropout_794[0][0]',            \n",
      "                                                                  'dropout_795[0][0]',            \n",
      "                                                                  'dropout_796[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_133 (  (None, 27)          0           ['concatenate_133[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_797 (Dropout)          (None, 27)           0           ['global_average_pooling1d_133[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_132 (TFOpLambda  (None, 1, 27)       0           ['dropout_797[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_535 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_132[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_132[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_130 (TFOp  (None, 27)          0           ['multi_head_attention_535[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_533 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_130[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_798 (Dropout)          (None, 27)           0           ['layer_normalization_533[0][0]']\n",
      "                                                                                                  \n",
      " dense_393 (Dense)              (None, 1024)         28672       ['dropout_798[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_799 (Dropout)          (None, 1024)         0           ['dense_393[0][0]']              \n",
      "                                                                                                  \n",
      " dense_394 (Dense)              (None, 128)          131200      ['dropout_799[0][0]']            \n",
      "                                                                                                  \n",
      " dense_395 (Dense)              (None, 1)            129         ['dense_394[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3426 - accuracy: 0.8597 - val_loss: 0.4386 - val_accuracy: 0.8337\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2602 - accuracy: 0.9102 - val_loss: 0.4673 - val_accuracy: 0.8363\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2063 - accuracy: 0.9358 - val_loss: 0.5592 - val_accuracy: 0.8456\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1808 - accuracy: 0.9465 - val_loss: 0.4782 - val_accuracy: 0.8585\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1667 - accuracy: 0.9514 - val_loss: 0.5380 - val_accuracy: 0.8562\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1575 - accuracy: 0.9546 - val_loss: 0.5037 - val_accuracy: 0.8597\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1469 - accuracy: 0.9575 - val_loss: 0.5057 - val_accuracy: 0.8614\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1378 - accuracy: 0.9603 - val_loss: 0.4438 - val_accuracy: 0.8609\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1284 - accuracy: 0.9637 - val_loss: 0.4458 - val_accuracy: 0.8614\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1252 - accuracy: 0.9650 - val_loss: 0.4399 - val_accuracy: 0.8562\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_132\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_403 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_404 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_405 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_402 (Reshape)          (None, 45, 8)        0           ['input_403[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_403 (Reshape)          (None, 45, 8)        0           ['input_404[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_404 (Reshape)          (None, 45, 11)       0           ['input_405[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_536 (Mult  (None, 45, 8)       2248        ['reshape_402[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_402[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_537 (Mult  (None, 45, 8)       2248        ['reshape_403[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_403[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_538 (Mult  (None, 45, 11)      4147        ['reshape_404[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_404[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_534 (Layer  (None, 45, 8)       16          ['multi_head_attention_536[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_535 (Layer  (None, 45, 8)       16          ['multi_head_attention_537[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_536 (Layer  (None, 45, 11)      22          ['multi_head_attention_538[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_800 (Dropout)          (None, 45, 8)        0           ['layer_normalization_534[0][0]']\n",
      "                                                                                                  \n",
      " dropout_801 (Dropout)          (None, 45, 8)        0           ['layer_normalization_535[0][0]']\n",
      "                                                                                                  \n",
      " dropout_802 (Dropout)          (None, 45, 11)       0           ['layer_normalization_536[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_134 (Concatenate)  (None, 45, 27)       0           ['dropout_800[0][0]',            \n",
      "                                                                  'dropout_801[0][0]',            \n",
      "                                                                  'dropout_802[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_134 (  (None, 27)          0           ['concatenate_134[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_803 (Dropout)          (None, 27)           0           ['global_average_pooling1d_134[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_133 (TFOpLambda  (None, 1, 27)       0           ['dropout_803[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_539 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_133[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_133[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_131 (TFOp  (None, 27)          0           ['multi_head_attention_539[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_537 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_131[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_804 (Dropout)          (None, 27)           0           ['layer_normalization_537[0][0]']\n",
      "                                                                                                  \n",
      " dense_396 (Dense)              (None, 1024)         28672       ['dropout_804[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_805 (Dropout)          (None, 1024)         0           ['dense_396[0][0]']              \n",
      "                                                                                                  \n",
      " dense_397 (Dense)              (None, 128)          131200      ['dropout_805[0][0]']            \n",
      "                                                                                                  \n",
      " dense_398 (Dense)              (None, 1)            129         ['dense_397[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3594 - accuracy: 0.8532 - val_loss: 0.3515 - val_accuracy: 0.7785\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3090 - accuracy: 0.8826 - val_loss: 0.3048 - val_accuracy: 0.8031\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2978 - accuracy: 0.8871 - val_loss: 0.1695 - val_accuracy: 0.9247\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2872 - accuracy: 0.8903 - val_loss: 0.1421 - val_accuracy: 0.9484\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2790 - accuracy: 0.8932 - val_loss: 0.2052 - val_accuracy: 0.9424\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2711 - accuracy: 0.8985 - val_loss: 0.1390 - val_accuracy: 0.9527\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2719 - accuracy: 0.8966 - val_loss: 0.1153 - val_accuracy: 0.9479\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2673 - accuracy: 0.8987 - val_loss: 0.1532 - val_accuracy: 0.9513\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2626 - accuracy: 0.9002 - val_loss: 0.1066 - val_accuracy: 0.9534\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2588 - accuracy: 0.9011 - val_loss: 0.1718 - val_accuracy: 0.9474\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "\t 2 19911\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_133\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_406 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_407 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_408 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_405 (Reshape)          (None, 45, 8)        0           ['input_406[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_406 (Reshape)          (None, 45, 8)        0           ['input_407[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_407 (Reshape)          (None, 45, 11)       0           ['input_408[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_540 (Mult  (None, 45, 8)       2248        ['reshape_405[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_405[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_541 (Mult  (None, 45, 8)       2248        ['reshape_406[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_406[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_542 (Mult  (None, 45, 11)      4147        ['reshape_407[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_407[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_538 (Layer  (None, 45, 8)       16          ['multi_head_attention_540[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_539 (Layer  (None, 45, 8)       16          ['multi_head_attention_541[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_540 (Layer  (None, 45, 11)      22          ['multi_head_attention_542[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_806 (Dropout)          (None, 45, 8)        0           ['layer_normalization_538[0][0]']\n",
      "                                                                                                  \n",
      " dropout_807 (Dropout)          (None, 45, 8)        0           ['layer_normalization_539[0][0]']\n",
      "                                                                                                  \n",
      " dropout_808 (Dropout)          (None, 45, 11)       0           ['layer_normalization_540[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_135 (Concatenate)  (None, 45, 27)       0           ['dropout_806[0][0]',            \n",
      "                                                                  'dropout_807[0][0]',            \n",
      "                                                                  'dropout_808[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_135 (  (None, 27)          0           ['concatenate_135[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_809 (Dropout)          (None, 27)           0           ['global_average_pooling1d_135[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_134 (TFOpLambda  (None, 1, 27)       0           ['dropout_809[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_543 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_134[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_134[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_132 (TFOp  (None, 27)          0           ['multi_head_attention_543[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_541 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_132[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_810 (Dropout)          (None, 27)           0           ['layer_normalization_541[0][0]']\n",
      "                                                                                                  \n",
      " dense_399 (Dense)              (None, 1024)         28672       ['dropout_810[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_811 (Dropout)          (None, 1024)         0           ['dense_399[0][0]']              \n",
      "                                                                                                  \n",
      " dense_400 (Dense)              (None, 128)          131200      ['dropout_811[0][0]']            \n",
      "                                                                                                  \n",
      " dense_401 (Dense)              (None, 1)            129         ['dense_400[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4633 - accuracy: 0.7681 - val_loss: 0.3756 - val_accuracy: 0.7575\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3725 - accuracy: 0.8349 - val_loss: 0.3997 - val_accuracy: 0.7391\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3553 - accuracy: 0.8457 - val_loss: 0.3532 - val_accuracy: 0.7505\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3431 - accuracy: 0.8525 - val_loss: 0.3935 - val_accuracy: 0.7529\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3347 - accuracy: 0.8549 - val_loss: 0.3169 - val_accuracy: 0.7919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3287 - accuracy: 0.8584 - val_loss: 0.2952 - val_accuracy: 0.8048\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3259 - accuracy: 0.8597 - val_loss: 0.3753 - val_accuracy: 0.7830\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3193 - accuracy: 0.8644 - val_loss: 0.3163 - val_accuracy: 0.8014\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3160 - accuracy: 0.8668 - val_loss: 0.3283 - val_accuracy: 0.7928\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3122 - accuracy: 0.8672 - val_loss: 0.2898 - val_accuracy: 0.8179\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_134\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_409 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_410 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_411 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_408 (Reshape)          (None, 45, 8)        0           ['input_409[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_409 (Reshape)          (None, 45, 8)        0           ['input_410[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_410 (Reshape)          (None, 45, 11)       0           ['input_411[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_544 (Mult  (None, 45, 8)       2248        ['reshape_408[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_408[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_545 (Mult  (None, 45, 8)       2248        ['reshape_409[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_409[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_546 (Mult  (None, 45, 11)      4147        ['reshape_410[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_410[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_542 (Layer  (None, 45, 8)       16          ['multi_head_attention_544[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_543 (Layer  (None, 45, 8)       16          ['multi_head_attention_545[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_544 (Layer  (None, 45, 11)      22          ['multi_head_attention_546[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_812 (Dropout)          (None, 45, 8)        0           ['layer_normalization_542[0][0]']\n",
      "                                                                                                  \n",
      " dropout_813 (Dropout)          (None, 45, 8)        0           ['layer_normalization_543[0][0]']\n",
      "                                                                                                  \n",
      " dropout_814 (Dropout)          (None, 45, 11)       0           ['layer_normalization_544[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_136 (Concatenate)  (None, 45, 27)       0           ['dropout_812[0][0]',            \n",
      "                                                                  'dropout_813[0][0]',            \n",
      "                                                                  'dropout_814[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_136 (  (None, 27)          0           ['concatenate_136[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_815 (Dropout)          (None, 27)           0           ['global_average_pooling1d_136[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_135 (TFOpLambda  (None, 1, 27)       0           ['dropout_815[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_547 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_135[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_135[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_133 (TFOp  (None, 27)          0           ['multi_head_attention_547[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_545 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_133[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_816 (Dropout)          (None, 27)           0           ['layer_normalization_545[0][0]']\n",
      "                                                                                                  \n",
      " dense_402 (Dense)              (None, 1024)         28672       ['dropout_816[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_817 (Dropout)          (None, 1024)         0           ['dense_402[0][0]']              \n",
      "                                                                                                  \n",
      " dense_403 (Dense)              (None, 128)          131200      ['dropout_817[0][0]']            \n",
      "                                                                                                  \n",
      " dense_404 (Dense)              (None, 1)            129         ['dense_403[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.5307 - accuracy: 0.7196 - val_loss: 0.3963 - val_accuracy: 0.7725\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3986 - accuracy: 0.7997 - val_loss: 0.3629 - val_accuracy: 0.8103\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4070 - accuracy: 0.7939 - val_loss: 0.3338 - val_accuracy: 0.8160\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3697 - accuracy: 0.8206 - val_loss: 0.3461 - val_accuracy: 0.8251\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3553 - accuracy: 0.8279 - val_loss: 0.3245 - val_accuracy: 0.8112\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3499 - accuracy: 0.8338 - val_loss: 0.3159 - val_accuracy: 0.8315\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3410 - accuracy: 0.8360 - val_loss: 0.3230 - val_accuracy: 0.8385\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3332 - accuracy: 0.8397 - val_loss: 0.3140 - val_accuracy: 0.8387\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3249 - accuracy: 0.8417 - val_loss: 0.2940 - val_accuracy: 0.8516\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3184 - accuracy: 0.8455 - val_loss: 0.2985 - val_accuracy: 0.8444\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_135\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_412 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_413 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_414 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_411 (Reshape)          (None, 45, 8)        0           ['input_412[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_412 (Reshape)          (None, 45, 8)        0           ['input_413[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_413 (Reshape)          (None, 45, 11)       0           ['input_414[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_548 (Mult  (None, 45, 8)       2248        ['reshape_411[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_411[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_549 (Mult  (None, 45, 8)       2248        ['reshape_412[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_412[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_550 (Mult  (None, 45, 11)      4147        ['reshape_413[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_413[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_546 (Layer  (None, 45, 8)       16          ['multi_head_attention_548[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_547 (Layer  (None, 45, 8)       16          ['multi_head_attention_549[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_548 (Layer  (None, 45, 11)      22          ['multi_head_attention_550[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_818 (Dropout)          (None, 45, 8)        0           ['layer_normalization_546[0][0]']\n",
      "                                                                                                  \n",
      " dropout_819 (Dropout)          (None, 45, 8)        0           ['layer_normalization_547[0][0]']\n",
      "                                                                                                  \n",
      " dropout_820 (Dropout)          (None, 45, 11)       0           ['layer_normalization_548[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_137 (Concatenate)  (None, 45, 27)       0           ['dropout_818[0][0]',            \n",
      "                                                                  'dropout_819[0][0]',            \n",
      "                                                                  'dropout_820[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_137 (  (None, 27)          0           ['concatenate_137[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_821 (Dropout)          (None, 27)           0           ['global_average_pooling1d_137[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_136 (TFOpLambda  (None, 1, 27)       0           ['dropout_821[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_551 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_136[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_136[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_134 (TFOp  (None, 27)          0           ['multi_head_attention_551[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_549 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_134[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_822 (Dropout)          (None, 27)           0           ['layer_normalization_549[0][0]']\n",
      "                                                                                                  \n",
      " dense_405 (Dense)              (None, 1024)         28672       ['dropout_822[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_823 (Dropout)          (None, 1024)         0           ['dense_405[0][0]']              \n",
      "                                                                                                  \n",
      " dense_406 (Dense)              (None, 128)          131200      ['dropout_823[0][0]']            \n",
      "                                                                                                  \n",
      " dense_407 (Dense)              (None, 1)            129         ['dense_406[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3606 - accuracy: 0.8429 - val_loss: 0.4980 - val_accuracy: 0.8127\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2273 - accuracy: 0.9253 - val_loss: 0.4976 - val_accuracy: 0.8165\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.2093 - accuracy: 0.9311 - val_loss: 0.6695 - val_accuracy: 0.7866\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1931 - accuracy: 0.9376 - val_loss: 0.5638 - val_accuracy: 0.8244\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1773 - accuracy: 0.9416 - val_loss: 0.6232 - val_accuracy: 0.8337\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1609 - accuracy: 0.9501 - val_loss: 0.5422 - val_accuracy: 0.8363\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1528 - accuracy: 0.9503 - val_loss: 0.6674 - val_accuracy: 0.8356\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1480 - accuracy: 0.9531 - val_loss: 0.5758 - val_accuracy: 0.8260\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1400 - accuracy: 0.9557 - val_loss: 0.6049 - val_accuracy: 0.8409\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1418 - accuracy: 0.9559 - val_loss: 0.6334 - val_accuracy: 0.8112\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_136\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_415 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_416 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_417 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_414 (Reshape)          (None, 45, 8)        0           ['input_415[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_415 (Reshape)          (None, 45, 8)        0           ['input_416[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_416 (Reshape)          (None, 45, 11)       0           ['input_417[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_552 (Mult  (None, 45, 8)       2248        ['reshape_414[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_414[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_553 (Mult  (None, 45, 8)       2248        ['reshape_415[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_415[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_554 (Mult  (None, 45, 11)      4147        ['reshape_416[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_416[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_550 (Layer  (None, 45, 8)       16          ['multi_head_attention_552[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_551 (Layer  (None, 45, 8)       16          ['multi_head_attention_553[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_552 (Layer  (None, 45, 11)      22          ['multi_head_attention_554[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_824 (Dropout)          (None, 45, 8)        0           ['layer_normalization_550[0][0]']\n",
      "                                                                                                  \n",
      " dropout_825 (Dropout)          (None, 45, 8)        0           ['layer_normalization_551[0][0]']\n",
      "                                                                                                  \n",
      " dropout_826 (Dropout)          (None, 45, 11)       0           ['layer_normalization_552[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_138 (Concatenate)  (None, 45, 27)       0           ['dropout_824[0][0]',            \n",
      "                                                                  'dropout_825[0][0]',            \n",
      "                                                                  'dropout_826[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_138 (  (None, 27)          0           ['concatenate_138[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_827 (Dropout)          (None, 27)           0           ['global_average_pooling1d_138[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_137 (TFOpLambda  (None, 1, 27)       0           ['dropout_827[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_555 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_137[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_137[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_135 (TFOp  (None, 27)          0           ['multi_head_attention_555[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_553 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_135[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_828 (Dropout)          (None, 27)           0           ['layer_normalization_553[0][0]']\n",
      "                                                                                                  \n",
      " dense_408 (Dense)              (None, 1024)         28672       ['dropout_828[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_829 (Dropout)          (None, 1024)         0           ['dense_408[0][0]']              \n",
      "                                                                                                  \n",
      " dense_409 (Dense)              (None, 128)          131200      ['dropout_829[0][0]']            \n",
      "                                                                                                  \n",
      " dense_410 (Dense)              (None, 1)            129         ['dense_409[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4334 - accuracy: 0.8056 - val_loss: 0.2428 - val_accuracy: 0.9109\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3746 - accuracy: 0.8438 - val_loss: 0.3230 - val_accuracy: 0.8681\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3595 - accuracy: 0.8500 - val_loss: 0.3070 - val_accuracy: 0.8557\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3408 - accuracy: 0.8545 - val_loss: 0.2686 - val_accuracy: 0.8612\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3332 - accuracy: 0.8551 - val_loss: 0.2980 - val_accuracy: 0.8526\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3214 - accuracy: 0.8569 - val_loss: 0.2627 - val_accuracy: 0.8487\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3166 - accuracy: 0.8608 - val_loss: 0.2418 - val_accuracy: 0.8717\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.3088 - accuracy: 0.8645 - val_loss: 0.2612 - val_accuracy: 0.8540\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3043 - accuracy: 0.8666 - val_loss: 0.2991 - val_accuracy: 0.8626\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3016 - accuracy: 0.8664 - val_loss: 0.2461 - val_accuracy: 0.8502\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_137\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_418 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_419 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_420 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_417 (Reshape)          (None, 45, 8)        0           ['input_418[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_418 (Reshape)          (None, 45, 8)        0           ['input_419[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_419 (Reshape)          (None, 45, 11)       0           ['input_420[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_556 (Mult  (None, 45, 8)       2248        ['reshape_417[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_417[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_557 (Mult  (None, 45, 8)       2248        ['reshape_418[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_418[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_558 (Mult  (None, 45, 11)      4147        ['reshape_419[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_419[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_554 (Layer  (None, 45, 8)       16          ['multi_head_attention_556[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_555 (Layer  (None, 45, 8)       16          ['multi_head_attention_557[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_556 (Layer  (None, 45, 11)      22          ['multi_head_attention_558[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_830 (Dropout)          (None, 45, 8)        0           ['layer_normalization_554[0][0]']\n",
      "                                                                                                  \n",
      " dropout_831 (Dropout)          (None, 45, 8)        0           ['layer_normalization_555[0][0]']\n",
      "                                                                                                  \n",
      " dropout_832 (Dropout)          (None, 45, 11)       0           ['layer_normalization_556[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_139 (Concatenate)  (None, 45, 27)       0           ['dropout_830[0][0]',            \n",
      "                                                                  'dropout_831[0][0]',            \n",
      "                                                                  'dropout_832[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_139 (  (None, 27)          0           ['concatenate_139[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_833 (Dropout)          (None, 27)           0           ['global_average_pooling1d_139[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_138 (TFOpLambda  (None, 1, 27)       0           ['dropout_833[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_559 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_138[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_138[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_136 (TFOp  (None, 27)          0           ['multi_head_attention_559[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_557 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_136[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_834 (Dropout)          (None, 27)           0           ['layer_normalization_557[0][0]']\n",
      "                                                                                                  \n",
      " dense_411 (Dense)              (None, 1024)         28672       ['dropout_834[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_835 (Dropout)          (None, 1024)         0           ['dense_411[0][0]']              \n",
      "                                                                                                  \n",
      " dense_412 (Dense)              (None, 128)          131200      ['dropout_835[0][0]']            \n",
      "                                                                                                  \n",
      " dense_413 (Dense)              (None, 1)            129         ['dense_412[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3047 - accuracy: 0.8655 - val_loss: 0.4590 - val_accuracy: 0.7785\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1947 - accuracy: 0.9313 - val_loss: 0.2234 - val_accuracy: 0.8877\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1620 - accuracy: 0.9458 - val_loss: 0.2081 - val_accuracy: 0.9018\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1354 - accuracy: 0.9570 - val_loss: 0.0836 - val_accuracy: 0.9618\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1274 - accuracy: 0.9591 - val_loss: 0.1711 - val_accuracy: 0.9333\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1159 - accuracy: 0.9652 - val_loss: 0.1383 - val_accuracy: 0.9486\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1104 - accuracy: 0.9670 - val_loss: 0.1673 - val_accuracy: 0.9438\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.1069 - accuracy: 0.9685 - val_loss: 0.1985 - val_accuracy: 0.9221\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1017 - accuracy: 0.9704 - val_loss: 0.1400 - val_accuracy: 0.9501\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1010 - accuracy: 0.9708 - val_loss: 0.1363 - val_accuracy: 0.9529\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_138\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_421 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_422 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_423 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_420 (Reshape)          (None, 45, 8)        0           ['input_421[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_421 (Reshape)          (None, 45, 8)        0           ['input_422[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_422 (Reshape)          (None, 45, 11)       0           ['input_423[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_560 (Mult  (None, 45, 8)       2248        ['reshape_420[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_420[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_561 (Mult  (None, 45, 8)       2248        ['reshape_421[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_421[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_562 (Mult  (None, 45, 11)      4147        ['reshape_422[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_422[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_558 (Layer  (None, 45, 8)       16          ['multi_head_attention_560[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_559 (Layer  (None, 45, 8)       16          ['multi_head_attention_561[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_560 (Layer  (None, 45, 11)      22          ['multi_head_attention_562[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_836 (Dropout)          (None, 45, 8)        0           ['layer_normalization_558[0][0]']\n",
      "                                                                                                  \n",
      " dropout_837 (Dropout)          (None, 45, 8)        0           ['layer_normalization_559[0][0]']\n",
      "                                                                                                  \n",
      " dropout_838 (Dropout)          (None, 45, 11)       0           ['layer_normalization_560[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_140 (Concatenate)  (None, 45, 27)       0           ['dropout_836[0][0]',            \n",
      "                                                                  'dropout_837[0][0]',            \n",
      "                                                                  'dropout_838[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_140 (  (None, 27)          0           ['concatenate_140[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_839 (Dropout)          (None, 27)           0           ['global_average_pooling1d_140[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_139 (TFOpLambda  (None, 1, 27)       0           ['dropout_839[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_563 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_139[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_139[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_137 (TFOp  (None, 27)          0           ['multi_head_attention_563[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_561 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_137[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_840 (Dropout)          (None, 27)           0           ['layer_normalization_561[0][0]']\n",
      "                                                                                                  \n",
      " dense_414 (Dense)              (None, 1024)         28672       ['dropout_840[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_841 (Dropout)          (None, 1024)         0           ['dense_414[0][0]']              \n",
      "                                                                                                  \n",
      " dense_415 (Dense)              (None, 128)          131200      ['dropout_841[0][0]']            \n",
      "                                                                                                  \n",
      " dense_416 (Dense)              (None, 1)            129         ['dense_415[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.2816 - accuracy: 0.8858 - val_loss: 0.4053 - val_accuracy: 0.6872\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2270 - accuracy: 0.9006 - val_loss: 0.4367 - val_accuracy: 0.6755\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2151 - accuracy: 0.9019 - val_loss: 0.4351 - val_accuracy: 0.6538\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2089 - accuracy: 0.9023 - val_loss: 0.4511 - val_accuracy: 0.7130\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1960 - accuracy: 0.9070 - val_loss: 0.3718 - val_accuracy: 0.7278\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1868 - accuracy: 0.9168 - val_loss: 0.3565 - val_accuracy: 0.8815\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1749 - accuracy: 0.9255 - val_loss: 0.3804 - val_accuracy: 0.9121\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1598 - accuracy: 0.9362 - val_loss: 0.2720 - val_accuracy: 0.9027\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1458 - accuracy: 0.9496 - val_loss: 0.3574 - val_accuracy: 0.8820\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1311 - accuracy: 0.9579 - val_loss: 0.3062 - val_accuracy: 0.8982\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_139\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_424 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_425 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_426 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_423 (Reshape)          (None, 45, 8)        0           ['input_424[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_424 (Reshape)          (None, 45, 8)        0           ['input_425[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_425 (Reshape)          (None, 45, 11)       0           ['input_426[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_564 (Mult  (None, 45, 8)       2248        ['reshape_423[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_423[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_565 (Mult  (None, 45, 8)       2248        ['reshape_424[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_424[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_566 (Mult  (None, 45, 11)      4147        ['reshape_425[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_425[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_562 (Layer  (None, 45, 8)       16          ['multi_head_attention_564[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_563 (Layer  (None, 45, 8)       16          ['multi_head_attention_565[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_564 (Layer  (None, 45, 11)      22          ['multi_head_attention_566[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_842 (Dropout)          (None, 45, 8)        0           ['layer_normalization_562[0][0]']\n",
      "                                                                                                  \n",
      " dropout_843 (Dropout)          (None, 45, 8)        0           ['layer_normalization_563[0][0]']\n",
      "                                                                                                  \n",
      " dropout_844 (Dropout)          (None, 45, 11)       0           ['layer_normalization_564[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_141 (Concatenate)  (None, 45, 27)       0           ['dropout_842[0][0]',            \n",
      "                                                                  'dropout_843[0][0]',            \n",
      "                                                                  'dropout_844[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_141 (  (None, 27)          0           ['concatenate_141[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_845 (Dropout)          (None, 27)           0           ['global_average_pooling1d_141[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_140 (TFOpLambda  (None, 1, 27)       0           ['dropout_845[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_567 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_140[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_140[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_138 (TFOp  (None, 27)          0           ['multi_head_attention_567[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_565 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_138[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_846 (Dropout)          (None, 27)           0           ['layer_normalization_565[0][0]']\n",
      "                                                                                                  \n",
      " dense_417 (Dense)              (None, 1024)         28672       ['dropout_846[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_847 (Dropout)          (None, 1024)         0           ['dense_417[0][0]']              \n",
      "                                                                                                  \n",
      " dense_418 (Dense)              (None, 128)          131200      ['dropout_847[0][0]']            \n",
      "                                                                                                  \n",
      " dense_419 (Dense)              (None, 1)            129         ['dense_418[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.3178 - accuracy: 0.8812 - val_loss: 0.4744 - val_accuracy: 0.8392\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2010 - accuracy: 0.9394 - val_loss: 0.4385 - val_accuracy: 0.8540\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1788 - accuracy: 0.9489 - val_loss: 0.5031 - val_accuracy: 0.8540\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1676 - accuracy: 0.9530 - val_loss: 0.4950 - val_accuracy: 0.8588\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1542 - accuracy: 0.9568 - val_loss: 0.5369 - val_accuracy: 0.8346\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1474 - accuracy: 0.9586 - val_loss: 0.5394 - val_accuracy: 0.8504\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1387 - accuracy: 0.9616 - val_loss: 0.4806 - val_accuracy: 0.8566\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1306 - accuracy: 0.9643 - val_loss: 0.4727 - val_accuracy: 0.8645\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1210 - accuracy: 0.9679 - val_loss: 0.4996 - val_accuracy: 0.8595\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1175 - accuracy: 0.9684 - val_loss: 0.4349 - val_accuracy: 0.8655\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_140\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_427 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_428 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_429 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_426 (Reshape)          (None, 45, 8)        0           ['input_427[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_427 (Reshape)          (None, 45, 8)        0           ['input_428[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_428 (Reshape)          (None, 45, 11)       0           ['input_429[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_568 (Mult  (None, 45, 8)       2248        ['reshape_426[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_426[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_569 (Mult  (None, 45, 8)       2248        ['reshape_427[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_427[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_570 (Mult  (None, 45, 11)      4147        ['reshape_428[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_428[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_566 (Layer  (None, 45, 8)       16          ['multi_head_attention_568[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_567 (Layer  (None, 45, 8)       16          ['multi_head_attention_569[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_568 (Layer  (None, 45, 11)      22          ['multi_head_attention_570[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_848 (Dropout)          (None, 45, 8)        0           ['layer_normalization_566[0][0]']\n",
      "                                                                                                  \n",
      " dropout_849 (Dropout)          (None, 45, 8)        0           ['layer_normalization_567[0][0]']\n",
      "                                                                                                  \n",
      " dropout_850 (Dropout)          (None, 45, 11)       0           ['layer_normalization_568[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_142 (Concatenate)  (None, 45, 27)       0           ['dropout_848[0][0]',            \n",
      "                                                                  'dropout_849[0][0]',            \n",
      "                                                                  'dropout_850[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_142 (  (None, 27)          0           ['concatenate_142[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_851 (Dropout)          (None, 27)           0           ['global_average_pooling1d_142[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_141 (TFOpLambda  (None, 1, 27)       0           ['dropout_851[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_571 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_141[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_141[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_139 (TFOp  (None, 27)          0           ['multi_head_attention_571[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_569 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_139[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_852 (Dropout)          (None, 27)           0           ['layer_normalization_569[0][0]']\n",
      "                                                                                                  \n",
      " dense_420 (Dense)              (None, 1024)         28672       ['dropout_852[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_853 (Dropout)          (None, 1024)         0           ['dense_420[0][0]']              \n",
      "                                                                                                  \n",
      " dense_421 (Dense)              (None, 128)          131200      ['dropout_853[0][0]']            \n",
      "                                                                                                  \n",
      " dense_422 (Dense)              (None, 1)            129         ['dense_421[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3708 - accuracy: 0.8491 - val_loss: 0.3028 - val_accuracy: 0.8827\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3158 - accuracy: 0.8792 - val_loss: 0.3488 - val_accuracy: 0.8741\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2980 - accuracy: 0.8904 - val_loss: 0.2258 - val_accuracy: 0.8894\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2916 - accuracy: 0.8932 - val_loss: 0.2184 - val_accuracy: 0.8963\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2805 - accuracy: 0.8966 - val_loss: 0.2378 - val_accuracy: 0.8949\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2765 - accuracy: 0.8981 - val_loss: 0.2330 - val_accuracy: 0.8941\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2705 - accuracy: 0.9018 - val_loss: 0.2372 - val_accuracy: 0.8918\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2639 - accuracy: 0.9012 - val_loss: 0.2993 - val_accuracy: 0.8607\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2634 - accuracy: 0.9004 - val_loss: 0.2145 - val_accuracy: 0.9097\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2609 - accuracy: 0.9001 - val_loss: 0.2884 - val_accuracy: 0.8667\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 3 19922\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_141\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_430 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_431 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_432 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_429 (Reshape)          (None, 45, 8)        0           ['input_430[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_430 (Reshape)          (None, 45, 8)        0           ['input_431[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_431 (Reshape)          (None, 45, 11)       0           ['input_432[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_572 (Mult  (None, 45, 8)       2248        ['reshape_429[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_429[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_573 (Mult  (None, 45, 8)       2248        ['reshape_430[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_430[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_574 (Mult  (None, 45, 11)      4147        ['reshape_431[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_431[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_570 (Layer  (None, 45, 8)       16          ['multi_head_attention_572[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_571 (Layer  (None, 45, 8)       16          ['multi_head_attention_573[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_572 (Layer  (None, 45, 11)      22          ['multi_head_attention_574[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_854 (Dropout)          (None, 45, 8)        0           ['layer_normalization_570[0][0]']\n",
      "                                                                                                  \n",
      " dropout_855 (Dropout)          (None, 45, 8)        0           ['layer_normalization_571[0][0]']\n",
      "                                                                                                  \n",
      " dropout_856 (Dropout)          (None, 45, 11)       0           ['layer_normalization_572[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_143 (Concatenate)  (None, 45, 27)       0           ['dropout_854[0][0]',            \n",
      "                                                                  'dropout_855[0][0]',            \n",
      "                                                                  'dropout_856[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_143 (  (None, 27)          0           ['concatenate_143[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_857 (Dropout)          (None, 27)           0           ['global_average_pooling1d_143[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_142 (TFOpLambda  (None, 1, 27)       0           ['dropout_857[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_575 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_142[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_142[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_140 (TFOp  (None, 27)          0           ['multi_head_attention_575[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_573 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_140[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_858 (Dropout)          (None, 27)           0           ['layer_normalization_573[0][0]']\n",
      "                                                                                                  \n",
      " dense_423 (Dense)              (None, 1024)         28672       ['dropout_858[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_859 (Dropout)          (None, 1024)         0           ['dense_423[0][0]']              \n",
      "                                                                                                  \n",
      " dense_424 (Dense)              (None, 128)          131200      ['dropout_859[0][0]']            \n",
      "                                                                                                  \n",
      " dense_425 (Dense)              (None, 1)            129         ['dense_424[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4615 - accuracy: 0.7655 - val_loss: 0.3755 - val_accuracy: 0.7319\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3708 - accuracy: 0.8376 - val_loss: 0.4214 - val_accuracy: 0.7479\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3534 - accuracy: 0.8454 - val_loss: 0.3986 - val_accuracy: 0.7508\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3450 - accuracy: 0.8503 - val_loss: 0.3500 - val_accuracy: 0.7816\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3381 - accuracy: 0.8543 - val_loss: 0.3627 - val_accuracy: 0.7603\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3338 - accuracy: 0.8577 - val_loss: 0.3591 - val_accuracy: 0.7730\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3290 - accuracy: 0.8606 - val_loss: 0.3351 - val_accuracy: 0.7888\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3213 - accuracy: 0.8646 - val_loss: 0.3597 - val_accuracy: 0.7833\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3188 - accuracy: 0.8649 - val_loss: 0.3754 - val_accuracy: 0.7663\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3156 - accuracy: 0.8659 - val_loss: 0.4038 - val_accuracy: 0.7778\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_142\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_433 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_434 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_435 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_432 (Reshape)          (None, 45, 8)        0           ['input_433[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_433 (Reshape)          (None, 45, 8)        0           ['input_434[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_434 (Reshape)          (None, 45, 11)       0           ['input_435[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_576 (Mult  (None, 45, 8)       2248        ['reshape_432[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_432[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_577 (Mult  (None, 45, 8)       2248        ['reshape_433[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_433[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_578 (Mult  (None, 45, 11)      4147        ['reshape_434[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_434[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_574 (Layer  (None, 45, 8)       16          ['multi_head_attention_576[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_575 (Layer  (None, 45, 8)       16          ['multi_head_attention_577[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_576 (Layer  (None, 45, 11)      22          ['multi_head_attention_578[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_860 (Dropout)          (None, 45, 8)        0           ['layer_normalization_574[0][0]']\n",
      "                                                                                                  \n",
      " dropout_861 (Dropout)          (None, 45, 8)        0           ['layer_normalization_575[0][0]']\n",
      "                                                                                                  \n",
      " dropout_862 (Dropout)          (None, 45, 11)       0           ['layer_normalization_576[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_144 (Concatenate)  (None, 45, 27)       0           ['dropout_860[0][0]',            \n",
      "                                                                  'dropout_861[0][0]',            \n",
      "                                                                  'dropout_862[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_144 (  (None, 27)          0           ['concatenate_144[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_863 (Dropout)          (None, 27)           0           ['global_average_pooling1d_144[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_143 (TFOpLambda  (None, 1, 27)       0           ['dropout_863[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_579 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_143[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_143[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_141 (TFOp  (None, 27)          0           ['multi_head_attention_579[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_577 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_141[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_864 (Dropout)          (None, 27)           0           ['layer_normalization_577[0][0]']\n",
      "                                                                                                  \n",
      " dense_426 (Dense)              (None, 1024)         28672       ['dropout_864[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_865 (Dropout)          (None, 1024)         0           ['dense_426[0][0]']              \n",
      "                                                                                                  \n",
      " dense_427 (Dense)              (None, 128)          131200      ['dropout_865[0][0]']            \n",
      "                                                                                                  \n",
      " dense_428 (Dense)              (None, 1)            129         ['dense_427[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5299 - accuracy: 0.7080 - val_loss: 0.4182 - val_accuracy: 0.6858\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3940 - accuracy: 0.8029 - val_loss: 0.3908 - val_accuracy: 0.6607\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3816 - accuracy: 0.8111 - val_loss: 0.3847 - val_accuracy: 0.6824\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3738 - accuracy: 0.8164 - val_loss: 0.4120 - val_accuracy: 0.6937\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3673 - accuracy: 0.8185 - val_loss: 0.4839 - val_accuracy: 0.6540\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3611 - accuracy: 0.8217 - val_loss: 0.4242 - val_accuracy: 0.6920\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3514 - accuracy: 0.8244 - val_loss: 0.4173 - val_accuracy: 0.7133\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3446 - accuracy: 0.8302 - val_loss: 0.4710 - val_accuracy: 0.6949\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3368 - accuracy: 0.8366 - val_loss: 0.5314 - val_accuracy: 0.6908\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3273 - accuracy: 0.8446 - val_loss: 0.4313 - val_accuracy: 0.7054\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_143\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_436 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_437 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_438 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_435 (Reshape)          (None, 45, 8)        0           ['input_436[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_436 (Reshape)          (None, 45, 8)        0           ['input_437[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_437 (Reshape)          (None, 45, 11)       0           ['input_438[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_580 (Mult  (None, 45, 8)       2248        ['reshape_435[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_435[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_581 (Mult  (None, 45, 8)       2248        ['reshape_436[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_436[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_582 (Mult  (None, 45, 11)      4147        ['reshape_437[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_437[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_578 (Layer  (None, 45, 8)       16          ['multi_head_attention_580[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_579 (Layer  (None, 45, 8)       16          ['multi_head_attention_581[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_580 (Layer  (None, 45, 11)      22          ['multi_head_attention_582[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_866 (Dropout)          (None, 45, 8)        0           ['layer_normalization_578[0][0]']\n",
      "                                                                                                  \n",
      " dropout_867 (Dropout)          (None, 45, 8)        0           ['layer_normalization_579[0][0]']\n",
      "                                                                                                  \n",
      " dropout_868 (Dropout)          (None, 45, 11)       0           ['layer_normalization_580[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_145 (Concatenate)  (None, 45, 27)       0           ['dropout_866[0][0]',            \n",
      "                                                                  'dropout_867[0][0]',            \n",
      "                                                                  'dropout_868[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_145 (  (None, 27)          0           ['concatenate_145[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_869 (Dropout)          (None, 27)           0           ['global_average_pooling1d_145[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_144 (TFOpLambda  (None, 1, 27)       0           ['dropout_869[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_583 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_144[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_144[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_142 (TFOp  (None, 27)          0           ['multi_head_attention_583[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_581 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_142[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_870 (Dropout)          (None, 27)           0           ['layer_normalization_581[0][0]']\n",
      "                                                                                                  \n",
      " dense_429 (Dense)              (None, 1024)         28672       ['dropout_870[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_871 (Dropout)          (None, 1024)         0           ['dense_429[0][0]']              \n",
      "                                                                                                  \n",
      " dense_430 (Dense)              (None, 128)          131200      ['dropout_871[0][0]']            \n",
      "                                                                                                  \n",
      " dense_431 (Dense)              (None, 1)            129         ['dense_430[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.4410 - accuracy: 0.7893 - val_loss: 0.1631 - val_accuracy: 0.9458\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2602 - accuracy: 0.9112 - val_loss: 0.1159 - val_accuracy: 0.9737\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2232 - accuracy: 0.9276 - val_loss: 0.1058 - val_accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2052 - accuracy: 0.9345 - val_loss: 0.0818 - val_accuracy: 0.9768\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1857 - accuracy: 0.9425 - val_loss: 0.0977 - val_accuracy: 0.9766\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1805 - accuracy: 0.9429 - val_loss: 0.0921 - val_accuracy: 0.9744\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1728 - accuracy: 0.9464 - val_loss: 0.0541 - val_accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1705 - accuracy: 0.9473 - val_loss: 0.0734 - val_accuracy: 0.9814\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1698 - accuracy: 0.9475 - val_loss: 0.0602 - val_accuracy: 0.9859\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1656 - accuracy: 0.9499 - val_loss: 0.0674 - val_accuracy: 0.9826\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_144\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_439 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_440 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_441 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_438 (Reshape)          (None, 45, 8)        0           ['input_439[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_439 (Reshape)          (None, 45, 8)        0           ['input_440[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_440 (Reshape)          (None, 45, 11)       0           ['input_441[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_584 (Mult  (None, 45, 8)       2248        ['reshape_438[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_438[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_585 (Mult  (None, 45, 8)       2248        ['reshape_439[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_439[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_586 (Mult  (None, 45, 11)      4147        ['reshape_440[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_440[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_582 (Layer  (None, 45, 8)       16          ['multi_head_attention_584[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_583 (Layer  (None, 45, 8)       16          ['multi_head_attention_585[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_584 (Layer  (None, 45, 11)      22          ['multi_head_attention_586[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_872 (Dropout)          (None, 45, 8)        0           ['layer_normalization_582[0][0]']\n",
      "                                                                                                  \n",
      " dropout_873 (Dropout)          (None, 45, 8)        0           ['layer_normalization_583[0][0]']\n",
      "                                                                                                  \n",
      " dropout_874 (Dropout)          (None, 45, 11)       0           ['layer_normalization_584[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_146 (Concatenate)  (None, 45, 27)       0           ['dropout_872[0][0]',            \n",
      "                                                                  'dropout_873[0][0]',            \n",
      "                                                                  'dropout_874[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_146 (  (None, 27)          0           ['concatenate_146[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_875 (Dropout)          (None, 27)           0           ['global_average_pooling1d_146[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_145 (TFOpLambda  (None, 1, 27)       0           ['dropout_875[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_587 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_145[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_145[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_143 (TFOp  (None, 27)          0           ['multi_head_attention_587[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_585 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_143[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_876 (Dropout)          (None, 27)           0           ['layer_normalization_585[0][0]']\n",
      "                                                                                                  \n",
      " dense_432 (Dense)              (None, 1024)         28672       ['dropout_876[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_877 (Dropout)          (None, 1024)         0           ['dense_432[0][0]']              \n",
      "                                                                                                  \n",
      " dense_433 (Dense)              (None, 128)          131200      ['dropout_877[0][0]']            \n",
      "                                                                                                  \n",
      " dense_434 (Dense)              (None, 1)            129         ['dense_433[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4173 - accuracy: 0.8245 - val_loss: 0.3810 - val_accuracy: 0.8241\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.3566 - accuracy: 0.8540 - val_loss: 0.3216 - val_accuracy: 0.8595\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3378 - accuracy: 0.8582 - val_loss: 0.2499 - val_accuracy: 0.8748\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3257 - accuracy: 0.8606 - val_loss: 0.3926 - val_accuracy: 0.8022\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3154 - accuracy: 0.8610 - val_loss: 0.3369 - val_accuracy: 0.8287\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3107 - accuracy: 0.8633 - val_loss: 0.3553 - val_accuracy: 0.8081\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3061 - accuracy: 0.8637 - val_loss: 0.3412 - val_accuracy: 0.7940\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2991 - accuracy: 0.8668 - val_loss: 0.3218 - val_accuracy: 0.7826\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.2910 - accuracy: 0.8681 - val_loss: 0.2492 - val_accuracy: 0.8430\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2903 - accuracy: 0.8699 - val_loss: 0.3846 - val_accuracy: 0.7940\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_145\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_442 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_443 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_444 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_441 (Reshape)          (None, 45, 8)        0           ['input_442[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_442 (Reshape)          (None, 45, 8)        0           ['input_443[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_443 (Reshape)          (None, 45, 11)       0           ['input_444[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_588 (Mult  (None, 45, 8)       2248        ['reshape_441[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_441[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_589 (Mult  (None, 45, 8)       2248        ['reshape_442[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_442[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_590 (Mult  (None, 45, 11)      4147        ['reshape_443[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_443[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_586 (Layer  (None, 45, 8)       16          ['multi_head_attention_588[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_587 (Layer  (None, 45, 8)       16          ['multi_head_attention_589[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_588 (Layer  (None, 45, 11)      22          ['multi_head_attention_590[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_878 (Dropout)          (None, 45, 8)        0           ['layer_normalization_586[0][0]']\n",
      "                                                                                                  \n",
      " dropout_879 (Dropout)          (None, 45, 8)        0           ['layer_normalization_587[0][0]']\n",
      "                                                                                                  \n",
      " dropout_880 (Dropout)          (None, 45, 11)       0           ['layer_normalization_588[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_147 (Concatenate)  (None, 45, 27)       0           ['dropout_878[0][0]',            \n",
      "                                                                  'dropout_879[0][0]',            \n",
      "                                                                  'dropout_880[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_147 (  (None, 27)          0           ['concatenate_147[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_881 (Dropout)          (None, 27)           0           ['global_average_pooling1d_147[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_146 (TFOpLambda  (None, 1, 27)       0           ['dropout_881[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_591 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_146[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_146[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_144 (TFOp  (None, 27)          0           ['multi_head_attention_591[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_589 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_144[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_882 (Dropout)          (None, 27)           0           ['layer_normalization_589[0][0]']\n",
      "                                                                                                  \n",
      " dense_435 (Dense)              (None, 1024)         28672       ['dropout_882[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_883 (Dropout)          (None, 1024)         0           ['dense_435[0][0]']              \n",
      "                                                                                                  \n",
      " dense_436 (Dense)              (None, 128)          131200      ['dropout_883[0][0]']            \n",
      "                                                                                                  \n",
      " dense_437 (Dense)              (None, 1)            129         ['dense_436[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.2918 - accuracy: 0.8745 - val_loss: 0.3075 - val_accuracy: 0.8351\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1930 - accuracy: 0.9331 - val_loss: 0.2347 - val_accuracy: 0.8667\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1656 - accuracy: 0.9435 - val_loss: 0.2890 - val_accuracy: 0.8789\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1353 - accuracy: 0.9561 - val_loss: 0.2399 - val_accuracy: 0.9030\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1264 - accuracy: 0.9608 - val_loss: 0.2415 - val_accuracy: 0.9030\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1170 - accuracy: 0.9642 - val_loss: 0.3426 - val_accuracy: 0.8698\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1049 - accuracy: 0.9688 - val_loss: 0.2308 - val_accuracy: 0.9159\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1011 - accuracy: 0.9692 - val_loss: 0.1900 - val_accuracy: 0.9302\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0893 - accuracy: 0.9738 - val_loss: 0.1828 - val_accuracy: 0.9305\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0913 - accuracy: 0.9728 - val_loss: 0.2069 - val_accuracy: 0.9297\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_146\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_445 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_446 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_447 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_444 (Reshape)          (None, 45, 8)        0           ['input_445[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_445 (Reshape)          (None, 45, 8)        0           ['input_446[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_446 (Reshape)          (None, 45, 11)       0           ['input_447[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_592 (Mult  (None, 45, 8)       2248        ['reshape_444[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_444[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_593 (Mult  (None, 45, 8)       2248        ['reshape_445[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_445[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_594 (Mult  (None, 45, 11)      4147        ['reshape_446[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_446[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_590 (Layer  (None, 45, 8)       16          ['multi_head_attention_592[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_591 (Layer  (None, 45, 8)       16          ['multi_head_attention_593[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_592 (Layer  (None, 45, 11)      22          ['multi_head_attention_594[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_884 (Dropout)          (None, 45, 8)        0           ['layer_normalization_590[0][0]']\n",
      "                                                                                                  \n",
      " dropout_885 (Dropout)          (None, 45, 8)        0           ['layer_normalization_591[0][0]']\n",
      "                                                                                                  \n",
      " dropout_886 (Dropout)          (None, 45, 11)       0           ['layer_normalization_592[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_148 (Concatenate)  (None, 45, 27)       0           ['dropout_884[0][0]',            \n",
      "                                                                  'dropout_885[0][0]',            \n",
      "                                                                  'dropout_886[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_148 (  (None, 27)          0           ['concatenate_148[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_887 (Dropout)          (None, 27)           0           ['global_average_pooling1d_148[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_147 (TFOpLambda  (None, 1, 27)       0           ['dropout_887[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_595 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_147[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_147[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_145 (TFOp  (None, 27)          0           ['multi_head_attention_595[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_593 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_145[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_888 (Dropout)          (None, 27)           0           ['layer_normalization_593[0][0]']\n",
      "                                                                                                  \n",
      " dense_438 (Dense)              (None, 1024)         28672       ['dropout_888[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_889 (Dropout)          (None, 1024)         0           ['dense_438[0][0]']              \n",
      "                                                                                                  \n",
      " dense_439 (Dense)              (None, 128)          131200      ['dropout_889[0][0]']            \n",
      "                                                                                                  \n",
      " dense_440 (Dense)              (None, 1)            129         ['dense_439[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.2775 - accuracy: 0.8785 - val_loss: 0.3815 - val_accuracy: 0.7823\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2208 - accuracy: 0.8915 - val_loss: 0.3122 - val_accuracy: 0.7861\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2066 - accuracy: 0.9002 - val_loss: 0.3980 - val_accuracy: 0.7622\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2073 - accuracy: 0.8990 - val_loss: 0.3029 - val_accuracy: 0.7372\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1970 - accuracy: 0.9012 - val_loss: 0.3369 - val_accuracy: 0.7890\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1912 - accuracy: 0.9037 - val_loss: 0.3160 - val_accuracy: 0.7835\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1855 - accuracy: 0.9103 - val_loss: 0.3407 - val_accuracy: 0.8258\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1801 - accuracy: 0.9202 - val_loss: 0.3307 - val_accuracy: 0.8640\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1715 - accuracy: 0.9340 - val_loss: 0.3529 - val_accuracy: 0.8674\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1542 - accuracy: 0.9460 - val_loss: 0.3886 - val_accuracy: 0.8800\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_147\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_448 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_449 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_450 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_447 (Reshape)          (None, 45, 8)        0           ['input_448[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_448 (Reshape)          (None, 45, 8)        0           ['input_449[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_449 (Reshape)          (None, 45, 11)       0           ['input_450[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_596 (Mult  (None, 45, 8)       2248        ['reshape_447[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_447[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_597 (Mult  (None, 45, 8)       2248        ['reshape_448[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_448[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_598 (Mult  (None, 45, 11)      4147        ['reshape_449[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_449[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_594 (Layer  (None, 45, 8)       16          ['multi_head_attention_596[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_595 (Layer  (None, 45, 8)       16          ['multi_head_attention_597[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_596 (Layer  (None, 45, 11)      22          ['multi_head_attention_598[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_890 (Dropout)          (None, 45, 8)        0           ['layer_normalization_594[0][0]']\n",
      "                                                                                                  \n",
      " dropout_891 (Dropout)          (None, 45, 8)        0           ['layer_normalization_595[0][0]']\n",
      "                                                                                                  \n",
      " dropout_892 (Dropout)          (None, 45, 11)       0           ['layer_normalization_596[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_149 (Concatenate)  (None, 45, 27)       0           ['dropout_890[0][0]',            \n",
      "                                                                  'dropout_891[0][0]',            \n",
      "                                                                  'dropout_892[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_149 (  (None, 27)          0           ['concatenate_149[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_893 (Dropout)          (None, 27)           0           ['global_average_pooling1d_149[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_148 (TFOpLambda  (None, 1, 27)       0           ['dropout_893[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_599 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_148[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_148[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_146 (TFOp  (None, 27)          0           ['multi_head_attention_599[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_597 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_146[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_894 (Dropout)          (None, 27)           0           ['layer_normalization_597[0][0]']\n",
      "                                                                                                  \n",
      " dense_441 (Dense)              (None, 1024)         28672       ['dropout_894[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_895 (Dropout)          (None, 1024)         0           ['dense_441[0][0]']              \n",
      "                                                                                                  \n",
      " dense_442 (Dense)              (None, 128)          131200      ['dropout_895[0][0]']            \n",
      "                                                                                                  \n",
      " dense_443 (Dense)              (None, 1)            129         ['dense_442[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3439 - accuracy: 0.8634 - val_loss: 0.1820 - val_accuracy: 0.9357\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2501 - accuracy: 0.9164 - val_loss: 0.1153 - val_accuracy: 0.9618\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2080 - accuracy: 0.9379 - val_loss: 0.0919 - val_accuracy: 0.9763\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1945 - accuracy: 0.9433 - val_loss: 0.0932 - val_accuracy: 0.9809\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1859 - accuracy: 0.9447 - val_loss: 0.0837 - val_accuracy: 0.9816\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1775 - accuracy: 0.9475 - val_loss: 0.0633 - val_accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1685 - accuracy: 0.9504 - val_loss: 0.0828 - val_accuracy: 0.9849\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1630 - accuracy: 0.9531 - val_loss: 0.0985 - val_accuracy: 0.9854\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1617 - accuracy: 0.9532 - val_loss: 0.0498 - val_accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1559 - accuracy: 0.9556 - val_loss: 0.0643 - val_accuracy: 0.9840\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_148\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_451 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_452 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_453 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_450 (Reshape)          (None, 45, 8)        0           ['input_451[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_451 (Reshape)          (None, 45, 8)        0           ['input_452[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_452 (Reshape)          (None, 45, 11)       0           ['input_453[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_600 (Mult  (None, 45, 8)       2248        ['reshape_450[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_450[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_601 (Mult  (None, 45, 8)       2248        ['reshape_451[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_451[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_602 (Mult  (None, 45, 11)      4147        ['reshape_452[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_452[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_598 (Layer  (None, 45, 8)       16          ['multi_head_attention_600[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_599 (Layer  (None, 45, 8)       16          ['multi_head_attention_601[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_600 (Layer  (None, 45, 11)      22          ['multi_head_attention_602[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_896 (Dropout)          (None, 45, 8)        0           ['layer_normalization_598[0][0]']\n",
      "                                                                                                  \n",
      " dropout_897 (Dropout)          (None, 45, 8)        0           ['layer_normalization_599[0][0]']\n",
      "                                                                                                  \n",
      " dropout_898 (Dropout)          (None, 45, 11)       0           ['layer_normalization_600[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_150 (Concatenate)  (None, 45, 27)       0           ['dropout_896[0][0]',            \n",
      "                                                                  'dropout_897[0][0]',            \n",
      "                                                                  'dropout_898[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_150 (  (None, 27)          0           ['concatenate_150[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_899 (Dropout)          (None, 27)           0           ['global_average_pooling1d_150[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_149 (TFOpLambda  (None, 1, 27)       0           ['dropout_899[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_603 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_149[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_149[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_147 (TFOp  (None, 27)          0           ['multi_head_attention_603[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_601 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_147[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_900 (Dropout)          (None, 27)           0           ['layer_normalization_601[0][0]']\n",
      "                                                                                                  \n",
      " dense_444 (Dense)              (None, 1024)         28672       ['dropout_900[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_901 (Dropout)          (None, 1024)         0           ['dense_444[0][0]']              \n",
      "                                                                                                  \n",
      " dense_445 (Dense)              (None, 128)          131200      ['dropout_901[0][0]']            \n",
      "                                                                                                  \n",
      " dense_446 (Dense)              (None, 1)            129         ['dense_445[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3576 - accuracy: 0.8576 - val_loss: 0.3774 - val_accuracy: 0.8148\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3078 - accuracy: 0.8849 - val_loss: 0.3167 - val_accuracy: 0.8339\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2892 - accuracy: 0.8938 - val_loss: 0.4011 - val_accuracy: 0.8043\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2834 - accuracy: 0.8981 - val_loss: 0.4102 - val_accuracy: 0.8131\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2779 - accuracy: 0.8991 - val_loss: 0.3227 - val_accuracy: 0.8748\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2748 - accuracy: 0.9014 - val_loss: 0.3249 - val_accuracy: 0.8380\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2708 - accuracy: 0.9025 - val_loss: 0.3931 - val_accuracy: 0.8127\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2698 - accuracy: 0.9015 - val_loss: 0.3156 - val_accuracy: 0.8363\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2671 - accuracy: 0.9022 - val_loss: 0.4285 - val_accuracy: 0.8170\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2660 - accuracy: 0.9028 - val_loss: 0.3071 - val_accuracy: 0.8468\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 4 19923\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_149\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_454 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_455 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_456 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_453 (Reshape)          (None, 45, 8)        0           ['input_454[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_454 (Reshape)          (None, 45, 8)        0           ['input_455[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_455 (Reshape)          (None, 45, 11)       0           ['input_456[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_604 (Mult  (None, 45, 8)       2248        ['reshape_453[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_453[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_605 (Mult  (None, 45, 8)       2248        ['reshape_454[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_454[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_606 (Mult  (None, 45, 11)      4147        ['reshape_455[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_455[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_602 (Layer  (None, 45, 8)       16          ['multi_head_attention_604[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_603 (Layer  (None, 45, 8)       16          ['multi_head_attention_605[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_604 (Layer  (None, 45, 11)      22          ['multi_head_attention_606[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_902 (Dropout)          (None, 45, 8)        0           ['layer_normalization_602[0][0]']\n",
      "                                                                                                  \n",
      " dropout_903 (Dropout)          (None, 45, 8)        0           ['layer_normalization_603[0][0]']\n",
      "                                                                                                  \n",
      " dropout_904 (Dropout)          (None, 45, 11)       0           ['layer_normalization_604[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_151 (Concatenate)  (None, 45, 27)       0           ['dropout_902[0][0]',            \n",
      "                                                                  'dropout_903[0][0]',            \n",
      "                                                                  'dropout_904[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_151 (  (None, 27)          0           ['concatenate_151[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_905 (Dropout)          (None, 27)           0           ['global_average_pooling1d_151[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_150 (TFOpLambda  (None, 1, 27)       0           ['dropout_905[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_607 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_150[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_150[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_148 (TFOp  (None, 27)          0           ['multi_head_attention_607[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_605 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_148[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_906 (Dropout)          (None, 27)           0           ['layer_normalization_605[0][0]']\n",
      "                                                                                                  \n",
      " dense_447 (Dense)              (None, 1024)         28672       ['dropout_906[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_907 (Dropout)          (None, 1024)         0           ['dense_447[0][0]']              \n",
      "                                                                                                  \n",
      " dense_448 (Dense)              (None, 128)          131200      ['dropout_907[0][0]']            \n",
      "                                                                                                  \n",
      " dense_449 (Dense)              (None, 1)            129         ['dense_448[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4669 - accuracy: 0.7652 - val_loss: 0.4849 - val_accuracy: 0.6848\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3697 - accuracy: 0.8390 - val_loss: 0.3917 - val_accuracy: 0.7649\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3506 - accuracy: 0.8479 - val_loss: 0.3728 - val_accuracy: 0.7775\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3438 - accuracy: 0.8502 - val_loss: 0.3361 - val_accuracy: 0.7919\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3342 - accuracy: 0.8570 - val_loss: 0.3037 - val_accuracy: 0.7947\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3282 - accuracy: 0.8593 - val_loss: 0.3044 - val_accuracy: 0.7904\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3230 - accuracy: 0.8615 - val_loss: 0.3349 - val_accuracy: 0.8010\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3147 - accuracy: 0.8656 - val_loss: 0.4204 - val_accuracy: 0.7615\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3119 - accuracy: 0.8666 - val_loss: 0.3805 - val_accuracy: 0.7749\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3061 - accuracy: 0.8702 - val_loss: 0.3041 - val_accuracy: 0.8117\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_150\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_457 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_458 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_459 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_456 (Reshape)          (None, 45, 8)        0           ['input_457[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_457 (Reshape)          (None, 45, 8)        0           ['input_458[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_458 (Reshape)          (None, 45, 11)       0           ['input_459[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_608 (Mult  (None, 45, 8)       2248        ['reshape_456[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_456[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_609 (Mult  (None, 45, 8)       2248        ['reshape_457[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_457[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_610 (Mult  (None, 45, 11)      4147        ['reshape_458[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_458[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_606 (Layer  (None, 45, 8)       16          ['multi_head_attention_608[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_607 (Layer  (None, 45, 8)       16          ['multi_head_attention_609[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_608 (Layer  (None, 45, 11)      22          ['multi_head_attention_610[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_908 (Dropout)          (None, 45, 8)        0           ['layer_normalization_606[0][0]']\n",
      "                                                                                                  \n",
      " dropout_909 (Dropout)          (None, 45, 8)        0           ['layer_normalization_607[0][0]']\n",
      "                                                                                                  \n",
      " dropout_910 (Dropout)          (None, 45, 11)       0           ['layer_normalization_608[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_152 (Concatenate)  (None, 45, 27)       0           ['dropout_908[0][0]',            \n",
      "                                                                  'dropout_909[0][0]',            \n",
      "                                                                  'dropout_910[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_152 (  (None, 27)          0           ['concatenate_152[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_911 (Dropout)          (None, 27)           0           ['global_average_pooling1d_152[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_151 (TFOpLambda  (None, 1, 27)       0           ['dropout_911[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_611 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_151[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_151[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_149 (TFOp  (None, 27)          0           ['multi_head_attention_611[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_609 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_149[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_912 (Dropout)          (None, 27)           0           ['layer_normalization_609[0][0]']\n",
      "                                                                                                  \n",
      " dense_450 (Dense)              (None, 1024)         28672       ['dropout_912[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_913 (Dropout)          (None, 1024)         0           ['dense_450[0][0]']              \n",
      "                                                                                                  \n",
      " dense_451 (Dense)              (None, 128)          131200      ['dropout_913[0][0]']            \n",
      "                                                                                                  \n",
      " dense_452 (Dense)              (None, 1)            129         ['dense_451[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 16ms/step - loss: 0.5041 - accuracy: 0.7311 - val_loss: 0.4562 - val_accuracy: 0.6593\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3957 - accuracy: 0.8031 - val_loss: 0.3692 - val_accuracy: 0.6896\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3904 - accuracy: 0.8053 - val_loss: 0.3912 - val_accuracy: 0.6824\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3806 - accuracy: 0.8120 - val_loss: 0.3923 - val_accuracy: 0.7006\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3727 - accuracy: 0.8157 - val_loss: 0.3934 - val_accuracy: 0.7161\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3625 - accuracy: 0.8216 - val_loss: 0.4343 - val_accuracy: 0.7114\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3563 - accuracy: 0.8277 - val_loss: 0.4247 - val_accuracy: 0.7073\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3535 - accuracy: 0.8279 - val_loss: 0.4207 - val_accuracy: 0.7233\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3478 - accuracy: 0.8326 - val_loss: 0.3742 - val_accuracy: 0.7572\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3392 - accuracy: 0.8399 - val_loss: 0.4941 - val_accuracy: 0.6982\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_151\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_460 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_461 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_462 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_459 (Reshape)          (None, 45, 8)        0           ['input_460[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_460 (Reshape)          (None, 45, 8)        0           ['input_461[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_461 (Reshape)          (None, 45, 11)       0           ['input_462[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_612 (Mult  (None, 45, 8)       2248        ['reshape_459[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_459[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_613 (Mult  (None, 45, 8)       2248        ['reshape_460[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_460[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_614 (Mult  (None, 45, 11)      4147        ['reshape_461[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_461[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_610 (Layer  (None, 45, 8)       16          ['multi_head_attention_612[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_611 (Layer  (None, 45, 8)       16          ['multi_head_attention_613[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_612 (Layer  (None, 45, 11)      22          ['multi_head_attention_614[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_914 (Dropout)          (None, 45, 8)        0           ['layer_normalization_610[0][0]']\n",
      "                                                                                                  \n",
      " dropout_915 (Dropout)          (None, 45, 8)        0           ['layer_normalization_611[0][0]']\n",
      "                                                                                                  \n",
      " dropout_916 (Dropout)          (None, 45, 11)       0           ['layer_normalization_612[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_153 (Concatenate)  (None, 45, 27)       0           ['dropout_914[0][0]',            \n",
      "                                                                  'dropout_915[0][0]',            \n",
      "                                                                  'dropout_916[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_153 (  (None, 27)          0           ['concatenate_153[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_917 (Dropout)          (None, 27)           0           ['global_average_pooling1d_153[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_152 (TFOpLambda  (None, 1, 27)       0           ['dropout_917[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_615 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_152[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_152[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_150 (TFOp  (None, 27)          0           ['multi_head_attention_615[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_613 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_150[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_918 (Dropout)          (None, 27)           0           ['layer_normalization_613[0][0]']\n",
      "                                                                                                  \n",
      " dense_453 (Dense)              (None, 1024)         28672       ['dropout_918[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_919 (Dropout)          (None, 1024)         0           ['dense_453[0][0]']              \n",
      "                                                                                                  \n",
      " dense_454 (Dense)              (None, 128)          131200      ['dropout_919[0][0]']            \n",
      "                                                                                                  \n",
      " dense_455 (Dense)              (None, 1)            129         ['dense_454[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4144 - accuracy: 0.8118 - val_loss: 0.1869 - val_accuracy: 0.9462\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2570 - accuracy: 0.9155 - val_loss: 0.1673 - val_accuracy: 0.9503\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2355 - accuracy: 0.9236 - val_loss: 0.1431 - val_accuracy: 0.9622\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2151 - accuracy: 0.9299 - val_loss: 0.1260 - val_accuracy: 0.9682\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1940 - accuracy: 0.9391 - val_loss: 0.1037 - val_accuracy: 0.9716\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1833 - accuracy: 0.9423 - val_loss: 0.1007 - val_accuracy: 0.9706\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1793 - accuracy: 0.9442 - val_loss: 0.1107 - val_accuracy: 0.9685\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1732 - accuracy: 0.9465 - val_loss: 0.1328 - val_accuracy: 0.9704\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1720 - accuracy: 0.9464 - val_loss: 0.1241 - val_accuracy: 0.9716\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1615 - accuracy: 0.9503 - val_loss: 0.0993 - val_accuracy: 0.9723\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_152\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_463 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_464 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_465 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_462 (Reshape)          (None, 45, 8)        0           ['input_463[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_463 (Reshape)          (None, 45, 8)        0           ['input_464[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_464 (Reshape)          (None, 45, 11)       0           ['input_465[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_616 (Mult  (None, 45, 8)       2248        ['reshape_462[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_462[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_617 (Mult  (None, 45, 8)       2248        ['reshape_463[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_463[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_618 (Mult  (None, 45, 11)      4147        ['reshape_464[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_464[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_614 (Layer  (None, 45, 8)       16          ['multi_head_attention_616[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_615 (Layer  (None, 45, 8)       16          ['multi_head_attention_617[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_616 (Layer  (None, 45, 11)      22          ['multi_head_attention_618[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_920 (Dropout)          (None, 45, 8)        0           ['layer_normalization_614[0][0]']\n",
      "                                                                                                  \n",
      " dropout_921 (Dropout)          (None, 45, 8)        0           ['layer_normalization_615[0][0]']\n",
      "                                                                                                  \n",
      " dropout_922 (Dropout)          (None, 45, 11)       0           ['layer_normalization_616[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_154 (Concatenate)  (None, 45, 27)       0           ['dropout_920[0][0]',            \n",
      "                                                                  'dropout_921[0][0]',            \n",
      "                                                                  'dropout_922[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_154 (  (None, 27)          0           ['concatenate_154[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_923 (Dropout)          (None, 27)           0           ['global_average_pooling1d_154[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_153 (TFOpLambda  (None, 1, 27)       0           ['dropout_923[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_619 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_153[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_153[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_151 (TFOp  (None, 27)          0           ['multi_head_attention_619[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_617 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_151[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_924 (Dropout)          (None, 27)           0           ['layer_normalization_617[0][0]']\n",
      "                                                                                                  \n",
      " dense_456 (Dense)              (None, 1024)         28672       ['dropout_924[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_925 (Dropout)          (None, 1024)         0           ['dense_456[0][0]']              \n",
      "                                                                                                  \n",
      " dense_457 (Dense)              (None, 128)          131200      ['dropout_925[0][0]']            \n",
      "                                                                                                  \n",
      " dense_458 (Dense)              (None, 1)            129         ['dense_457[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4201 - accuracy: 0.8217 - val_loss: 0.2327 - val_accuracy: 0.8891\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3561 - accuracy: 0.8551 - val_loss: 0.2325 - val_accuracy: 0.8631\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3420 - accuracy: 0.8624 - val_loss: 0.3388 - val_accuracy: 0.8323\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3346 - accuracy: 0.8591 - val_loss: 0.2790 - val_accuracy: 0.8550\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3190 - accuracy: 0.8646 - val_loss: 0.3115 - val_accuracy: 0.8492\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3155 - accuracy: 0.8628 - val_loss: 0.3246 - val_accuracy: 0.8557\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3117 - accuracy: 0.8606 - val_loss: 0.3122 - val_accuracy: 0.8533\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3049 - accuracy: 0.8672 - val_loss: 0.2851 - val_accuracy: 0.8547\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3002 - accuracy: 0.8671 - val_loss: 0.2847 - val_accuracy: 0.8533\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2965 - accuracy: 0.8694 - val_loss: 0.2764 - val_accuracy: 0.8562\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_153\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_466 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_467 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_468 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_465 (Reshape)          (None, 45, 8)        0           ['input_466[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_466 (Reshape)          (None, 45, 8)        0           ['input_467[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_467 (Reshape)          (None, 45, 11)       0           ['input_468[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_620 (Mult  (None, 45, 8)       2248        ['reshape_465[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_465[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_621 (Mult  (None, 45, 8)       2248        ['reshape_466[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_466[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_622 (Mult  (None, 45, 11)      4147        ['reshape_467[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_467[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_618 (Layer  (None, 45, 8)       16          ['multi_head_attention_620[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_619 (Layer  (None, 45, 8)       16          ['multi_head_attention_621[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_620 (Layer  (None, 45, 11)      22          ['multi_head_attention_622[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_926 (Dropout)          (None, 45, 8)        0           ['layer_normalization_618[0][0]']\n",
      "                                                                                                  \n",
      " dropout_927 (Dropout)          (None, 45, 8)        0           ['layer_normalization_619[0][0]']\n",
      "                                                                                                  \n",
      " dropout_928 (Dropout)          (None, 45, 11)       0           ['layer_normalization_620[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_155 (Concatenate)  (None, 45, 27)       0           ['dropout_926[0][0]',            \n",
      "                                                                  'dropout_927[0][0]',            \n",
      "                                                                  'dropout_928[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_155 (  (None, 27)          0           ['concatenate_155[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_929 (Dropout)          (None, 27)           0           ['global_average_pooling1d_155[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_154 (TFOpLambda  (None, 1, 27)       0           ['dropout_929[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_623 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_154[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_154[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_152 (TFOp  (None, 27)          0           ['multi_head_attention_623[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_621 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_152[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_930 (Dropout)          (None, 27)           0           ['layer_normalization_621[0][0]']\n",
      "                                                                                                  \n",
      " dense_459 (Dense)              (None, 1024)         28672       ['dropout_930[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_931 (Dropout)          (None, 1024)         0           ['dense_459[0][0]']              \n",
      "                                                                                                  \n",
      " dense_460 (Dense)              (None, 128)          131200      ['dropout_931[0][0]']            \n",
      "                                                                                                  \n",
      " dense_461 (Dense)              (None, 1)            129         ['dense_460[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.3040 - accuracy: 0.8665 - val_loss: 0.2751 - val_accuracy: 0.8440\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1906 - accuracy: 0.9348 - val_loss: 0.1897 - val_accuracy: 0.9006\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1559 - accuracy: 0.9480 - val_loss: 0.2847 - val_accuracy: 0.8891\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1393 - accuracy: 0.9541 - val_loss: 0.2531 - val_accuracy: 0.8915\n",
      "Epoch 5/10\n",
      "132/938 [===>..........................] - ETA: 12s - loss: 0.1265 - accuracy: 0.9605TRAIN sleep 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_155\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_472 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_473 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_474 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_471 (Reshape)          (None, 45, 8)        0           ['input_472[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_472 (Reshape)          (None, 45, 8)        0           ['input_473[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_473 (Reshape)          (None, 45, 11)       0           ['input_474[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_628 (Mult  (None, 45, 8)       2248        ['reshape_471[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_471[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_629 (Mult  (None, 45, 8)       2248        ['reshape_472[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_472[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_630 (Mult  (None, 45, 11)      4147        ['reshape_473[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_473[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_626 (Layer  (None, 45, 8)       16          ['multi_head_attention_628[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_627 (Layer  (None, 45, 8)       16          ['multi_head_attention_629[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_628 (Layer  (None, 45, 11)      22          ['multi_head_attention_630[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_938 (Dropout)          (None, 45, 8)        0           ['layer_normalization_626[0][0]']\n",
      "                                                                                                  \n",
      " dropout_939 (Dropout)          (None, 45, 8)        0           ['layer_normalization_627[0][0]']\n",
      "                                                                                                  \n",
      " dropout_940 (Dropout)          (None, 45, 11)       0           ['layer_normalization_628[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_157 (Concatenate)  (None, 45, 27)       0           ['dropout_938[0][0]',            \n",
      "                                                                  'dropout_939[0][0]',            \n",
      "                                                                  'dropout_940[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_157 (  (None, 27)          0           ['concatenate_157[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_941 (Dropout)          (None, 27)           0           ['global_average_pooling1d_157[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_156 (TFOpLambda  (None, 1, 27)       0           ['dropout_941[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_631 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_156[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_156[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_154 (TFOp  (None, 27)          0           ['multi_head_attention_631[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_629 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_154[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_942 (Dropout)          (None, 27)           0           ['layer_normalization_629[0][0]']\n",
      "                                                                                                  \n",
      " dense_465 (Dense)              (None, 1024)         28672       ['dropout_942[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_943 (Dropout)          (None, 1024)         0           ['dense_465[0][0]']              \n",
      "                                                                                                  \n",
      " dense_466 (Dense)              (None, 128)          131200      ['dropout_943[0][0]']            \n",
      "                                                                                                  \n",
      " dense_467 (Dense)              (None, 1)            129         ['dense_466[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3219 - accuracy: 0.8758 - val_loss: 0.2005 - val_accuracy: 0.9326\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2590 - accuracy: 0.9112 - val_loss: 0.1250 - val_accuracy: 0.9694\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2204 - accuracy: 0.9343 - val_loss: 0.1000 - val_accuracy: 0.9720\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2063 - accuracy: 0.9392 - val_loss: 0.1125 - val_accuracy: 0.9697\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1988 - accuracy: 0.9417 - val_loss: 0.0850 - val_accuracy: 0.9802\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1913 - accuracy: 0.9437 - val_loss: 0.0773 - val_accuracy: 0.9806\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1809 - accuracy: 0.9475 - val_loss: 0.0871 - val_accuracy: 0.9751\n",
      "Epoch 8/10\n",
      "106/938 [==>...........................] - ETA: 13s - loss: 0.1935 - accuracy: 0.9413TRAIN kitchen 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_156\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_475 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_476 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_477 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_474 (Reshape)          (None, 45, 8)        0           ['input_475[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_475 (Reshape)          (None, 45, 8)        0           ['input_476[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_476 (Reshape)          (None, 45, 11)       0           ['input_477[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_632 (Mult  (None, 45, 8)       2248        ['reshape_474[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_474[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_633 (Mult  (None, 45, 8)       2248        ['reshape_475[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_475[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_634 (Mult  (None, 45, 11)      4147        ['reshape_476[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_476[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_630 (Layer  (None, 45, 8)       16          ['multi_head_attention_632[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_631 (Layer  (None, 45, 8)       16          ['multi_head_attention_633[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_632 (Layer  (None, 45, 11)      22          ['multi_head_attention_634[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_944 (Dropout)          (None, 45, 8)        0           ['layer_normalization_630[0][0]']\n",
      "                                                                                                  \n",
      " dropout_945 (Dropout)          (None, 45, 8)        0           ['layer_normalization_631[0][0]']\n",
      "                                                                                                  \n",
      " dropout_946 (Dropout)          (None, 45, 11)       0           ['layer_normalization_632[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_158 (Concatenate)  (None, 45, 27)       0           ['dropout_944[0][0]',            \n",
      "                                                                  'dropout_945[0][0]',            \n",
      "                                                                  'dropout_946[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_158 (  (None, 27)          0           ['concatenate_158[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_947 (Dropout)          (None, 27)           0           ['global_average_pooling1d_158[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_157 (TFOpLambda  (None, 1, 27)       0           ['dropout_947[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_635 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_157[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_157[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_155 (TFOp  (None, 27)          0           ['multi_head_attention_635[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_633 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_155[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_948 (Dropout)          (None, 27)           0           ['layer_normalization_633[0][0]']\n",
      "                                                                                                  \n",
      " dense_468 (Dense)              (None, 1024)         28672       ['dropout_948[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_949 (Dropout)          (None, 1024)         0           ['dense_468[0][0]']              \n",
      "                                                                                                  \n",
      " dense_469 (Dense)              (None, 128)          131200      ['dropout_949[0][0]']            \n",
      "                                                                                                  \n",
      " dense_470 (Dense)              (None, 1)            129         ['dense_469[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3679 - accuracy: 0.8530 - val_loss: 0.2179 - val_accuracy: 0.8624\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.3200 - accuracy: 0.8779 - val_loss: 0.2705 - val_accuracy: 0.8734\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3038 - accuracy: 0.8814 - val_loss: 0.2250 - val_accuracy: 0.8796\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3001 - accuracy: 0.8835 - val_loss: 0.2600 - val_accuracy: 0.8741\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2939 - accuracy: 0.8861 - val_loss: 0.2734 - val_accuracy: 0.8884\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2912 - accuracy: 0.8882 - val_loss: 0.2838 - val_accuracy: 0.8779\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2822 - accuracy: 0.8914 - val_loss: 0.2912 - val_accuracy: 0.8829\n",
      "Epoch 8/10\n",
      "195/938 [=====>........................] - ETA: 10s - loss: 0.2725 - accuracy: 0.9034TRAIN toileting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_157\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_478 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_479 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_480 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_477 (Reshape)          (None, 45, 8)        0           ['input_478[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_478 (Reshape)          (None, 45, 8)        0           ['input_479[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_479 (Reshape)          (None, 45, 11)       0           ['input_480[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_636 (Mult  (None, 45, 8)       2248        ['reshape_477[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_477[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_637 (Mult  (None, 45, 8)       2248        ['reshape_478[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_478[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_638 (Mult  (None, 45, 11)      4147        ['reshape_479[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_479[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_634 (Layer  (None, 45, 8)       16          ['multi_head_attention_636[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_635 (Layer  (None, 45, 8)       16          ['multi_head_attention_637[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_636 (Layer  (None, 45, 11)      22          ['multi_head_attention_638[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_950 (Dropout)          (None, 45, 8)        0           ['layer_normalization_634[0][0]']\n",
      "                                                                                                  \n",
      " dropout_951 (Dropout)          (None, 45, 8)        0           ['layer_normalization_635[0][0]']\n",
      "                                                                                                  \n",
      " dropout_952 (Dropout)          (None, 45, 11)       0           ['layer_normalization_636[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_159 (Concatenate)  (None, 45, 27)       0           ['dropout_950[0][0]',            \n",
      "                                                                  'dropout_951[0][0]',            \n",
      "                                                                  'dropout_952[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_159 (  (None, 27)          0           ['concatenate_159[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_953 (Dropout)          (None, 27)           0           ['global_average_pooling1d_159[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_158 (TFOpLambda  (None, 1, 27)       0           ['dropout_953[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_639 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_158[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_158[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_156 (TFOp  (None, 27)          0           ['multi_head_attention_639[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_637 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_156[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_954 (Dropout)          (None, 27)           0           ['layer_normalization_637[0][0]']\n",
      "                                                                                                  \n",
      " dense_471 (Dense)              (None, 1024)         28672       ['dropout_954[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_955 (Dropout)          (None, 1024)         0           ['dense_471[0][0]']              \n",
      "                                                                                                  \n",
      " dense_472 (Dense)              (None, 128)          131200      ['dropout_955[0][0]']            \n",
      "                                                                                                  \n",
      " dense_473 (Dense)              (None, 1)            129         ['dense_472[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4815 - accuracy: 0.7424 - val_loss: 0.3867 - val_accuracy: 0.7486\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3772 - accuracy: 0.8352 - val_loss: 0.2885 - val_accuracy: 0.7914\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3578 - accuracy: 0.8449 - val_loss: 0.3160 - val_accuracy: 0.8062\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3462 - accuracy: 0.8507 - val_loss: 0.3444 - val_accuracy: 0.8005\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3366 - accuracy: 0.8568 - val_loss: 0.3168 - val_accuracy: 0.7962\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3322 - accuracy: 0.8582 - val_loss: 0.3425 - val_accuracy: 0.7668\n",
      "Epoch 7/10\n",
      "777/938 [=======================>......] - ETA: 2s - loss: 0.3289 - accuracy: 0.8594TRAIN resting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_158\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_481 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_482 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_483 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_480 (Reshape)          (None, 45, 8)        0           ['input_481[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_481 (Reshape)          (None, 45, 8)        0           ['input_482[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_482 (Reshape)          (None, 45, 11)       0           ['input_483[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_640 (Mult  (None, 45, 8)       2248        ['reshape_480[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_480[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_641 (Mult  (None, 45, 8)       2248        ['reshape_481[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_481[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_642 (Mult  (None, 45, 11)      4147        ['reshape_482[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_482[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_638 (Layer  (None, 45, 8)       16          ['multi_head_attention_640[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_639 (Layer  (None, 45, 8)       16          ['multi_head_attention_641[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_640 (Layer  (None, 45, 11)      22          ['multi_head_attention_642[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_956 (Dropout)          (None, 45, 8)        0           ['layer_normalization_638[0][0]']\n",
      "                                                                                                  \n",
      " dropout_957 (Dropout)          (None, 45, 8)        0           ['layer_normalization_639[0][0]']\n",
      "                                                                                                  \n",
      " dropout_958 (Dropout)          (None, 45, 11)       0           ['layer_normalization_640[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_160 (Concatenate)  (None, 45, 27)       0           ['dropout_956[0][0]',            \n",
      "                                                                  'dropout_957[0][0]',            \n",
      "                                                                  'dropout_958[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_160 (  (None, 27)          0           ['concatenate_160[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_959 (Dropout)          (None, 27)           0           ['global_average_pooling1d_160[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_159 (TFOpLambda  (None, 1, 27)       0           ['dropout_959[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_643 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_159[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_159[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_157 (TFOp  (None, 27)          0           ['multi_head_attention_643[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_641 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_157[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_960 (Dropout)          (None, 27)           0           ['layer_normalization_641[0][0]']\n",
      "                                                                                                  \n",
      " dense_474 (Dense)              (None, 1024)         28672       ['dropout_960[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_961 (Dropout)          (None, 1024)         0           ['dense_474[0][0]']              \n",
      "                                                                                                  \n",
      " dense_475 (Dense)              (None, 128)          131200      ['dropout_961[0][0]']            \n",
      "                                                                                                  \n",
      " dense_476 (Dense)              (None, 1)            129         ['dense_475[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5607 - accuracy: 0.6986 - val_loss: 0.4576 - val_accuracy: 0.6344\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4085 - accuracy: 0.7930 - val_loss: 0.3829 - val_accuracy: 0.7006\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3818 - accuracy: 0.8145 - val_loss: 0.3973 - val_accuracy: 0.7386\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3648 - accuracy: 0.8292 - val_loss: 0.4058 - val_accuracy: 0.7546\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3593 - accuracy: 0.8335 - val_loss: 0.3707 - val_accuracy: 0.7797\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3502 - accuracy: 0.8369 - val_loss: 0.3499 - val_accuracy: 0.7881\n",
      "Epoch 7/10\n",
      "541/938 [================>.............] - ETA: 6s - loss: 0.3447 - accuracy: 0.8417TRAIN exit 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_159\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_484 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_485 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_486 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_483 (Reshape)          (None, 45, 8)        0           ['input_484[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_484 (Reshape)          (None, 45, 8)        0           ['input_485[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_485 (Reshape)          (None, 45, 11)       0           ['input_486[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_644 (Mult  (None, 45, 8)       2248        ['reshape_483[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_483[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_645 (Mult  (None, 45, 8)       2248        ['reshape_484[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_484[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_646 (Mult  (None, 45, 11)      4147        ['reshape_485[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_485[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_642 (Layer  (None, 45, 8)       16          ['multi_head_attention_644[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_643 (Layer  (None, 45, 8)       16          ['multi_head_attention_645[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_644 (Layer  (None, 45, 11)      22          ['multi_head_attention_646[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_962 (Dropout)          (None, 45, 8)        0           ['layer_normalization_642[0][0]']\n",
      "                                                                                                  \n",
      " dropout_963 (Dropout)          (None, 45, 8)        0           ['layer_normalization_643[0][0]']\n",
      "                                                                                                  \n",
      " dropout_964 (Dropout)          (None, 45, 11)       0           ['layer_normalization_644[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_161 (Concatenate)  (None, 45, 27)       0           ['dropout_962[0][0]',            \n",
      "                                                                  'dropout_963[0][0]',            \n",
      "                                                                  'dropout_964[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_161 (  (None, 27)          0           ['concatenate_161[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_965 (Dropout)          (None, 27)           0           ['global_average_pooling1d_161[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_160 (TFOpLambda  (None, 1, 27)       0           ['dropout_965[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_647 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_160[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_160[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_158 (TFOp  (None, 27)          0           ['multi_head_attention_647[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_645 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_158[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_966 (Dropout)          (None, 27)           0           ['layer_normalization_645[0][0]']\n",
      "                                                                                                  \n",
      " dense_477 (Dense)              (None, 1024)         28672       ['dropout_966[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_967 (Dropout)          (None, 1024)         0           ['dense_477[0][0]']              \n",
      "                                                                                                  \n",
      " dense_478 (Dense)              (None, 128)          131200      ['dropout_967[0][0]']            \n",
      "                                                                                                  \n",
      " dense_479 (Dense)              (None, 1)            129         ['dense_478[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3913 - accuracy: 0.8282 - val_loss: 0.2028 - val_accuracy: 0.9374\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2566 - accuracy: 0.9168 - val_loss: 0.1708 - val_accuracy: 0.9479\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2286 - accuracy: 0.9259 - val_loss: 0.1478 - val_accuracy: 0.9534\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2118 - accuracy: 0.9336 - val_loss: 0.1240 - val_accuracy: 0.9608\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1997 - accuracy: 0.9384 - val_loss: 0.1465 - val_accuracy: 0.9553\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1868 - accuracy: 0.9415 - val_loss: 0.1394 - val_accuracy: 0.9634\n",
      "Epoch 7/10\n",
      "735/938 [======================>.......] - ETA: 2s - loss: 0.1808 - accuracy: 0.9426TRAIN cooking 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_160\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_487 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_488 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_489 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_486 (Reshape)          (None, 45, 8)        0           ['input_487[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_487 (Reshape)          (None, 45, 8)        0           ['input_488[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_488 (Reshape)          (None, 45, 11)       0           ['input_489[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_648 (Mult  (None, 45, 8)       2248        ['reshape_486[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_486[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_649 (Mult  (None, 45, 8)       2248        ['reshape_487[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_487[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_650 (Mult  (None, 45, 11)      4147        ['reshape_488[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_488[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_646 (Layer  (None, 45, 8)       16          ['multi_head_attention_648[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_647 (Layer  (None, 45, 8)       16          ['multi_head_attention_649[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_648 (Layer  (None, 45, 11)      22          ['multi_head_attention_650[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_968 (Dropout)          (None, 45, 8)        0           ['layer_normalization_646[0][0]']\n",
      "                                                                                                  \n",
      " dropout_969 (Dropout)          (None, 45, 8)        0           ['layer_normalization_647[0][0]']\n",
      "                                                                                                  \n",
      " dropout_970 (Dropout)          (None, 45, 11)       0           ['layer_normalization_648[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_162 (Concatenate)  (None, 45, 27)       0           ['dropout_968[0][0]',            \n",
      "                                                                  'dropout_969[0][0]',            \n",
      "                                                                  'dropout_970[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_162 (  (None, 27)          0           ['concatenate_162[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_971 (Dropout)          (None, 27)           0           ['global_average_pooling1d_162[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_161 (TFOpLambda  (None, 1, 27)       0           ['dropout_971[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_651 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_161[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_161[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_159 (TFOp  (None, 27)          0           ['multi_head_attention_651[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_649 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_159[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_972 (Dropout)          (None, 27)           0           ['layer_normalization_649[0][0]']\n",
      "                                                                                                  \n",
      " dense_480 (Dense)              (None, 1024)         28672       ['dropout_972[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_973 (Dropout)          (None, 1024)         0           ['dense_480[0][0]']              \n",
      "                                                                                                  \n",
      " dense_481 (Dense)              (None, 128)          131200      ['dropout_973[0][0]']            \n",
      "                                                                                                  \n",
      " dense_482 (Dense)              (None, 1)            129         ['dense_481[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 16ms/step - loss: 0.4208 - accuracy: 0.8176 - val_loss: 0.2380 - val_accuracy: 0.8989\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3631 - accuracy: 0.8505 - val_loss: 0.3324 - val_accuracy: 0.8538\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3450 - accuracy: 0.8584 - val_loss: 0.3170 - val_accuracy: 0.8569\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3363 - accuracy: 0.8589 - val_loss: 0.2189 - val_accuracy: 0.8839\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3226 - accuracy: 0.8625 - val_loss: 0.2650 - val_accuracy: 0.8741\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3157 - accuracy: 0.8649 - val_loss: 0.2329 - val_accuracy: 0.8645\n",
      "Epoch 7/10\n",
      "630/938 [===================>..........] - ETA: 4s - loss: 0.3073 - accuracy: 0.8676TRAIN shower 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_161\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_490 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_491 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_492 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_489 (Reshape)          (None, 45, 8)        0           ['input_490[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_490 (Reshape)          (None, 45, 8)        0           ['input_491[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_491 (Reshape)          (None, 45, 11)       0           ['input_492[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_652 (Mult  (None, 45, 8)       2248        ['reshape_489[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_489[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_653 (Mult  (None, 45, 8)       2248        ['reshape_490[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_490[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_654 (Mult  (None, 45, 11)      4147        ['reshape_491[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_491[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_650 (Layer  (None, 45, 8)       16          ['multi_head_attention_652[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_651 (Layer  (None, 45, 8)       16          ['multi_head_attention_653[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_652 (Layer  (None, 45, 11)      22          ['multi_head_attention_654[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_974 (Dropout)          (None, 45, 8)        0           ['layer_normalization_650[0][0]']\n",
      "                                                                                                  \n",
      " dropout_975 (Dropout)          (None, 45, 8)        0           ['layer_normalization_651[0][0]']\n",
      "                                                                                                  \n",
      " dropout_976 (Dropout)          (None, 45, 11)       0           ['layer_normalization_652[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_163 (Concatenate)  (None, 45, 27)       0           ['dropout_974[0][0]',            \n",
      "                                                                  'dropout_975[0][0]',            \n",
      "                                                                  'dropout_976[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_163 (  (None, 27)          0           ['concatenate_163[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_977 (Dropout)          (None, 27)           0           ['global_average_pooling1d_163[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_162 (TFOpLambda  (None, 1, 27)       0           ['dropout_977[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_655 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_162[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_162[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_160 (TFOp  (None, 27)          0           ['multi_head_attention_655[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_653 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_160[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_978 (Dropout)          (None, 27)           0           ['layer_normalization_653[0][0]']\n",
      "                                                                                                  \n",
      " dense_483 (Dense)              (None, 1024)         28672       ['dropout_978[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_979 (Dropout)          (None, 1024)         0           ['dense_483[0][0]']              \n",
      "                                                                                                  \n",
      " dense_484 (Dense)              (None, 128)          131200      ['dropout_979[0][0]']            \n",
      "                                                                                                  \n",
      " dense_485 (Dense)              (None, 1)            129         ['dense_484[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.2788 - accuracy: 0.8794 - val_loss: 0.3211 - val_accuracy: 0.8437\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1781 - accuracy: 0.9380 - val_loss: 0.3606 - val_accuracy: 0.8562\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1516 - accuracy: 0.9495 - val_loss: 0.1904 - val_accuracy: 0.9190\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1302 - accuracy: 0.9581 - val_loss: 0.0935 - val_accuracy: 0.9611\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1167 - accuracy: 0.9653 - val_loss: 0.1036 - val_accuracy: 0.9599\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1089 - accuracy: 0.9683 - val_loss: 0.1019 - val_accuracy: 0.9596\n",
      "Epoch 7/10\n",
      "590/938 [=================>............] - ETA: 4s - loss: 0.0975 - accuracy: 0.9716EVAL pc 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.2985 - accuracy: 0.8771 - val_loss: 0.1780 - val_accuracy: 0.8753\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2527 - accuracy: 0.8910 - val_loss: 0.1329 - val_accuracy: 0.8875\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2281 - accuracy: 0.8947 - val_loss: 0.0782 - val_accuracy: 0.9130\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2172 - accuracy: 0.8976 - val_loss: 0.1082 - val_accuracy: 0.8798\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2058 - accuracy: 0.9051 - val_loss: 0.0586 - val_accuracy: 0.9967\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2023 - accuracy: 0.9085 - val_loss: 0.0533 - val_accuracy: 0.9962\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1884 - accuracy: 0.9196 - val_loss: 0.0353 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3305 - accuracy: 0.8754 - val_loss: 0.2717 - val_accuracy: 0.8858\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2478 - accuracy: 0.9186 - val_loss: 0.2690 - val_accuracy: 0.8946\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2115 - accuracy: 0.9373 - val_loss: 0.1519 - val_accuracy: 0.9584\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1979 - accuracy: 0.9423 - val_loss: 0.1445 - val_accuracy: 0.9656\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1900 - accuracy: 0.9440 - val_loss: 0.1502 - val_accuracy: 0.9673\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1805 - accuracy: 0.9478 - val_loss: 0.1185 - val_accuracy: 0.9711\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1650 - accuracy: 0.9521 - val_loss: 0.1231 - val_accuracy: 0.9759\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3163 - accuracy: 0.8794 - val_loss: 0.2806 - val_accuracy: 0.8798\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3029 - accuracy: 0.8848 - val_loss: 0.2470 - val_accuracy: 0.8843\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2953 - accuracy: 0.8857 - val_loss: 0.1625 - val_accuracy: 0.9341\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2890 - accuracy: 0.8896 - val_loss: 0.3086 - val_accuracy: 0.8724\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2835 - accuracy: 0.8949 - val_loss: 0.2651 - val_accuracy: 0.8846\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2780 - accuracy: 0.8966 - val_loss: 0.2323 - val_accuracy: 0.8846\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2721 - accuracy: 0.8986 - val_loss: 0.2820 - val_accuracy: 0.8645\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3743 - accuracy: 0.8377 - val_loss: 0.3331 - val_accuracy: 0.8010\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3628 - accuracy: 0.8444 - val_loss: 0.3895 - val_accuracy: 0.7711\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3517 - accuracy: 0.8487 - val_loss: 0.2811 - val_accuracy: 0.8241\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3421 - accuracy: 0.8538 - val_loss: 0.3142 - val_accuracy: 0.8022\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3359 - accuracy: 0.8565 - val_loss: 0.3000 - val_accuracy: 0.8196\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3341 - accuracy: 0.8585 - val_loss: 0.2597 - val_accuracy: 0.8294\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3304 - accuracy: 0.8601 - val_loss: 0.3108 - val_accuracy: 0.8237\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4044 - accuracy: 0.7949 - val_loss: 0.3772 - val_accuracy: 0.7116\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3903 - accuracy: 0.8060 - val_loss: 0.3469 - val_accuracy: 0.7254\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3800 - accuracy: 0.8121 - val_loss: 0.4144 - val_accuracy: 0.7317\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3719 - accuracy: 0.8177 - val_loss: 0.4338 - val_accuracy: 0.7121\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3631 - accuracy: 0.8246 - val_loss: 0.3378 - val_accuracy: 0.7632\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3519 - accuracy: 0.8310 - val_loss: 0.3608 - val_accuracy: 0.7663\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3434 - accuracy: 0.8379 - val_loss: 0.3586 - val_accuracy: 0.7596\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2194 - accuracy: 0.9303 - val_loss: 0.1070 - val_accuracy: 0.9811\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1993 - accuracy: 0.9374 - val_loss: 0.0958 - val_accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1843 - accuracy: 0.9426 - val_loss: 0.0809 - val_accuracy: 0.9816\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1817 - accuracy: 0.9430 - val_loss: 0.0952 - val_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1802 - accuracy: 0.9443 - val_loss: 0.0595 - val_accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1715 - accuracy: 0.9471 - val_loss: 0.0704 - val_accuracy: 0.9840\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1716 - accuracy: 0.9479 - val_loss: 0.0784 - val_accuracy: 0.9816\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1681 - accuracy: 0.9479 - val_loss: 0.1039 - val_accuracy: 0.9747\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_168\"\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3339 - accuracy: 0.8601 - val_loss: 0.2892 - val_accuracy: 0.8418\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3212 - accuracy: 0.8637 - val_loss: 0.3030 - val_accuracy: 0.8315\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3134 - accuracy: 0.8665 - val_loss: 0.2585 - val_accuracy: 0.8535\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3040 - accuracy: 0.8672 - val_loss: 0.2584 - val_accuracy: 0.8581\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3016 - accuracy: 0.8684 - val_loss: 0.2154 - val_accuracy: 0.8335\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2938 - accuracy: 0.8710 - val_loss: 0.2358 - val_accuracy: 0.8468\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2896 - accuracy: 0.8713 - val_loss: 0.2198 - val_accuracy: 0.8607\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_169\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_514 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_515 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_516 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_513 (Reshape)          (None, 45, 8)        0           ['input_514[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_514 (Reshape)          (None, 45, 8)        0           ['input_515[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_515 (Reshape)          (None, 45, 11)       0           ['input_516[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_684 (Mult  (None, 45, 8)       2248        ['reshape_513[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_513[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_685 (Mult  (None, 45, 8)       2248        ['reshape_514[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_514[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_686 (Mult  (None, 45, 11)      4147        ['reshape_515[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_515[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_682 (Layer  (None, 45, 8)       16          ['multi_head_attention_684[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_683 (Layer  (None, 45, 8)       16          ['multi_head_attention_685[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_684 (Layer  (None, 45, 11)      22          ['multi_head_attention_686[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1022 (Dropout)         (None, 45, 8)        0           ['layer_normalization_682[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1023 (Dropout)         (None, 45, 8)        0           ['layer_normalization_683[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1024 (Dropout)         (None, 45, 11)       0           ['layer_normalization_684[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_171 (Concatenate)  (None, 45, 27)       0           ['dropout_1022[0][0]',           \n",
      "                                                                  'dropout_1023[0][0]',           \n",
      "                                                                  'dropout_1024[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_171 (  (None, 27)          0           ['concatenate_171[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1025 (Dropout)         (None, 27)           0           ['global_average_pooling1d_171[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_170 (TFOpLambda  (None, 1, 27)       0           ['dropout_1025[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_687 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_170[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_170[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_168 (TFOp  (None, 27)          0           ['multi_head_attention_687[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_685 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_168[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1026 (Dropout)         (None, 27)           0           ['layer_normalization_685[0][0]']\n",
      "                                                                                                  \n",
      " dense_507 (Dense)              (None, 1024)         28672       ['dropout_1026[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1027 (Dropout)         (None, 1024)         0           ['dense_507[0][0]']              \n",
      "                                                                                                  \n",
      " dense_508 (Dense)              (None, 128)          131200      ['dropout_1027[0][0]']           \n",
      "                                                                                                  \n",
      " dense_509 (Dense)              (None, 1)            129         ['dense_508[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1361 - accuracy: 0.9556 - val_loss: 0.2573 - val_accuracy: 0.8896\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1181 - accuracy: 0.9622 - val_loss: 0.2260 - val_accuracy: 0.9154\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1104 - accuracy: 0.9652 - val_loss: 0.1683 - val_accuracy: 0.9300\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1088 - accuracy: 0.9660 - val_loss: 0.1930 - val_accuracy: 0.9321\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1069 - accuracy: 0.9673 - val_loss: 0.2102 - val_accuracy: 0.9209\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0993 - accuracy: 0.9711 - val_loss: 0.1503 - val_accuracy: 0.9427\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_170\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_517 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_518 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_519 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_516 (Reshape)          (None, 45, 8)        0           ['input_517[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_517 (Reshape)          (None, 45, 8)        0           ['input_518[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_518 (Reshape)          (None, 45, 11)       0           ['input_519[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_688 (Mult  (None, 45, 8)       2248        ['reshape_516[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_516[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_689 (Mult  (None, 45, 8)       2248        ['reshape_517[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_517[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_690 (Mult  (None, 45, 11)      4147        ['reshape_518[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_518[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_686 (Layer  (None, 45, 8)       16          ['multi_head_attention_688[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_687 (Layer  (None, 45, 8)       16          ['multi_head_attention_689[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_688 (Layer  (None, 45, 11)      22          ['multi_head_attention_690[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1028 (Dropout)         (None, 45, 8)        0           ['layer_normalization_686[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1029 (Dropout)         (None, 45, 8)        0           ['layer_normalization_687[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1030 (Dropout)         (None, 45, 11)       0           ['layer_normalization_688[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_172 (Concatenate)  (None, 45, 27)       0           ['dropout_1028[0][0]',           \n",
      "                                                                  'dropout_1029[0][0]',           \n",
      "                                                                  'dropout_1030[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_172 (  (None, 27)          0           ['concatenate_172[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1031 (Dropout)         (None, 27)           0           ['global_average_pooling1d_172[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_171 (TFOpLambda  (None, 1, 27)       0           ['dropout_1031[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_691 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_171[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_171[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_169 (TFOp  (None, 27)          0           ['multi_head_attention_691[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_689 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_169[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1032 (Dropout)         (None, 27)           0           ['layer_normalization_689[0][0]']\n",
      "                                                                                                  \n",
      " dense_510 (Dense)              (None, 1024)         28672       ['dropout_1032[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1033 (Dropout)         (None, 1024)         0           ['dense_510[0][0]']              \n",
      "                                                                                                  \n",
      " dense_511 (Dense)              (None, 128)          131200      ['dropout_1033[0][0]']           \n",
      "                                                                                                  \n",
      " dense_512 (Dense)              (None, 1)            129         ['dense_511[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.2976 - accuracy: 0.8768 - val_loss: 0.3328 - val_accuracy: 0.8005\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2395 - accuracy: 0.8978 - val_loss: 0.3521 - val_accuracy: 0.8012\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1772 - accuracy: 0.9235 - val_loss: 0.2219 - val_accuracy: 0.9204\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1550 - accuracy: 0.9443 - val_loss: 0.2026 - val_accuracy: 0.9200\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1343 - accuracy: 0.9569 - val_loss: 0.2969 - val_accuracy: 0.8703\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1212 - accuracy: 0.9621 - val_loss: 0.2074 - val_accuracy: 0.9173\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_171\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_520 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_521 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_522 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_519 (Reshape)          (None, 45, 8)        0           ['input_520[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_520 (Reshape)          (None, 45, 8)        0           ['input_521[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_521 (Reshape)          (None, 45, 11)       0           ['input_522[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_692 (Mult  (None, 45, 8)       2248        ['reshape_519[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_519[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_693 (Mult  (None, 45, 8)       2248        ['reshape_520[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_520[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_694 (Mult  (None, 45, 11)      4147        ['reshape_521[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_521[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_690 (Layer  (None, 45, 8)       16          ['multi_head_attention_692[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_691 (Layer  (None, 45, 8)       16          ['multi_head_attention_693[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_692 (Layer  (None, 45, 11)      22          ['multi_head_attention_694[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1034 (Dropout)         (None, 45, 8)        0           ['layer_normalization_690[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1035 (Dropout)         (None, 45, 8)        0           ['layer_normalization_691[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1036 (Dropout)         (None, 45, 11)       0           ['layer_normalization_692[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_173 (Concatenate)  (None, 45, 27)       0           ['dropout_1034[0][0]',           \n",
      "                                                                  'dropout_1035[0][0]',           \n",
      "                                                                  'dropout_1036[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_173 (  (None, 27)          0           ['concatenate_173[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1037 (Dropout)         (None, 27)           0           ['global_average_pooling1d_173[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_172 (TFOpLambda  (None, 1, 27)       0           ['dropout_1037[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_695 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_172[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_172[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_170 (TFOp  (None, 27)          0           ['multi_head_attention_695[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_693 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_170[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1038 (Dropout)         (None, 27)           0           ['layer_normalization_693[0][0]']\n",
      "                                                                                                  \n",
      " dense_513 (Dense)              (None, 1024)         28672       ['dropout_1038[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1039 (Dropout)         (None, 1024)         0           ['dense_513[0][0]']              \n",
      "                                                                                                  \n",
      " dense_514 (Dense)              (None, 128)          131200      ['dropout_1039[0][0]']           \n",
      "                                                                                                  \n",
      " dense_515 (Dense)              (None, 1)            129         ['dense_514[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3414 - accuracy: 0.8654 - val_loss: 0.2539 - val_accuracy: 0.8973\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2810 - accuracy: 0.8982 - val_loss: 0.2522 - val_accuracy: 0.9049\n",
      "Epoch 3/10\n",
      "362/938 [==========>...................] - ETA: 8s - loss: 0.2666 - accuracy: 0.9085\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_172\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_523 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_524 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_525 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_522 (Reshape)          (None, 45, 8)        0           ['input_523[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_523 (Reshape)          (None, 45, 8)        0           ['input_524[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_524 (Reshape)          (None, 45, 11)       0           ['input_525[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_696 (Mult  (None, 45, 8)       2248        ['reshape_522[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_522[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_697 (Mult  (None, 45, 8)       2248        ['reshape_523[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_523[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_698 (Mult  (None, 45, 11)      4147        ['reshape_524[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_524[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_694 (Layer  (None, 45, 8)       16          ['multi_head_attention_696[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_695 (Layer  (None, 45, 8)       16          ['multi_head_attention_697[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_696 (Layer  (None, 45, 11)      22          ['multi_head_attention_698[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1040 (Dropout)         (None, 45, 8)        0           ['layer_normalization_694[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1041 (Dropout)         (None, 45, 8)        0           ['layer_normalization_695[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1042 (Dropout)         (None, 45, 11)       0           ['layer_normalization_696[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_174 (Concatenate)  (None, 45, 27)       0           ['dropout_1040[0][0]',           \n",
      "                                                                  'dropout_1041[0][0]',           \n",
      "                                                                  'dropout_1042[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_174 (  (None, 27)          0           ['concatenate_174[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1043 (Dropout)         (None, 27)           0           ['global_average_pooling1d_174[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_173 (TFOpLambda  (None, 1, 27)       0           ['dropout_1043[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_699 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_173[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_173[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_171 (TFOp  (None, 27)          0           ['multi_head_attention_699[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_697 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_171[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1044 (Dropout)         (None, 27)           0           ['layer_normalization_697[0][0]']\n",
      "                                                                                                  \n",
      " dense_516 (Dense)              (None, 1024)         28672       ['dropout_1044[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1045 (Dropout)         (None, 1024)         0           ['dense_516[0][0]']              \n",
      "                                                                                                  \n",
      " dense_517 (Dense)              (None, 128)          131200      ['dropout_1045[0][0]']           \n",
      "                                                                                                  \n",
      " dense_518 (Dense)              (None, 1)            129         ['dense_517[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3733 - accuracy: 0.8501 - val_loss: 0.2876 - val_accuracy: 0.8822\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3080 - accuracy: 0.8867 - val_loss: 0.1890 - val_accuracy: 0.9183\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2898 - accuracy: 0.8935 - val_loss: 0.2936 - val_accuracy: 0.8793\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2881 - accuracy: 0.8944 - val_loss: 0.1971 - val_accuracy: 0.9154\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2781 - accuracy: 0.8987 - val_loss: 0.2300 - val_accuracy: 0.9008\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2753 - accuracy: 0.8977 - val_loss: 0.2314 - val_accuracy: 0.9030\n",
      "Epoch 7/10\n",
      "103/938 [==>...........................] - ETA: 11s - loss: 0.2687 - accuracy: 0.9029\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_173\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_526 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_527 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_528 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_525 (Reshape)          (None, 45, 8)        0           ['input_526[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_526 (Reshape)          (None, 45, 8)        0           ['input_527[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_527 (Reshape)          (None, 45, 11)       0           ['input_528[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_700 (Mult  (None, 45, 8)       2248        ['reshape_525[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_525[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_701 (Mult  (None, 45, 8)       2248        ['reshape_526[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_526[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_702 (Mult  (None, 45, 11)      4147        ['reshape_527[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_527[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_698 (Layer  (None, 45, 8)       16          ['multi_head_attention_700[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_699 (Layer  (None, 45, 8)       16          ['multi_head_attention_701[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_700 (Layer  (None, 45, 11)      22          ['multi_head_attention_702[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1046 (Dropout)         (None, 45, 8)        0           ['layer_normalization_698[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1047 (Dropout)         (None, 45, 8)        0           ['layer_normalization_699[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1048 (Dropout)         (None, 45, 11)       0           ['layer_normalization_700[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_175 (Concatenate)  (None, 45, 27)       0           ['dropout_1046[0][0]',           \n",
      "                                                                  'dropout_1047[0][0]',           \n",
      "                                                                  'dropout_1048[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_175 (  (None, 27)          0           ['concatenate_175[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1049 (Dropout)         (None, 27)           0           ['global_average_pooling1d_175[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_174 (TFOpLambda  (None, 1, 27)       0           ['dropout_1049[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_703 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_174[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_174[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_172 (TFOp  (None, 27)          0           ['multi_head_attention_703[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_701 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_172[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1050 (Dropout)         (None, 27)           0           ['layer_normalization_701[0][0]']\n",
      "                                                                                                  \n",
      " dense_519 (Dense)              (None, 1024)         28672       ['dropout_1050[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1051 (Dropout)         (None, 1024)         0           ['dense_519[0][0]']              \n",
      "                                                                                                  \n",
      " dense_520 (Dense)              (None, 128)          131200      ['dropout_1051[0][0]']           \n",
      "                                                                                                  \n",
      " dense_521 (Dense)              (None, 1)            129         ['dense_520[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 15ms/step - loss: 0.4692 - accuracy: 0.7623 - val_loss: 0.3047 - val_accuracy: 0.8093\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3855 - accuracy: 0.8294 - val_loss: 0.3093 - val_accuracy: 0.8081\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3616 - accuracy: 0.8403 - val_loss: 0.3754 - val_accuracy: 0.7603\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3501 - accuracy: 0.8458 - val_loss: 0.4041 - val_accuracy: 0.7180\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3421 - accuracy: 0.8494 - val_loss: 0.2928 - val_accuracy: 0.8155\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3340 - accuracy: 0.8555 - val_loss: 0.3285 - val_accuracy: 0.7969\n",
      "Epoch 7/10\n",
      "913/938 [============================>.] - ETA: 0s - loss: 0.3279 - accuracy: 0.8567\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_174\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_529 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_530 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_531 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_528 (Reshape)          (None, 45, 8)        0           ['input_529[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_529 (Reshape)          (None, 45, 8)        0           ['input_530[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_530 (Reshape)          (None, 45, 11)       0           ['input_531[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_704 (Mult  (None, 45, 8)       2248        ['reshape_528[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_528[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_705 (Mult  (None, 45, 8)       2248        ['reshape_529[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_529[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_706 (Mult  (None, 45, 11)      4147        ['reshape_530[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_530[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_702 (Layer  (None, 45, 8)       16          ['multi_head_attention_704[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_703 (Layer  (None, 45, 8)       16          ['multi_head_attention_705[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_704 (Layer  (None, 45, 11)      22          ['multi_head_attention_706[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1052 (Dropout)         (None, 45, 8)        0           ['layer_normalization_702[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1053 (Dropout)         (None, 45, 8)        0           ['layer_normalization_703[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1054 (Dropout)         (None, 45, 11)       0           ['layer_normalization_704[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_176 (Concatenate)  (None, 45, 27)       0           ['dropout_1052[0][0]',           \n",
      "                                                                  'dropout_1053[0][0]',           \n",
      "                                                                  'dropout_1054[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_176 (  (None, 27)          0           ['concatenate_176[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1055 (Dropout)         (None, 27)           0           ['global_average_pooling1d_176[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_175 (TFOpLambda  (None, 1, 27)       0           ['dropout_1055[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_707 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_175[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_175[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_173 (TFOp  (None, 27)          0           ['multi_head_attention_707[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_705 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_173[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1056 (Dropout)         (None, 27)           0           ['layer_normalization_705[0][0]']\n",
      "                                                                                                  \n",
      " dense_522 (Dense)              (None, 1024)         28672       ['dropout_1056[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1057 (Dropout)         (None, 1024)         0           ['dense_522[0][0]']              \n",
      "                                                                                                  \n",
      " dense_523 (Dense)              (None, 128)          131200      ['dropout_1057[0][0]']           \n",
      "                                                                                                  \n",
      " dense_524 (Dense)              (None, 1)            129         ['dense_523[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.5166 - accuracy: 0.7217 - val_loss: 0.3769 - val_accuracy: 0.7231\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3944 - accuracy: 0.8053 - val_loss: 0.3547 - val_accuracy: 0.7266\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3818 - accuracy: 0.8127 - val_loss: 0.3624 - val_accuracy: 0.7250\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3691 - accuracy: 0.8187 - val_loss: 0.3682 - val_accuracy: 0.7350\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3601 - accuracy: 0.8246 - val_loss: 0.3347 - val_accuracy: 0.7811\n",
      "Epoch 6/10\n",
      "296/938 [========>.....................] - ETA: 9s - loss: 0.3508 - accuracy: 0.8329TRAIN exit 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_175\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_532 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_533 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_534 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_531 (Reshape)          (None, 45, 8)        0           ['input_532[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_532 (Reshape)          (None, 45, 8)        0           ['input_533[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_533 (Reshape)          (None, 45, 11)       0           ['input_534[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_708 (Mult  (None, 45, 8)       2248        ['reshape_531[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_531[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_709 (Mult  (None, 45, 8)       2248        ['reshape_532[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_532[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_710 (Mult  (None, 45, 11)      4147        ['reshape_533[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_533[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_706 (Layer  (None, 45, 8)       16          ['multi_head_attention_708[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_707 (Layer  (None, 45, 8)       16          ['multi_head_attention_709[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_708 (Layer  (None, 45, 11)      22          ['multi_head_attention_710[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1058 (Dropout)         (None, 45, 8)        0           ['layer_normalization_706[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1059 (Dropout)         (None, 45, 8)        0           ['layer_normalization_707[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1060 (Dropout)         (None, 45, 11)       0           ['layer_normalization_708[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_177 (Concatenate)  (None, 45, 27)       0           ['dropout_1058[0][0]',           \n",
      "                                                                  'dropout_1059[0][0]',           \n",
      "                                                                  'dropout_1060[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_177 (  (None, 27)          0           ['concatenate_177[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1061 (Dropout)         (None, 27)           0           ['global_average_pooling1d_177[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_176 (TFOpLambda  (None, 1, 27)       0           ['dropout_1061[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_711 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_176[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_176[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_174 (TFOp  (None, 27)          0           ['multi_head_attention_711[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_709 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_174[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1062 (Dropout)         (None, 27)           0           ['layer_normalization_709[0][0]']\n",
      "                                                                                                  \n",
      " dense_525 (Dense)              (None, 1024)         28672       ['dropout_1062[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1063 (Dropout)         (None, 1024)         0           ['dense_525[0][0]']              \n",
      "                                                                                                  \n",
      " dense_526 (Dense)              (None, 128)          131200      ['dropout_1063[0][0]']           \n",
      "                                                                                                  \n",
      " dense_527 (Dense)              (None, 1)            129         ['dense_526[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.3866 - accuracy: 0.8369 - val_loss: 0.1950 - val_accuracy: 0.9548\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2654 - accuracy: 0.9138 - val_loss: 0.1621 - val_accuracy: 0.9670\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2363 - accuracy: 0.9217 - val_loss: 0.1117 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2151 - accuracy: 0.9308 - val_loss: 0.1211 - val_accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1988 - accuracy: 0.9354 - val_loss: 0.0902 - val_accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "120/938 [==>...........................] - ETA: 11s - loss: 0.1861 - accuracy: 0.9422TRAIN cooking 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_176\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_535 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_536 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_537 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_534 (Reshape)          (None, 45, 8)        0           ['input_535[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_535 (Reshape)          (None, 45, 8)        0           ['input_536[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_536 (Reshape)          (None, 45, 11)       0           ['input_537[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_712 (Mult  (None, 45, 8)       2248        ['reshape_534[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_534[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_713 (Mult  (None, 45, 8)       2248        ['reshape_535[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_535[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_714 (Mult  (None, 45, 11)      4147        ['reshape_536[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_536[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_710 (Layer  (None, 45, 8)       16          ['multi_head_attention_712[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_711 (Layer  (None, 45, 8)       16          ['multi_head_attention_713[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_712 (Layer  (None, 45, 11)      22          ['multi_head_attention_714[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1064 (Dropout)         (None, 45, 8)        0           ['layer_normalization_710[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1065 (Dropout)         (None, 45, 8)        0           ['layer_normalization_711[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1066 (Dropout)         (None, 45, 11)       0           ['layer_normalization_712[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_178 (Concatenate)  (None, 45, 27)       0           ['dropout_1064[0][0]',           \n",
      "                                                                  'dropout_1065[0][0]',           \n",
      "                                                                  'dropout_1066[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_178 (  (None, 27)          0           ['concatenate_178[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1067 (Dropout)         (None, 27)           0           ['global_average_pooling1d_178[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_177 (TFOpLambda  (None, 1, 27)       0           ['dropout_1067[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_715 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_177[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_177[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_175 (TFOp  (None, 27)          0           ['multi_head_attention_715[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_713 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_175[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1068 (Dropout)         (None, 27)           0           ['layer_normalization_713[0][0]']\n",
      "                                                                                                  \n",
      " dense_528 (Dense)              (None, 1024)         28672       ['dropout_1068[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1069 (Dropout)         (None, 1024)         0           ['dense_528[0][0]']              \n",
      "                                                                                                  \n",
      " dense_529 (Dense)              (None, 128)          131200      ['dropout_1069[0][0]']           \n",
      "                                                                                                  \n",
      " dense_530 (Dense)              (None, 1)            129         ['dense_529[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4044 - accuracy: 0.8289 - val_loss: 0.2647 - val_accuracy: 0.8736\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.3492 - accuracy: 0.8613 - val_loss: 0.2526 - val_accuracy: 0.8734\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3341 - accuracy: 0.8643 - val_loss: 0.3377 - val_accuracy: 0.8327\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3265 - accuracy: 0.8640 - val_loss: 0.2750 - val_accuracy: 0.8514\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3176 - accuracy: 0.8662 - val_loss: 0.2447 - val_accuracy: 0.8516\n",
      "Epoch 6/10\n",
      "364/938 [==========>...................] - ETA: 8s - loss: 0.3147 - accuracy: 0.8636TRAIN shower 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_177\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_538 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_539 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_540 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_537 (Reshape)          (None, 45, 8)        0           ['input_538[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_538 (Reshape)          (None, 45, 8)        0           ['input_539[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_539 (Reshape)          (None, 45, 11)       0           ['input_540[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_716 (Mult  (None, 45, 8)       2248        ['reshape_537[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_537[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_717 (Mult  (None, 45, 8)       2248        ['reshape_538[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_538[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_718 (Mult  (None, 45, 11)      4147        ['reshape_539[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_539[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_714 (Layer  (None, 45, 8)       16          ['multi_head_attention_716[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_715 (Layer  (None, 45, 8)       16          ['multi_head_attention_717[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_716 (Layer  (None, 45, 11)      22          ['multi_head_attention_718[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1070 (Dropout)         (None, 45, 8)        0           ['layer_normalization_714[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1071 (Dropout)         (None, 45, 8)        0           ['layer_normalization_715[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1072 (Dropout)         (None, 45, 11)       0           ['layer_normalization_716[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_179 (Concatenate)  (None, 45, 27)       0           ['dropout_1070[0][0]',           \n",
      "                                                                  'dropout_1071[0][0]',           \n",
      "                                                                  'dropout_1072[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_179 (  (None, 27)          0           ['concatenate_179[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1073 (Dropout)         (None, 27)           0           ['global_average_pooling1d_179[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_178 (TFOpLambda  (None, 1, 27)       0           ['dropout_1073[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_719 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_178[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_178[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_176 (TFOp  (None, 27)          0           ['multi_head_attention_719[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_717 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_176[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1074 (Dropout)         (None, 27)           0           ['layer_normalization_717[0][0]']\n",
      "                                                                                                  \n",
      " dense_531 (Dense)              (None, 1024)         28672       ['dropout_1074[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1075 (Dropout)         (None, 1024)         0           ['dense_531[0][0]']              \n",
      "                                                                                                  \n",
      " dense_532 (Dense)              (None, 128)          131200      ['dropout_1075[0][0]']           \n",
      "                                                                                                  \n",
      " dense_533 (Dense)              (None, 1)            129         ['dense_532[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.2823 - accuracy: 0.8796 - val_loss: 0.1657 - val_accuracy: 0.9202\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1842 - accuracy: 0.9363 - val_loss: 0.1258 - val_accuracy: 0.9317\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.1729 - accuracy: 0.9419 - val_loss: 0.1222 - val_accuracy: 0.9388\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1647 - accuracy: 0.9437 - val_loss: 0.1330 - val_accuracy: 0.9388\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1316 - accuracy: 0.9587 - val_loss: 0.0993 - val_accuracy: 0.9505\n",
      "Epoch 6/10\n",
      "125/938 [==>...........................] - ETA: 11s - loss: 0.1207 - accuracy: 0.9630TRAIN pc 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_178\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_541 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_542 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_543 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_540 (Reshape)          (None, 45, 8)        0           ['input_541[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_541 (Reshape)          (None, 45, 8)        0           ['input_542[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_542 (Reshape)          (None, 45, 11)       0           ['input_543[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_720 (Mult  (None, 45, 8)       2248        ['reshape_540[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_540[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_721 (Mult  (None, 45, 8)       2248        ['reshape_541[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_541[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_722 (Mult  (None, 45, 11)      4147        ['reshape_542[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_542[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_718 (Layer  (None, 45, 8)       16          ['multi_head_attention_720[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_719 (Layer  (None, 45, 8)       16          ['multi_head_attention_721[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_720 (Layer  (None, 45, 11)      22          ['multi_head_attention_722[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1076 (Dropout)         (None, 45, 8)        0           ['layer_normalization_718[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1077 (Dropout)         (None, 45, 8)        0           ['layer_normalization_719[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1078 (Dropout)         (None, 45, 11)       0           ['layer_normalization_720[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_180 (Concatenate)  (None, 45, 27)       0           ['dropout_1076[0][0]',           \n",
      "                                                                  'dropout_1077[0][0]',           \n",
      "                                                                  'dropout_1078[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_180 (  (None, 27)          0           ['concatenate_180[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1079 (Dropout)         (None, 27)           0           ['global_average_pooling1d_180[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_179 (TFOpLambda  (None, 1, 27)       0           ['dropout_1079[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_723 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_179[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_179[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_177 (TFOp  (None, 27)          0           ['multi_head_attention_723[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_721 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_177[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1080 (Dropout)         (None, 27)           0           ['layer_normalization_721[0][0]']\n",
      "                                                                                                  \n",
      " dense_534 (Dense)              (None, 1024)         28672       ['dropout_1080[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1081 (Dropout)         (None, 1024)         0           ['dense_534[0][0]']              \n",
      "                                                                                                  \n",
      " dense_535 (Dense)              (None, 128)          131200      ['dropout_1081[0][0]']           \n",
      "                                                                                                  \n",
      " dense_536 (Dense)              (None, 1)            129         ['dense_535[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3004 - accuracy: 0.8759 - val_loss: 0.1902 - val_accuracy: 0.8612\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2454 - accuracy: 0.8891 - val_loss: 0.1909 - val_accuracy: 0.8980\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2217 - accuracy: 0.8973 - val_loss: 0.1829 - val_accuracy: 0.8956\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2113 - accuracy: 0.8988 - val_loss: 0.1864 - val_accuracy: 0.9027\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1996 - accuracy: 0.9099 - val_loss: 0.1804 - val_accuracy: 0.9300\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.3358 - accuracy: 0.8675 - val_loss: 0.2407 - val_accuracy: 0.9168\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2675 - accuracy: 0.9058 - val_loss: 0.1560 - val_accuracy: 0.9584\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2166 - accuracy: 0.9316 - val_loss: 0.1467 - val_accuracy: 0.9546\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1957 - accuracy: 0.9426 - val_loss: 0.1372 - val_accuracy: 0.9563\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1842 - accuracy: 0.9447 - val_loss: 0.1319 - val_accuracy: 0.9622\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3659 - accuracy: 0.8512 - val_loss: 0.2274 - val_accuracy: 0.8784\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3119 - accuracy: 0.8790 - val_loss: 0.2207 - val_accuracy: 0.8934\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3013 - accuracy: 0.8840 - val_loss: 0.2007 - val_accuracy: 0.9106\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2957 - accuracy: 0.8841 - val_loss: 0.2702 - val_accuracy: 0.8784\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2917 - accuracy: 0.8852 - val_loss: 0.2801 - val_accuracy: 0.8719\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4702 - accuracy: 0.7591 - val_loss: 0.3994 - val_accuracy: 0.7496\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3794 - accuracy: 0.8330 - val_loss: 0.3120 - val_accuracy: 0.8084\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3618 - accuracy: 0.8422 - val_loss: 0.4046 - val_accuracy: 0.7740\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3533 - accuracy: 0.8447 - val_loss: 0.3644 - val_accuracy: 0.7892\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3427 - accuracy: 0.8505 - val_loss: 0.3532 - val_accuracy: 0.7842\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3345 - accuracy: 0.8570 - val_loss: 0.3051 - val_accuracy: 0.8215\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3944 - accuracy: 0.8022 - val_loss: 0.3695 - val_accuracy: 0.7004\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3862 - accuracy: 0.8048 - val_loss: 0.3331 - val_accuracy: 0.7364\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3775 - accuracy: 0.8103 - val_loss: 0.3984 - val_accuracy: 0.7023\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3663 - accuracy: 0.8199 - val_loss: 0.4340 - val_accuracy: 0.7042\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3620 - accuracy: 0.8195 - val_loss: 0.4618 - val_accuracy: 0.6939\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3570 - accuracy: 0.8244 - val_loss: 0.3831 - val_accuracy: 0.7216\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2110 - accuracy: 0.9329 - val_loss: 0.1097 - val_accuracy: 0.9694\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1989 - accuracy: 0.9382 - val_loss: 0.0911 - val_accuracy: 0.9723\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1877 - accuracy: 0.9408 - val_loss: 0.0881 - val_accuracy: 0.9754\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1782 - accuracy: 0.9440 - val_loss: 0.0811 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1755 - accuracy: 0.9449 - val_loss: 0.0768 - val_accuracy: 0.9780\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1709 - accuracy: 0.9479 - val_loss: 0.0851 - val_accuracy: 0.9795\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3129 - accuracy: 0.8619 - val_loss: 0.3171 - val_accuracy: 0.8208\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3078 - accuracy: 0.8664 - val_loss: 0.3055 - val_accuracy: 0.8115\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3069 - accuracy: 0.8663 - val_loss: 0.2991 - val_accuracy: 0.8461\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3044 - accuracy: 0.8643 - val_loss: 0.3083 - val_accuracy: 0.8299\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3003 - accuracy: 0.8678 - val_loss: 0.2984 - val_accuracy: 0.8471\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_185\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_562 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_563 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_564 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_561 (Reshape)          (None, 45, 8)        0           ['input_562[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_562 (Reshape)          (None, 45, 8)        0           ['input_563[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_563 (Reshape)          (None, 45, 11)       0           ['input_564[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_748 (Mult  (None, 45, 8)       2248        ['reshape_561[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_561[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_749 (Mult  (None, 45, 8)       2248        ['reshape_562[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_562[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_750 (Mult  (None, 45, 11)      4147        ['reshape_563[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_563[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_746 (Layer  (None, 45, 8)       16          ['multi_head_attention_748[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_747 (Layer  (None, 45, 8)       16          ['multi_head_attention_749[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_748 (Layer  (None, 45, 11)      22          ['multi_head_attention_750[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1118 (Dropout)         (None, 45, 8)        0           ['layer_normalization_746[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1119 (Dropout)         (None, 45, 8)        0           ['layer_normalization_747[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1120 (Dropout)         (None, 45, 11)       0           ['layer_normalization_748[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_187 (Concatenate)  (None, 45, 27)       0           ['dropout_1118[0][0]',           \n",
      "                                                                  'dropout_1119[0][0]',           \n",
      "                                                                  'dropout_1120[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_187 (  (None, 27)          0           ['concatenate_187[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1121 (Dropout)         (None, 27)           0           ['global_average_pooling1d_187[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_186 (TFOpLambda  (None, 1, 27)       0           ['dropout_1121[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_751 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_186[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_186[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_184 (TFOp  (None, 27)          0           ['multi_head_attention_751[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_749 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_184[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1122 (Dropout)         (None, 27)           0           ['layer_normalization_749[0][0]']\n",
      "                                                                                                  \n",
      " dense_555 (Dense)              (None, 1024)         28672       ['dropout_1122[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1123 (Dropout)         (None, 1024)         0           ['dense_555[0][0]']              \n",
      "                                                                                                  \n",
      " dense_556 (Dense)              (None, 128)          131200      ['dropout_1123[0][0]']           \n",
      "                                                                                                  \n",
      " dense_557 (Dense)              (None, 1)            129         ['dense_556[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 17ms/step - loss: 0.3007 - accuracy: 0.8693 - val_loss: 0.1767 - val_accuracy: 0.8875\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1976 - accuracy: 0.9300 - val_loss: 0.1530 - val_accuracy: 0.9235\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1243 - accuracy: 0.9606 - val_loss: 0.0989 - val_accuracy: 0.9627\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1279 - accuracy: 0.9591 - val_loss: 0.0744 - val_accuracy: 0.9754\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1105 - accuracy: 0.9661 - val_loss: 0.0893 - val_accuracy: 0.9668\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0951 - accuracy: 0.9718 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_186\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_565 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_566 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_567 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_564 (Reshape)          (None, 45, 8)        0           ['input_565[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_565 (Reshape)          (None, 45, 8)        0           ['input_566[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_566 (Reshape)          (None, 45, 11)       0           ['input_567[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_752 (Mult  (None, 45, 8)       2248        ['reshape_564[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_564[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_753 (Mult  (None, 45, 8)       2248        ['reshape_565[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_565[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_754 (Mult  (None, 45, 11)      4147        ['reshape_566[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_566[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_750 (Layer  (None, 45, 8)       16          ['multi_head_attention_752[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_751 (Layer  (None, 45, 8)       16          ['multi_head_attention_753[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_752 (Layer  (None, 45, 11)      22          ['multi_head_attention_754[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1124 (Dropout)         (None, 45, 8)        0           ['layer_normalization_750[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1125 (Dropout)         (None, 45, 8)        0           ['layer_normalization_751[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1126 (Dropout)         (None, 45, 11)       0           ['layer_normalization_752[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_188 (Concatenate)  (None, 45, 27)       0           ['dropout_1124[0][0]',           \n",
      "                                                                  'dropout_1125[0][0]',           \n",
      "                                                                  'dropout_1126[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_188 (  (None, 27)          0           ['concatenate_188[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1127 (Dropout)         (None, 27)           0           ['global_average_pooling1d_188[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_187 (TFOpLambda  (None, 1, 27)       0           ['dropout_1127[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_755 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_187[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_187[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_185 (TFOp  (None, 27)          0           ['multi_head_attention_755[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_753 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_185[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1128 (Dropout)         (None, 27)           0           ['layer_normalization_753[0][0]']\n",
      "                                                                                                  \n",
      " dense_558 (Dense)              (None, 1024)         28672       ['dropout_1128[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1129 (Dropout)         (None, 1024)         0           ['dense_558[0][0]']              \n",
      "                                                                                                  \n",
      " dense_559 (Dense)              (None, 128)          131200      ['dropout_1129[0][0]']           \n",
      "                                                                                                  \n",
      " dense_560 (Dense)              (None, 1)            129         ['dense_559[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.2956 - accuracy: 0.8787 - val_loss: 0.4916 - val_accuracy: 0.7056\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2602 - accuracy: 0.8997 - val_loss: 0.4842 - val_accuracy: 0.6956\n",
      "Epoch 3/10\n",
      " 47/938 [>.............................] - ETA: 14s - loss: 0.2519 - accuracy: 0.9049\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_187\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_568 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_569 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_570 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_567 (Reshape)          (None, 45, 8)        0           ['input_568[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_568 (Reshape)          (None, 45, 8)        0           ['input_569[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_569 (Reshape)          (None, 45, 11)       0           ['input_570[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_756 (Mult  (None, 45, 8)       2248        ['reshape_567[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_567[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_757 (Mult  (None, 45, 8)       2248        ['reshape_568[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_568[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_758 (Mult  (None, 45, 11)      4147        ['reshape_569[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_569[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_754 (Layer  (None, 45, 8)       16          ['multi_head_attention_756[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_755 (Layer  (None, 45, 8)       16          ['multi_head_attention_757[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_756 (Layer  (None, 45, 11)      22          ['multi_head_attention_758[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1130 (Dropout)         (None, 45, 8)        0           ['layer_normalization_754[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1131 (Dropout)         (None, 45, 8)        0           ['layer_normalization_755[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1132 (Dropout)         (None, 45, 11)       0           ['layer_normalization_756[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_189 (Concatenate)  (None, 45, 27)       0           ['dropout_1130[0][0]',           \n",
      "                                                                  'dropout_1131[0][0]',           \n",
      "                                                                  'dropout_1132[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_189 (  (None, 27)          0           ['concatenate_189[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1133 (Dropout)         (None, 27)           0           ['global_average_pooling1d_189[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_188 (TFOpLambda  (None, 1, 27)       0           ['dropout_1133[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_759 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_188[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_188[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_186 (TFOp  (None, 27)          0           ['multi_head_attention_759[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_757 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_186[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1134 (Dropout)         (None, 27)           0           ['layer_normalization_757[0][0]']\n",
      "                                                                                                  \n",
      " dense_561 (Dense)              (None, 1024)         28672       ['dropout_1134[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1135 (Dropout)         (None, 1024)         0           ['dense_561[0][0]']              \n",
      "                                                                                                  \n",
      " dense_562 (Dense)              (None, 128)          131200      ['dropout_1135[0][0]']           \n",
      "                                                                                                  \n",
      " dense_563 (Dense)              (None, 1)            129         ['dense_562[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3296 - accuracy: 0.8733 - val_loss: 0.2028 - val_accuracy: 0.9352\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2491 - accuracy: 0.9168 - val_loss: 0.1531 - val_accuracy: 0.9565\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2047 - accuracy: 0.9386 - val_loss: 0.1326 - val_accuracy: 0.9649\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1991 - accuracy: 0.9409 - val_loss: 0.1283 - val_accuracy: 0.9634\n",
      "Epoch 5/10\n",
      "853/938 [==========================>...] - ETA: 1s - loss: 0.1918 - accuracy: 0.9427\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_188\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_571 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_572 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_573 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_570 (Reshape)          (None, 45, 8)        0           ['input_571[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_571 (Reshape)          (None, 45, 8)        0           ['input_572[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_572 (Reshape)          (None, 45, 11)       0           ['input_573[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_760 (Mult  (None, 45, 8)       2248        ['reshape_570[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_570[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_761 (Mult  (None, 45, 8)       2248        ['reshape_571[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_571[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_762 (Mult  (None, 45, 11)      4147        ['reshape_572[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_572[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_758 (Layer  (None, 45, 8)       16          ['multi_head_attention_760[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_759 (Layer  (None, 45, 8)       16          ['multi_head_attention_761[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_760 (Layer  (None, 45, 11)      22          ['multi_head_attention_762[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1136 (Dropout)         (None, 45, 8)        0           ['layer_normalization_758[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1137 (Dropout)         (None, 45, 8)        0           ['layer_normalization_759[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1138 (Dropout)         (None, 45, 11)       0           ['layer_normalization_760[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_190 (Concatenate)  (None, 45, 27)       0           ['dropout_1136[0][0]',           \n",
      "                                                                  'dropout_1137[0][0]',           \n",
      "                                                                  'dropout_1138[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_190 (  (None, 27)          0           ['concatenate_190[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1139 (Dropout)         (None, 27)           0           ['global_average_pooling1d_190[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_189 (TFOpLambda  (None, 1, 27)       0           ['dropout_1139[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_763 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_189[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_189[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_187 (TFOp  (None, 27)          0           ['multi_head_attention_763[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_761 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_187[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1140 (Dropout)         (None, 27)           0           ['layer_normalization_761[0][0]']\n",
      "                                                                                                  \n",
      " dense_564 (Dense)              (None, 1024)         28672       ['dropout_1140[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1141 (Dropout)         (None, 1024)         0           ['dense_564[0][0]']              \n",
      "                                                                                                  \n",
      " dense_565 (Dense)              (None, 128)          131200      ['dropout_1141[0][0]']           \n",
      "                                                                                                  \n",
      " dense_566 (Dense)              (None, 1)            129         ['dense_565[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3573 - accuracy: 0.8563 - val_loss: 0.3767 - val_accuracy: 0.8033\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2990 - accuracy: 0.8902 - val_loss: 0.2497 - val_accuracy: 0.8989\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2859 - accuracy: 0.8953 - val_loss: 0.3072 - val_accuracy: 0.8072\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2807 - accuracy: 0.8981 - val_loss: 0.1895 - val_accuracy: 0.9243\n",
      "Epoch 5/10\n",
      "701/938 [=====================>........] - ETA: 3s - loss: 0.2734 - accuracy: 0.8995TRAIN toileting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_189\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_574 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_575 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_576 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_573 (Reshape)          (None, 45, 8)        0           ['input_574[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_574 (Reshape)          (None, 45, 8)        0           ['input_575[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_575 (Reshape)          (None, 45, 11)       0           ['input_576[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_764 (Mult  (None, 45, 8)       2248        ['reshape_573[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_573[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_765 (Mult  (None, 45, 8)       2248        ['reshape_574[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_574[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_766 (Mult  (None, 45, 11)      4147        ['reshape_575[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_575[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_762 (Layer  (None, 45, 8)       16          ['multi_head_attention_764[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_763 (Layer  (None, 45, 8)       16          ['multi_head_attention_765[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_764 (Layer  (None, 45, 11)      22          ['multi_head_attention_766[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1142 (Dropout)         (None, 45, 8)        0           ['layer_normalization_762[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1143 (Dropout)         (None, 45, 8)        0           ['layer_normalization_763[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1144 (Dropout)         (None, 45, 11)       0           ['layer_normalization_764[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_191 (Concatenate)  (None, 45, 27)       0           ['dropout_1142[0][0]',           \n",
      "                                                                  'dropout_1143[0][0]',           \n",
      "                                                                  'dropout_1144[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_191 (  (None, 27)          0           ['concatenate_191[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1145 (Dropout)         (None, 27)           0           ['global_average_pooling1d_191[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_190 (TFOpLambda  (None, 1, 27)       0           ['dropout_1145[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_767 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_190[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_190[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_188 (TFOp  (None, 27)          0           ['multi_head_attention_767[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_765 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_188[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1146 (Dropout)         (None, 27)           0           ['layer_normalization_765[0][0]']\n",
      "                                                                                                  \n",
      " dense_567 (Dense)              (None, 1024)         28672       ['dropout_1146[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1147 (Dropout)         (None, 1024)         0           ['dense_567[0][0]']              \n",
      "                                                                                                  \n",
      " dense_568 (Dense)              (None, 128)          131200      ['dropout_1147[0][0]']           \n",
      "                                                                                                  \n",
      " dense_569 (Dense)              (None, 1)            129         ['dense_568[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4721 - accuracy: 0.7566 - val_loss: 0.3336 - val_accuracy: 0.7778\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3755 - accuracy: 0.8348 - val_loss: 0.2858 - val_accuracy: 0.8366\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3559 - accuracy: 0.8448 - val_loss: 0.2993 - val_accuracy: 0.8041\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3461 - accuracy: 0.8514 - val_loss: 0.2555 - val_accuracy: 0.8356\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3374 - accuracy: 0.8531 - val_loss: 0.2936 - val_accuracy: 0.8139\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3291 - accuracy: 0.8573 - val_loss: 0.2694 - val_accuracy: 0.8344\n",
      "Epoch 7/10\n",
      "656/938 [===================>..........] - ETA: 4s - loss: 0.3260 - accuracy: 0.8626TRAIN resting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_190\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_577 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_578 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_579 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_576 (Reshape)          (None, 45, 8)        0           ['input_577[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_577 (Reshape)          (None, 45, 8)        0           ['input_578[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_578 (Reshape)          (None, 45, 11)       0           ['input_579[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_768 (Mult  (None, 45, 8)       2248        ['reshape_576[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_576[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_769 (Mult  (None, 45, 8)       2248        ['reshape_577[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_577[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_770 (Mult  (None, 45, 11)      4147        ['reshape_578[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_578[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_766 (Layer  (None, 45, 8)       16          ['multi_head_attention_768[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_767 (Layer  (None, 45, 8)       16          ['multi_head_attention_769[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_768 (Layer  (None, 45, 11)      22          ['multi_head_attention_770[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1148 (Dropout)         (None, 45, 8)        0           ['layer_normalization_766[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1149 (Dropout)         (None, 45, 8)        0           ['layer_normalization_767[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1150 (Dropout)         (None, 45, 11)       0           ['layer_normalization_768[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_192 (Concatenate)  (None, 45, 27)       0           ['dropout_1148[0][0]',           \n",
      "                                                                  'dropout_1149[0][0]',           \n",
      "                                                                  'dropout_1150[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_192 (  (None, 27)          0           ['concatenate_192[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1151 (Dropout)         (None, 27)           0           ['global_average_pooling1d_192[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_191 (TFOpLambda  (None, 1, 27)       0           ['dropout_1151[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_771 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_191[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_191[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_189 (TFOp  (None, 27)          0           ['multi_head_attention_771[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_769 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_189[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1152 (Dropout)         (None, 27)           0           ['layer_normalization_769[0][0]']\n",
      "                                                                                                  \n",
      " dense_570 (Dense)              (None, 1024)         28672       ['dropout_1152[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1153 (Dropout)         (None, 1024)         0           ['dense_570[0][0]']              \n",
      "                                                                                                  \n",
      " dense_571 (Dense)              (None, 128)          131200      ['dropout_1153[0][0]']           \n",
      "                                                                                                  \n",
      " dense_572 (Dense)              (None, 1)            129         ['dense_571[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 16ms/step - loss: 0.5030 - accuracy: 0.7372 - val_loss: 0.3194 - val_accuracy: 0.7367\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3922 - accuracy: 0.8039 - val_loss: 0.2701 - val_accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3729 - accuracy: 0.8183 - val_loss: 0.3059 - val_accuracy: 0.7551\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3638 - accuracy: 0.8218 - val_loss: 0.2536 - val_accuracy: 0.8122\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 21s 16ms/step - loss: 0.3921 - accuracy: 0.8296 - val_loss: 0.1940 - val_accuracy: 0.9584\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2544 - accuracy: 0.9156 - val_loss: 0.1157 - val_accuracy: 0.9723\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2241 - accuracy: 0.9291 - val_loss: 0.1081 - val_accuracy: 0.9740\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.2076 - accuracy: 0.9347 - val_loss: 0.1161 - val_accuracy: 0.9661\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4142 - accuracy: 0.8228 - val_loss: 0.2574 - val_accuracy: 0.8891\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3555 - accuracy: 0.8562 - val_loss: 0.2481 - val_accuracy: 0.8609\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3361 - accuracy: 0.8625 - val_loss: 0.2651 - val_accuracy: 0.8636\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3153 - accuracy: 0.8642 - val_loss: 0.2587 - val_accuracy: 0.8217\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.2991 - accuracy: 0.8680 - val_loss: 0.2152 - val_accuracy: 0.8640\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1978 - accuracy: 0.9305 - val_loss: 0.1725 - val_accuracy: 0.9133\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1698 - accuracy: 0.9436 - val_loss: 0.1438 - val_accuracy: 0.9286\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1539 - accuracy: 0.9487 - val_loss: 0.0879 - val_accuracy: 0.9589\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1340 - accuracy: 0.9561 - val_loss: 0.0684 - val_accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2374 - accuracy: 0.8994 - val_loss: 0.3975 - val_accuracy: 0.7508\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2198 - accuracy: 0.8984 - val_loss: 0.2663 - val_accuracy: 0.7603\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2109 - accuracy: 0.9059 - val_loss: 0.2512 - val_accuracy: 0.9125\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1820 - accuracy: 0.9333 - val_loss: 0.1709 - val_accuracy: 0.8973\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1516 - accuracy: 0.9480 - val_loss: 0.2067 - val_accuracy: 0.9082\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1832 - accuracy: 0.9466 - val_loss: 0.1065 - val_accuracy: 0.9692\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1753 - accuracy: 0.9509 - val_loss: 0.1115 - val_accuracy: 0.9680\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1621 - accuracy: 0.9548 - val_loss: 0.1013 - val_accuracy: 0.9718\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1515 - accuracy: 0.9584 - val_loss: 0.1021 - val_accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1476 - accuracy: 0.9603 - val_loss: 0.0968 - val_accuracy: 0.9716\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2720 - accuracy: 0.8989 - val_loss: 0.1888 - val_accuracy: 0.9092\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2703 - accuracy: 0.8995 - val_loss: 0.1351 - val_accuracy: 0.9398\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2657 - accuracy: 0.9018 - val_loss: 0.1961 - val_accuracy: 0.9228\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2627 - accuracy: 0.9022 - val_loss: 0.1340 - val_accuracy: 0.9376\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2574 - accuracy: 0.9033 - val_loss: 0.1315 - val_accuracy: 0.9431\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 10 19932\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_197\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_598 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_599 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_600 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_597 (Reshape)          (None, 45, 8)        0           ['input_598[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_598 (Reshape)          (None, 45, 8)        0           ['input_599[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_599 (Reshape)          (None, 45, 11)       0           ['input_600[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_796 (Mult  (None, 45, 8)       2248        ['reshape_597[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_597[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_797 (Mult  (None, 45, 8)       2248        ['reshape_598[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_598[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_798 (Mult  (None, 45, 11)      4147        ['reshape_599[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_599[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_794 (Layer  (None, 45, 8)       16          ['multi_head_attention_796[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_795 (Layer  (None, 45, 8)       16          ['multi_head_attention_797[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_796 (Layer  (None, 45, 11)      22          ['multi_head_attention_798[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1190 (Dropout)         (None, 45, 8)        0           ['layer_normalization_794[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1191 (Dropout)         (None, 45, 8)        0           ['layer_normalization_795[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1192 (Dropout)         (None, 45, 11)       0           ['layer_normalization_796[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_199 (Concatenate)  (None, 45, 27)       0           ['dropout_1190[0][0]',           \n",
      "                                                                  'dropout_1191[0][0]',           \n",
      "                                                                  'dropout_1192[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_199 (  (None, 27)          0           ['concatenate_199[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1193 (Dropout)         (None, 27)           0           ['global_average_pooling1d_199[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_198 (TFOpLambda  (None, 1, 27)       0           ['dropout_1193[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_799 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_198[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_198[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_196 (TFOp  (None, 27)          0           ['multi_head_attention_799[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_797 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_196[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1194 (Dropout)         (None, 27)           0           ['layer_normalization_797[0][0]']\n",
      "                                                                                                  \n",
      " dense_591 (Dense)              (None, 1024)         28672       ['dropout_1194[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1195 (Dropout)         (None, 1024)         0           ['dense_591[0][0]']              \n",
      "                                                                                                  \n",
      " dense_592 (Dense)              (None, 128)          131200      ['dropout_1195[0][0]']           \n",
      "                                                                                                  \n",
      " dense_593 (Dense)              (None, 1)            129         ['dense_592[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3255 - accuracy: 0.8638 - val_loss: 0.2349 - val_accuracy: 0.8547\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3184 - accuracy: 0.8673 - val_loss: 0.2139 - val_accuracy: 0.8602\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3132 - accuracy: 0.8707 - val_loss: 0.2385 - val_accuracy: 0.8600\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_198\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_601 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_602 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_603 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_600 (Reshape)          (None, 45, 8)        0           ['input_601[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_601 (Reshape)          (None, 45, 8)        0           ['input_602[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_602 (Reshape)          (None, 45, 11)       0           ['input_603[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_800 (Mult  (None, 45, 8)       2248        ['reshape_600[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_600[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_801 (Mult  (None, 45, 8)       2248        ['reshape_601[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_601[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_802 (Mult  (None, 45, 11)      4147        ['reshape_602[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_602[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_798 (Layer  (None, 45, 8)       16          ['multi_head_attention_800[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_799 (Layer  (None, 45, 8)       16          ['multi_head_attention_801[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_800 (Layer  (None, 45, 11)      22          ['multi_head_attention_802[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1196 (Dropout)         (None, 45, 8)        0           ['layer_normalization_798[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1197 (Dropout)         (None, 45, 8)        0           ['layer_normalization_799[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1198 (Dropout)         (None, 45, 11)       0           ['layer_normalization_800[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_200 (Concatenate)  (None, 45, 27)       0           ['dropout_1196[0][0]',           \n",
      "                                                                  'dropout_1197[0][0]',           \n",
      "                                                                  'dropout_1198[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_200 (  (None, 27)          0           ['concatenate_200[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1199 (Dropout)         (None, 27)           0           ['global_average_pooling1d_200[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_199 (TFOpLambda  (None, 1, 27)       0           ['dropout_1199[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_803 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_199[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_199[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_197 (TFOp  (None, 27)          0           ['multi_head_attention_803[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_801 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_197[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1200 (Dropout)         (None, 27)           0           ['layer_normalization_801[0][0]']\n",
      "                                                                                                  \n",
      " dense_594 (Dense)              (None, 1024)         28672       ['dropout_1200[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1201 (Dropout)         (None, 1024)         0           ['dense_594[0][0]']              \n",
      "                                                                                                  \n",
      " dense_595 (Dense)              (None, 128)          131200      ['dropout_1201[0][0]']           \n",
      "                                                                                                  \n",
      " dense_596 (Dense)              (None, 1)            129         ['dense_595[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5169 - accuracy: 0.7197 - val_loss: 0.2719 - val_accuracy: 0.7675\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3529 - accuracy: 0.8288 - val_loss: 0.2713 - val_accuracy: 0.8038\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3420 - accuracy: 0.8337 - val_loss: 0.3324 - val_accuracy: 0.7926\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_199\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_604 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_605 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_606 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_603 (Reshape)          (None, 45, 8)        0           ['input_604[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_604 (Reshape)          (None, 45, 8)        0           ['input_605[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_605 (Reshape)          (None, 45, 11)       0           ['input_606[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_804 (Mult  (None, 45, 8)       2248        ['reshape_603[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_603[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_805 (Mult  (None, 45, 8)       2248        ['reshape_604[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_604[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_806 (Mult  (None, 45, 11)      4147        ['reshape_605[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_605[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_802 (Layer  (None, 45, 8)       16          ['multi_head_attention_804[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_803 (Layer  (None, 45, 8)       16          ['multi_head_attention_805[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_804 (Layer  (None, 45, 11)      22          ['multi_head_attention_806[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1202 (Dropout)         (None, 45, 8)        0           ['layer_normalization_802[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1203 (Dropout)         (None, 45, 8)        0           ['layer_normalization_803[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1204 (Dropout)         (None, 45, 11)       0           ['layer_normalization_804[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_201 (Concatenate)  (None, 45, 27)       0           ['dropout_1202[0][0]',           \n",
      "                                                                  'dropout_1203[0][0]',           \n",
      "                                                                  'dropout_1204[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_201 (  (None, 27)          0           ['concatenate_201[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1205 (Dropout)         (None, 27)           0           ['global_average_pooling1d_201[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_200 (TFOpLambda  (None, 1, 27)       0           ['dropout_1205[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_807 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_200[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_200[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_198 (TFOp  (None, 27)          0           ['multi_head_attention_807[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_805 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_198[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1206 (Dropout)         (None, 27)           0           ['layer_normalization_805[0][0]']\n",
      "                                                                                                  \n",
      " dense_597 (Dense)              (None, 1024)         28672       ['dropout_1206[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1207 (Dropout)         (None, 1024)         0           ['dense_597[0][0]']              \n",
      "                                                                                                  \n",
      " dense_598 (Dense)              (None, 128)          131200      ['dropout_1207[0][0]']           \n",
      "                                                                                                  \n",
      " dense_599 (Dense)              (None, 1)            129         ['dense_598[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3840 - accuracy: 0.8438 - val_loss: 0.1305 - val_accuracy: 0.9785\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2639 - accuracy: 0.9107 - val_loss: 0.0954 - val_accuracy: 0.9802\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1721 - accuracy: 0.9474 - val_loss: 0.0631 - val_accuracy: 0.9852\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_200\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_607 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_608 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_609 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_606 (Reshape)          (None, 45, 8)        0           ['input_607[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_607 (Reshape)          (None, 45, 8)        0           ['input_608[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_608 (Reshape)          (None, 45, 11)       0           ['input_609[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_808 (Mult  (None, 45, 8)       2248        ['reshape_606[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_606[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_809 (Mult  (None, 45, 8)       2248        ['reshape_607[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_607[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_810 (Mult  (None, 45, 11)      4147        ['reshape_608[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_608[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_806 (Layer  (None, 45, 8)       16          ['multi_head_attention_808[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_807 (Layer  (None, 45, 8)       16          ['multi_head_attention_809[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_808 (Layer  (None, 45, 11)      22          ['multi_head_attention_810[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1208 (Dropout)         (None, 45, 8)        0           ['layer_normalization_806[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1209 (Dropout)         (None, 45, 8)        0           ['layer_normalization_807[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1210 (Dropout)         (None, 45, 11)       0           ['layer_normalization_808[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_202 (Concatenate)  (None, 45, 27)       0           ['dropout_1208[0][0]',           \n",
      "                                                                  'dropout_1209[0][0]',           \n",
      "                                                                  'dropout_1210[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_202 (  (None, 27)          0           ['concatenate_202[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1211 (Dropout)         (None, 27)           0           ['global_average_pooling1d_202[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_201 (TFOpLambda  (None, 1, 27)       0           ['dropout_1211[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_811 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_201[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_201[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_199 (TFOp  (None, 27)          0           ['multi_head_attention_811[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_809 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_199[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1212 (Dropout)         (None, 27)           0           ['layer_normalization_809[0][0]']\n",
      "                                                                                                  \n",
      " dense_600 (Dense)              (None, 1024)         28672       ['dropout_1212[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1213 (Dropout)         (None, 1024)         0           ['dense_600[0][0]']              \n",
      "                                                                                                  \n",
      " dense_601 (Dense)              (None, 128)          131200      ['dropout_1213[0][0]']           \n",
      "                                                                                                  \n",
      " dense_602 (Dense)              (None, 1)            129         ['dense_601[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4197 - accuracy: 0.8198 - val_loss: 0.3084 - val_accuracy: 0.8810\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3634 - accuracy: 0.8514 - val_loss: 0.2841 - val_accuracy: 0.8848\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3452 - accuracy: 0.8571 - val_loss: 0.2147 - val_accuracy: 0.9118\n",
      "Epoch 4/10\n",
      "835/938 [=========================>....] - ETA: 1s - loss: 0.3364 - accuracy: 0.8575\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_201\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_610 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_611 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_612 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_609 (Reshape)          (None, 45, 8)        0           ['input_610[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_610 (Reshape)          (None, 45, 8)        0           ['input_611[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_611 (Reshape)          (None, 45, 11)       0           ['input_612[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_812 (Mult  (None, 45, 8)       2248        ['reshape_609[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_609[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_813 (Mult  (None, 45, 8)       2248        ['reshape_610[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_610[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_814 (Mult  (None, 45, 11)      4147        ['reshape_611[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_611[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_810 (Layer  (None, 45, 8)       16          ['multi_head_attention_812[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_811 (Layer  (None, 45, 8)       16          ['multi_head_attention_813[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_812 (Layer  (None, 45, 11)      22          ['multi_head_attention_814[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1214 (Dropout)         (None, 45, 8)        0           ['layer_normalization_810[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1215 (Dropout)         (None, 45, 8)        0           ['layer_normalization_811[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1216 (Dropout)         (None, 45, 11)       0           ['layer_normalization_812[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_203 (Concatenate)  (None, 45, 27)       0           ['dropout_1214[0][0]',           \n",
      "                                                                  'dropout_1215[0][0]',           \n",
      "                                                                  'dropout_1216[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_203 (  (None, 27)          0           ['concatenate_203[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1217 (Dropout)         (None, 27)           0           ['global_average_pooling1d_203[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_202 (TFOpLambda  (None, 1, 27)       0           ['dropout_1217[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_815 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_202[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_202[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_200 (TFOp  (None, 27)          0           ['multi_head_attention_815[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_813 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_200[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1218 (Dropout)         (None, 27)           0           ['layer_normalization_813[0][0]']\n",
      "                                                                                                  \n",
      " dense_603 (Dense)              (None, 1024)         28672       ['dropout_1218[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1219 (Dropout)         (None, 1024)         0           ['dense_603[0][0]']              \n",
      "                                                                                                  \n",
      " dense_604 (Dense)              (None, 128)          131200      ['dropout_1219[0][0]']           \n",
      "                                                                                                  \n",
      " dense_605 (Dense)              (None, 1)            129         ['dense_604[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 17ms/step - loss: 0.3105 - accuracy: 0.8588 - val_loss: 0.1536 - val_accuracy: 0.9221\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1924 - accuracy: 0.9323 - val_loss: 0.1586 - val_accuracy: 0.9281\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1557 - accuracy: 0.9493 - val_loss: 0.1106 - val_accuracy: 0.9336\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1359 - accuracy: 0.9560 - val_loss: 0.1956 - val_accuracy: 0.9309\n",
      "Epoch 5/10\n",
      "105/938 [==>...........................] - ETA: 12s - loss: 0.1276 - accuracy: 0.9592\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_202\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_613 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_614 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_615 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_612 (Reshape)          (None, 45, 8)        0           ['input_613[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_613 (Reshape)          (None, 45, 8)        0           ['input_614[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_614 (Reshape)          (None, 45, 11)       0           ['input_615[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_816 (Mult  (None, 45, 8)       2248        ['reshape_612[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_612[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_817 (Mult  (None, 45, 8)       2248        ['reshape_613[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_613[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_818 (Mult  (None, 45, 11)      4147        ['reshape_614[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_614[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_814 (Layer  (None, 45, 8)       16          ['multi_head_attention_816[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_815 (Layer  (None, 45, 8)       16          ['multi_head_attention_817[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_816 (Layer  (None, 45, 11)      22          ['multi_head_attention_818[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1220 (Dropout)         (None, 45, 8)        0           ['layer_normalization_814[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1221 (Dropout)         (None, 45, 8)        0           ['layer_normalization_815[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1222 (Dropout)         (None, 45, 11)       0           ['layer_normalization_816[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_204 (Concatenate)  (None, 45, 27)       0           ['dropout_1220[0][0]',           \n",
      "                                                                  'dropout_1221[0][0]',           \n",
      "                                                                  'dropout_1222[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_204 (  (None, 27)          0           ['concatenate_204[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1223 (Dropout)         (None, 27)           0           ['global_average_pooling1d_204[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_203 (TFOpLambda  (None, 1, 27)       0           ['dropout_1223[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_819 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_203[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_203[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_201 (TFOp  (None, 27)          0           ['multi_head_attention_819[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_817 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_201[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1224 (Dropout)         (None, 27)           0           ['layer_normalization_817[0][0]']\n",
      "                                                                                                  \n",
      " dense_606 (Dense)              (None, 1024)         28672       ['dropout_1224[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1225 (Dropout)         (None, 1024)         0           ['dense_606[0][0]']              \n",
      "                                                                                                  \n",
      " dense_607 (Dense)              (None, 128)          131200      ['dropout_1225[0][0]']           \n",
      "                                                                                                  \n",
      " dense_608 (Dense)              (None, 1)            129         ['dense_607[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3056 - accuracy: 0.8725 - val_loss: 0.0998 - val_accuracy: 0.9345\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2495 - accuracy: 0.8840 - val_loss: 0.0764 - val_accuracy: 0.9415\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2314 - accuracy: 0.8924 - val_loss: 0.0970 - val_accuracy: 0.9348\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2219 - accuracy: 0.8936 - val_loss: 0.0752 - val_accuracy: 0.9548\n",
      "Epoch 5/10\n",
      "307/938 [========>.....................] - ETA: 9s - loss: 0.2143 - accuracy: 0.9003\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_203\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_616 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_617 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_618 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_615 (Reshape)          (None, 45, 8)        0           ['input_616[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_616 (Reshape)          (None, 45, 8)        0           ['input_617[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_617 (Reshape)          (None, 45, 11)       0           ['input_618[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_820 (Mult  (None, 45, 8)       2248        ['reshape_615[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_615[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_821 (Mult  (None, 45, 8)       2248        ['reshape_616[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_616[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_822 (Mult  (None, 45, 11)      4147        ['reshape_617[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_617[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_818 (Layer  (None, 45, 8)       16          ['multi_head_attention_820[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_819 (Layer  (None, 45, 8)       16          ['multi_head_attention_821[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_820 (Layer  (None, 45, 11)      22          ['multi_head_attention_822[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1226 (Dropout)         (None, 45, 8)        0           ['layer_normalization_818[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1227 (Dropout)         (None, 45, 8)        0           ['layer_normalization_819[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1228 (Dropout)         (None, 45, 11)       0           ['layer_normalization_820[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_205 (Concatenate)  (None, 45, 27)       0           ['dropout_1226[0][0]',           \n",
      "                                                                  'dropout_1227[0][0]',           \n",
      "                                                                  'dropout_1228[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_205 (  (None, 27)          0           ['concatenate_205[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1229 (Dropout)         (None, 27)           0           ['global_average_pooling1d_205[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_204 (TFOpLambda  (None, 1, 27)       0           ['dropout_1229[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_823 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_204[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_204[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_202 (TFOp  (None, 27)          0           ['multi_head_attention_823[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_821 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_202[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1230 (Dropout)         (None, 27)           0           ['layer_normalization_821[0][0]']\n",
      "                                                                                                  \n",
      " dense_609 (Dense)              (None, 1024)         28672       ['dropout_1230[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1231 (Dropout)         (None, 1024)         0           ['dense_609[0][0]']              \n",
      "                                                                                                  \n",
      " dense_610 (Dense)              (None, 128)          131200      ['dropout_1231[0][0]']           \n",
      "                                                                                                  \n",
      " dense_611 (Dense)              (None, 1)            129         ['dense_610[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3349 - accuracy: 0.8682 - val_loss: 0.2597 - val_accuracy: 0.9030\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2599 - accuracy: 0.9113 - val_loss: 0.1415 - val_accuracy: 0.9584\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2089 - accuracy: 0.9371 - val_loss: 0.1359 - val_accuracy: 0.9625\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1917 - accuracy: 0.9433 - val_loss: 0.1120 - val_accuracy: 0.9668\n",
      "Epoch 5/10\n",
      "268/938 [=======>......................] - ETA: 9s - loss: 0.1896 - accuracy: 0.9450\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_204\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_619 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_620 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_621 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_618 (Reshape)          (None, 45, 8)        0           ['input_619[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_619 (Reshape)          (None, 45, 8)        0           ['input_620[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_620 (Reshape)          (None, 45, 11)       0           ['input_621[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_824 (Mult  (None, 45, 8)       2248        ['reshape_618[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_618[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_825 (Mult  (None, 45, 8)       2248        ['reshape_619[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_619[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_826 (Mult  (None, 45, 11)      4147        ['reshape_620[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_620[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_822 (Layer  (None, 45, 8)       16          ['multi_head_attention_824[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_823 (Layer  (None, 45, 8)       16          ['multi_head_attention_825[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_824 (Layer  (None, 45, 11)      22          ['multi_head_attention_826[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1232 (Dropout)         (None, 45, 8)        0           ['layer_normalization_822[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1233 (Dropout)         (None, 45, 8)        0           ['layer_normalization_823[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1234 (Dropout)         (None, 45, 11)       0           ['layer_normalization_824[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_206 (Concatenate)  (None, 45, 27)       0           ['dropout_1232[0][0]',           \n",
      "                                                                  'dropout_1233[0][0]',           \n",
      "                                                                  'dropout_1234[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_206 (  (None, 27)          0           ['concatenate_206[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1235 (Dropout)         (None, 27)           0           ['global_average_pooling1d_206[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_205 (TFOpLambda  (None, 1, 27)       0           ['dropout_1235[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_827 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_205[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_205[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_203 (TFOp  (None, 27)          0           ['multi_head_attention_827[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_825 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_203[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1236 (Dropout)         (None, 27)           0           ['layer_normalization_825[0][0]']\n",
      "                                                                                                  \n",
      " dense_612 (Dense)              (None, 1024)         28672       ['dropout_1236[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1237 (Dropout)         (None, 1024)         0           ['dense_612[0][0]']              \n",
      "                                                                                                  \n",
      " dense_613 (Dense)              (None, 128)          131200      ['dropout_1237[0][0]']           \n",
      "                                                                                                  \n",
      " dense_614 (Dense)              (None, 1)            129         ['dense_613[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 17ms/step - loss: 0.3588 - accuracy: 0.8562 - val_loss: 0.1516 - val_accuracy: 0.9295\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3048 - accuracy: 0.8858 - val_loss: 0.2082 - val_accuracy: 0.9116\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2952 - accuracy: 0.8920 - val_loss: 0.2371 - val_accuracy: 0.9164\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2884 - accuracy: 0.8947 - val_loss: 0.1933 - val_accuracy: 0.9288\n",
      "Epoch 5/10\n",
      " 59/938 [>.............................] - ETA: 13s - loss: 0.3030 - accuracy: 0.8925\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN toileting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_205\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_622 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_623 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_624 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_621 (Reshape)          (None, 45, 8)        0           ['input_622[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_622 (Reshape)          (None, 45, 8)        0           ['input_623[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_623 (Reshape)          (None, 45, 11)       0           ['input_624[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_828 (Mult  (None, 45, 8)       2248        ['reshape_621[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_621[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_829 (Mult  (None, 45, 8)       2248        ['reshape_622[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_622[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_830 (Mult  (None, 45, 11)      4147        ['reshape_623[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_623[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_826 (Layer  (None, 45, 8)       16          ['multi_head_attention_828[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_827 (Layer  (None, 45, 8)       16          ['multi_head_attention_829[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_828 (Layer  (None, 45, 11)      22          ['multi_head_attention_830[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1238 (Dropout)         (None, 45, 8)        0           ['layer_normalization_826[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1239 (Dropout)         (None, 45, 8)        0           ['layer_normalization_827[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1240 (Dropout)         (None, 45, 11)       0           ['layer_normalization_828[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_207 (Concatenate)  (None, 45, 27)       0           ['dropout_1238[0][0]',           \n",
      "                                                                  'dropout_1239[0][0]',           \n",
      "                                                                  'dropout_1240[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_207 (  (None, 27)          0           ['concatenate_207[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1241 (Dropout)         (None, 27)           0           ['global_average_pooling1d_207[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_206 (TFOpLambda  (None, 1, 27)       0           ['dropout_1241[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_831 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_206[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_206[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_204 (TFOp  (None, 27)          0           ['multi_head_attention_831[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_829 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_204[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1242 (Dropout)         (None, 27)           0           ['layer_normalization_829[0][0]']\n",
      "                                                                                                  \n",
      " dense_615 (Dense)              (None, 1024)         28672       ['dropout_1242[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1243 (Dropout)         (None, 1024)         0           ['dense_615[0][0]']              \n",
      "                                                                                                  \n",
      " dense_616 (Dense)              (None, 128)          131200      ['dropout_1243[0][0]']           \n",
      "                                                                                                  \n",
      " dense_617 (Dense)              (None, 1)            129         ['dense_616[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4802 - accuracy: 0.7449 - val_loss: 0.2985 - val_accuracy: 0.8033\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3746 - accuracy: 0.8335 - val_loss: 0.2716 - val_accuracy: 0.8490\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3515 - accuracy: 0.8501 - val_loss: 0.3009 - val_accuracy: 0.8174\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3410 - accuracy: 0.8550 - val_loss: 0.2400 - val_accuracy: 0.8447\n",
      "Epoch 5/10\n",
      "154/938 [===>..........................] - ETA: 11s - loss: 0.3266 - accuracy: 0.8602TRAIN resting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_206\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_625 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_626 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_627 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_624 (Reshape)          (None, 45, 8)        0           ['input_625[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_625 (Reshape)          (None, 45, 8)        0           ['input_626[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_626 (Reshape)          (None, 45, 11)       0           ['input_627[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_832 (Mult  (None, 45, 8)       2248        ['reshape_624[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_624[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_833 (Mult  (None, 45, 8)       2248        ['reshape_625[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_625[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_834 (Mult  (None, 45, 11)      4147        ['reshape_626[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_626[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_830 (Layer  (None, 45, 8)       16          ['multi_head_attention_832[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_831 (Layer  (None, 45, 8)       16          ['multi_head_attention_833[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_832 (Layer  (None, 45, 11)      22          ['multi_head_attention_834[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1244 (Dropout)         (None, 45, 8)        0           ['layer_normalization_830[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1245 (Dropout)         (None, 45, 8)        0           ['layer_normalization_831[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1246 (Dropout)         (None, 45, 11)       0           ['layer_normalization_832[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_208 (Concatenate)  (None, 45, 27)       0           ['dropout_1244[0][0]',           \n",
      "                                                                  'dropout_1245[0][0]',           \n",
      "                                                                  'dropout_1246[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_208 (  (None, 27)          0           ['concatenate_208[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1247 (Dropout)         (None, 27)           0           ['global_average_pooling1d_208[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_207 (TFOpLambda  (None, 1, 27)       0           ['dropout_1247[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_835 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_207[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_207[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_205 (TFOp  (None, 27)          0           ['multi_head_attention_835[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_833 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_205[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1248 (Dropout)         (None, 27)           0           ['layer_normalization_833[0][0]']\n",
      "                                                                                                  \n",
      " dense_618 (Dense)              (None, 1024)         28672       ['dropout_1248[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1249 (Dropout)         (None, 1024)         0           ['dense_618[0][0]']              \n",
      "                                                                                                  \n",
      " dense_619 (Dense)              (None, 128)          131200      ['dropout_1249[0][0]']           \n",
      "                                                                                                  \n",
      " dense_620 (Dense)              (None, 1)            129         ['dense_619[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5092 - accuracy: 0.7275 - val_loss: 0.5283 - val_accuracy: 0.5577\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.4017 - accuracy: 0.7984 - val_loss: 0.4897 - val_accuracy: 0.5931\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3817 - accuracy: 0.8140 - val_loss: 0.4344 - val_accuracy: 0.6471\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3930 - accuracy: 0.8278 - val_loss: 0.1661 - val_accuracy: 0.9532\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.2632 - accuracy: 0.9146 - val_loss: 0.1581 - val_accuracy: 0.9611\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2373 - accuracy: 0.9225 - val_loss: 0.1192 - val_accuracy: 0.9706\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2153 - accuracy: 0.9293 - val_loss: 0.1476 - val_accuracy: 0.9591\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3399 - accuracy: 0.8648 - val_loss: 0.2553 - val_accuracy: 0.8743\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.3245 - accuracy: 0.8645 - val_loss: 0.2224 - val_accuracy: 0.8956\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3121 - accuracy: 0.8672 - val_loss: 0.2497 - val_accuracy: 0.8640\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3057 - accuracy: 0.8653 - val_loss: 0.2671 - val_accuracy: 0.8616\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1193 - accuracy: 0.9627 - val_loss: 0.0858 - val_accuracy: 0.9651\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1084 - accuracy: 0.9667 - val_loss: 0.0796 - val_accuracy: 0.9670\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1000 - accuracy: 0.9696 - val_loss: 0.0698 - val_accuracy: 0.9735\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0901 - accuracy: 0.9739 - val_loss: 0.0893 - val_accuracy: 0.9706\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0840 - accuracy: 0.9757 - val_loss: 0.0727 - val_accuracy: 0.9711\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2132 - accuracy: 0.8968 - val_loss: 0.1247 - val_accuracy: 0.9288\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2067 - accuracy: 0.9002 - val_loss: 0.1333 - val_accuracy: 0.9245\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2001 - accuracy: 0.9102 - val_loss: 0.1244 - val_accuracy: 0.9517\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1889 - accuracy: 0.9225 - val_loss: 0.1638 - val_accuracy: 0.9259\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN sleep 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_211\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_640 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_641 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_642 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_639 (Reshape)          (None, 45, 8)        0           ['input_640[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_640 (Reshape)          (None, 45, 8)        0           ['input_641[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_641 (Reshape)          (None, 45, 11)       0           ['input_642[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_852 (Mult  (None, 45, 8)       2248        ['reshape_639[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_639[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_853 (Mult  (None, 45, 8)       2248        ['reshape_640[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_640[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_854 (Mult  (None, 45, 11)      4147        ['reshape_641[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_641[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_850 (Layer  (None, 45, 8)       16          ['multi_head_attention_852[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_851 (Layer  (None, 45, 8)       16          ['multi_head_attention_853[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_852 (Layer  (None, 45, 11)      22          ['multi_head_attention_854[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1274 (Dropout)         (None, 45, 8)        0           ['layer_normalization_850[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1275 (Dropout)         (None, 45, 8)        0           ['layer_normalization_851[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1276 (Dropout)         (None, 45, 11)       0           ['layer_normalization_852[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_213 (Concatenate)  (None, 45, 27)       0           ['dropout_1274[0][0]',           \n",
      "                                                                  'dropout_1275[0][0]',           \n",
      "                                                                  'dropout_1276[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_213 (  (None, 27)          0           ['concatenate_213[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1277 (Dropout)         (None, 27)           0           ['global_average_pooling1d_213[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_212 (TFOpLambda  (None, 1, 27)       0           ['dropout_1277[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_855 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_212[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_212[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_210 (TFOp  (None, 27)          0           ['multi_head_attention_855[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_853 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_210[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1278 (Dropout)         (None, 27)           0           ['layer_normalization_853[0][0]']\n",
      "                                                                                                  \n",
      " dense_633 (Dense)              (None, 1024)         28672       ['dropout_1278[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1279 (Dropout)         (None, 1024)         0           ['dense_633[0][0]']              \n",
      "                                                                                                  \n",
      " dense_634 (Dense)              (None, 128)          131200      ['dropout_1279[0][0]']           \n",
      "                                                                                                  \n",
      " dense_635 (Dense)              (None, 1)            129         ['dense_634[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1629 - accuracy: 0.9523 - val_loss: 0.0579 - val_accuracy: 0.9864\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1533 - accuracy: 0.9555 - val_loss: 0.0815 - val_accuracy: 0.9799\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1463 - accuracy: 0.9585 - val_loss: 0.0707 - val_accuracy: 0.9907\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_212\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_643 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_644 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_645 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_642 (Reshape)          (None, 45, 8)        0           ['input_643[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_643 (Reshape)          (None, 45, 8)        0           ['input_644[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_644 (Reshape)          (None, 45, 11)       0           ['input_645[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_856 (Mult  (None, 45, 8)       2248        ['reshape_642[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_642[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_857 (Mult  (None, 45, 8)       2248        ['reshape_643[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_643[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_858 (Mult  (None, 45, 11)      4147        ['reshape_644[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_644[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_854 (Layer  (None, 45, 8)       16          ['multi_head_attention_856[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_855 (Layer  (None, 45, 8)       16          ['multi_head_attention_857[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_856 (Layer  (None, 45, 11)      22          ['multi_head_attention_858[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1280 (Dropout)         (None, 45, 8)        0           ['layer_normalization_854[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1281 (Dropout)         (None, 45, 8)        0           ['layer_normalization_855[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1282 (Dropout)         (None, 45, 11)       0           ['layer_normalization_856[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_214 (Concatenate)  (None, 45, 27)       0           ['dropout_1280[0][0]',           \n",
      "                                                                  'dropout_1281[0][0]',           \n",
      "                                                                  'dropout_1282[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_214 (  (None, 27)          0           ['concatenate_214[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1283 (Dropout)         (None, 27)           0           ['global_average_pooling1d_214[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_213 (TFOpLambda  (None, 1, 27)       0           ['dropout_1283[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_859 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_213[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_213[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_211 (TFOp  (None, 27)          0           ['multi_head_attention_859[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_857 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_211[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1284 (Dropout)         (None, 27)           0           ['layer_normalization_857[0][0]']\n",
      "                                                                                                  \n",
      " dense_636 (Dense)              (None, 1024)         28672       ['dropout_1284[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1285 (Dropout)         (None, 1024)         0           ['dense_636[0][0]']              \n",
      "                                                                                                  \n",
      " dense_637 (Dense)              (None, 128)          131200      ['dropout_1285[0][0]']           \n",
      "                                                                                                  \n",
      " dense_638 (Dense)              (None, 1)            129         ['dense_637[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.3644 - accuracy: 0.8533 - val_loss: 0.2170 - val_accuracy: 0.8843\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2655 - accuracy: 0.8995 - val_loss: 0.2039 - val_accuracy: 0.9154\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2650 - accuracy: 0.9010 - val_loss: 0.1808 - val_accuracy: 0.9137\n",
      "131/131 [==============================] - 1s 6ms/step\n",
      "(4185, 1)\n",
      "\t 12 19934\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN toileting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_213\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_646 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_647 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_648 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_645 (Reshape)          (None, 45, 8)        0           ['input_646[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_646 (Reshape)          (None, 45, 8)        0           ['input_647[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_647 (Reshape)          (None, 45, 11)       0           ['input_648[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_860 (Mult  (None, 45, 8)       2248        ['reshape_645[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_645[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_861 (Mult  (None, 45, 8)       2248        ['reshape_646[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_646[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_862 (Mult  (None, 45, 11)      4147        ['reshape_647[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_647[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_858 (Layer  (None, 45, 8)       16          ['multi_head_attention_860[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_859 (Layer  (None, 45, 8)       16          ['multi_head_attention_861[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_860 (Layer  (None, 45, 11)      22          ['multi_head_attention_862[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1286 (Dropout)         (None, 45, 8)        0           ['layer_normalization_858[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1287 (Dropout)         (None, 45, 8)        0           ['layer_normalization_859[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1288 (Dropout)         (None, 45, 11)       0           ['layer_normalization_860[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_215 (Concatenate)  (None, 45, 27)       0           ['dropout_1286[0][0]',           \n",
      "                                                                  'dropout_1287[0][0]',           \n",
      "                                                                  'dropout_1288[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_215 (  (None, 27)          0           ['concatenate_215[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1289 (Dropout)         (None, 27)           0           ['global_average_pooling1d_215[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_214 (TFOpLambda  (None, 1, 27)       0           ['dropout_1289[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_863 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_214[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_214[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_212 (TFOp  (None, 27)          0           ['multi_head_attention_863[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_861 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_212[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1290 (Dropout)         (None, 27)           0           ['layer_normalization_861[0][0]']\n",
      "                                                                                                  \n",
      " dense_639 (Dense)              (None, 1024)         28672       ['dropout_1290[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1291 (Dropout)         (None, 1024)         0           ['dense_639[0][0]']              \n",
      "                                                                                                  \n",
      " dense_640 (Dense)              (None, 128)          131200      ['dropout_1291[0][0]']           \n",
      "                                                                                                  \n",
      " dense_641 (Dense)              (None, 1)            129         ['dense_640[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.4869 - accuracy: 0.7323 - val_loss: 0.3304 - val_accuracy: 0.7919\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3834 - accuracy: 0.8299 - val_loss: 0.2995 - val_accuracy: 0.8060\n",
      "Epoch 3/10\n",
      "616/938 [==================>...........] - ETA: 4s - loss: 0.3637 - accuracy: 0.8424\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN resting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_214\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_649 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_650 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_651 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_648 (Reshape)          (None, 45, 8)        0           ['input_649[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_649 (Reshape)          (None, 45, 8)        0           ['input_650[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_650 (Reshape)          (None, 45, 11)       0           ['input_651[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_864 (Mult  (None, 45, 8)       2248        ['reshape_648[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_648[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_865 (Mult  (None, 45, 8)       2248        ['reshape_649[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_649[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_866 (Mult  (None, 45, 11)      4147        ['reshape_650[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_650[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_862 (Layer  (None, 45, 8)       16          ['multi_head_attention_864[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_863 (Layer  (None, 45, 8)       16          ['multi_head_attention_865[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_864 (Layer  (None, 45, 11)      22          ['multi_head_attention_866[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1292 (Dropout)         (None, 45, 8)        0           ['layer_normalization_862[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1293 (Dropout)         (None, 45, 8)        0           ['layer_normalization_863[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1294 (Dropout)         (None, 45, 11)       0           ['layer_normalization_864[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_216 (Concatenate)  (None, 45, 27)       0           ['dropout_1292[0][0]',           \n",
      "                                                                  'dropout_1293[0][0]',           \n",
      "                                                                  'dropout_1294[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_216 (  (None, 27)          0           ['concatenate_216[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1295 (Dropout)         (None, 27)           0           ['global_average_pooling1d_216[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_215 (TFOpLambda  (None, 1, 27)       0           ['dropout_1295[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_867 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_215[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_215[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_213 (TFOp  (None, 27)          0           ['multi_head_attention_867[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_865 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_213[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1296 (Dropout)         (None, 27)           0           ['layer_normalization_865[0][0]']\n",
      "                                                                                                  \n",
      " dense_642 (Dense)              (None, 1024)         28672       ['dropout_1296[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1297 (Dropout)         (None, 1024)         0           ['dense_642[0][0]']              \n",
      "                                                                                                  \n",
      " dense_643 (Dense)              (None, 128)          131200      ['dropout_1297[0][0]']           \n",
      "                                                                                                  \n",
      " dense_644 (Dense)              (None, 1)            129         ['dense_643[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.5424 - accuracy: 0.7102 - val_loss: 0.3845 - val_accuracy: 0.6875\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.4020 - accuracy: 0.7987 - val_loss: 0.3451 - val_accuracy: 0.7240\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3881 - accuracy: 0.8083 - val_loss: 0.3623 - val_accuracy: 0.7102\n",
      "Epoch 4/10\n",
      "774/938 [=======================>......] - ETA: 2s - loss: 0.3818 - accuracy: 0.8121\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN exit 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_215\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_652 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_653 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_654 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_651 (Reshape)          (None, 45, 8)        0           ['input_652[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_652 (Reshape)          (None, 45, 8)        0           ['input_653[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_653 (Reshape)          (None, 45, 11)       0           ['input_654[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_868 (Mult  (None, 45, 8)       2248        ['reshape_651[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_651[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_869 (Mult  (None, 45, 8)       2248        ['reshape_652[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_652[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_870 (Mult  (None, 45, 11)      4147        ['reshape_653[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_653[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_866 (Layer  (None, 45, 8)       16          ['multi_head_attention_868[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_867 (Layer  (None, 45, 8)       16          ['multi_head_attention_869[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_868 (Layer  (None, 45, 11)      22          ['multi_head_attention_870[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1298 (Dropout)         (None, 45, 8)        0           ['layer_normalization_866[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1299 (Dropout)         (None, 45, 8)        0           ['layer_normalization_867[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1300 (Dropout)         (None, 45, 11)       0           ['layer_normalization_868[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_217 (Concatenate)  (None, 45, 27)       0           ['dropout_1298[0][0]',           \n",
      "                                                                  'dropout_1299[0][0]',           \n",
      "                                                                  'dropout_1300[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_217 (  (None, 27)          0           ['concatenate_217[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1301 (Dropout)         (None, 27)           0           ['global_average_pooling1d_217[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_216 (TFOpLambda  (None, 1, 27)       0           ['dropout_1301[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_871 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_216[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_216[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_214 (TFOp  (None, 27)          0           ['multi_head_attention_871[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_869 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_214[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1302 (Dropout)         (None, 27)           0           ['layer_normalization_869[0][0]']\n",
      "                                                                                                  \n",
      " dense_645 (Dense)              (None, 1024)         28672       ['dropout_1302[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1303 (Dropout)         (None, 1024)         0           ['dense_645[0][0]']              \n",
      "                                                                                                  \n",
      " dense_646 (Dense)              (None, 128)          131200      ['dropout_1303[0][0]']           \n",
      "                                                                                                  \n",
      " dense_647 (Dense)              (None, 1)            129         ['dense_646[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3657 - accuracy: 0.8508 - val_loss: 0.1486 - val_accuracy: 0.9620\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2579 - accuracy: 0.9156 - val_loss: 0.1455 - val_accuracy: 0.9579\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2303 - accuracy: 0.9278 - val_loss: 0.1236 - val_accuracy: 0.9730\n",
      "Epoch 4/10\n",
      "678/938 [====================>.........] - ETA: 3s - loss: 0.2165 - accuracy: 0.9300\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN cooking 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_216\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_655 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_656 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_657 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_654 (Reshape)          (None, 45, 8)        0           ['input_655[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_655 (Reshape)          (None, 45, 8)        0           ['input_656[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_656 (Reshape)          (None, 45, 11)       0           ['input_657[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_872 (Mult  (None, 45, 8)       2248        ['reshape_654[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_654[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_873 (Mult  (None, 45, 8)       2248        ['reshape_655[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_655[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_874 (Mult  (None, 45, 11)      4147        ['reshape_656[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_656[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_870 (Layer  (None, 45, 8)       16          ['multi_head_attention_872[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_871 (Layer  (None, 45, 8)       16          ['multi_head_attention_873[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_872 (Layer  (None, 45, 11)      22          ['multi_head_attention_874[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1304 (Dropout)         (None, 45, 8)        0           ['layer_normalization_870[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1305 (Dropout)         (None, 45, 8)        0           ['layer_normalization_871[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1306 (Dropout)         (None, 45, 11)       0           ['layer_normalization_872[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_218 (Concatenate)  (None, 45, 27)       0           ['dropout_1304[0][0]',           \n",
      "                                                                  'dropout_1305[0][0]',           \n",
      "                                                                  'dropout_1306[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_218 (  (None, 27)          0           ['concatenate_218[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1307 (Dropout)         (None, 27)           0           ['global_average_pooling1d_218[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_217 (TFOpLambda  (None, 1, 27)       0           ['dropout_1307[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_875 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_217[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_217[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_215 (TFOp  (None, 27)          0           ['multi_head_attention_875[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_873 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_215[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1308 (Dropout)         (None, 27)           0           ['layer_normalization_873[0][0]']\n",
      "                                                                                                  \n",
      " dense_648 (Dense)              (None, 1024)         28672       ['dropout_1308[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1309 (Dropout)         (None, 1024)         0           ['dense_648[0][0]']              \n",
      "                                                                                                  \n",
      " dense_649 (Dense)              (None, 128)          131200      ['dropout_1309[0][0]']           \n",
      "                                                                                                  \n",
      " dense_650 (Dense)              (None, 1)            129         ['dense_649[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4224 - accuracy: 0.8165 - val_loss: 0.2019 - val_accuracy: 0.9090\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3601 - accuracy: 0.8567 - val_loss: 0.2263 - val_accuracy: 0.8987\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3480 - accuracy: 0.8591 - val_loss: 0.2661 - val_accuracy: 0.8679\n",
      "Epoch 4/10\n",
      "610/938 [==================>...........] - ETA: 4s - loss: 0.3314 - accuracy: 0.8636TRAIN shower 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_217\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_658 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_659 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_660 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_657 (Reshape)          (None, 45, 8)        0           ['input_658[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_658 (Reshape)          (None, 45, 8)        0           ['input_659[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_659 (Reshape)          (None, 45, 11)       0           ['input_660[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_876 (Mult  (None, 45, 8)       2248        ['reshape_657[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_657[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_877 (Mult  (None, 45, 8)       2248        ['reshape_658[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_658[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_878 (Mult  (None, 45, 11)      4147        ['reshape_659[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_659[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_874 (Layer  (None, 45, 8)       16          ['multi_head_attention_876[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_875 (Layer  (None, 45, 8)       16          ['multi_head_attention_877[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_876 (Layer  (None, 45, 11)      22          ['multi_head_attention_878[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1310 (Dropout)         (None, 45, 8)        0           ['layer_normalization_874[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1311 (Dropout)         (None, 45, 8)        0           ['layer_normalization_875[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1312 (Dropout)         (None, 45, 11)       0           ['layer_normalization_876[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_219 (Concatenate)  (None, 45, 27)       0           ['dropout_1310[0][0]',           \n",
      "                                                                  'dropout_1311[0][0]',           \n",
      "                                                                  'dropout_1312[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_219 (  (None, 27)          0           ['concatenate_219[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1313 (Dropout)         (None, 27)           0           ['global_average_pooling1d_219[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_218 (TFOpLambda  (None, 1, 27)       0           ['dropout_1313[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_879 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_218[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_218[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_216 (TFOp  (None, 27)          0           ['multi_head_attention_879[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_877 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_216[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1314 (Dropout)         (None, 27)           0           ['layer_normalization_877[0][0]']\n",
      "                                                                                                  \n",
      " dense_651 (Dense)              (None, 1024)         28672       ['dropout_1314[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1315 (Dropout)         (None, 1024)         0           ['dense_651[0][0]']              \n",
      "                                                                                                  \n",
      " dense_652 (Dense)              (None, 128)          131200      ['dropout_1315[0][0]']           \n",
      "                                                                                                  \n",
      " dense_653 (Dense)              (None, 1)            129         ['dense_652[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.2800 - accuracy: 0.8780 - val_loss: 0.1125 - val_accuracy: 0.9329\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1745 - accuracy: 0.9422 - val_loss: 0.1312 - val_accuracy: 0.9341\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1629 - accuracy: 0.9469 - val_loss: 0.1001 - val_accuracy: 0.9546\n",
      "Epoch 4/10\n",
      "498/938 [==============>...............] - ETA: 6s - loss: 0.1435 - accuracy: 0.9538TRAIN pc 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_218\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_661 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_662 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_663 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_660 (Reshape)          (None, 45, 8)        0           ['input_661[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_661 (Reshape)          (None, 45, 8)        0           ['input_662[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_662 (Reshape)          (None, 45, 11)       0           ['input_663[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_880 (Mult  (None, 45, 8)       2248        ['reshape_660[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_660[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_881 (Mult  (None, 45, 8)       2248        ['reshape_661[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_661[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_882 (Mult  (None, 45, 11)      4147        ['reshape_662[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_662[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_878 (Layer  (None, 45, 8)       16          ['multi_head_attention_880[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_879 (Layer  (None, 45, 8)       16          ['multi_head_attention_881[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_880 (Layer  (None, 45, 11)      22          ['multi_head_attention_882[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1316 (Dropout)         (None, 45, 8)        0           ['layer_normalization_878[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1317 (Dropout)         (None, 45, 8)        0           ['layer_normalization_879[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1318 (Dropout)         (None, 45, 11)       0           ['layer_normalization_880[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_220 (Concatenate)  (None, 45, 27)       0           ['dropout_1316[0][0]',           \n",
      "                                                                  'dropout_1317[0][0]',           \n",
      "                                                                  'dropout_1318[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_220 (  (None, 27)          0           ['concatenate_220[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1319 (Dropout)         (None, 27)           0           ['global_average_pooling1d_220[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_219 (TFOpLambda  (None, 1, 27)       0           ['dropout_1319[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_883 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_219[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_219[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_217 (TFOp  (None, 27)          0           ['multi_head_attention_883[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_881 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_217[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1320 (Dropout)         (None, 27)           0           ['layer_normalization_881[0][0]']\n",
      "                                                                                                  \n",
      " dense_654 (Dense)              (None, 1024)         28672       ['dropout_1320[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1321 (Dropout)         (None, 1024)         0           ['dense_654[0][0]']              \n",
      "                                                                                                  \n",
      " dense_655 (Dense)              (None, 128)          131200      ['dropout_1321[0][0]']           \n",
      "                                                                                                  \n",
      " dense_656 (Dense)              (None, 1)            129         ['dense_655[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.3008 - accuracy: 0.8697 - val_loss: 0.0636 - val_accuracy: 0.9618\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2462 - accuracy: 0.8873 - val_loss: 0.0381 - val_accuracy: 0.9754\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2291 - accuracy: 0.8933 - val_loss: 0.0499 - val_accuracy: 0.9692\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2206 - accuracy: 0.8922 - val_loss: 0.0387 - val_accuracy: 0.9756\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3287 - accuracy: 0.8757 - val_loss: 0.2439 - val_accuracy: 0.8980\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2346 - accuracy: 0.9265 - val_loss: 0.1428 - val_accuracy: 0.9606\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2092 - accuracy: 0.9394 - val_loss: 0.1241 - val_accuracy: 0.9620\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.3625 - accuracy: 0.8539 - val_loss: 0.1886 - val_accuracy: 0.9030\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3089 - accuracy: 0.8825 - val_loss: 0.2160 - val_accuracy: 0.9004\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.2977 - accuracy: 0.8875 - val_loss: 0.2210 - val_accuracy: 0.9047\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2870 - accuracy: 0.8929 - val_loss: 0.1751 - val_accuracy: 0.9276\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3618 - accuracy: 0.8430 - val_loss: 0.4046 - val_accuracy: 0.7701\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3487 - accuracy: 0.8492 - val_loss: 0.3240 - val_accuracy: 0.8308\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3421 - accuracy: 0.8547 - val_loss: 0.2983 - val_accuracy: 0.8222\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.3348 - accuracy: 0.8581 - val_loss: 0.3324 - val_accuracy: 0.7821\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.3633 - accuracy: 0.8260 - val_loss: 0.4082 - val_accuracy: 0.7235\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3541 - accuracy: 0.8345 - val_loss: 0.3848 - val_accuracy: 0.7599\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3473 - accuracy: 0.8384 - val_loss: 0.4491 - val_accuracy: 0.6982\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.3432 - accuracy: 0.8418 - val_loss: 0.3216 - val_accuracy: 0.8172\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1696 - accuracy: 0.9471 - val_loss: 0.1163 - val_accuracy: 0.9625\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.1653 - accuracy: 0.9498 - val_loss: 0.1203 - val_accuracy: 0.9658\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1652 - accuracy: 0.9497 - val_loss: 0.0980 - val_accuracy: 0.9668\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN cooking 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_679 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_680 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_681 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_678 (Reshape)          (None, 45, 8)        0           ['input_679[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_679 (Reshape)          (None, 45, 8)        0           ['input_680[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_680 (Reshape)          (None, 45, 11)       0           ['input_681[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_904 (Mult  (None, 45, 8)       2248        ['reshape_678[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_678[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_905 (Mult  (None, 45, 8)       2248        ['reshape_679[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_679[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_906 (Mult  (None, 45, 11)      4147        ['reshape_680[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_680[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_902 (Layer  (None, 45, 8)       16          ['multi_head_attention_904[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_903 (Layer  (None, 45, 8)       16          ['multi_head_attention_905[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_904 (Layer  (None, 45, 11)      22          ['multi_head_attention_906[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1352 (Dropout)         (None, 45, 8)        0           ['layer_normalization_902[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1353 (Dropout)         (None, 45, 8)        0           ['layer_normalization_903[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1354 (Dropout)         (None, 45, 11)       0           ['layer_normalization_904[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_226 (Concatenate)  (None, 45, 27)       0           ['dropout_1352[0][0]',           \n",
      "                                                                  'dropout_1353[0][0]',           \n",
      "                                                                  'dropout_1354[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_226 (  (None, 27)          0           ['concatenate_226[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1355 (Dropout)         (None, 27)           0           ['global_average_pooling1d_226[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_225 (TFOpLambda  (None, 1, 27)       0           ['dropout_1355[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_907 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_225[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_225[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_223 (TFOp  (None, 27)          0           ['multi_head_attention_907[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_905 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_223[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1356 (Dropout)         (None, 27)           0           ['layer_normalization_905[0][0]']\n",
      "                                                                                                  \n",
      " dense_672 (Dense)              (None, 1024)         28672       ['dropout_1356[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1357 (Dropout)         (None, 1024)         0           ['dense_672[0][0]']              \n",
      "                                                                                                  \n",
      " dense_673 (Dense)              (None, 128)          131200      ['dropout_1357[0][0]']           \n",
      "                                                                                                  \n",
      " dense_674 (Dense)              (None, 1)            129         ['dense_673[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 15ms/step - loss: 0.4190 - accuracy: 0.8218 - val_loss: 0.2933 - val_accuracy: 0.8538\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.3002 - accuracy: 0.8654 - val_loss: 0.2616 - val_accuracy: 0.8554\n",
      "131/131 [==============================] - 1s 5ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN shower 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_225\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_682 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_683 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_684 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_681 (Reshape)          (None, 45, 8)        0           ['input_682[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_682 (Reshape)          (None, 45, 8)        0           ['input_683[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_683 (Reshape)          (None, 45, 11)       0           ['input_684[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_908 (Mult  (None, 45, 8)       2248        ['reshape_681[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_681[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_909 (Mult  (None, 45, 8)       2248        ['reshape_682[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_682[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_910 (Mult  (None, 45, 11)      4147        ['reshape_683[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_683[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_906 (Layer  (None, 45, 8)       16          ['multi_head_attention_908[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_907 (Layer  (None, 45, 8)       16          ['multi_head_attention_909[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_908 (Layer  (None, 45, 11)      22          ['multi_head_attention_910[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1358 (Dropout)         (None, 45, 8)        0           ['layer_normalization_906[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1359 (Dropout)         (None, 45, 8)        0           ['layer_normalization_907[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1360 (Dropout)         (None, 45, 11)       0           ['layer_normalization_908[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_227 (Concatenate)  (None, 45, 27)       0           ['dropout_1358[0][0]',           \n",
      "                                                                  'dropout_1359[0][0]',           \n",
      "                                                                  'dropout_1360[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_227 (  (None, 27)          0           ['concatenate_227[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1361 (Dropout)         (None, 27)           0           ['global_average_pooling1d_227[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_226 (TFOpLambda  (None, 1, 27)       0           ['dropout_1361[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_911 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_226[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_226[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_224 (TFOp  (None, 27)          0           ['multi_head_attention_911[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_909 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_224[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1362 (Dropout)         (None, 27)           0           ['layer_normalization_909[0][0]']\n",
      "                                                                                                  \n",
      " dense_675 (Dense)              (None, 1024)         28672       ['dropout_1362[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1363 (Dropout)         (None, 1024)         0           ['dense_675[0][0]']              \n",
      "                                                                                                  \n",
      " dense_676 (Dense)              (None, 128)          131200      ['dropout_1363[0][0]']           \n",
      "                                                                                                  \n",
      " dense_677 (Dense)              (None, 1)            129         ['dense_676[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3072 - accuracy: 0.8651 - val_loss: 0.1461 - val_accuracy: 0.9180\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2008 - accuracy: 0.9297 - val_loss: 0.1160 - val_accuracy: 0.9386\n",
      "Epoch 3/10\n",
      "829/938 [=========================>....] - ETA: 1s - loss: 0.1693 - accuracy: 0.9429\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN pc 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_226\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_685 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_686 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_687 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_684 (Reshape)          (None, 45, 8)        0           ['input_685[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_685 (Reshape)          (None, 45, 8)        0           ['input_686[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_686 (Reshape)          (None, 45, 11)       0           ['input_687[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_912 (Mult  (None, 45, 8)       2248        ['reshape_684[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_684[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_913 (Mult  (None, 45, 8)       2248        ['reshape_685[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_685[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_914 (Mult  (None, 45, 11)      4147        ['reshape_686[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_686[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_910 (Layer  (None, 45, 8)       16          ['multi_head_attention_912[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_911 (Layer  (None, 45, 8)       16          ['multi_head_attention_913[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_912 (Layer  (None, 45, 11)      22          ['multi_head_attention_914[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1364 (Dropout)         (None, 45, 8)        0           ['layer_normalization_910[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1365 (Dropout)         (None, 45, 8)        0           ['layer_normalization_911[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1366 (Dropout)         (None, 45, 11)       0           ['layer_normalization_912[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_228 (Concatenate)  (None, 45, 27)       0           ['dropout_1364[0][0]',           \n",
      "                                                                  'dropout_1365[0][0]',           \n",
      "                                                                  'dropout_1366[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_228 (  (None, 27)          0           ['concatenate_228[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1367 (Dropout)         (None, 27)           0           ['global_average_pooling1d_228[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_227 (TFOpLambda  (None, 1, 27)       0           ['dropout_1367[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_915 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_227[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_227[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_225 (TFOp  (None, 27)          0           ['multi_head_attention_915[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_913 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_225[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1368 (Dropout)         (None, 27)           0           ['layer_normalization_913[0][0]']\n",
      "                                                                                                  \n",
      " dense_678 (Dense)              (None, 1024)         28672       ['dropout_1368[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1369 (Dropout)         (None, 1024)         0           ['dense_678[0][0]']              \n",
      "                                                                                                  \n",
      " dense_679 (Dense)              (None, 128)          131200      ['dropout_1369[0][0]']           \n",
      "                                                                                                  \n",
      " dense_680 (Dense)              (None, 1)            129         ['dense_679[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 21s 17ms/step - loss: 0.2971 - accuracy: 0.8769 - val_loss: 0.1220 - val_accuracy: 0.9355\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2428 - accuracy: 0.8887 - val_loss: 0.1325 - val_accuracy: 0.9288\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2274 - accuracy: 0.8921 - val_loss: 0.1657 - val_accuracy: 0.8927\n",
      "Epoch 4/10\n",
      "390/938 [===========>..................] - ETA: 7s - loss: 0.2244 - accuracy: 0.8913\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN sleep 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_227\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_688 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_689 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_690 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_687 (Reshape)          (None, 45, 8)        0           ['input_688[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_688 (Reshape)          (None, 45, 8)        0           ['input_689[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_689 (Reshape)          (None, 45, 11)       0           ['input_690[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_916 (Mult  (None, 45, 8)       2248        ['reshape_687[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_687[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_917 (Mult  (None, 45, 8)       2248        ['reshape_688[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_688[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_918 (Mult  (None, 45, 11)      4147        ['reshape_689[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_689[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_914 (Layer  (None, 45, 8)       16          ['multi_head_attention_916[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_915 (Layer  (None, 45, 8)       16          ['multi_head_attention_917[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_916 (Layer  (None, 45, 11)      22          ['multi_head_attention_918[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1370 (Dropout)         (None, 45, 8)        0           ['layer_normalization_914[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1371 (Dropout)         (None, 45, 8)        0           ['layer_normalization_915[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1372 (Dropout)         (None, 45, 11)       0           ['layer_normalization_916[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_229 (Concatenate)  (None, 45, 27)       0           ['dropout_1370[0][0]',           \n",
      "                                                                  'dropout_1371[0][0]',           \n",
      "                                                                  'dropout_1372[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_229 (  (None, 27)          0           ['concatenate_229[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1373 (Dropout)         (None, 27)           0           ['global_average_pooling1d_229[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_228 (TFOpLambda  (None, 1, 27)       0           ['dropout_1373[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_919 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_228[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_228[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_226 (TFOp  (None, 27)          0           ['multi_head_attention_919[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_917 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_226[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1374 (Dropout)         (None, 27)           0           ['layer_normalization_917[0][0]']\n",
      "                                                                                                  \n",
      " dense_681 (Dense)              (None, 1024)         28672       ['dropout_1374[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1375 (Dropout)         (None, 1024)         0           ['dense_681[0][0]']              \n",
      "                                                                                                  \n",
      " dense_682 (Dense)              (None, 128)          131200      ['dropout_1375[0][0]']           \n",
      "                                                                                                  \n",
      " dense_683 (Dense)              (None, 1)            129         ['dense_682[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3444 - accuracy: 0.8658 - val_loss: 0.2577 - val_accuracy: 0.8679\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2548 - accuracy: 0.9152 - val_loss: 0.1098 - val_accuracy: 0.9730\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2159 - accuracy: 0.9373 - val_loss: 0.1002 - val_accuracy: 0.9730\n",
      "Epoch 4/10\n",
      "256/938 [=======>......................] - ETA: 10s - loss: 0.1905 - accuracy: 0.9464\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN kitchen 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_228\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_691 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_692 (InputLayer)         [(None, 8, 45, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " input_693 (InputLayer)         [(None, 11, 45, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " reshape_690 (Reshape)          (None, 45, 8)        0           ['input_691[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_691 (Reshape)          (None, 45, 8)        0           ['input_692[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_692 (Reshape)          (None, 45, 11)       0           ['input_693[0][0]']              \n",
      "                                                                                                  \n",
      " multi_head_attention_920 (Mult  (None, 45, 8)       2248        ['reshape_690[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_690[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_921 (Mult  (None, 45, 8)       2248        ['reshape_691[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_691[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_922 (Mult  (None, 45, 11)      4147        ['reshape_692[0][0]',            \n",
      " iHeadAttention)                                                  'reshape_692[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_918 (Layer  (None, 45, 8)       16          ['multi_head_attention_920[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_919 (Layer  (None, 45, 8)       16          ['multi_head_attention_921[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_920 (Layer  (None, 45, 11)      22          ['multi_head_attention_922[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1376 (Dropout)         (None, 45, 8)        0           ['layer_normalization_918[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1377 (Dropout)         (None, 45, 8)        0           ['layer_normalization_919[0][0]']\n",
      "                                                                                                  \n",
      " dropout_1378 (Dropout)         (None, 45, 11)       0           ['layer_normalization_920[0][0]']\n",
      "                                                                                                  \n",
      " concatenate_230 (Concatenate)  (None, 45, 27)       0           ['dropout_1376[0][0]',           \n",
      "                                                                  'dropout_1377[0][0]',           \n",
      "                                                                  'dropout_1378[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_230 (  (None, 27)          0           ['concatenate_230[0][0]']        \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout_1379 (Dropout)         (None, 27)           0           ['global_average_pooling1d_230[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_229 (TFOpLambda  (None, 1, 27)       0           ['dropout_1379[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_923 (Mult  (None, 1, 27)       24003       ['tf.expand_dims_229[0][0]',     \n",
      " iHeadAttention)                                                  'tf.expand_dims_229[0][0]']     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_227 (TFOp  (None, 27)          0           ['multi_head_attention_923[0][0]'\n",
      " Lambda)                                                         ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_921 (Layer  (None, 27)          54          ['tf.compat.v1.squeeze_227[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_1380 (Dropout)         (None, 27)           0           ['layer_normalization_921[0][0]']\n",
      "                                                                                                  \n",
      " dense_684 (Dense)              (None, 1024)         28672       ['dropout_1380[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1381 (Dropout)         (None, 1024)         0           ['dense_684[0][0]']              \n",
      "                                                                                                  \n",
      " dense_685 (Dense)              (None, 128)          131200      ['dropout_1381[0][0]']           \n",
      "                                                                                                  \n",
      " dense_686 (Dense)              (None, 1)            129         ['dense_685[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 192,755\n",
      "Trainable params: 192,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 16ms/step - loss: 0.3469 - accuracy: 0.8613 - val_loss: 0.2666 - val_accuracy: 0.8626\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2860 - accuracy: 0.8959 - val_loss: 0.2086 - val_accuracy: 0.8968\n",
      "Epoch 3/10\n",
      "222/938 [======>.......................] - ETA: 10s - loss: 0.2729 - accuracy: 0.9023"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time_distributed_47 (TimeD  (None, 8, 5760)              0         ['time_distributed_46[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_50 (TimeD  (None, 8, 5760)              0         ['time_distributed_49[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_53 (TimeD  (None, 11, 5760)             0         ['time_distributed_52[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " gru_25 (GRU)                (None, 8, 128)               2261760   ['time_distributed_47[0][0]'] \n",
      "                                                                                                  \n",
      " gru_26 (GRU)                (None, 8, 128)               2261760   ['time_distributed_50[0][0]'] \n",
      "                                                                                                  \n",
      " gru_27 (GRU)                (None, 11, 128)              2261760   ['time_distributed_53[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 27, 128)              0         ['gru_25[0][0]',              \n",
      " )                                                                   'gru_26[0][0]',              \n",
      "                                                                     'gru_27[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)        (None, 27, 128)              0         ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " gru_28 (GRU)                (None, 27, 256)              296448    ['dropout_25[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)        (None, 27, 256)              0         ['gru_28[0][0]']              \n",
      "                                                                                                  \n",
      " gru_29 (GRU)                (None, 27, 512)              1182720   ['dropout_26[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)        (None, 27, 512)              0         ['gru_29[0][0]']              \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, 27, 512)              0         ['dropout_27[0][0]',          \n",
      "                                                                     'dropout_27[0][0]']          \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 27, 512)              0         ['dropout_27[0][0]',          \n",
      "                                                                     'attention_5[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_23 (Flatten)        (None, 13824)                0         ['add_5[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)        (None, 13824)                0         ['flatten_23[0][0]']          \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 128)                  1769600   ['dropout_28[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)        (None, 128)                  0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 32)                   4128      ['dropout_29[0][0]']          \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 1)                    33        ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10113089 (38.58 MB)\n",
      "Trainable params: 10113089 (38.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 2195s 2s/step - loss: 0.0632 - accuracy: 0.9826 - val_loss: 0.0305 - val_accuracy: 0.9931\n",
      "Epoch 2/10\n",
      "434/938 [============>.................] - ETA: 17:11 - loss: 0.0409 - accuracy: 0.9936"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "SizeTrainOk=4000\n",
    "SizeTrainKo=6000\n",
    "\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    print(\"\\t\",dx,day)\n",
    "    other_dx= [other for other in range(0,len(days)) if other != dx]\n",
    "\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    \n",
    "    for ax,activity in enumerate(activities):\n",
    "            print(ax,activity)\n",
    "            \n",
    "            ##TRAING DATA\n",
    "            L1=[]\n",
    "            L2=[]\n",
    "            S=[]\n",
    "            Y=[]\n",
    "            for ux,user in enumerate(users):\n",
    "                    print(\"\\t\\t\",ux,user)\n",
    "                    other_ux= [other for other in range(0,len(users)) if other != ux]\n",
    "                    print(day,user,other_dx,other_ux)\n",
    "\n",
    "                    #OK act\n",
    "                    for ix in range(0,SizeTrainOk):\n",
    "                        #print(\"SizeTrainOk\",ix,\"vs\",SizeTrainOk)\n",
    "                        filtered_elements = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 1)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            #print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                            X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        Ss=[]\n",
    "                        for sx, sensor in enumerate(sensors):\n",
    "                            Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                        L1.append(X1s)\n",
    "                        L2.append(X2s)\n",
    "                        S.append(Ss)\n",
    "                        Y.append(user_activity[index])\n",
    "                        \n",
    "                    #KO act\n",
    "                    ix=0\n",
    "                    while ix < SizeTrainKo:\n",
    "                        #print(\"SizeTrainKo\",ix,\"vs\",SizeTrainKo)\n",
    "                        filtered_elements_specific = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 0)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        none=True\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            #if(ax2==ax):\n",
    "                                r=np.random.rand()\n",
    "                                #print(\" removing loc?:\",loc_user[ax2][iu][idy][tt],r)\n",
    "                                if(r<loc_user[ax2][iu][idy][tt]+0.05):\n",
    "                                    #print(\"NOT  removing loc:\",loc_user[ax2][iu][idy][tt])\n",
    "                                    none=False\n",
    "                                    \n",
    "                                X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                                X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        if not none:\n",
    "                            L1.append(X1s)\n",
    "                            L2.append(X2s)\n",
    "                            Ss=[]\n",
    "                            for sx, sensor in enumerate(sensors):\n",
    "                                Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                            S.append(Ss)\n",
    "                            Y.append(user_activity[index])       \n",
    "                            ix=ix+1\n",
    "\n",
    "            L1=np.array(L1)        \n",
    "            L2=np.array(L2)        \n",
    "            S=np.array(S)\n",
    "            Y=np.array(Y)\n",
    "            print(\"TRAIN\",activity,day,L1.shape,L2.shape,S.shape,Y.shape)\n",
    "            \n",
    "            \n",
    "            model=getModelHAR()\n",
    "            model.summary()\n",
    "            \n",
    "            ##TEST DATA\n",
    "            TL1=[]\n",
    "            TL2=[]\n",
    "            TS=[]\n",
    "            TY=[]\n",
    "            \n",
    "            \n",
    "            (t0,tN)=t0N_days[day]\n",
    "            ts=list(range(TWA,sizeT(t0,tN)-TWB))\n",
    "            \n",
    "            for ux2,user2 in enumerate(users):\n",
    "                other_ux2= [other for other in range(0,len(users)) if other != ux2]\n",
    "\n",
    "                for tx in ts:\n",
    "\n",
    "                    Ss=[]\n",
    "                    for sx, sensor in enumerate(sensors):\n",
    "                        Ss.append(act_sensors[sx][dx][tx-TWA:tx+TWB])\n",
    "                    \n",
    "                    X1s=[]\n",
    "                    X2s=[]\n",
    "                    for ax2,activity2 in enumerate(activities):\n",
    "                        X1s.append(loc_user[ax2][ux2][dx][tx-TWA:tx+TWB])\n",
    "                        X2s.append(np.amax(loc_user[ax2,other_ux2,dx,tx-TWA:tx+TWB],axis=0))\n",
    "\n",
    "\n",
    "                    TL1.append(X1s)\n",
    "                    TL2.append(X2s)\n",
    "                    TS.append(Ss)\n",
    "                    TY.append(user_activity[ax, ux2, dx, tx])\n",
    "                        \n",
    "            TL1=np.array(TL1)        \n",
    "            TL2=np.array(TL2)        \n",
    "            TS=np.array(TS)\n",
    "            TY=np.array(TY)\n",
    "            print(\"EVAL\",activity,day,TL1.shape,TL2.shape,TS.shape,TY.shape)\n",
    "            \n",
    "            history = model.fit([L1,L2,S] , Y, shuffle=True, batch_size=32,epochs=10, validation_data = ([TL1,TL2,TS], TY))\n",
    "            YT_prediction = model.predict([TL1,TL2,TS])\n",
    "            print(YT_prediction.shape)\n",
    "            \n",
    "            ix=0\n",
    "            for ux2,user2 in enumerate(users):\n",
    "                with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/PREDICTION-TRANS-ENC-DEC-1024-30+15.\"+user2+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                    for tx in (ts):\n",
    "                        tt=tx*time_step2+t0\n",
    "                        #print(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0]))\n",
    "                        file.write(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0])+\"\\n\")\n",
    "                        \n",
    "                        ix=ix+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fc952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
