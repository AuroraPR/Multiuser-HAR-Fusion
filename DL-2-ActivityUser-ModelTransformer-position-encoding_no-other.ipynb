{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934b764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2024-07-05': ['0001', '3d57', 'ed9c'], '2024-07-06': ['0001', '3d57', 'ed9c'], '2024-07-07': ['0001', '3d57', 'ed9c'], '2024-07-18': ['16fe', 'f02e', 'ed9c'], '2024-07-19': ['16fe', 'f02e', 'ed9c'], '2024-07-20': ['16fe', 'f02e', 'ed9c'], '2024-07-24': ['16fe', '5b66', 'ed9c'], '2024-07-25': ['16fe', '5b66', 'ed9c'], '2024-07-26': ['16fe', '5b66', 'ed9c'], '2024-07-27': ['16fe', '5b66', 'ed9c'], '2024-07-28': ['16fe', '5b66', 'ed9c'], '2024-07-29': ['16fe', '5b66', 'ed9c'], '2024-07-30': ['16fe', '5b66', 'ed9c'], '2024-07-31': ['16fe', '5b66', 'ed9c']}\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('agg-config.txt')\n",
    "\n",
    "\n",
    "time_step = int(config.get('Configuration', 'time_step'))\n",
    "time_step2 = int(config.get('Configuration', 'time_step2'))\n",
    "\n",
    "window_size = int(config.get('Configuration', 'window_size'))\n",
    "processed_data_folder = config.get('Configuration', 'processed_data_folder')\n",
    "raw_data_folder = config.get('Configuration', 'raw_data_folder')\n",
    "\n",
    "ini_date = config.get('Configuration', 'ini_date')\n",
    "end_date = config.get('Configuration', 'end_date')\n",
    "\n",
    "\n",
    "activities=config.get('Configuration', 'learn_activities')\n",
    "activities = [(item.strip()) for item in activities.split(',')]\n",
    "\n",
    "cross_days=config.get('Configuration', 'cross_days')\n",
    "cross_days = [(item.strip()) for item in cross_days.split(',')]\n",
    "\n",
    "sensors=config.get('Configuration', 'sensors')\n",
    "sensors = [(item.strip()) for item in sensors.split(',')]\n",
    "\n",
    "w = int(config.get('Configuration', 'w'))\n",
    "h = int(config.get('Configuration', 'h'))\n",
    "\n",
    "users_day={}\n",
    "for cross_day in cross_days:\n",
    "    users_day[cross_day]=config.get('Configuration', cross_day)\n",
    "    users_day[cross_day] = [(item.strip()) for item in users_day[cross_day].split(',')]\n",
    "print(users_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ea50ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv    \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "off_zone=60*60*2\n",
    "\n",
    "def day_time(t0,tN,ti):\n",
    "    return int((int)((ti+off_zone)/(60*60*24)))\n",
    "\n",
    "\n",
    "def time2str(t0,tN,tt):\n",
    "    return datetime.fromtimestamp(tt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def day_time0(t0,tN,ti):\n",
    "    return day_time(ti)-day_time(t0)+1\n",
    "\n",
    "def relT(t0,tN,ti):\n",
    "    return (int)((ti-t0)/time_step2)\n",
    "\n",
    "def sizeT(t0,tN):\n",
    "    return relT(t0,tN,tN)+1\n",
    "\n",
    "\n",
    "def initTime(ini_date,end_date):\n",
    "    tN = (int)(datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "\n",
    "    t0 = (int)(datetime.strptime(ini_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    print (ini_date,\"Init date is\", t0, \"day:\",day_time(t0,tN,t0), time2str(t0,tN,t0))\n",
    "    print (end_date,\"End date is\", tN, \"day:\",day_time(t0,tN,tN), time2str(t0,tN,tN))\n",
    "\n",
    "    day=list(range(day_time(t0,tN,t0),day_time(t0,tN,tN)+1))[0]\n",
    "    return day,t0,tN\n",
    "    \n",
    "initTime(ini_date,end_date)\n",
    "\n",
    "\n",
    "def getStrDatefrom(day_number):\n",
    "    # Reference date (1970-01-01)\n",
    "    reference_date = datetime(1970, 1, 1)\n",
    "    \n",
    "    # Compute the date corresponding to the day number\n",
    "    resulting_date = reference_date + timedelta(days=day_number)\n",
    "    \n",
    "    return resulting_date.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeeab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ed8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-05\n",
      "New ini_date: 2024-07-05 02:00:00\n",
      "New end_date: 2024-07-06 01:59:59\n",
      "2024-07-05 02:00:00 Init date is 1720137600 day: 19909 2024-07-05 02:00:00\n",
      "2024-07-06 01:59:59 End date is 1720223999 day: 19910 2024-07-06 01:59:59\n",
      "2024-07-06\n",
      "New ini_date: 2024-07-06 02:00:00\n",
      "New end_date: 2024-07-07 01:59:59\n",
      "2024-07-06 02:00:00 Init date is 1720224000 day: 19910 2024-07-06 02:00:00\n",
      "2024-07-07 01:59:59 End date is 1720310399 day: 19911 2024-07-07 01:59:59\n",
      "2024-07-07\n",
      "New ini_date: 2024-07-07 02:00:00\n",
      "New end_date: 2024-07-08 01:59:59\n",
      "2024-07-07 02:00:00 Init date is 1720310400 day: 19911 2024-07-07 02:00:00\n",
      "2024-07-08 01:59:59 End date is 1720396799 day: 19912 2024-07-08 01:59:59\n",
      "2024-07-18\n",
      "New ini_date: 2024-07-18 02:00:00\n",
      "New end_date: 2024-07-19 01:59:59\n",
      "2024-07-18 02:00:00 Init date is 1721260800 day: 19922 2024-07-18 02:00:00\n",
      "2024-07-19 01:59:59 End date is 1721347199 day: 19923 2024-07-19 01:59:59\n",
      "2024-07-19\n",
      "New ini_date: 2024-07-19 02:00:00\n",
      "New end_date: 2024-07-20 01:59:59\n",
      "2024-07-19 02:00:00 Init date is 1721347200 day: 19923 2024-07-19 02:00:00\n",
      "2024-07-20 01:59:59 End date is 1721433599 day: 19924 2024-07-20 01:59:59\n",
      "2024-07-20\n",
      "New ini_date: 2024-07-20 02:00:00\n",
      "New end_date: 2024-07-21 01:59:59\n",
      "2024-07-20 02:00:00 Init date is 1721433600 day: 19924 2024-07-20 02:00:00\n",
      "2024-07-21 01:59:59 End date is 1721519999 day: 19925 2024-07-21 01:59:59\n",
      "2024-07-24\n",
      "New ini_date: 2024-07-24 02:00:00\n",
      "New end_date: 2024-07-25 01:59:59\n",
      "2024-07-24 02:00:00 Init date is 1721779200 day: 19928 2024-07-24 02:00:00\n",
      "2024-07-25 01:59:59 End date is 1721865599 day: 19929 2024-07-25 01:59:59\n",
      "2024-07-25\n",
      "New ini_date: 2024-07-25 02:00:00\n",
      "New end_date: 2024-07-26 01:59:59\n",
      "2024-07-25 02:00:00 Init date is 1721865600 day: 19929 2024-07-25 02:00:00\n",
      "2024-07-26 01:59:59 End date is 1721951999 day: 19930 2024-07-26 01:59:59\n",
      "2024-07-26\n",
      "New ini_date: 2024-07-26 02:00:00\n",
      "New end_date: 2024-07-27 01:59:59\n",
      "2024-07-26 02:00:00 Init date is 1721952000 day: 19930 2024-07-26 02:00:00\n",
      "2024-07-27 01:59:59 End date is 1722038399 day: 19931 2024-07-27 01:59:59\n",
      "2024-07-27\n",
      "New ini_date: 2024-07-27 02:00:00\n",
      "New end_date: 2024-07-28 01:59:59\n",
      "2024-07-27 02:00:00 Init date is 1722038400 day: 19931 2024-07-27 02:00:00\n",
      "2024-07-28 01:59:59 End date is 1722124799 day: 19932 2024-07-28 01:59:59\n",
      "2024-07-28\n",
      "New ini_date: 2024-07-28 02:00:00\n",
      "New end_date: 2024-07-29 01:59:59\n",
      "2024-07-28 02:00:00 Init date is 1722124800 day: 19932 2024-07-28 02:00:00\n",
      "2024-07-29 01:59:59 End date is 1722211199 day: 19933 2024-07-29 01:59:59\n",
      "2024-07-29\n",
      "New ini_date: 2024-07-29 02:00:00\n",
      "New end_date: 2024-07-30 01:59:59\n",
      "2024-07-29 02:00:00 Init date is 1722211200 day: 19933 2024-07-29 02:00:00\n",
      "2024-07-30 01:59:59 End date is 1722297599 day: 19934 2024-07-30 01:59:59\n",
      "2024-07-30\n",
      "New ini_date: 2024-07-30 02:00:00\n",
      "New end_date: 2024-07-31 01:59:59\n",
      "2024-07-30 02:00:00 Init date is 1722297600 day: 19934 2024-07-30 02:00:00\n",
      "2024-07-31 01:59:59 End date is 1722383999 day: 19935 2024-07-31 01:59:59\n",
      "2024-07-31\n",
      "New ini_date: 2024-07-31 02:00:00\n",
      "New end_date: 2024-08-01 01:59:59\n",
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n",
      "[19909, 19910, 19911, 19922, 19923, 19924, 19928, 19929, 19930, 19931, 19932, 19933, 19934, 19935]\n",
      "{19909: (1720137600, 1720223999), 19910: (1720224000, 1720310399), 19911: (1720310400, 1720396799), 19922: (1721260800, 1721347199), 19923: (1721347200, 1721433599), 19924: (1721433600, 1721519999), 19928: (1721779200, 1721865599), 19929: (1721865600, 1721951999), 19930: (1721952000, 1722038399), 19931: (1722038400, 1722124799), 19932: (1722124800, 1722211199), 19933: (1722211200, 1722297599), 19934: (1722297600, 1722383999), 19935: (1722384000, 1722470399)}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "days=[]\n",
    "t0N_days={}\n",
    "\n",
    "for cross_day in cross_days:\n",
    "    print(cross_day)\n",
    "    # Convertir las fechas a objetos datetime\n",
    "    ini_date_dt = datetime.strptime(ini_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    cross_day_dt = datetime.strptime(cross_day, \"%Y-%m-%d\")\n",
    "\n",
    "    # Reemplazar el día manteniendo la hora original\n",
    "    new_ini_date = cross_day_dt.replace(hour=ini_date_dt.hour, minute=ini_date_dt.minute, second=ini_date_dt.second)\n",
    "    new_end_date = cross_day_dt.replace(hour=end_date_dt.hour, minute=end_date_dt.minute, second=end_date_dt.second) + timedelta(days=1)\n",
    "\n",
    "    # Convertir las fechas de nuevo a cadena si es necesario\n",
    "    new_ini_date_str = new_ini_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    new_end_date_str = new_end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    print(f\"New ini_date: {new_ini_date_str}\")\n",
    "    print(f\"New end_date: {new_end_date_str}\")\n",
    "    day,t0,tN=initTime(new_ini_date_str,new_end_date_str)\n",
    "    days.append(day)\n",
    "    t0N_days[day]=(t0,tN)\n",
    "    \n",
    "\n",
    "print(days)\n",
    "print(t0N_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 14, 1440)\n",
      "\t toileting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.toileting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.toileting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.toileting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.toileting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.toileting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.toileting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.toileting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.toileting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.toileting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.toileting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.toileting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.toileting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.toileting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.toileting.tsv\n",
      "19935 (1440,)\n",
      "\t resting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.resting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.resting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.resting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.resting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.resting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.resting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.resting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.resting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.resting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.resting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.resting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.resting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.resting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.resting.tsv\n",
      "19935 (1440,)\n",
      "\t exit\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.exit.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.exit.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.exit.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.exit.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.exit.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.exit.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.exit.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.exit.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.exit.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.exit.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.exit.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.exit.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.exit.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.exit.tsv\n",
      "19935 (1440,)\n",
      "\t cooking\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.cooking.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.cooking.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.cooking.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.cooking.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.cooking.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.cooking.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.cooking.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.cooking.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.cooking.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.cooking.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.cooking.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.cooking.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.cooking.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.cooking.tsv\n",
      "19935 (1440,)\n",
      "\t shower\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.shower.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.shower.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.shower.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.shower.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.shower.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.shower.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.shower.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.shower.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.shower.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.shower.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.shower.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.shower.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.shower.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.shower.tsv\n",
      "19935 (1440,)\n",
      "\t pc\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.pc.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.pc.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.pc.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.pc.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.pc.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.pc.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.pc.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.pc.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.pc.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.pc.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.pc.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.pc.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.pc.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.pc.tsv\n",
      "19935 (1440,)\n",
      "\t sleep\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.sleep.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.sleep.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.sleep.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.sleep.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.sleep.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.sleep.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.sleep.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.sleep.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.sleep.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.sleep.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.sleep.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.sleep.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.sleep.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.sleep.tsv\n",
      "19935 (1440,)\n",
      "\t kitchen\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.kitchen.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.kitchen.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.kitchen.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.kitchen.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.kitchen.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.kitchen.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.kitchen.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.kitchen.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.kitchen.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.kitchen.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.kitchen.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.kitchen.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.kitchen.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.kitchen.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "len_users=3\n",
    "loc_user=np.zeros((len(activities),len_users,len(days),sizeT(t0,tN)))\n",
    "print(loc_user.shape)\n",
    "for ax,activity in enumerate(activities):\n",
    "    print(\"\\t\",activity)\n",
    "    for dx,day in enumerate(days):\n",
    "        day_str=getStrDatefrom(day)\n",
    "        users=users_day[day_str]\n",
    "        print(day,users)\n",
    "        for ux,user in enumerate(users):\n",
    "            print(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\")\n",
    "            series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"loc\"])\n",
    "            series=series[\"loc\"].values\n",
    "            print(day,series.shape)\n",
    "            loc_user[ax][ux][dx]=series\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9631e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 14, 1440)\n",
      "\t fridge_13\n",
      "./data-har//DAY_19909/object_sensor/fridge_13.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/fridge_13.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/fridge_13.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/fridge_13.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/fridge_13.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/fridge_13.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/fridge_13.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/fridge_13.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/fridge_13.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/fridge_13.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/fridge_13.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/fridge_13.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/fridge_13.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/fridge_13.tsv\n",
      "19935 (1440,)\n",
      "\t tap_22\n",
      "./data-har//DAY_19909/object_sensor/tap_22.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/tap_22.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/tap_22.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/tap_22.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/tap_22.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/tap_22.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/tap_22.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/tap_22.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/tap_22.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/tap_22.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/tap_22.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/tap_22.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/tap_22.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/tap_22.tsv\n",
      "19935 (1440,)\n",
      "\t micro_5\n",
      "./data-har//DAY_19909/object_sensor/micro_5.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/micro_5.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/micro_5.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/micro_5.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/micro_5.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/micro_5.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/micro_5.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/micro_5.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/micro_5.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/micro_5.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/micro_5.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/micro_5.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/micro_5.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/micro_5.tsv\n",
      "19935 (1440,)\n",
      "\t pans_8\n",
      "./data-har//DAY_19909/object_sensor/pans_8.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pans_8.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pans_8.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pans_8.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pans_8.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pans_8.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pans_8.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pans_8.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pans_8.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pans_8.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pans_8.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pans_8.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pans_8.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pans_8.tsv\n",
      "19935 (1440,)\n",
      "\t dishes_9\n",
      "./data-har//DAY_19909/object_sensor/dishes_9.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/dishes_9.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/dishes_9.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/dishes_9.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/dishes_9.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/dishes_9.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/dishes_9.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/dishes_9.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/dishes_9.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/dishes_9.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/dishes_9.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/dishes_9.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/dishes_9.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/dishes_9.tsv\n",
      "19935 (1440,)\n",
      "\t shower_24_apertura\n",
      "./data-har//DAY_19909/object_sensor/shower_24_apertura.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_24_apertura.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_24_apertura.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_24_apertura.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_24_apertura.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_24_apertura.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_24_apertura.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_24_apertura.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_24_apertura.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_24_apertura.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_24_apertura.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_24_apertura.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_24_apertura.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_24_apertura.tsv\n",
      "19935 (1440,)\n",
      "\t hum_shower_25\n",
      "./data-har//DAY_19909/object_sensor/hum_shower_25.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/hum_shower_25.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/hum_shower_25.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/hum_shower_25.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/hum_shower_25.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/hum_shower_25.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/hum_shower_25.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/hum_shower_25.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/hum_shower_25.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/hum_shower_25.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/hum_shower_25.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/hum_shower_25.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/hum_shower_25.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/hum_shower_25.tsv\n",
      "19935 (1440,)\n",
      "\t shower_31\n",
      "./data-har//DAY_19909/object_sensor/shower_31.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_31.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_31.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_31.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_31.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_31.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_31.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_31.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_31.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_31.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_31.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_31.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_31.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_31.tsv\n",
      "19935 (1440,)\n",
      "\t wc_17\n",
      "./data-har//DAY_19909/object_sensor/wc_17.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/wc_17.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/wc_17.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/wc_17.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/wc_17.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/wc_17.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/wc_17.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/wc_17.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/wc_17.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/wc_17.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/wc_17.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/wc_17.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/wc_17.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/wc_17.tsv\n",
      "19935 (1440,)\n",
      "\t sink_21\n",
      "./data-har//DAY_19909/object_sensor/sink_21.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/sink_21.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/sink_21.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/sink_21.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/sink_21.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/sink_21.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/sink_21.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/sink_21.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/sink_21.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/sink_21.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/sink_21.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/sink_21.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/sink_21.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/sink_21.tsv\n",
      "19935 (1440,)\n",
      "\t pc_1_current_consumption\n",
      "./data-har//DAY_19909/object_sensor/pc_1_current_consumption.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pc_1_current_consumption.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pc_1_current_consumption.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pc_1_current_consumption.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pc_1_current_consumption.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pc_1_current_consumption.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pc_1_current_consumption.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pc_1_current_consumption.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pc_1_current_consumption.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pc_1_current_consumption.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pc_1_current_consumption.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pc_1_current_consumption.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pc_1_current_consumption.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pc_1_current_consumption.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "act_sensors=np.zeros((len(sensors),len(days),sizeT(t0,tN)))\n",
    "print(act_sensors.shape)\n",
    "for sx,sensor in enumerate(sensors):\n",
    "    print(\"\\t\",sensor)\n",
    "    for dx,day in enumerate(days):\n",
    "        print(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\")\n",
    "        series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"status\"])\n",
    "        series=series[\"status\"].values\n",
    "        print(day,series.shape)\n",
    "        act_sensors[sx][dx]=series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n"
     ]
    }
   ],
   "source": [
    "user_activity=np.zeros((len(activities),len(users),len(days),sizeT(t0,tN)))\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            df_total=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/INTERVAL.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"ix\",\"d0\",\"dN\"])\n",
    "            #print(df_total)\n",
    "            #print(pd.to_datetime(df_total['d0']))\n",
    "            df_total['d0'] = pd.to_datetime(df_total['d0'])\n",
    "            df_total['dN'] = pd.to_datetime(df_total['dN'])\n",
    "            #print(df_total)\n",
    "\n",
    "            for tx,tt in enumerate(ts):\n",
    "                ttt=pd.to_datetime(time2str(t0,tN,tt))\n",
    "#                print(ttt)\n",
    "                row = df_total[(df_total['d0'] <= ttt) & (df_total['dN'] >= ttt)]\n",
    "#                print(\"df_in#tervalo\",row)\n",
    "                if(row.size>0):\n",
    "                    user_activity[ax][ux][dx][tx]=1\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "            \n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/LABEL3.\"+user+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                for tx,tt in enumerate(ts):\n",
    "                    file.write(time2str(t0,tN,tt)+\"\\t\"+str(user_activity[ax][ux][dx][tx])+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b92a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 18:53:37.008844: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-11 18:53:37.181918: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 18:53:38.094235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 18:53:40.127886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 8, 45)       0           ['input_1[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 11, 45)      0           ['input_2[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 8, 45)       65925       ['tf.__operators__.add[0][0]',   \n",
      " dAttention)                                                      'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 8, 45)       90          ['multi_head_attention[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8, 45)        0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 11, 45)       0           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 45)          0           ['dropout[0][0]']                \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 18:53:40.247697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 18:53:40.247737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 18:53:40.251048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 18:53:40.251086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 18:53:40.251111: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 18:53:40.460659: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 18:53:40.460722: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 18:53:40.460729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-12-11 18:53:40.460752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-11 18:53:40.460774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " global_average_pooling1d_1 (Gl  (None, 45)          0           ['dropout_1[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 90)           0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'global_average_pooling1d_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 90)           0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          11648       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, MultiHeadAttention, LayerNormalization, Dropout, Concatenate, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "N1 = len(activities)\n",
    "N2 = len(activities)\n",
    "N3 = len(sensors)\n",
    "\n",
    "TWA = 30\n",
    "TWB = 15\n",
    "T = TWA + TWB\n",
    "\n",
    "print(N1,N2,N3)\n",
    "\n",
    "# Positional Encoding function\n",
    "def getPositionEncoding(seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Computes positional encoding for a given sequence length and embedding dimension.\n",
    "    \"\"\"\n",
    "    position = np.arange(seq_len)[:, np.newaxis]  # (seq_len, 1)\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "\n",
    "    pos_enc = np.zeros((seq_len, d_model))  # Inicializar matriz de codificación posicional\n",
    "\n",
    "    # Llenar columnas pares con seno\n",
    "    pos_enc[:, 0::2] = np.sin(position * div_term)\n",
    "\n",
    "    # Llenar columnas impares con coseno\n",
    "    pos_enc[:, 1::2] = np.cos(position * div_term[:len(pos_enc[0, 1::2])])\n",
    "\n",
    "    # Expandir dimensiones para coincidir con batch size\n",
    "    pos_enc = np.expand_dims(pos_enc, axis=0)  # (1, seq_len, d_model)\n",
    "\n",
    "    return tf.cast(pos_enc, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modelo con Positional Encoding\n",
    "def getModelHAR():\n",
    "    # Define inputs\n",
    "    input1 = Input(shape=(8, 45))  # Forma de L1: (batch_size, 8, 45)\n",
    "    input3 = Input(shape=(11, 45))  # Forma de S: (batch_size, 11, 45)\n",
    "\n",
    "    # Codificación posicional\n",
    "    pos_enc1 = getPositionEncoding(8, 45)\n",
    "    pos_enc3 = getPositionEncoding(11, 45)\n",
    "\n",
    "    # Añadir Positional Encoding a las entradas\n",
    "    encoded1 = input1 + pos_enc1\n",
    "    encoded3 = input3 + pos_enc3\n",
    "\n",
    "    # Encoder para la primera secuencia\n",
    "    encoder1 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded1, encoded1)\n",
    "    encoder1 = LayerNormalization()(encoder1)\n",
    "    encoder1 = Dropout(0.5)(encoder1)\n",
    "\n",
    "    # Encoder para la tercera secuencia\n",
    "    encoder3 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded3, encoded3)\n",
    "    encoder3 = LayerNormalization()(encoder3)\n",
    "    encoder3 = Dropout(0.5)(encoder3)\n",
    "\n",
    "    # Reducir las dimensiones de las secuencias\n",
    "    reduced1 = GlobalAveragePooling1D()(encoder1)\n",
    "    reduced3 = GlobalAveragePooling1D()(encoder3)\n",
    "\n",
    "    # Concatenar las secuencias reducidas\n",
    "    merged_encoded = Concatenate(axis=-1)([reduced1, reduced3])\n",
    "\n",
    "    # Capa Bottleneck\n",
    "    bottleneck = Dropout(0.5)(merged_encoded)\n",
    "\n",
    "    # Capas densas para clasificación\n",
    "    dense = Dense(128, activation='relu')(bottleneck)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = Model(inputs=[input1, input3], outputs=output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = getModelHAR()\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "386cb41e-bb1e-4043-b002-ea2c550f5dbd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a216fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 19909\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 8, 45)       0           ['input_3[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 11, 45)      0           ['input_4[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_2[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 8, 45)        0           ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 11, 45)       0           ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 45)          0           ['dropout_4[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 45)          0           ['dropout_5[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 90)           0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          11648       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            129         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 18:54:53.182224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-12-11 18:54:53.236146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-12-11 18:54:53.311128: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3040c50210 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-11 18:54:53.311166: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-12-11 18:54:53.336700: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-11 18:54:53.597157: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 13s 10ms/step - loss: 0.2019 - accuracy: 0.9138 - val_loss: 0.1427 - val_accuracy: 0.9565\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0655 - accuracy: 0.9792 - val_loss: 0.0527 - val_accuracy: 0.9809\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 0.0315 - val_accuracy: 0.9873\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0407 - accuracy: 0.9855 - val_loss: 0.0197 - val_accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.0182 - val_accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.0337 - val_accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 0.0337 - val_accuracy: 0.9859\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.0299 - val_accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.0260 - accuracy: 0.9917 - val_loss: 0.1626 - val_accuracy: 0.9627\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 0.0120 - val_accuracy: 0.9964\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 8, 45)       0           ['input_5[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 11, 45)      0           ['input_6[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_4[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 8, 45)        0           ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 11, 45)       0           ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 45)          0           ['dropout_8[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 45)          0           ['dropout_9[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 90)           0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          11648       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            129         ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.2960 - accuracy: 0.8481 - val_loss: 0.2204 - val_accuracy: 0.8832\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1054 - accuracy: 0.9601 - val_loss: 0.3299 - val_accuracy: 0.8858\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0911 - accuracy: 0.9672 - val_loss: 0.4532 - val_accuracy: 0.8889\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0788 - accuracy: 0.9723 - val_loss: 0.2982 - val_accuracy: 0.8875\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0712 - accuracy: 0.9744 - val_loss: 0.3631 - val_accuracy: 0.8949\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0644 - accuracy: 0.9771 - val_loss: 0.5195 - val_accuracy: 0.8898\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0603 - accuracy: 0.9798 - val_loss: 0.3122 - val_accuracy: 0.8810\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0589 - accuracy: 0.9800 - val_loss: 0.4917 - val_accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 0.5054 - val_accuracy: 0.8920\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0505 - accuracy: 0.9827 - val_loss: 0.3643 - val_accuracy: 0.8927\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 8, 45)       0           ['input_7[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 11, 45)      0           ['input_8[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_6[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_7[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_7[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 8, 45)        0           ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 11, 45)       0           ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 45)          0           ['dropout_12[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 45)          0           ['dropout_13[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 90)           0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          11648       ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 128)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            129         ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.2008 - accuracy: 0.9245 - val_loss: 0.0339 - val_accuracy: 0.9943\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.1149 - accuracy: 0.9700 - val_loss: 0.0386 - val_accuracy: 0.9909\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1127 - accuracy: 0.9703 - val_loss: 0.0345 - val_accuracy: 0.9955\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1011 - accuracy: 0.9721 - val_loss: 0.0515 - val_accuracy: 0.9969\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0988 - accuracy: 0.9727 - val_loss: 0.0371 - val_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0964 - accuracy: 0.9735 - val_loss: 0.0442 - val_accuracy: 0.9978\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0939 - accuracy: 0.9743 - val_loss: 0.0460 - val_accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0918 - accuracy: 0.9744 - val_loss: 0.0276 - val_accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0893 - accuracy: 0.9753 - val_loss: 0.0194 - val_accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0873 - accuracy: 0.9751 - val_loss: 0.0423 - val_accuracy: 0.9959\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 8, 45)       0           ['input_9[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 11, 45)      0           ['input_10[0][0]']               \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_8[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_9[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_8[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_9[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 8, 45)        0           ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 11, 45)       0           ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 45)          0           ['dropout_16[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 45)          0           ['dropout_17[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 90)           0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          11648       ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1694 - accuracy: 0.9273 - val_loss: 0.0460 - val_accuracy: 0.9852\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0631 - accuracy: 0.9805 - val_loss: 0.0513 - val_accuracy: 0.9838\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 0.0295 - val_accuracy: 0.9895\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0446 - accuracy: 0.9860 - val_loss: 0.0493 - val_accuracy: 0.9835\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.0346 - val_accuracy: 0.9907\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.0282 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0321 - accuracy: 0.9899 - val_loss: 0.0209 - val_accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0310 - accuracy: 0.9904 - val_loss: 0.0243 - val_accuracy: 0.9940\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0300 - accuracy: 0.9913 - val_loss: 0.0343 - val_accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0292 - val_accuracy: 0.9912\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 8, 45)       0           ['input_11[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 11, 45)      0           ['input_12[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_10[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_11[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 8, 45)       90          ['multi_head_attention_10[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 11, 45)      90          ['multi_head_attention_11[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 8, 45)        0           ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 11, 45)       0           ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 45)          0           ['dropout_20[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_11 (G  (None, 45)          0           ['dropout_21[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_10[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 90)           0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          11648       ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 128)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            129         ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 11s 9ms/step - loss: 0.0961 - accuracy: 0.9617 - val_loss: 0.0186 - val_accuracy: 0.9947\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 0.0239 - val_accuracy: 0.9947\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0186 - val_accuracy: 0.9962\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.0158 - val_accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0106 - val_accuracy: 0.9981\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.0072 - val_accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9990\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0081 - val_accuracy: 0.9981\n",
      "131/131 [==============================] - 0s 3ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 8, 45)       0           ['input_13[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 11, 45)      0           ['input_14[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_12[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_13[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 8, 45)       90          ['multi_head_attention_12[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 11, 45)      90          ['multi_head_attention_13[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 8, 45)        0           ['layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 11, 45)       0           ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_12 (G  (None, 45)          0           ['dropout_24[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_13 (G  (None, 45)          0           ['dropout_25[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_12[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 90)           0           ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          11648       ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 128)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            129         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.1073 - accuracy: 0.9606 - val_loss: 0.0181 - val_accuracy: 0.9955\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0217 - accuracy: 0.9954 - val_loss: 0.1089 - val_accuracy: 0.9838\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.0120 - val_accuracy: 0.9962\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0132 - val_accuracy: 0.9962\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0170 - val_accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.0442 - val_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.0197 - val_accuracy: 0.9943\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0121 - val_accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.0394 - val_accuracy: 0.9921\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 8, 45)       0           ['input_15[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 11, 45)      0           ['input_16[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_14[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_15[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 8, 45)       90          ['multi_head_attention_14[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 11, 45)      90          ['multi_head_attention_15[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 8, 45)        0           ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 11, 45)       0           ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_14 (G  (None, 45)          0           ['dropout_28[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 45)          0           ['dropout_29[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_14[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 90)           0           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          11648       ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 128)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            129         ['dropout_31[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.1685 - accuracy: 0.9399 - val_loss: 0.0371 - val_accuracy: 0.9919\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1030 - accuracy: 0.9741 - val_loss: 0.0356 - val_accuracy: 0.9952\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0999 - accuracy: 0.9754 - val_loss: 0.0278 - val_accuracy: 0.9955\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0952 - accuracy: 0.9759 - val_loss: 0.0209 - val_accuracy: 0.9950\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0881 - accuracy: 0.9771 - val_loss: 0.0361 - val_accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0840 - accuracy: 0.9773 - val_loss: 0.0351 - val_accuracy: 0.9943\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0783 - accuracy: 0.9783 - val_loss: 0.0275 - val_accuracy: 0.9959\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0749 - accuracy: 0.9779 - val_loss: 0.0208 - val_accuracy: 0.9940\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0742 - accuracy: 0.9783 - val_loss: 0.0381 - val_accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0747 - accuracy: 0.9780 - val_loss: 0.0457 - val_accuracy: 0.9935\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 8, 45)       0           ['input_17[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 11, 45)      0           ['input_18[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_16[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_17[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 8, 45)       90          ['multi_head_attention_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 11, 45)      90          ['multi_head_attention_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 8, 45)        0           ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 11, 45)       0           ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_16 (G  (None, 45)          0           ['dropout_32[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_17 (G  (None, 45)          0           ['dropout_33[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_16[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 90)           0           ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          11648       ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            129         ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.2613 - accuracy: 0.8925 - val_loss: 0.1435 - val_accuracy: 0.9300\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1376 - accuracy: 0.9492 - val_loss: 0.0656 - val_accuracy: 0.9754\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1030 - accuracy: 0.9637 - val_loss: 0.0867 - val_accuracy: 0.9718\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0919 - accuracy: 0.9676 - val_loss: 0.0918 - val_accuracy: 0.9756\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0845 - accuracy: 0.9700 - val_loss: 0.1135 - val_accuracy: 0.9687\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0749 - accuracy: 0.9734 - val_loss: 0.1355 - val_accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0674 - accuracy: 0.9776 - val_loss: 0.1131 - val_accuracy: 0.9639\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.1338 - val_accuracy: 0.9756\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0625 - accuracy: 0.9786 - val_loss: 0.1589 - val_accuracy: 0.9740\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0587 - accuracy: 0.9800 - val_loss: 0.1251 - val_accuracy: 0.9747\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "\t 1 19910\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 8, 45)       0           ['input_19[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 11, 45)      0           ['input_20[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_18[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_19[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 8, 45)       90          ['multi_head_attention_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 11, 45)      90          ['multi_head_attention_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 8, 45)        0           ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 11, 45)       0           ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_18 (G  (None, 45)          0           ['dropout_36[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_19 (G  (None, 45)          0           ['dropout_37[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_18[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 90)           0           ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          11648       ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 128)          0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            129         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.2064 - accuracy: 0.9119 - val_loss: 0.0466 - val_accuracy: 0.9871\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0725 - accuracy: 0.9762 - val_loss: 0.0232 - val_accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.0524 - accuracy: 0.9822 - val_loss: 0.0231 - val_accuracy: 0.9892\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0438 - accuracy: 0.9839 - val_loss: 0.0421 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0358 - accuracy: 0.9886 - val_loss: 0.0243 - val_accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.0140 - val_accuracy: 0.9943\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0310 - accuracy: 0.9895 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0284 - accuracy: 0.9904 - val_loss: 0.0211 - val_accuracy: 0.9921\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.0100 - val_accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.0202 - val_accuracy: 0.9916\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 8, 45)       0           ['input_21[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 11, 45)      0           ['input_22[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_20[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_21[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 8, 45)       90          ['multi_head_attention_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 11, 45)      90          ['multi_head_attention_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 8, 45)        0           ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 11, 45)       0           ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_20 (G  (None, 45)          0           ['dropout_40[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_21 (G  (None, 45)          0           ['dropout_41[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_20[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_21[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 90)           0           ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          11648       ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 128)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            129         ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.2769 - accuracy: 0.8660 - val_loss: 0.0281 - val_accuracy: 0.9907\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1285 - accuracy: 0.9443 - val_loss: 0.0403 - val_accuracy: 0.9816\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.1166 - accuracy: 0.9501 - val_loss: 0.0334 - val_accuracy: 0.9883\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.1079 - accuracy: 0.9558 - val_loss: 0.0295 - val_accuracy: 0.9924\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1026 - accuracy: 0.9576 - val_loss: 0.0317 - val_accuracy: 0.9916\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0968 - accuracy: 0.9611 - val_loss: 0.0297 - val_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0926 - accuracy: 0.9621 - val_loss: 0.0215 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0884 - accuracy: 0.9639 - val_loss: 0.0205 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0883 - accuracy: 0.9643 - val_loss: 0.0264 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0876 - accuracy: 0.9648 - val_loss: 0.0246 - val_accuracy: 0.9919\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 8, 45)       0           ['input_23[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 11, 45)      0           ['input_24[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_22[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_23[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_23[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 8, 45)       90          ['multi_head_attention_22[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 11, 45)      90          ['multi_head_attention_23[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 8, 45)        0           ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 11, 45)       0           ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_22 (G  (None, 45)          0           ['dropout_44[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_23 (G  (None, 45)          0           ['dropout_45[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_22[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_23[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 90)           0           ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 128)          11648       ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 128)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            129         ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.1738 - accuracy: 0.9396 - val_loss: 0.4068 - val_accuracy: 0.8767\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0949 - accuracy: 0.9787 - val_loss: 0.4440 - val_accuracy: 0.8793\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0883 - accuracy: 0.9802 - val_loss: 0.3652 - val_accuracy: 0.8784\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0798 - accuracy: 0.9820 - val_loss: 0.4385 - val_accuracy: 0.8777\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0748 - accuracy: 0.9827 - val_loss: 0.3525 - val_accuracy: 0.8791\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0736 - accuracy: 0.9815 - val_loss: 0.3842 - val_accuracy: 0.8786\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0693 - accuracy: 0.9821 - val_loss: 0.4805 - val_accuracy: 0.8796\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0657 - accuracy: 0.9839 - val_loss: 0.3700 - val_accuracy: 0.8781\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0658 - accuracy: 0.9831 - val_loss: 0.4544 - val_accuracy: 0.8796\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0638 - accuracy: 0.9831 - val_loss: 0.4675 - val_accuracy: 0.8789\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 8, 45)       0           ['input_25[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 11, 45)      0           ['input_26[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_24[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_25[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 8, 45)       90          ['multi_head_attention_24[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 11, 45)      90          ['multi_head_attention_25[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 8, 45)        0           ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 11, 45)       0           ['layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_24 (G  (None, 45)          0           ['dropout_48[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_25 (G  (None, 45)          0           ['dropout_49[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_24[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_25[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 90)           0           ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 128)          11648       ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 128)          0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1)            129         ['dropout_51[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 11ms/step - loss: 0.1721 - accuracy: 0.9282 - val_loss: 0.0414 - val_accuracy: 0.9871\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0625 - accuracy: 0.9825 - val_loss: 0.0333 - val_accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0483 - accuracy: 0.9858 - val_loss: 0.0201 - val_accuracy: 0.9943\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0454 - accuracy: 0.9868 - val_loss: 0.0233 - val_accuracy: 0.9938\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0398 - accuracy: 0.9882 - val_loss: 0.0173 - val_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.0167 - val_accuracy: 0.9957\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.0208 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0328 - accuracy: 0.9908 - val_loss: 0.0159 - val_accuracy: 0.9957\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0221 - val_accuracy: 0.9945\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0294 - val_accuracy: 0.9931\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 8, 45)       0           ['input_27[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 11, 45)      0           ['input_28[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_26[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_27[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 8, 45)       90          ['multi_head_attention_26[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 11, 45)      90          ['multi_head_attention_27[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 8, 45)        0           ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 11, 45)       0           ['layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_26 (G  (None, 45)          0           ['dropout_52[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_27 (G  (None, 45)          0           ['dropout_53[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_26[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_27[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 90)           0           ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          11648       ['dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 128)          0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1)            129         ['dropout_55[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0973 - accuracy: 0.9610 - val_loss: 0.0346 - val_accuracy: 0.9912\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0210 - accuracy: 0.9952 - val_loss: 0.0295 - val_accuracy: 0.9914\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.0028 - val_accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9995\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_29 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 8, 45)       0           ['input_29[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 11, 45)      0           ['input_30[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_28[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_29[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 8, 45)       90          ['multi_head_attention_28[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 11, 45)      90          ['multi_head_attention_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 8, 45)        0           ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 11, 45)       0           ['layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_28 (G  (None, 45)          0           ['dropout_56[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_29 (G  (None, 45)          0           ['dropout_57[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_28[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_29[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 90)           0           ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          11648       ['dropout_58[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 128)          0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            129         ['dropout_59[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0961 - accuracy: 0.9633 - val_loss: 0.0586 - val_accuracy: 0.9881\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0210 - accuracy: 0.9954 - val_loss: 0.0765 - val_accuracy: 0.9876\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0176 - accuracy: 0.9966 - val_loss: 0.0411 - val_accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0181 - accuracy: 0.9964 - val_loss: 0.0301 - val_accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.0303 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.0263 - val_accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 0.0497 - val_accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0134 - accuracy: 0.9974 - val_loss: 0.0514 - val_accuracy: 0.9902\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.0429 - val_accuracy: 0.9904\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.0443 - val_accuracy: 0.9921\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 8, 45)       0           ['input_31[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 11, 45)      0           ['input_32[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_30[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_31 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_31[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_31[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 8, 45)       90          ['multi_head_attention_30[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 11, 45)      90          ['multi_head_attention_31[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 8, 45)        0           ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 11, 45)       0           ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_30 (G  (None, 45)          0           ['dropout_60[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_31 (G  (None, 45)          0           ['dropout_61[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_30[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_31[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 90)           0           ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 128)          11648       ['dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 128)          0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            129         ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.1384 - accuracy: 0.9508 - val_loss: 0.4769 - val_accuracy: 0.8779\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0765 - accuracy: 0.9827 - val_loss: 0.4308 - val_accuracy: 0.8769\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0698 - accuracy: 0.9833 - val_loss: 0.3659 - val_accuracy: 0.8772\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0684 - accuracy: 0.9838 - val_loss: 0.3827 - val_accuracy: 0.8772\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0643 - accuracy: 0.9839 - val_loss: 0.4687 - val_accuracy: 0.8719\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0617 - accuracy: 0.9843 - val_loss: 0.5865 - val_accuracy: 0.8726\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0577 - accuracy: 0.9861 - val_loss: 0.5059 - val_accuracy: 0.8755\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0576 - accuracy: 0.9855 - val_loss: 0.6073 - val_accuracy: 0.8753\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0528 - accuracy: 0.9861 - val_loss: 0.5602 - val_accuracy: 0.8748\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0527 - accuracy: 0.9864 - val_loss: 0.6071 - val_accuracy: 0.8750\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_33 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 8, 45)       0           ['input_33[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 11, 45)      0           ['input_34[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_32 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_32[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_33 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_33[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 8, 45)       90          ['multi_head_attention_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 11, 45)      90          ['multi_head_attention_33[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 8, 45)        0           ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)           (None, 11, 45)       0           ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_32 (G  (None, 45)          0           ['dropout_64[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_33 (G  (None, 45)          0           ['dropout_65[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_32[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_33[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 90)           0           ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          11648       ['dropout_66[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 128)          0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 1)            129         ['dropout_67[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2613 - accuracy: 0.8901 - val_loss: 0.0458 - val_accuracy: 0.9737\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1312 - accuracy: 0.9503 - val_loss: 0.0870 - val_accuracy: 0.9618\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1033 - accuracy: 0.9647 - val_loss: 0.0646 - val_accuracy: 0.9747\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0945 - accuracy: 0.9687 - val_loss: 0.0276 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0890 - accuracy: 0.9704 - val_loss: 0.0614 - val_accuracy: 0.9797\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0843 - accuracy: 0.9730 - val_loss: 0.0653 - val_accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0782 - accuracy: 0.9737 - val_loss: 0.0418 - val_accuracy: 0.9857\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0737 - accuracy: 0.9758 - val_loss: 0.0437 - val_accuracy: 0.9840\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0705 - accuracy: 0.9776 - val_loss: 0.0360 - val_accuracy: 0.9864\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0665 - accuracy: 0.9778 - val_loss: 0.0359 - val_accuracy: 0.9873\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 2 19911\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_35 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 8, 45)       0           ['input_35[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 11, 45)      0           ['input_36[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_34 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_34[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_35 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_35[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 8, 45)       90          ['multi_head_attention_34[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 11, 45)      90          ['multi_head_attention_35[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_68 (Dropout)           (None, 8, 45)        0           ['layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 11, 45)       0           ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_34 (G  (None, 45)          0           ['dropout_68[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_35 (G  (None, 45)          0           ['dropout_69[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_34[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_35[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_70 (Dropout)           (None, 90)           0           ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          11648       ['dropout_70[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 128)          0           ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 1)            129         ['dropout_71[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2070 - accuracy: 0.9108 - val_loss: 0.0360 - val_accuracy: 0.9919\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0687 - accuracy: 0.9786 - val_loss: 0.0423 - val_accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.0329 - val_accuracy: 0.9912\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0419 - accuracy: 0.9858 - val_loss: 0.0323 - val_accuracy: 0.9885\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 0.0714 - val_accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.0527 - val_accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.0337 - val_accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.0934 - val_accuracy: 0.9749\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0590 - val_accuracy: 0.9821\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_38 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (TFOpL  (None, 8, 45)       0           ['input_37[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (TFOpL  (None, 11, 45)      0           ['input_38[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_36 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_36[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_36[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_37 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_37[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_37[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 8, 45)       90          ['multi_head_attention_36[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 11, 45)      90          ['multi_head_attention_37[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 8, 45)        0           ['layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 11, 45)       0           ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_36 (G  (None, 45)          0           ['dropout_72[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_37 (G  (None, 45)          0           ['dropout_73[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_36[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_37[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 90)           0           ['concatenate_18[0][0]']         \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 128)          11648       ['dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 128)          0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 1)            129         ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2828 - accuracy: 0.8614 - val_loss: 0.1318 - val_accuracy: 0.9393\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1329 - accuracy: 0.9446 - val_loss: 0.1721 - val_accuracy: 0.9570\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1182 - accuracy: 0.9508 - val_loss: 0.1845 - val_accuracy: 0.9570\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1061 - accuracy: 0.9576 - val_loss: 0.1988 - val_accuracy: 0.9517\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0997 - accuracy: 0.9598 - val_loss: 0.1878 - val_accuracy: 0.9596\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0942 - accuracy: 0.9610 - val_loss: 0.1853 - val_accuracy: 0.9630\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0924 - accuracy: 0.9623 - val_loss: 0.1367 - val_accuracy: 0.9582\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0882 - accuracy: 0.9636 - val_loss: 0.1606 - val_accuracy: 0.9577\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0869 - accuracy: 0.9647 - val_loss: 0.2591 - val_accuracy: 0.9587\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0815 - accuracy: 0.9658 - val_loss: 0.1628 - val_accuracy: 0.9591\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_39 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_40 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (TFOpL  (None, 8, 45)       0           ['input_39[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (TFOpL  (None, 11, 45)      0           ['input_40[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_38 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_38[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_38[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_39 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_39[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_39[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 8, 45)       90          ['multi_head_attention_38[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 11, 45)      90          ['multi_head_attention_39[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)           (None, 8, 45)        0           ['layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 11, 45)       0           ['layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_38 (G  (None, 45)          0           ['dropout_76[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_39 (G  (None, 45)          0           ['dropout_77[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_38[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_39[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 90)           0           ['concatenate_19[0][0]']         \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 128)          11648       ['dropout_78[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)           (None, 128)          0           ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 1)            129         ['dropout_79[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1665 - accuracy: 0.9377 - val_loss: 0.5314 - val_accuracy: 0.8452\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0771 - accuracy: 0.9835 - val_loss: 0.6915 - val_accuracy: 0.8413\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0707 - accuracy: 0.9841 - val_loss: 0.7515 - val_accuracy: 0.8397\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0645 - accuracy: 0.9851 - val_loss: 0.6765 - val_accuracy: 0.8392\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0639 - accuracy: 0.9853 - val_loss: 0.5654 - val_accuracy: 0.8404\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0611 - accuracy: 0.9855 - val_loss: 0.5253 - val_accuracy: 0.8418\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0606 - accuracy: 0.9859 - val_loss: 0.6410 - val_accuracy: 0.8409\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0582 - accuracy: 0.9859 - val_loss: 0.7656 - val_accuracy: 0.8389\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0569 - accuracy: 0.9864 - val_loss: 0.5808 - val_accuracy: 0.8392\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0562 - accuracy: 0.9858 - val_loss: 0.6877 - val_accuracy: 0.8406\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_41 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_42 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (TFOpL  (None, 8, 45)       0           ['input_41[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (TFOpL  (None, 11, 45)      0           ['input_42[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_40 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_40[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_40[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_41 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_41[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_41[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 8, 45)       90          ['multi_head_attention_40[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 11, 45)      90          ['multi_head_attention_41[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 8, 45)        0           ['layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_81 (Dropout)           (None, 11, 45)       0           ['layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_40 (G  (None, 45)          0           ['dropout_80[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_41 (G  (None, 45)          0           ['dropout_81[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_40[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_41[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_82 (Dropout)           (None, 90)           0           ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 128)          11648       ['dropout_82[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_83 (Dropout)           (None, 128)          0           ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 1)            129         ['dropout_83[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1763 - accuracy: 0.9238 - val_loss: 0.0962 - val_accuracy: 0.9740\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0648 - accuracy: 0.9803 - val_loss: 0.0517 - val_accuracy: 0.9821\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0545 - accuracy: 0.9836 - val_loss: 0.0603 - val_accuracy: 0.9857\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 0.0459 - val_accuracy: 0.9861\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0394 - accuracy: 0.9875 - val_loss: 0.0543 - val_accuracy: 0.9847\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0362 - accuracy: 0.9883 - val_loss: 0.0396 - val_accuracy: 0.9869\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0309 - accuracy: 0.9895 - val_loss: 0.0647 - val_accuracy: 0.9799\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.0709 - val_accuracy: 0.9773\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0990 - val_accuracy: 0.9728\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0281 - accuracy: 0.9900 - val_loss: 0.0340 - val_accuracy: 0.9895\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_43 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_44 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (TFOpL  (None, 8, 45)       0           ['input_43[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (TFOpL  (None, 11, 45)      0           ['input_44[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_42 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_42[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_42[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_43 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_43[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_43[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 8, 45)       90          ['multi_head_attention_42[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 11, 45)      90          ['multi_head_attention_43[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_84 (Dropout)           (None, 8, 45)        0           ['layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_85 (Dropout)           (None, 11, 45)       0           ['layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_42 (G  (None, 45)          0           ['dropout_84[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_43 (G  (None, 45)          0           ['dropout_85[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_42[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_43[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_86 (Dropout)           (None, 90)           0           ['concatenate_21[0][0]']         \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 128)          11648       ['dropout_86[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_87 (Dropout)           (None, 128)          0           ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 1)            129         ['dropout_87[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.0979 - accuracy: 0.9574 - val_loss: 0.0270 - val_accuracy: 0.9947\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0163 - accuracy: 0.9964 - val_loss: 0.0408 - val_accuracy: 0.9952\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0466 - val_accuracy: 0.9933\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0510 - val_accuracy: 0.9945\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0087 - accuracy: 0.9981 - val_loss: 0.0415 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0539 - val_accuracy: 0.9957\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.0333 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0468 - val_accuracy: 0.9940\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0587 - val_accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0476 - val_accuracy: 0.9950\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_45 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_46 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  (None, 8, 45)       0           ['input_45[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (TFOpL  (None, 11, 45)      0           ['input_46[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_44 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_44[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_45 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_45[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_45[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 8, 45)       90          ['multi_head_attention_44[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 11, 45)      90          ['multi_head_attention_45[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 8, 45)        0           ['layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 11, 45)       0           ['layer_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_44 (G  (None, 45)          0           ['dropout_88[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_45 (G  (None, 45)          0           ['dropout_89[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_44[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_45[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_90 (Dropout)           (None, 90)           0           ['concatenate_22[0][0]']         \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 128)          11648       ['dropout_90[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)           (None, 128)          0           ['dense_44[0][0]']               \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 1)            129         ['dropout_91[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0996 - accuracy: 0.9618 - val_loss: 0.2170 - val_accuracy: 0.9568\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0246 - accuracy: 0.9951 - val_loss: 0.1700 - val_accuracy: 0.9565\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0203 - accuracy: 0.9961 - val_loss: 0.2263 - val_accuracy: 0.9544\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 0.0165 - val_accuracy: 0.9926\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.0307 - val_accuracy: 0.9921\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.1053 - val_accuracy: 0.9584\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0963 - val_accuracy: 0.9665\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.0893 - val_accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0762 - val_accuracy: 0.9677\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0111 - val_accuracy: 0.9950\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_47 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_48 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_46 (TFOpL  (None, 8, 45)       0           ['input_47[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (TFOpL  (None, 11, 45)      0           ['input_48[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_46 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_46[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_46[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_47 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_47[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_47[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 8, 45)       90          ['multi_head_attention_46[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 11, 45)      90          ['multi_head_attention_47[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)           (None, 8, 45)        0           ['layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)           (None, 11, 45)       0           ['layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_46 (G  (None, 45)          0           ['dropout_92[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_47 (G  (None, 45)          0           ['dropout_93[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_46[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)           (None, 90)           0           ['concatenate_23[0][0]']         \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 128)          11648       ['dropout_94[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)           (None, 128)          0           ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 1)            129         ['dropout_95[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1471 - accuracy: 0.9472 - val_loss: 0.4955 - val_accuracy: 0.8588\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0793 - accuracy: 0.9820 - val_loss: 0.4563 - val_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0753 - accuracy: 0.9830 - val_loss: 0.3447 - val_accuracy: 0.8784\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0701 - accuracy: 0.9840 - val_loss: 0.4483 - val_accuracy: 0.8657\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0669 - accuracy: 0.9847 - val_loss: 0.4342 - val_accuracy: 0.8638\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0650 - accuracy: 0.9845 - val_loss: 0.5015 - val_accuracy: 0.8628\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0613 - accuracy: 0.9850 - val_loss: 0.4244 - val_accuracy: 0.8652\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0616 - accuracy: 0.9847 - val_loss: 0.4804 - val_accuracy: 0.8674\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0617 - accuracy: 0.9854 - val_loss: 0.4804 - val_accuracy: 0.8671\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0609 - accuracy: 0.9851 - val_loss: 0.5006 - val_accuracy: 0.8679\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_49 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_50 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_48 (TFOpL  (None, 8, 45)       0           ['input_49[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_49 (TFOpL  (None, 11, 45)      0           ['input_50[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_48 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_48[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_48[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_49 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_49[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_49[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_48 (LayerN  (None, 8, 45)       90          ['multi_head_attention_48[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 11, 45)      90          ['multi_head_attention_49[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_96 (Dropout)           (None, 8, 45)        0           ['layer_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_97 (Dropout)           (None, 11, 45)       0           ['layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_48 (G  (None, 45)          0           ['dropout_96[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_49 (G  (None, 45)          0           ['dropout_97[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_48[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_49[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_98 (Dropout)           (None, 90)           0           ['concatenate_24[0][0]']         \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 128)          11648       ['dropout_98[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_99 (Dropout)           (None, 128)          0           ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 1)            129         ['dropout_99[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2534 - accuracy: 0.8914 - val_loss: 0.1326 - val_accuracy: 0.9360\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1194 - accuracy: 0.9582 - val_loss: 0.0827 - val_accuracy: 0.9632\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0989 - accuracy: 0.9663 - val_loss: 0.0861 - val_accuracy: 0.9637\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0881 - accuracy: 0.9697 - val_loss: 0.0971 - val_accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 0.0599 - val_accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0783 - accuracy: 0.9721 - val_loss: 0.1069 - val_accuracy: 0.9611\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0748 - accuracy: 0.9727 - val_loss: 0.0531 - val_accuracy: 0.9826\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0703 - accuracy: 0.9754 - val_loss: 0.0750 - val_accuracy: 0.9749\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0673 - accuracy: 0.9774 - val_loss: 0.0644 - val_accuracy: 0.9811\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0652 - accuracy: 0.9773 - val_loss: 0.2018 - val_accuracy: 0.9407\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "\t 3 19922\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_51 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_52 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (TFOpL  (None, 8, 45)       0           ['input_51[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_51 (TFOpL  (None, 11, 45)      0           ['input_52[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_50 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_50[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_50[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_51 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_51[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_51[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 8, 45)       90          ['multi_head_attention_50[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 11, 45)      90          ['multi_head_attention_51[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_100 (Dropout)          (None, 8, 45)        0           ['layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_101 (Dropout)          (None, 11, 45)       0           ['layer_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_50 (G  (None, 45)          0           ['dropout_100[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_51 (G  (None, 45)          0           ['dropout_101[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_50[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_51[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_102 (Dropout)          (None, 90)           0           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 128)          11648       ['dropout_102[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_103 (Dropout)          (None, 128)          0           ['dense_50[0][0]']               \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 1)            129         ['dropout_103[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1957 - accuracy: 0.9172 - val_loss: 0.0871 - val_accuracy: 0.9790\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0685 - accuracy: 0.9781 - val_loss: 0.0557 - val_accuracy: 0.9790\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0544 - accuracy: 0.9821 - val_loss: 0.0487 - val_accuracy: 0.9838\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.0834 - val_accuracy: 0.9689\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0341 - accuracy: 0.9884 - val_loss: 0.0598 - val_accuracy: 0.9799\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0319 - accuracy: 0.9895 - val_loss: 0.0402 - val_accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0516 - val_accuracy: 0.9857\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.0482 - val_accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.0380 - val_accuracy: 0.9864\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.0721 - val_accuracy: 0.9730\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_53 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_54 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_52 (TFOpL  (None, 8, 45)       0           ['input_53[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_53 (TFOpL  (None, 11, 45)      0           ['input_54[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_52 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_52[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_52[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_53 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_53[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_53[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 8, 45)       90          ['multi_head_attention_52[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 11, 45)      90          ['multi_head_attention_53[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_104 (Dropout)          (None, 8, 45)        0           ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_105 (Dropout)          (None, 11, 45)       0           ['layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_52 (G  (None, 45)          0           ['dropout_104[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_53 (G  (None, 45)          0           ['dropout_105[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_52[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_53[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_106 (Dropout)          (None, 90)           0           ['concatenate_26[0][0]']         \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 128)          11648       ['dropout_106[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_107 (Dropout)          (None, 128)          0           ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 1)            129         ['dropout_107[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2704 - accuracy: 0.8724 - val_loss: 0.3381 - val_accuracy: 0.9027\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1281 - accuracy: 0.9480 - val_loss: 0.2649 - val_accuracy: 0.9023\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1162 - accuracy: 0.9538 - val_loss: 0.2327 - val_accuracy: 0.8789\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1049 - accuracy: 0.9576 - val_loss: 0.2523 - val_accuracy: 0.8736\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1041 - accuracy: 0.9570 - val_loss: 0.2253 - val_accuracy: 0.8762\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0939 - accuracy: 0.9622 - val_loss: 0.2349 - val_accuracy: 0.8968\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0880 - accuracy: 0.9643 - val_loss: 0.2698 - val_accuracy: 0.8956\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0867 - accuracy: 0.9643 - val_loss: 0.2390 - val_accuracy: 0.8860\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0840 - accuracy: 0.9670 - val_loss: 0.2601 - val_accuracy: 0.8999\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0806 - accuracy: 0.9679 - val_loss: 0.2399 - val_accuracy: 0.9004\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_55 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_56 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 8, 45)       0           ['input_55[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  (None, 11, 45)      0           ['input_56[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_54 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_54[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_55 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_55[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 8, 45)       90          ['multi_head_attention_54[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 11, 45)      90          ['multi_head_attention_55[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_108 (Dropout)          (None, 8, 45)        0           ['layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_109 (Dropout)          (None, 11, 45)       0           ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_54 (G  (None, 45)          0           ['dropout_108[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_55 (G  (None, 45)          0           ['dropout_109[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_54[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_55[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_110 (Dropout)          (None, 90)           0           ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 128)          11648       ['dropout_110[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_111 (Dropout)          (None, 128)          0           ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 1)            129         ['dropout_111[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.2128 - accuracy: 0.9211 - val_loss: 0.0427 - val_accuracy: 0.9945\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1187 - accuracy: 0.9708 - val_loss: 0.0446 - val_accuracy: 0.9955\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1085 - accuracy: 0.9719 - val_loss: 0.0612 - val_accuracy: 0.9933\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1020 - accuracy: 0.9723 - val_loss: 0.1073 - val_accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1004 - accuracy: 0.9726 - val_loss: 0.0634 - val_accuracy: 0.9935\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0968 - accuracy: 0.9725 - val_loss: 0.1256 - val_accuracy: 0.9943\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0852 - accuracy: 0.9740 - val_loss: 0.0742 - val_accuracy: 0.9947\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0818 - accuracy: 0.9739 - val_loss: 0.0873 - val_accuracy: 0.9957\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0785 - accuracy: 0.9740 - val_loss: 0.0788 - val_accuracy: 0.9943\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0764 - accuracy: 0.9742 - val_loss: 0.0729 - val_accuracy: 0.9950\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_57 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_58 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_56 (TFOpL  (None, 8, 45)       0           ['input_57[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_57 (TFOpL  (None, 11, 45)      0           ['input_58[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_56 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_56[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_56[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_57 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_57[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_57[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 8, 45)       90          ['multi_head_attention_56[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 11, 45)      90          ['multi_head_attention_57[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_112 (Dropout)          (None, 8, 45)        0           ['layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_113 (Dropout)          (None, 11, 45)       0           ['layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_56 (G  (None, 45)          0           ['dropout_112[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_57 (G  (None, 45)          0           ['dropout_113[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_56[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_114 (Dropout)          (None, 90)           0           ['concatenate_28[0][0]']         \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 128)          11648       ['dropout_114[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_115 (Dropout)          (None, 128)          0           ['dense_56[0][0]']               \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 1)            129         ['dropout_115[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1767 - accuracy: 0.9208 - val_loss: 0.0563 - val_accuracy: 0.9876\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0615 - accuracy: 0.9823 - val_loss: 0.0685 - val_accuracy: 0.9816\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0466 - accuracy: 0.9855 - val_loss: 0.0358 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0418 - accuracy: 0.9871 - val_loss: 0.0370 - val_accuracy: 0.9849\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.0434 - val_accuracy: 0.9871\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.0441 - val_accuracy: 0.9871\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0479 - val_accuracy: 0.9871\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0928 - val_accuracy: 0.9768\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0463 - val_accuracy: 0.9838\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0432 - val_accuracy: 0.9890\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_59 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_60 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_58 (TFOpL  (None, 8, 45)       0           ['input_59[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_59 (TFOpL  (None, 11, 45)      0           ['input_60[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_58 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_58[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_58[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_59 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_59[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_59[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_58 (LayerN  (None, 8, 45)       90          ['multi_head_attention_58[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_59 (LayerN  (None, 11, 45)      90          ['multi_head_attention_59[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)          (None, 8, 45)        0           ['layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)          (None, 11, 45)       0           ['layer_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_58 (G  (None, 45)          0           ['dropout_116[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_59 (G  (None, 45)          0           ['dropout_117[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_58[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_59[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_118 (Dropout)          (None, 90)           0           ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 128)          11648       ['dropout_118[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_119 (Dropout)          (None, 128)          0           ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 1)            129         ['dropout_119[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.0857 - accuracy: 0.9663 - val_loss: 0.0355 - val_accuracy: 0.9914\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0149 - accuracy: 0.9963 - val_loss: 0.0292 - val_accuracy: 0.9955\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0283 - val_accuracy: 0.9955\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0380 - val_accuracy: 0.9935\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0391 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0370 - val_accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0358 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0366 - val_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0439 - val_accuracy: 0.9962\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0420 - val_accuracy: 0.9957\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_61 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_62 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_60 (TFOpL  (None, 8, 45)       0           ['input_61[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_61 (TFOpL  (None, 11, 45)      0           ['input_62[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_60 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_60[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_60[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_61 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_61[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_61[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_60 (LayerN  (None, 8, 45)       90          ['multi_head_attention_60[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_61 (LayerN  (None, 11, 45)      90          ['multi_head_attention_61[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_120 (Dropout)          (None, 8, 45)        0           ['layer_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_121 (Dropout)          (None, 11, 45)       0           ['layer_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_60 (G  (None, 45)          0           ['dropout_120[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_61 (G  (None, 45)          0           ['dropout_121[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_60[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_61[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_122 (Dropout)          (None, 90)           0           ['concatenate_30[0][0]']         \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 128)          11648       ['dropout_122[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_123 (Dropout)          (None, 128)          0           ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 1)            129         ['dropout_123[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0968 - accuracy: 0.9608 - val_loss: 0.0272 - val_accuracy: 0.9921\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.0807 - val_accuracy: 0.9857\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.0521 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.0661 - val_accuracy: 0.9869\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.1049 - val_accuracy: 0.9771\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0525 - val_accuracy: 0.9892\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0757 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.0380 - val_accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0106 - accuracy: 0.9982 - val_loss: 0.0793 - val_accuracy: 0.9857\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.0530 - val_accuracy: 0.9890\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_63 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_64 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_62 (TFOpL  (None, 8, 45)       0           ['input_63[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_63 (TFOpL  (None, 11, 45)      0           ['input_64[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_62 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_62[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_62[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_63 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_63[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_63[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_62 (LayerN  (None, 8, 45)       90          ['multi_head_attention_62[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_63 (LayerN  (None, 11, 45)      90          ['multi_head_attention_63[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_124 (Dropout)          (None, 8, 45)        0           ['layer_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_125 (Dropout)          (None, 11, 45)       0           ['layer_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_62 (G  (None, 45)          0           ['dropout_124[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_63 (G  (None, 45)          0           ['dropout_125[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_62[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_63[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_126 (Dropout)          (None, 90)           0           ['concatenate_31[0][0]']         \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 128)          11648       ['dropout_126[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_127 (Dropout)          (None, 128)          0           ['dense_62[0][0]']               \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 1)            129         ['dropout_127[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1686 - accuracy: 0.9414 - val_loss: 0.0314 - val_accuracy: 0.9955\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1032 - accuracy: 0.9749 - val_loss: 0.0352 - val_accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0953 - accuracy: 0.9758 - val_loss: 0.0287 - val_accuracy: 0.9935\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0932 - accuracy: 0.9756 - val_loss: 0.0223 - val_accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0889 - accuracy: 0.9776 - val_loss: 0.0186 - val_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0873 - accuracy: 0.9765 - val_loss: 0.0269 - val_accuracy: 0.9938\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0835 - accuracy: 0.9771 - val_loss: 0.0316 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0781 - accuracy: 0.9781 - val_loss: 0.0338 - val_accuracy: 0.9933\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0798 - accuracy: 0.9782 - val_loss: 0.0268 - val_accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0765 - accuracy: 0.9783 - val_loss: 0.0230 - val_accuracy: 0.9933\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_65 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_66 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_64 (TFOpL  (None, 8, 45)       0           ['input_65[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_65 (TFOpL  (None, 11, 45)      0           ['input_66[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_64 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_64[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_64[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_65 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_65[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_65[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_64 (LayerN  (None, 8, 45)       90          ['multi_head_attention_64[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_65 (LayerN  (None, 11, 45)      90          ['multi_head_attention_65[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_128 (Dropout)          (None, 8, 45)        0           ['layer_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_129 (Dropout)          (None, 11, 45)       0           ['layer_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_64 (G  (None, 45)          0           ['dropout_128[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_65 (G  (None, 45)          0           ['dropout_129[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_64[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_65[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_130 (Dropout)          (None, 90)           0           ['concatenate_32[0][0]']         \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 128)          11648       ['dropout_130[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, 128)          0           ['dense_64[0][0]']               \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 1)            129         ['dropout_131[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2672 - accuracy: 0.8803 - val_loss: 0.2652 - val_accuracy: 0.8440\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1132 - accuracy: 0.9597 - val_loss: 0.3509 - val_accuracy: 0.8863\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0893 - accuracy: 0.9696 - val_loss: 0.2553 - val_accuracy: 0.8930\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0807 - accuracy: 0.9747 - val_loss: 0.2675 - val_accuracy: 0.8958\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0735 - accuracy: 0.9758 - val_loss: 0.3527 - val_accuracy: 0.8958\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0685 - accuracy: 0.9771 - val_loss: 0.2434 - val_accuracy: 0.9209\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0687 - accuracy: 0.9772 - val_loss: 0.2393 - val_accuracy: 0.9360\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0649 - accuracy: 0.9785 - val_loss: 0.3057 - val_accuracy: 0.8934\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0606 - accuracy: 0.9793 - val_loss: 0.2511 - val_accuracy: 0.9228\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.2662 - val_accuracy: 0.9350\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 4 19923\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_67 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_68 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_66 (TFOpL  (None, 8, 45)       0           ['input_67[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_67 (TFOpL  (None, 11, 45)      0           ['input_68[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_66 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_66[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_66[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_67 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_67[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_67[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_66 (LayerN  (None, 8, 45)       90          ['multi_head_attention_66[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_67 (LayerN  (None, 11, 45)      90          ['multi_head_attention_67[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_132 (Dropout)          (None, 8, 45)        0           ['layer_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_133 (Dropout)          (None, 11, 45)       0           ['layer_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_66 (G  (None, 45)          0           ['dropout_132[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_67 (G  (None, 45)          0           ['dropout_133[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_66[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_67[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_134 (Dropout)          (None, 90)           0           ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 128)          11648       ['dropout_134[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_135 (Dropout)          (None, 128)          0           ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 1)            129         ['dropout_135[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2217 - accuracy: 0.9029 - val_loss: 0.0344 - val_accuracy: 0.9890\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0665 - accuracy: 0.9779 - val_loss: 0.0361 - val_accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0497 - accuracy: 0.9834 - val_loss: 0.0269 - val_accuracy: 0.9914\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.0352 - val_accuracy: 0.9900\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0382 - accuracy: 0.9872 - val_loss: 0.0443 - val_accuracy: 0.9888\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 0.0479 - val_accuracy: 0.9876\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0317 - accuracy: 0.9894 - val_loss: 0.0302 - val_accuracy: 0.9902\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.0495 - val_accuracy: 0.9866\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0311 - accuracy: 0.9892 - val_loss: 0.0368 - val_accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.0353 - val_accuracy: 0.9892\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_69 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_70 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (TFOpL  (None, 8, 45)       0           ['input_69[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (TFOpL  (None, 11, 45)      0           ['input_70[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_68 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_68[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_69 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_69[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_68 (LayerN  (None, 8, 45)       90          ['multi_head_attention_68[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_69 (LayerN  (None, 11, 45)      90          ['multi_head_attention_69[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 8, 45)        0           ['layer_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 11, 45)       0           ['layer_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_68 (G  (None, 45)          0           ['dropout_136[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_69 (G  (None, 45)          0           ['dropout_137[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_68[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_69[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 90)           0           ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 128)          11648       ['dropout_138[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 128)          0           ['dense_68[0][0]']               \n",
      "                                                                                                  \n",
      " dense_69 (Dense)               (None, 1)            129         ['dropout_139[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2669 - accuracy: 0.8728 - val_loss: 0.1493 - val_accuracy: 0.9381\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1344 - accuracy: 0.9414 - val_loss: 0.1794 - val_accuracy: 0.9078\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1160 - accuracy: 0.9510 - val_loss: 0.1303 - val_accuracy: 0.9611\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1066 - accuracy: 0.9556 - val_loss: 0.1575 - val_accuracy: 0.9386\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0985 - accuracy: 0.9603 - val_loss: 0.1545 - val_accuracy: 0.9594\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0900 - accuracy: 0.9628 - val_loss: 0.1569 - val_accuracy: 0.9436\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0873 - accuracy: 0.9653 - val_loss: 0.1855 - val_accuracy: 0.9355\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0813 - accuracy: 0.9666 - val_loss: 0.1705 - val_accuracy: 0.9431\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0811 - accuracy: 0.9670 - val_loss: 0.1567 - val_accuracy: 0.9517\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0782 - accuracy: 0.9694 - val_loss: 0.1892 - val_accuracy: 0.9486\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_71 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_72 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 8, 45)       0           ['input_71[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 11, 45)      0           ['input_72[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_70 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_70[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_71 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_71[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_71[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_70 (LayerN  (None, 8, 45)       90          ['multi_head_attention_70[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_71 (LayerN  (None, 11, 45)      90          ['multi_head_attention_71[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 8, 45)        0           ['layer_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 11, 45)       0           ['layer_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_70 (G  (None, 45)          0           ['dropout_140[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_71 (G  (None, 45)          0           ['dropout_141[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_70[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_71[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 90)           0           ['concatenate_35[0][0]']         \n",
      "                                                                                                  \n",
      " dense_70 (Dense)               (None, 128)          11648       ['dropout_142[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 128)          0           ['dense_70[0][0]']               \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 1)            129         ['dropout_143[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2069 - accuracy: 0.9265 - val_loss: 0.0737 - val_accuracy: 0.9890\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1153 - accuracy: 0.9724 - val_loss: 0.0637 - val_accuracy: 0.9842\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.1049 - accuracy: 0.9726 - val_loss: 0.0474 - val_accuracy: 0.9931\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0990 - accuracy: 0.9742 - val_loss: 0.0735 - val_accuracy: 0.9916\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0936 - accuracy: 0.9745 - val_loss: 0.0565 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0895 - accuracy: 0.9745 - val_loss: 0.0718 - val_accuracy: 0.9921\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0845 - accuracy: 0.9754 - val_loss: 0.0563 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0807 - accuracy: 0.9747 - val_loss: 0.0680 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0766 - accuracy: 0.9757 - val_loss: 0.0499 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0713 - accuracy: 0.9761 - val_loss: 0.0580 - val_accuracy: 0.9928\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_73 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_74 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_72 (TFOpL  (None, 8, 45)       0           ['input_73[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_73 (TFOpL  (None, 11, 45)      0           ['input_74[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_72 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_72[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_72[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_73 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_73[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_73[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_72 (LayerN  (None, 8, 45)       90          ['multi_head_attention_72[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_73 (LayerN  (None, 11, 45)      90          ['multi_head_attention_73[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_144 (Dropout)          (None, 8, 45)        0           ['layer_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_145 (Dropout)          (None, 11, 45)       0           ['layer_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_72 (G  (None, 45)          0           ['dropout_144[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_73 (G  (None, 45)          0           ['dropout_145[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_72[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_73[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 90)           0           ['concatenate_36[0][0]']         \n",
      "                                                                                                  \n",
      " dense_72 (Dense)               (None, 128)          11648       ['dropout_146[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 128)          0           ['dense_72[0][0]']               \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 1)            129         ['dropout_147[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1736 - accuracy: 0.9243 - val_loss: 0.1040 - val_accuracy: 0.9704\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0649 - accuracy: 0.9810 - val_loss: 0.1075 - val_accuracy: 0.9744\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0530 - accuracy: 0.9850 - val_loss: 0.0535 - val_accuracy: 0.9854\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0451 - accuracy: 0.9869 - val_loss: 0.0580 - val_accuracy: 0.9857\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.0777 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0372 - accuracy: 0.9891 - val_loss: 0.1181 - val_accuracy: 0.9694\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0333 - accuracy: 0.9901 - val_loss: 0.0614 - val_accuracy: 0.9845\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0324 - accuracy: 0.9898 - val_loss: 0.0663 - val_accuracy: 0.9866\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.0675 - val_accuracy: 0.9859\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0277 - accuracy: 0.9914 - val_loss: 0.1168 - val_accuracy: 0.9735\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_75 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_76 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_74 (TFOpL  (None, 8, 45)       0           ['input_75[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_75 (TFOpL  (None, 11, 45)      0           ['input_76[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_74 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_74[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_74[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_75 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_75[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_75[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_74 (LayerN  (None, 8, 45)       90          ['multi_head_attention_74[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_75 (LayerN  (None, 11, 45)      90          ['multi_head_attention_75[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_148 (Dropout)          (None, 8, 45)        0           ['layer_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_149 (Dropout)          (None, 11, 45)       0           ['layer_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_74 (G  (None, 45)          0           ['dropout_148[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_75 (G  (None, 45)          0           ['dropout_149[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_74[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_75[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_150 (Dropout)          (None, 90)           0           ['concatenate_37[0][0]']         \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 128)          11648       ['dropout_150[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_151 (Dropout)          (None, 128)          0           ['dense_74[0][0]']               \n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 1)            129         ['dropout_151[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0875 - accuracy: 0.9623 - val_loss: 0.0204 - val_accuracy: 0.9938\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0091 - val_accuracy: 0.9967\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0037 - val_accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.0267 - val_accuracy: 0.9892\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.0092 - val_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.1143 - val_accuracy: 0.9744\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0075 - accuracy: 0.9986 - val_loss: 0.0061 - val_accuracy: 0.9986\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_77 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_78 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_76 (TFOpL  (None, 8, 45)       0           ['input_77[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_77 (TFOpL  (None, 11, 45)      0           ['input_78[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_76 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_76[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_76[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_77 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_77[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_77[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_76 (LayerN  (None, 8, 45)       90          ['multi_head_attention_76[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_77 (LayerN  (None, 11, 45)      90          ['multi_head_attention_77[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_152 (Dropout)          (None, 8, 45)        0           ['layer_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_153 (Dropout)          (None, 11, 45)       0           ['layer_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_76 (G  (None, 45)          0           ['dropout_152[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_77 (G  (None, 45)          0           ['dropout_153[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_76[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_77[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_154 (Dropout)          (None, 90)           0           ['concatenate_38[0][0]']         \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 128)          11648       ['dropout_154[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_155 (Dropout)          (None, 128)          0           ['dense_76[0][0]']               \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 1)            129         ['dropout_155[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1220 - accuracy: 0.9522 - val_loss: 0.0995 - val_accuracy: 0.9816\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0203 - accuracy: 0.9961 - val_loss: 0.0662 - val_accuracy: 0.9890\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0174 - accuracy: 0.9968 - val_loss: 0.0587 - val_accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0853 - val_accuracy: 0.9869\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 0.0798 - val_accuracy: 0.9873\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0146 - accuracy: 0.9972 - val_loss: 0.0802 - val_accuracy: 0.9840\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0129 - accuracy: 0.9975 - val_loss: 0.0946 - val_accuracy: 0.9823\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0136 - accuracy: 0.9977 - val_loss: 0.0477 - val_accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.0671 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.0630 - val_accuracy: 0.9876\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_79 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_80 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_78 (TFOpL  (None, 8, 45)       0           ['input_79[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_79 (TFOpL  (None, 11, 45)      0           ['input_80[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_78 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_78[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_78[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_79 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_79[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_79[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_78 (LayerN  (None, 8, 45)       90          ['multi_head_attention_78[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_79 (LayerN  (None, 11, 45)      90          ['multi_head_attention_79[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_156 (Dropout)          (None, 8, 45)        0           ['layer_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_157 (Dropout)          (None, 11, 45)       0           ['layer_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_78 (G  (None, 45)          0           ['dropout_156[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_79 (G  (None, 45)          0           ['dropout_157[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_78[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_79[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_158 (Dropout)          (None, 90)           0           ['concatenate_39[0][0]']         \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 128)          11648       ['dropout_158[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_159 (Dropout)          (None, 128)          0           ['dense_78[0][0]']               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 1)            129         ['dropout_159[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1908 - accuracy: 0.9263 - val_loss: 0.0227 - val_accuracy: 0.9967\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1044 - accuracy: 0.9737 - val_loss: 0.0189 - val_accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1005 - accuracy: 0.9744 - val_loss: 0.0442 - val_accuracy: 0.9988\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0935 - accuracy: 0.9756 - val_loss: 0.0151 - val_accuracy: 0.9988\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0898 - accuracy: 0.9760 - val_loss: 0.0182 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0822 - accuracy: 0.9773 - val_loss: 0.0199 - val_accuracy: 0.9943\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0815 - accuracy: 0.9772 - val_loss: 0.0135 - val_accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0796 - accuracy: 0.9775 - val_loss: 0.0179 - val_accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0788 - accuracy: 0.9783 - val_loss: 0.0188 - val_accuracy: 0.9976\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0747 - accuracy: 0.9785 - val_loss: 0.0248 - val_accuracy: 0.9881\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_81 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_82 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_80 (TFOpL  (None, 8, 45)       0           ['input_81[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_81 (TFOpL  (None, 11, 45)      0           ['input_82[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_80 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_80[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_80[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_81 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_81[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_81[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_80 (LayerN  (None, 8, 45)       90          ['multi_head_attention_80[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_81 (LayerN  (None, 11, 45)      90          ['multi_head_attention_81[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_160 (Dropout)          (None, 8, 45)        0           ['layer_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_161 (Dropout)          (None, 11, 45)       0           ['layer_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_80 (G  (None, 45)          0           ['dropout_160[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_81 (G  (None, 45)          0           ['dropout_161[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_80[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_81[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_162 (Dropout)          (None, 90)           0           ['concatenate_40[0][0]']         \n",
      "                                                                                                  \n",
      " dense_80 (Dense)               (None, 128)          11648       ['dropout_162[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_163 (Dropout)          (None, 128)          0           ['dense_80[0][0]']               \n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 1)            129         ['dropout_163[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 12ms/step - loss: 0.2620 - accuracy: 0.8899 - val_loss: 0.1417 - val_accuracy: 0.9200\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1285 - accuracy: 0.9529 - val_loss: 0.0845 - val_accuracy: 0.9615\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1065 - accuracy: 0.9640 - val_loss: 0.1001 - val_accuracy: 0.9560\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0955 - accuracy: 0.9686 - val_loss: 0.0853 - val_accuracy: 0.9599\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0890 - accuracy: 0.9708 - val_loss: 0.1100 - val_accuracy: 0.9582\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0831 - accuracy: 0.9728 - val_loss: 0.1481 - val_accuracy: 0.9491\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0759 - accuracy: 0.9739 - val_loss: 0.1072 - val_accuracy: 0.9579\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0749 - accuracy: 0.9748 - val_loss: 0.1091 - val_accuracy: 0.9611\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 0.1846 - val_accuracy: 0.9398\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0701 - accuracy: 0.9768 - val_loss: 0.1059 - val_accuracy: 0.9591\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 5 19924\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_83 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_84 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_82 (TFOpL  (None, 8, 45)       0           ['input_83[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_83 (TFOpL  (None, 11, 45)      0           ['input_84[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_82 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_82[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_82[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_83 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_83[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_83[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_82 (LayerN  (None, 8, 45)       90          ['multi_head_attention_82[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_83 (LayerN  (None, 11, 45)      90          ['multi_head_attention_83[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_164 (Dropout)          (None, 8, 45)        0           ['layer_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_165 (Dropout)          (None, 11, 45)       0           ['layer_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_82 (G  (None, 45)          0           ['dropout_164[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_83 (G  (None, 45)          0           ['dropout_165[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_82[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_83[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_166 (Dropout)          (None, 90)           0           ['concatenate_41[0][0]']         \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 128)          11648       ['dropout_166[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_167 (Dropout)          (None, 128)          0           ['dense_82[0][0]']               \n",
      "                                                                                                  \n",
      " dense_83 (Dense)               (None, 1)            129         ['dropout_167[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2018 - accuracy: 0.9131 - val_loss: 0.0412 - val_accuracy: 0.9873\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0727 - accuracy: 0.9747 - val_loss: 0.0557 - val_accuracy: 0.9797\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 0.0413 - val_accuracy: 0.9904\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 0.0243 - val_accuracy: 0.9881\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0387 - accuracy: 0.9871 - val_loss: 0.0154 - val_accuracy: 0.9943\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0314 - accuracy: 0.9893 - val_loss: 0.0236 - val_accuracy: 0.9904\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.0261 - val_accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.0237 - val_accuracy: 0.9921\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0263 - accuracy: 0.9912 - val_loss: 0.0283 - val_accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.0490 - val_accuracy: 0.9892\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_85 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_86 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_84 (TFOpL  (None, 8, 45)       0           ['input_85[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_85 (TFOpL  (None, 11, 45)      0           ['input_86[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_84 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_84[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_84[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_85 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_85[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_85[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_84 (LayerN  (None, 8, 45)       90          ['multi_head_attention_84[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_85 (LayerN  (None, 11, 45)      90          ['multi_head_attention_85[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_168 (Dropout)          (None, 8, 45)        0           ['layer_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_169 (Dropout)          (None, 11, 45)       0           ['layer_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_84 (G  (None, 45)          0           ['dropout_168[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_85 (G  (None, 45)          0           ['dropout_169[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_84[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_85[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_170 (Dropout)          (None, 90)           0           ['concatenate_42[0][0]']         \n",
      "                                                                                                  \n",
      " dense_84 (Dense)               (None, 128)          11648       ['dropout_170[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_171 (Dropout)          (None, 128)          0           ['dense_84[0][0]']               \n",
      "                                                                                                  \n",
      " dense_85 (Dense)               (None, 1)            129         ['dropout_171[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2742 - accuracy: 0.8669 - val_loss: 0.1650 - val_accuracy: 0.9147\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1154 - accuracy: 0.9550 - val_loss: 0.0990 - val_accuracy: 0.9728\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1039 - accuracy: 0.9598 - val_loss: 0.1260 - val_accuracy: 0.9582\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0957 - accuracy: 0.9633 - val_loss: 0.0965 - val_accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0861 - accuracy: 0.9670 - val_loss: 0.1424 - val_accuracy: 0.9505\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0841 - accuracy: 0.9674 - val_loss: 0.1359 - val_accuracy: 0.9496\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0797 - accuracy: 0.9697 - val_loss: 0.1072 - val_accuracy: 0.9582\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0764 - accuracy: 0.9708 - val_loss: 0.1231 - val_accuracy: 0.9556\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0719 - accuracy: 0.9713 - val_loss: 0.0914 - val_accuracy: 0.9699\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0726 - accuracy: 0.9722 - val_loss: 0.0987 - val_accuracy: 0.9611\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_87 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_88 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_86 (TFOpL  (None, 8, 45)       0           ['input_87[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_87 (TFOpL  (None, 11, 45)      0           ['input_88[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_86 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_86[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_86[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_87 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_87[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_87[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_86 (LayerN  (None, 8, 45)       90          ['multi_head_attention_86[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_87 (LayerN  (None, 11, 45)      90          ['multi_head_attention_87[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_172 (Dropout)          (None, 8, 45)        0           ['layer_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_173 (Dropout)          (None, 11, 45)       0           ['layer_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_86 (G  (None, 45)          0           ['dropout_172[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_87 (G  (None, 45)          0           ['dropout_173[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_86[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_87[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_174 (Dropout)          (None, 90)           0           ['concatenate_43[0][0]']         \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 128)          11648       ['dropout_174[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_175 (Dropout)          (None, 128)          0           ['dense_86[0][0]']               \n",
      "                                                                                                  \n",
      " dense_87 (Dense)               (None, 1)            129         ['dropout_175[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1958 - accuracy: 0.9278 - val_loss: 0.0411 - val_accuracy: 0.9914\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1100 - accuracy: 0.9731 - val_loss: 0.0439 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1005 - accuracy: 0.9741 - val_loss: 0.0459 - val_accuracy: 0.9892\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0980 - accuracy: 0.9748 - val_loss: 0.0446 - val_accuracy: 0.9931\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0947 - accuracy: 0.9747 - val_loss: 0.0364 - val_accuracy: 0.9924\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0916 - accuracy: 0.9761 - val_loss: 0.0301 - val_accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0910 - accuracy: 0.9760 - val_loss: 0.0328 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0867 - accuracy: 0.9770 - val_loss: 0.0564 - val_accuracy: 0.9909\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0868 - accuracy: 0.9756 - val_loss: 0.0324 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0833 - accuracy: 0.9773 - val_loss: 0.0524 - val_accuracy: 0.9914\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_89 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_90 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_88 (TFOpL  (None, 8, 45)       0           ['input_89[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_89 (TFOpL  (None, 11, 45)      0           ['input_90[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_88 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_88[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_88[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_89 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_89[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_89[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_88 (LayerN  (None, 8, 45)       90          ['multi_head_attention_88[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_89 (LayerN  (None, 11, 45)      90          ['multi_head_attention_89[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_176 (Dropout)          (None, 8, 45)        0           ['layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_177 (Dropout)          (None, 11, 45)       0           ['layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_88 (G  (None, 45)          0           ['dropout_176[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_89 (G  (None, 45)          0           ['dropout_177[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_88[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_89[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_178 (Dropout)          (None, 90)           0           ['concatenate_44[0][0]']         \n",
      "                                                                                                  \n",
      " dense_88 (Dense)               (None, 128)          11648       ['dropout_178[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_179 (Dropout)          (None, 128)          0           ['dense_88[0][0]']               \n",
      "                                                                                                  \n",
      " dense_89 (Dense)               (None, 1)            129         ['dropout_179[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1795 - accuracy: 0.9264 - val_loss: 0.0499 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0630 - accuracy: 0.9807 - val_loss: 0.0420 - val_accuracy: 0.9871\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0537 - accuracy: 0.9843 - val_loss: 0.0624 - val_accuracy: 0.9761\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.0743 - val_accuracy: 0.9806\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.0564 - val_accuracy: 0.9842\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0375 - val_accuracy: 0.9873\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.0809 - val_accuracy: 0.9811\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.0378 - val_accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0640 - val_accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0526 - val_accuracy: 0.9830\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_91 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_92 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_90 (TFOpL  (None, 8, 45)       0           ['input_91[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_91 (TFOpL  (None, 11, 45)      0           ['input_92[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_90 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_90[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_90[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_91 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_91[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_91[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_90 (LayerN  (None, 8, 45)       90          ['multi_head_attention_90[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_91 (LayerN  (None, 11, 45)      90          ['multi_head_attention_91[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_180 (Dropout)          (None, 8, 45)        0           ['layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_181 (Dropout)          (None, 11, 45)       0           ['layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_90 (G  (None, 45)          0           ['dropout_180[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_91 (G  (None, 45)          0           ['dropout_181[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_45 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_90[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_91[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_182 (Dropout)          (None, 90)           0           ['concatenate_45[0][0]']         \n",
      "                                                                                                  \n",
      " dense_90 (Dense)               (None, 128)          11648       ['dropout_182[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_183 (Dropout)          (None, 128)          0           ['dense_90[0][0]']               \n",
      "                                                                                                  \n",
      " dense_91 (Dense)               (None, 1)            129         ['dropout_183[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0849 - accuracy: 0.9640 - val_loss: 0.0187 - val_accuracy: 0.9950\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 0.0377 - val_accuracy: 0.9928\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0221 - val_accuracy: 0.9964\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0107 - val_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.0272 - val_accuracy: 0.9957\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.0158 - val_accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0212 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0227 - val_accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0102 - val_accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0178 - val_accuracy: 0.9981\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_93 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_94 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_92 (TFOpL  (None, 8, 45)       0           ['input_93[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_93 (TFOpL  (None, 11, 45)      0           ['input_94[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_92 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_92[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_92[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_93 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_93[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_93[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_92 (LayerN  (None, 8, 45)       90          ['multi_head_attention_92[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_93 (LayerN  (None, 11, 45)      90          ['multi_head_attention_93[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_184 (Dropout)          (None, 8, 45)        0           ['layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_185 (Dropout)          (None, 11, 45)       0           ['layer_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_92 (G  (None, 45)          0           ['dropout_184[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_93 (G  (None, 45)          0           ['dropout_185[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_46 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_92[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_93[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_186 (Dropout)          (None, 90)           0           ['concatenate_46[0][0]']         \n",
      "                                                                                                  \n",
      " dense_92 (Dense)               (None, 128)          11648       ['dropout_186[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_187 (Dropout)          (None, 128)          0           ['dense_92[0][0]']               \n",
      "                                                                                                  \n",
      " dense_93 (Dense)               (None, 1)            129         ['dropout_187[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1138 - accuracy: 0.9561 - val_loss: 2.1541e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0288 - accuracy: 0.9941 - val_loss: 5.4348e-04 - val_accuracy: 0.9998\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0215 - accuracy: 0.9955 - val_loss: 7.5624e-04 - val_accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0169 - accuracy: 0.9967 - val_loss: 3.3557e-04 - val_accuracy: 0.9998\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0161 - accuracy: 0.9964 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0143 - accuracy: 0.9972 - val_loss: 3.0468e-04 - val_accuracy: 0.9998\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0151 - accuracy: 0.9969 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 2.9945e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 5.6339e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 9.0282e-05 - val_accuracy: 1.0000\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_95 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_96 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_94 (TFOpL  (None, 8, 45)       0           ['input_95[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_95 (TFOpL  (None, 11, 45)      0           ['input_96[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_94 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_94[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_94[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_95 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_95[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_95[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_94 (LayerN  (None, 8, 45)       90          ['multi_head_attention_94[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_95 (LayerN  (None, 11, 45)      90          ['multi_head_attention_95[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_188 (Dropout)          (None, 8, 45)        0           ['layer_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_189 (Dropout)          (None, 11, 45)       0           ['layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_94 (G  (None, 45)          0           ['dropout_188[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_95 (G  (None, 45)          0           ['dropout_189[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_94[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_95[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_190 (Dropout)          (None, 90)           0           ['concatenate_47[0][0]']         \n",
      "                                                                                                  \n",
      " dense_94 (Dense)               (None, 128)          11648       ['dropout_190[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_191 (Dropout)          (None, 128)          0           ['dense_94[0][0]']               \n",
      "                                                                                                  \n",
      " dense_95 (Dense)               (None, 1)            129         ['dropout_191[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1587 - accuracy: 0.9421 - val_loss: 0.0901 - val_accuracy: 0.9871\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0936 - accuracy: 0.9771 - val_loss: 0.1163 - val_accuracy: 0.9873\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0840 - accuracy: 0.9785 - val_loss: 0.1534 - val_accuracy: 0.9878\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0841 - accuracy: 0.9786 - val_loss: 0.1304 - val_accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0796 - accuracy: 0.9792 - val_loss: 0.1130 - val_accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0769 - accuracy: 0.9799 - val_loss: 0.1404 - val_accuracy: 0.9861\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0707 - accuracy: 0.9802 - val_loss: 0.1603 - val_accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0680 - accuracy: 0.9814 - val_loss: 0.1824 - val_accuracy: 0.9885\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0675 - accuracy: 0.9805 - val_loss: 0.1913 - val_accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0631 - accuracy: 0.9818 - val_loss: 0.1764 - val_accuracy: 0.9878\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_97 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_98 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_96 (TFOpL  (None, 8, 45)       0           ['input_97[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_97 (TFOpL  (None, 11, 45)      0           ['input_98[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_96 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_96[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_96[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_97 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_97[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_97[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_96 (LayerN  (None, 8, 45)       90          ['multi_head_attention_96[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_97 (LayerN  (None, 11, 45)      90          ['multi_head_attention_97[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_192 (Dropout)          (None, 8, 45)        0           ['layer_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_193 (Dropout)          (None, 11, 45)       0           ['layer_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_96 (G  (None, 45)          0           ['dropout_192[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_97 (G  (None, 45)          0           ['dropout_193[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_96[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_97[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_194 (Dropout)          (None, 90)           0           ['concatenate_48[0][0]']         \n",
      "                                                                                                  \n",
      " dense_96 (Dense)               (None, 128)          11648       ['dropout_194[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_195 (Dropout)          (None, 128)          0           ['dense_96[0][0]']               \n",
      "                                                                                                  \n",
      " dense_97 (Dense)               (None, 1)            129         ['dropout_195[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2566 - accuracy: 0.8933 - val_loss: 0.1855 - val_accuracy: 0.9047\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1402 - accuracy: 0.9481 - val_loss: 0.1005 - val_accuracy: 0.9625\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1083 - accuracy: 0.9611 - val_loss: 0.0695 - val_accuracy: 0.9713\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0959 - accuracy: 0.9675 - val_loss: 0.1469 - val_accuracy: 0.9517\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0862 - accuracy: 0.9713 - val_loss: 0.0893 - val_accuracy: 0.9694\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0791 - accuracy: 0.9737 - val_loss: 0.1151 - val_accuracy: 0.9618\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0736 - accuracy: 0.9759 - val_loss: 0.1292 - val_accuracy: 0.9673\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0720 - accuracy: 0.9763 - val_loss: 0.1196 - val_accuracy: 0.9579\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0682 - accuracy: 0.9774 - val_loss: 0.0724 - val_accuracy: 0.9756\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0654 - accuracy: 0.9792 - val_loss: 0.0670 - val_accuracy: 0.9744\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 6 19928\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_99 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_100 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_98 (TFOpL  (None, 8, 45)       0           ['input_99[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_99 (TFOpL  (None, 11, 45)      0           ['input_100[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_98 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_98[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_98[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_99 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_99[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_99[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_98 (LayerN  (None, 8, 45)       90          ['multi_head_attention_98[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_99 (LayerN  (None, 11, 45)      90          ['multi_head_attention_99[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_196 (Dropout)          (None, 8, 45)        0           ['layer_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_197 (Dropout)          (None, 11, 45)       0           ['layer_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_98 (G  (None, 45)          0           ['dropout_196[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_99 (G  (None, 45)          0           ['dropout_197[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_98[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_99[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_198 (Dropout)          (None, 90)           0           ['concatenate_49[0][0]']         \n",
      "                                                                                                  \n",
      " dense_98 (Dense)               (None, 128)          11648       ['dropout_198[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_199 (Dropout)          (None, 128)          0           ['dense_98[0][0]']               \n",
      "                                                                                                  \n",
      " dense_99 (Dense)               (None, 1)            129         ['dropout_199[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1980 - accuracy: 0.9156 - val_loss: 0.0488 - val_accuracy: 0.9864\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0694 - accuracy: 0.9765 - val_loss: 0.0290 - val_accuracy: 0.9935\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0467 - accuracy: 0.9838 - val_loss: 0.0566 - val_accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0391 - accuracy: 0.9861 - val_loss: 0.0437 - val_accuracy: 0.9861\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.0350 - val_accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0337 - accuracy: 0.9883 - val_loss: 0.0266 - val_accuracy: 0.9919\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.0236 - val_accuracy: 0.9945\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0439 - val_accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.0308 - val_accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0193 - val_accuracy: 0.9950\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_101 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_102 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_100 (TFOp  (None, 8, 45)       0           ['input_101[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_101 (TFOp  (None, 11, 45)      0           ['input_102[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_100 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_100[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_100[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_101 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_101[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_101[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_100 (Layer  (None, 8, 45)       90          ['multi_head_attention_100[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_101 (Layer  (None, 11, 45)      90          ['multi_head_attention_101[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_200 (Dropout)          (None, 8, 45)        0           ['layer_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " dropout_201 (Dropout)          (None, 11, 45)       0           ['layer_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_100 (  (None, 45)          0           ['dropout_200[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_101 (  (None, 45)          0           ['dropout_201[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_50 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_100[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_101[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_202 (Dropout)          (None, 90)           0           ['concatenate_50[0][0]']         \n",
      "                                                                                                  \n",
      " dense_100 (Dense)              (None, 128)          11648       ['dropout_202[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_203 (Dropout)          (None, 128)          0           ['dense_100[0][0]']              \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 1)            129         ['dropout_203[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2724 - accuracy: 0.8706 - val_loss: 0.1377 - val_accuracy: 0.9202\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1386 - accuracy: 0.9430 - val_loss: 0.0804 - val_accuracy: 0.9864\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1213 - accuracy: 0.9506 - val_loss: 0.0909 - val_accuracy: 0.9780\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1078 - accuracy: 0.9571 - val_loss: 0.0784 - val_accuracy: 0.9847\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1061 - accuracy: 0.9575 - val_loss: 0.1135 - val_accuracy: 0.9606\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0969 - accuracy: 0.9616 - val_loss: 0.1193 - val_accuracy: 0.9668\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0936 - accuracy: 0.9612 - val_loss: 0.0683 - val_accuracy: 0.9847\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0904 - accuracy: 0.9626 - val_loss: 0.0990 - val_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0879 - accuracy: 0.9633 - val_loss: 0.0518 - val_accuracy: 0.9859\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0832 - accuracy: 0.9654 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_103 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_104 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_102 (TFOp  (None, 8, 45)       0           ['input_103[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_103 (TFOp  (None, 11, 45)      0           ['input_104[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_102 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_102[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_102[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_103 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_103[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_103[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_102 (Layer  (None, 8, 45)       90          ['multi_head_attention_102[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_103 (Layer  (None, 11, 45)      90          ['multi_head_attention_103[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_204 (Dropout)          (None, 8, 45)        0           ['layer_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " dropout_205 (Dropout)          (None, 11, 45)       0           ['layer_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_102 (  (None, 45)          0           ['dropout_204[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_103 (  (None, 45)          0           ['dropout_205[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_51 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_102[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_103[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_206 (Dropout)          (None, 90)           0           ['concatenate_51[0][0]']         \n",
      "                                                                                                  \n",
      " dense_102 (Dense)              (None, 128)          11648       ['dropout_206[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_207 (Dropout)          (None, 128)          0           ['dense_102[0][0]']              \n",
      "                                                                                                  \n",
      " dense_103 (Dense)              (None, 1)            129         ['dropout_207[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1999 - accuracy: 0.9305 - val_loss: 0.0326 - val_accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1169 - accuracy: 0.9723 - val_loss: 0.0421 - val_accuracy: 0.9967\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1055 - accuracy: 0.9735 - val_loss: 0.0457 - val_accuracy: 0.9924\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1004 - accuracy: 0.9743 - val_loss: 0.0229 - val_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0957 - accuracy: 0.9748 - val_loss: 0.0409 - val_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0925 - accuracy: 0.9750 - val_loss: 0.0198 - val_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0870 - accuracy: 0.9761 - val_loss: 0.0239 - val_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0762 - accuracy: 0.9764 - val_loss: 0.0518 - val_accuracy: 0.9986\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0750 - accuracy: 0.9769 - val_loss: 0.0442 - val_accuracy: 0.9983\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0672 - accuracy: 0.9779 - val_loss: 0.0255 - val_accuracy: 0.9986\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_105 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_106 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_104 (TFOp  (None, 8, 45)       0           ['input_105[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_105 (TFOp  (None, 11, 45)      0           ['input_106[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_104 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_104[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_104[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_105 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_105[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_105[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_104 (Layer  (None, 8, 45)       90          ['multi_head_attention_104[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_105 (Layer  (None, 11, 45)      90          ['multi_head_attention_105[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_208 (Dropout)          (None, 8, 45)        0           ['layer_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " dropout_209 (Dropout)          (None, 11, 45)       0           ['layer_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_104 (  (None, 45)          0           ['dropout_208[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_105 (  (None, 45)          0           ['dropout_209[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_52 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_104[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_105[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_210 (Dropout)          (None, 90)           0           ['concatenate_52[0][0]']         \n",
      "                                                                                                  \n",
      " dense_104 (Dense)              (None, 128)          11648       ['dropout_210[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_211 (Dropout)          (None, 128)          0           ['dense_104[0][0]']              \n",
      "                                                                                                  \n",
      " dense_105 (Dense)              (None, 1)            129         ['dropout_211[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 10ms/step - loss: 0.1871 - accuracy: 0.9186 - val_loss: 0.0413 - val_accuracy: 0.9861\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0630 - accuracy: 0.9804 - val_loss: 0.1065 - val_accuracy: 0.9720\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.0601 - val_accuracy: 0.9842\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0425 - accuracy: 0.9873 - val_loss: 0.0539 - val_accuracy: 0.9842\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0387 - accuracy: 0.9880 - val_loss: 0.0420 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0633 - val_accuracy: 0.9878\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.0644 - val_accuracy: 0.9809\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0293 - accuracy: 0.9904 - val_loss: 0.1168 - val_accuracy: 0.9735\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.0632 - val_accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.0603 - val_accuracy: 0.9838\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_107 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_108 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_106 (TFOp  (None, 8, 45)       0           ['input_107[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_107 (TFOp  (None, 11, 45)      0           ['input_108[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_106 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_106[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_106[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_107 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_107[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_107[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_106 (Layer  (None, 8, 45)       90          ['multi_head_attention_106[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_107 (Layer  (None, 11, 45)      90          ['multi_head_attention_107[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_212 (Dropout)          (None, 8, 45)        0           ['layer_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " dropout_213 (Dropout)          (None, 11, 45)       0           ['layer_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_106 (  (None, 45)          0           ['dropout_212[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_107 (  (None, 45)          0           ['dropout_213[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_53 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_106[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_107[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_214 (Dropout)          (None, 90)           0           ['concatenate_53[0][0]']         \n",
      "                                                                                                  \n",
      " dense_106 (Dense)              (None, 128)          11648       ['dropout_214[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_215 (Dropout)          (None, 128)          0           ['dense_106[0][0]']              \n",
      "                                                                                                  \n",
      " dense_107 (Dense)              (None, 1)            129         ['dropout_215[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0859 - accuracy: 0.9645 - val_loss: 0.0109 - val_accuracy: 0.9969\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0064 - val_accuracy: 0.9981\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0075 - val_accuracy: 0.9983\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0077 - val_accuracy: 0.9986\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0099 - val_accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0065 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 5.2936e-04 - accuracy: 0.9999 - val_loss: 0.0090 - val_accuracy: 0.9993\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_109 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_110 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_108 (TFOp  (None, 8, 45)       0           ['input_109[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_109 (TFOp  (None, 11, 45)      0           ['input_110[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_108 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_108[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_108[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_109 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_109[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_109[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_108 (Layer  (None, 8, 45)       90          ['multi_head_attention_108[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_109 (Layer  (None, 11, 45)      90          ['multi_head_attention_109[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_216 (Dropout)          (None, 8, 45)        0           ['layer_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " dropout_217 (Dropout)          (None, 11, 45)       0           ['layer_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_108 (  (None, 45)          0           ['dropout_216[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_109 (  (None, 45)          0           ['dropout_217[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_54 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_108[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_109[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_218 (Dropout)          (None, 90)           0           ['concatenate_54[0][0]']         \n",
      "                                                                                                  \n",
      " dense_108 (Dense)              (None, 128)          11648       ['dropout_218[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_219 (Dropout)          (None, 128)          0           ['dense_108[0][0]']              \n",
      "                                                                                                  \n",
      " dense_109 (Dense)              (None, 1)            129         ['dropout_219[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0961 - accuracy: 0.9631 - val_loss: 0.0208 - val_accuracy: 0.9955\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.0242 - val_accuracy: 0.9950\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0188 - accuracy: 0.9962 - val_loss: 0.0190 - val_accuracy: 0.9959\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0197 - val_accuracy: 0.9964\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0152 - val_accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0133 - accuracy: 0.9976 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0150 - accuracy: 0.9975 - val_loss: 0.0280 - val_accuracy: 0.9947\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.0106 - val_accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.0156 - val_accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_55\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_111 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_112 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_110 (TFOp  (None, 8, 45)       0           ['input_111[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_111 (TFOp  (None, 11, 45)      0           ['input_112[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_110 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_110[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_110[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_111 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_111[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_111[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_110 (Layer  (None, 8, 45)       90          ['multi_head_attention_110[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_111 (Layer  (None, 11, 45)      90          ['multi_head_attention_111[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_220 (Dropout)          (None, 8, 45)        0           ['layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " dropout_221 (Dropout)          (None, 11, 45)       0           ['layer_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_110 (  (None, 45)          0           ['dropout_220[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_111 (  (None, 45)          0           ['dropout_221[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_55 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_110[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_111[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_222 (Dropout)          (None, 90)           0           ['concatenate_55[0][0]']         \n",
      "                                                                                                  \n",
      " dense_110 (Dense)              (None, 128)          11648       ['dropout_222[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_223 (Dropout)          (None, 128)          0           ['dense_110[0][0]']              \n",
      "                                                                                                  \n",
      " dense_111 (Dense)              (None, 1)            129         ['dropout_223[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1680 - accuracy: 0.9411 - val_loss: 0.0294 - val_accuracy: 0.9967\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1011 - accuracy: 0.9754 - val_loss: 0.0207 - val_accuracy: 0.9976\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0953 - accuracy: 0.9758 - val_loss: 0.0242 - val_accuracy: 0.9969\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0901 - accuracy: 0.9759 - val_loss: 0.0212 - val_accuracy: 0.9959\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0865 - accuracy: 0.9770 - val_loss: 0.0245 - val_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0822 - accuracy: 0.9774 - val_loss: 0.0193 - val_accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0803 - accuracy: 0.9782 - val_loss: 0.0215 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0786 - accuracy: 0.9782 - val_loss: 0.0363 - val_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0768 - accuracy: 0.9785 - val_loss: 0.0272 - val_accuracy: 0.9969\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0797 - accuracy: 0.9777 - val_loss: 0.0226 - val_accuracy: 0.9971\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_113 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_114 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_112 (TFOp  (None, 8, 45)       0           ['input_113[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_113 (TFOp  (None, 11, 45)      0           ['input_114[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_112 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_112[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_112[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_113 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_113[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_113[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_112 (Layer  (None, 8, 45)       90          ['multi_head_attention_112[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_113 (Layer  (None, 11, 45)      90          ['multi_head_attention_113[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_224 (Dropout)          (None, 8, 45)        0           ['layer_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " dropout_225 (Dropout)          (None, 11, 45)       0           ['layer_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_112 (  (None, 45)          0           ['dropout_224[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_113 (  (None, 45)          0           ['dropout_225[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_56 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_112[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_113[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_226 (Dropout)          (None, 90)           0           ['concatenate_56[0][0]']         \n",
      "                                                                                                  \n",
      " dense_112 (Dense)              (None, 128)          11648       ['dropout_226[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_227 (Dropout)          (None, 128)          0           ['dense_112[0][0]']              \n",
      "                                                                                                  \n",
      " dense_113 (Dense)              (None, 1)            129         ['dropout_227[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2508 - accuracy: 0.8945 - val_loss: 0.1537 - val_accuracy: 0.9039\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1287 - accuracy: 0.9523 - val_loss: 0.0944 - val_accuracy: 0.9594\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1101 - accuracy: 0.9615 - val_loss: 0.1298 - val_accuracy: 0.9553\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0932 - accuracy: 0.9669 - val_loss: 0.0830 - val_accuracy: 0.9697\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0852 - accuracy: 0.9717 - val_loss: 0.0816 - val_accuracy: 0.9680\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0796 - accuracy: 0.9721 - val_loss: 0.0804 - val_accuracy: 0.9694\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0754 - accuracy: 0.9741 - val_loss: 0.0858 - val_accuracy: 0.9694\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.0841 - val_accuracy: 0.9687\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0697 - accuracy: 0.9772 - val_loss: 0.0838 - val_accuracy: 0.9701\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0659 - accuracy: 0.9788 - val_loss: 0.1413 - val_accuracy: 0.9496\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 7 19929\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_115 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_116 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_114 (TFOp  (None, 8, 45)       0           ['input_115[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_115 (TFOp  (None, 11, 45)      0           ['input_116[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_114 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_114[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_114[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_115 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_115[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_115[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_114 (Layer  (None, 8, 45)       90          ['multi_head_attention_114[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_115 (Layer  (None, 11, 45)      90          ['multi_head_attention_115[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_228 (Dropout)          (None, 8, 45)        0           ['layer_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " dropout_229 (Dropout)          (None, 11, 45)       0           ['layer_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_114 (  (None, 45)          0           ['dropout_228[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_115 (  (None, 45)          0           ['dropout_229[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_57 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_114[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_115[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_230 (Dropout)          (None, 90)           0           ['concatenate_57[0][0]']         \n",
      "                                                                                                  \n",
      " dense_114 (Dense)              (None, 128)          11648       ['dropout_230[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_231 (Dropout)          (None, 128)          0           ['dense_114[0][0]']              \n",
      "                                                                                                  \n",
      " dense_115 (Dense)              (None, 1)            129         ['dropout_231[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 12ms/step - loss: 0.2193 - accuracy: 0.9043 - val_loss: 0.0677 - val_accuracy: 0.9747\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0670 - accuracy: 0.9769 - val_loss: 0.0171 - val_accuracy: 0.9952\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0464 - accuracy: 0.9840 - val_loss: 0.0309 - val_accuracy: 0.9895\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.0449 - val_accuracy: 0.9828\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.0115 - val_accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.0169 - val_accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 0.0110 - val_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0282 - accuracy: 0.9907 - val_loss: 0.0248 - val_accuracy: 0.9912\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0253 - accuracy: 0.9914 - val_loss: 0.0246 - val_accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.0307 - val_accuracy: 0.9938\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_117 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_118 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_116 (TFOp  (None, 8, 45)       0           ['input_117[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_117 (TFOp  (None, 11, 45)      0           ['input_118[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_116 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_116[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_116[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_117 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_117[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_117[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_116 (Layer  (None, 8, 45)       90          ['multi_head_attention_116[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_117 (Layer  (None, 11, 45)      90          ['multi_head_attention_117[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_232 (Dropout)          (None, 8, 45)        0           ['layer_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " dropout_233 (Dropout)          (None, 11, 45)       0           ['layer_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_116 (  (None, 45)          0           ['dropout_232[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_117 (  (None, 45)          0           ['dropout_233[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_58 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_116[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_117[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_234 (Dropout)          (None, 90)           0           ['concatenate_58[0][0]']         \n",
      "                                                                                                  \n",
      " dense_116 (Dense)              (None, 128)          11648       ['dropout_234[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_235 (Dropout)          (None, 128)          0           ['dense_116[0][0]']              \n",
      "                                                                                                  \n",
      " dense_117 (Dense)              (None, 1)            129         ['dropout_235[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2808 - accuracy: 0.8574 - val_loss: 0.1325 - val_accuracy: 0.9278\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1437 - accuracy: 0.9376 - val_loss: 0.1229 - val_accuracy: 0.9384\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1231 - accuracy: 0.9494 - val_loss: 0.0785 - val_accuracy: 0.9732\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1140 - accuracy: 0.9539 - val_loss: 0.1060 - val_accuracy: 0.9553\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1053 - accuracy: 0.9583 - val_loss: 0.0786 - val_accuracy: 0.9763\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0969 - accuracy: 0.9607 - val_loss: 0.0934 - val_accuracy: 0.9649\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0900 - accuracy: 0.9654 - val_loss: 0.0703 - val_accuracy: 0.9775\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0898 - accuracy: 0.9646 - val_loss: 0.1158 - val_accuracy: 0.9496\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0837 - accuracy: 0.9673 - val_loss: 0.0993 - val_accuracy: 0.9627\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0809 - accuracy: 0.9679 - val_loss: 0.0600 - val_accuracy: 0.9811\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_119 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_120 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_118 (TFOp  (None, 8, 45)       0           ['input_119[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_119 (TFOp  (None, 11, 45)      0           ['input_120[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_118 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_118[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_118[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_119 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_119[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_119[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_118 (Layer  (None, 8, 45)       90          ['multi_head_attention_118[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_119 (Layer  (None, 11, 45)      90          ['multi_head_attention_119[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_236 (Dropout)          (None, 8, 45)        0           ['layer_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " dropout_237 (Dropout)          (None, 11, 45)       0           ['layer_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_118 (  (None, 45)          0           ['dropout_236[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_119 (  (None, 45)          0           ['dropout_237[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_59 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_118[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_119[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_238 (Dropout)          (None, 90)           0           ['concatenate_59[0][0]']         \n",
      "                                                                                                  \n",
      " dense_118 (Dense)              (None, 128)          11648       ['dropout_238[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_239 (Dropout)          (None, 128)          0           ['dense_118[0][0]']              \n",
      "                                                                                                  \n",
      " dense_119 (Dense)              (None, 1)            129         ['dropout_239[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1945 - accuracy: 0.9332 - val_loss: 0.0521 - val_accuracy: 0.9967\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1209 - accuracy: 0.9715 - val_loss: 0.0487 - val_accuracy: 0.9986\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1053 - accuracy: 0.9729 - val_loss: 0.0611 - val_accuracy: 0.9967\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0967 - accuracy: 0.9743 - val_loss: 0.0690 - val_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0959 - accuracy: 0.9742 - val_loss: 0.0348 - val_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0935 - accuracy: 0.9743 - val_loss: 0.0367 - val_accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0901 - accuracy: 0.9750 - val_loss: 0.0179 - val_accuracy: 0.9990\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0913 - accuracy: 0.9745 - val_loss: 0.0235 - val_accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0846 - accuracy: 0.9755 - val_loss: 0.0389 - val_accuracy: 0.9990\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0839 - accuracy: 0.9759 - val_loss: 0.0502 - val_accuracy: 0.9976\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_121 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_122 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_120 (TFOp  (None, 8, 45)       0           ['input_121[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_121 (TFOp  (None, 11, 45)      0           ['input_122[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_120 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_120[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_120[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_121 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_121[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_121[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_120 (Layer  (None, 8, 45)       90          ['multi_head_attention_120[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_121 (Layer  (None, 11, 45)      90          ['multi_head_attention_121[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_240 (Dropout)          (None, 8, 45)        0           ['layer_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " dropout_241 (Dropout)          (None, 11, 45)       0           ['layer_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_120 (  (None, 45)          0           ['dropout_240[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_121 (  (None, 45)          0           ['dropout_241[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_60 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_120[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_121[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_242 (Dropout)          (None, 90)           0           ['concatenate_60[0][0]']         \n",
      "                                                                                                  \n",
      " dense_120 (Dense)              (None, 128)          11648       ['dropout_242[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_243 (Dropout)          (None, 128)          0           ['dense_120[0][0]']              \n",
      "                                                                                                  \n",
      " dense_121 (Dense)              (None, 1)            129         ['dropout_243[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1762 - accuracy: 0.9250 - val_loss: 0.0370 - val_accuracy: 0.9909\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0662 - accuracy: 0.9808 - val_loss: 0.0292 - val_accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0581 - accuracy: 0.9838 - val_loss: 0.0546 - val_accuracy: 0.9818\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0480 - accuracy: 0.9859 - val_loss: 0.0198 - val_accuracy: 0.9943\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0430 - accuracy: 0.9874 - val_loss: 0.0245 - val_accuracy: 0.9924\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.0215 - val_accuracy: 0.9921\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.0197 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0338 - accuracy: 0.9894 - val_loss: 0.0242 - val_accuracy: 0.9926\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0324 - accuracy: 0.9897 - val_loss: 0.0281 - val_accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0304 - val_accuracy: 0.9907\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_61\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_123 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_124 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_122 (TFOp  (None, 8, 45)       0           ['input_123[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_123 (TFOp  (None, 11, 45)      0           ['input_124[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_122 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_122[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_122[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_123 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_123[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_123[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_122 (Layer  (None, 8, 45)       90          ['multi_head_attention_122[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_123 (Layer  (None, 11, 45)      90          ['multi_head_attention_123[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_244 (Dropout)          (None, 8, 45)        0           ['layer_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " dropout_245 (Dropout)          (None, 11, 45)       0           ['layer_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_122 (  (None, 45)          0           ['dropout_244[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_123 (  (None, 45)          0           ['dropout_245[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_61 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_122[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_123[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_246 (Dropout)          (None, 90)           0           ['concatenate_61[0][0]']         \n",
      "                                                                                                  \n",
      " dense_122 (Dense)              (None, 128)          11648       ['dropout_246[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_247 (Dropout)          (None, 128)          0           ['dense_122[0][0]']              \n",
      "                                                                                                  \n",
      " dense_123 (Dense)              (None, 1)            129         ['dropout_247[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0913 - accuracy: 0.9626 - val_loss: 0.0319 - val_accuracy: 0.9924\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.0233 - val_accuracy: 0.9952\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0171 - accuracy: 0.9966 - val_loss: 0.0046 - val_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.0151 - val_accuracy: 0.9959\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0107 - val_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0159 - val_accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.0043 - val_accuracy: 0.9986\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.0030 - val_accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0069 - val_accuracy: 0.9986\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0172 - val_accuracy: 0.9971\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_125 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_126 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_124 (TFOp  (None, 8, 45)       0           ['input_125[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_125 (TFOp  (None, 11, 45)      0           ['input_126[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_124 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_124[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_124[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_125 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_125[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_125[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_124 (Layer  (None, 8, 45)       90          ['multi_head_attention_124[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_125 (Layer  (None, 11, 45)      90          ['multi_head_attention_125[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_248 (Dropout)          (None, 8, 45)        0           ['layer_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " dropout_249 (Dropout)          (None, 11, 45)       0           ['layer_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_124 (  (None, 45)          0           ['dropout_248[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_125 (  (None, 45)          0           ['dropout_249[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_62 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_124[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_125[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_250 (Dropout)          (None, 90)           0           ['concatenate_62[0][0]']         \n",
      "                                                                                                  \n",
      " dense_124 (Dense)              (None, 128)          11648       ['dropout_250[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_251 (Dropout)          (None, 128)          0           ['dense_124[0][0]']              \n",
      "                                                                                                  \n",
      " dense_125 (Dense)              (None, 1)            129         ['dropout_251[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1036 - accuracy: 0.9608 - val_loss: 0.0208 - val_accuracy: 0.9943\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0265 - accuracy: 0.9945 - val_loss: 0.0272 - val_accuracy: 0.9921\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 0.0096 - val_accuracy: 0.9967\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0182 - accuracy: 0.9964 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.0046 - val_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.0135 - val_accuracy: 0.9974\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.0069 - val_accuracy: 0.9974\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0127 - accuracy: 0.9978 - val_loss: 0.0184 - val_accuracy: 0.9957\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.0087 - val_accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0117 - accuracy: 0.9977 - val_loss: 0.0076 - val_accuracy: 0.9978\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_63\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_127 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_128 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_126 (TFOp  (None, 8, 45)       0           ['input_127[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_127 (TFOp  (None, 11, 45)      0           ['input_128[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_126 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_126[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_126[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_127 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_127[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_127[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_126 (Layer  (None, 8, 45)       90          ['multi_head_attention_126[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_127 (Layer  (None, 11, 45)      90          ['multi_head_attention_127[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_252 (Dropout)          (None, 8, 45)        0           ['layer_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " dropout_253 (Dropout)          (None, 11, 45)       0           ['layer_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_126 (  (None, 45)          0           ['dropout_252[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_127 (  (None, 45)          0           ['dropout_253[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_63 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_126[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_127[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_254 (Dropout)          (None, 90)           0           ['concatenate_63[0][0]']         \n",
      "                                                                                                  \n",
      " dense_126 (Dense)              (None, 128)          11648       ['dropout_254[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_255 (Dropout)          (None, 128)          0           ['dense_126[0][0]']              \n",
      "                                                                                                  \n",
      " dense_127 (Dense)              (None, 1)            129         ['dropout_255[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1786 - accuracy: 0.9327 - val_loss: 0.1052 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1023 - accuracy: 0.9751 - val_loss: 0.0803 - val_accuracy: 0.9835\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0976 - accuracy: 0.9764 - val_loss: 0.0690 - val_accuracy: 0.9854\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0916 - accuracy: 0.9767 - val_loss: 0.0748 - val_accuracy: 0.9838\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0903 - accuracy: 0.9764 - val_loss: 0.0591 - val_accuracy: 0.9852\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0872 - accuracy: 0.9770 - val_loss: 0.1077 - val_accuracy: 0.9763\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0850 - accuracy: 0.9776 - val_loss: 0.0732 - val_accuracy: 0.9821\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0794 - accuracy: 0.9784 - val_loss: 0.0707 - val_accuracy: 0.9878\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0793 - accuracy: 0.9779 - val_loss: 0.0568 - val_accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0755 - accuracy: 0.9781 - val_loss: 0.0595 - val_accuracy: 0.9849\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_64\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_129 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_130 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_128 (TFOp  (None, 8, 45)       0           ['input_129[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_129 (TFOp  (None, 11, 45)      0           ['input_130[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_128 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_128[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_128[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_129 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_129[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_129[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_128 (Layer  (None, 8, 45)       90          ['multi_head_attention_128[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_129 (Layer  (None, 11, 45)      90          ['multi_head_attention_129[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_256 (Dropout)          (None, 8, 45)        0           ['layer_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " dropout_257 (Dropout)          (None, 11, 45)       0           ['layer_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_128 (  (None, 45)          0           ['dropout_256[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_129 (  (None, 45)          0           ['dropout_257[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_64 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_128[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_129[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_258 (Dropout)          (None, 90)           0           ['concatenate_64[0][0]']         \n",
      "                                                                                                  \n",
      " dense_128 (Dense)              (None, 128)          11648       ['dropout_258[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_259 (Dropout)          (None, 128)          0           ['dense_128[0][0]']              \n",
      "                                                                                                  \n",
      " dense_129 (Dense)              (None, 1)            129         ['dropout_259[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 12s 10ms/step - loss: 0.2692 - accuracy: 0.8847 - val_loss: 0.1172 - val_accuracy: 0.9321\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1322 - accuracy: 0.9518 - val_loss: 0.1181 - val_accuracy: 0.9438\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1141 - accuracy: 0.9607 - val_loss: 0.1028 - val_accuracy: 0.9620\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1039 - accuracy: 0.9639 - val_loss: 0.1112 - val_accuracy: 0.9568\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0941 - accuracy: 0.9664 - val_loss: 0.0704 - val_accuracy: 0.9646\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0885 - accuracy: 0.9684 - val_loss: 0.0746 - val_accuracy: 0.9663\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0831 - accuracy: 0.9695 - val_loss: 0.0821 - val_accuracy: 0.9613\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0828 - accuracy: 0.9708 - val_loss: 0.1019 - val_accuracy: 0.9584\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0763 - accuracy: 0.9723 - val_loss: 0.1020 - val_accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0747 - accuracy: 0.9728 - val_loss: 0.0933 - val_accuracy: 0.9637\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "\t 8 19930\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_65\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_131 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_132 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_130 (TFOp  (None, 8, 45)       0           ['input_131[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_131 (TFOp  (None, 11, 45)      0           ['input_132[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_130 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_130[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_130[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_131 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_131[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_131[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_130 (Layer  (None, 8, 45)       90          ['multi_head_attention_130[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_131 (Layer  (None, 11, 45)      90          ['multi_head_attention_131[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_260 (Dropout)          (None, 8, 45)        0           ['layer_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " dropout_261 (Dropout)          (None, 11, 45)       0           ['layer_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_130 (  (None, 45)          0           ['dropout_260[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_131 (  (None, 45)          0           ['dropout_261[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_65 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_130[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_131[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_262 (Dropout)          (None, 90)           0           ['concatenate_65[0][0]']         \n",
      "                                                                                                  \n",
      " dense_130 (Dense)              (None, 128)          11648       ['dropout_262[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_263 (Dropout)          (None, 128)          0           ['dense_130[0][0]']              \n",
      "                                                                                                  \n",
      " dense_131 (Dense)              (None, 1)            129         ['dropout_263[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1976 - accuracy: 0.9158 - val_loss: 0.0842 - val_accuracy: 0.9720\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0675 - accuracy: 0.9777 - val_loss: 0.0300 - val_accuracy: 0.9895\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0514 - accuracy: 0.9817 - val_loss: 0.0196 - val_accuracy: 0.9931\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0429 - accuracy: 0.9849 - val_loss: 0.0324 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0373 - accuracy: 0.9876 - val_loss: 0.0211 - val_accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.0313 - val_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0336 - accuracy: 0.9892 - val_loss: 0.0181 - val_accuracy: 0.9935\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.0415 - val_accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 0.0316 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0259 - accuracy: 0.9911 - val_loss: 0.0617 - val_accuracy: 0.9811\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_66\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_133 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_134 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_132 (TFOp  (None, 8, 45)       0           ['input_133[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_133 (TFOp  (None, 11, 45)      0           ['input_134[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_132 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_132[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_132[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_133 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_133[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_133[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_132 (Layer  (None, 8, 45)       90          ['multi_head_attention_132[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_133 (Layer  (None, 11, 45)      90          ['multi_head_attention_133[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_264 (Dropout)          (None, 8, 45)        0           ['layer_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " dropout_265 (Dropout)          (None, 11, 45)       0           ['layer_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_132 (  (None, 45)          0           ['dropout_264[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_133 (  (None, 45)          0           ['dropout_265[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_66 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_132[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_133[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_266 (Dropout)          (None, 90)           0           ['concatenate_66[0][0]']         \n",
      "                                                                                                  \n",
      " dense_132 (Dense)              (None, 128)          11648       ['dropout_266[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_267 (Dropout)          (None, 128)          0           ['dense_132[0][0]']              \n",
      "                                                                                                  \n",
      " dense_133 (Dense)              (None, 1)            129         ['dropout_267[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2949 - accuracy: 0.8567 - val_loss: 0.1793 - val_accuracy: 0.8956\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1376 - accuracy: 0.9409 - val_loss: 0.1760 - val_accuracy: 0.9223\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1203 - accuracy: 0.9504 - val_loss: 0.1138 - val_accuracy: 0.9665\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1084 - accuracy: 0.9539 - val_loss: 0.0797 - val_accuracy: 0.9787\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1042 - accuracy: 0.9585 - val_loss: 0.1001 - val_accuracy: 0.9663\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0966 - accuracy: 0.9603 - val_loss: 0.1060 - val_accuracy: 0.9613\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0929 - accuracy: 0.9626 - val_loss: 0.1045 - val_accuracy: 0.9556\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0876 - accuracy: 0.9642 - val_loss: 0.0740 - val_accuracy: 0.9771\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0854 - accuracy: 0.9654 - val_loss: 0.0577 - val_accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0834 - accuracy: 0.9663 - val_loss: 0.0712 - val_accuracy: 0.9806\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_67\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_135 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_136 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_134 (TFOp  (None, 8, 45)       0           ['input_135[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_135 (TFOp  (None, 11, 45)      0           ['input_136[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_134 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_134[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_134[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_135 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_135[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_135[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_134 (Layer  (None, 8, 45)       90          ['multi_head_attention_134[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_135 (Layer  (None, 11, 45)      90          ['multi_head_attention_135[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_268 (Dropout)          (None, 8, 45)        0           ['layer_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " dropout_269 (Dropout)          (None, 11, 45)       0           ['layer_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_134 (  (None, 45)          0           ['dropout_268[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_135 (  (None, 45)          0           ['dropout_269[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_67 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_134[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_135[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_270 (Dropout)          (None, 90)           0           ['concatenate_67[0][0]']         \n",
      "                                                                                                  \n",
      " dense_134 (Dense)              (None, 128)          11648       ['dropout_270[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_271 (Dropout)          (None, 128)          0           ['dense_134[0][0]']              \n",
      "                                                                                                  \n",
      " dense_135 (Dense)              (None, 1)            129         ['dropout_271[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2009 - accuracy: 0.9282 - val_loss: 0.0515 - val_accuracy: 0.9971\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1205 - accuracy: 0.9712 - val_loss: 0.0363 - val_accuracy: 0.9974\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1083 - accuracy: 0.9728 - val_loss: 0.0283 - val_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1038 - accuracy: 0.9735 - val_loss: 0.0390 - val_accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0970 - accuracy: 0.9742 - val_loss: 0.0674 - val_accuracy: 0.9967\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0951 - accuracy: 0.9747 - val_loss: 0.0280 - val_accuracy: 0.9981\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0921 - accuracy: 0.9755 - val_loss: 0.0339 - val_accuracy: 0.9978\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0901 - accuracy: 0.9752 - val_loss: 0.0320 - val_accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0876 - accuracy: 0.9759 - val_loss: 0.0179 - val_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0842 - accuracy: 0.9765 - val_loss: 0.0296 - val_accuracy: 0.9981\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_68\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_137 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_138 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_136 (TFOp  (None, 8, 45)       0           ['input_137[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_137 (TFOp  (None, 11, 45)      0           ['input_138[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_136 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_136[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_136[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_137 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_137[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_137[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_136 (Layer  (None, 8, 45)       90          ['multi_head_attention_136[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_137 (Layer  (None, 11, 45)      90          ['multi_head_attention_137[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_272 (Dropout)          (None, 8, 45)        0           ['layer_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " dropout_273 (Dropout)          (None, 11, 45)       0           ['layer_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_136 (  (None, 45)          0           ['dropout_272[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_137 (  (None, 45)          0           ['dropout_273[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_68 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_136[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_137[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_274 (Dropout)          (None, 90)           0           ['concatenate_68[0][0]']         \n",
      "                                                                                                  \n",
      " dense_136 (Dense)              (None, 128)          11648       ['dropout_274[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_275 (Dropout)          (None, 128)          0           ['dense_136[0][0]']              \n",
      "                                                                                                  \n",
      " dense_137 (Dense)              (None, 1)            129         ['dropout_275[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 12ms/step - loss: 0.1678 - accuracy: 0.9303 - val_loss: 0.0553 - val_accuracy: 0.9821\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0676 - accuracy: 0.9794 - val_loss: 0.0483 - val_accuracy: 0.9864\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0557 - accuracy: 0.9841 - val_loss: 0.0574 - val_accuracy: 0.9828\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0496 - accuracy: 0.9850 - val_loss: 0.0234 - val_accuracy: 0.9924\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0436 - accuracy: 0.9865 - val_loss: 0.0675 - val_accuracy: 0.9814\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0537 - val_accuracy: 0.9871\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0360 - accuracy: 0.9875 - val_loss: 0.0951 - val_accuracy: 0.9778\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 0.0430 - val_accuracy: 0.9842\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.0579 - val_accuracy: 0.9852\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.0399 - val_accuracy: 0.9885\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_69\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_139 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_140 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_138 (TFOp  (None, 8, 45)       0           ['input_139[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_139 (TFOp  (None, 11, 45)      0           ['input_140[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_138 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_138[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_138[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_139 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_139[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_139[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_138 (Layer  (None, 8, 45)       90          ['multi_head_attention_138[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_139 (Layer  (None, 11, 45)      90          ['multi_head_attention_139[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_276 (Dropout)          (None, 8, 45)        0           ['layer_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " dropout_277 (Dropout)          (None, 11, 45)       0           ['layer_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_138 (  (None, 45)          0           ['dropout_276[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_139 (  (None, 45)          0           ['dropout_277[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_69 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_138[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_139[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_278 (Dropout)          (None, 90)           0           ['concatenate_69[0][0]']         \n",
      "                                                                                                  \n",
      " dense_138 (Dense)              (None, 128)          11648       ['dropout_278[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_279 (Dropout)          (None, 128)          0           ['dense_138[0][0]']              \n",
      "                                                                                                  \n",
      " dense_139 (Dense)              (None, 1)            129         ['dropout_279[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1027 - accuracy: 0.9565 - val_loss: 0.0040 - val_accuracy: 0.9986\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 0.0073 - val_accuracy: 0.9981\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0113 - val_accuracy: 0.9981\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0032 - val_accuracy: 0.9998\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 0.0116 - val_accuracy: 0.9978\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0068 - val_accuracy: 0.9990\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0042 - val_accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0061 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0049 - val_accuracy: 0.9993\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_70\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_141 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_142 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_140 (TFOp  (None, 8, 45)       0           ['input_141[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_141 (TFOp  (None, 11, 45)      0           ['input_142[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_140 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_140[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_140[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_141 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_141[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_141[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_140 (Layer  (None, 8, 45)       90          ['multi_head_attention_140[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_141 (Layer  (None, 11, 45)      90          ['multi_head_attention_141[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_280 (Dropout)          (None, 8, 45)        0           ['layer_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " dropout_281 (Dropout)          (None, 11, 45)       0           ['layer_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_140 (  (None, 45)          0           ['dropout_280[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_141 (  (None, 45)          0           ['dropout_281[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_70 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_140[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_141[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_282 (Dropout)          (None, 90)           0           ['concatenate_70[0][0]']         \n",
      "                                                                                                  \n",
      " dense_140 (Dense)              (None, 128)          11648       ['dropout_282[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_283 (Dropout)          (None, 128)          0           ['dense_140[0][0]']              \n",
      "                                                                                                  \n",
      " dense_141 (Dense)              (None, 1)            129         ['dropout_283[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0935 - accuracy: 0.9644 - val_loss: 0.0475 - val_accuracy: 0.9888\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0157 - accuracy: 0.9970 - val_loss: 0.0422 - val_accuracy: 0.9888\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 0.0251 - val_accuracy: 0.9950\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0391 - val_accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0141 - accuracy: 0.9969 - val_loss: 0.0332 - val_accuracy: 0.9945\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0318 - val_accuracy: 0.9947\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0566 - val_accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0409 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0465 - val_accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0449 - val_accuracy: 0.9933\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_71\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_143 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_144 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_142 (TFOp  (None, 8, 45)       0           ['input_143[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_143 (TFOp  (None, 11, 45)      0           ['input_144[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_142 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_142[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_142[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_143 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_143[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_143[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_142 (Layer  (None, 8, 45)       90          ['multi_head_attention_142[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_143 (Layer  (None, 11, 45)      90          ['multi_head_attention_143[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_284 (Dropout)          (None, 8, 45)        0           ['layer_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " dropout_285 (Dropout)          (None, 11, 45)       0           ['layer_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_142 (  (None, 45)          0           ['dropout_284[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_143 (  (None, 45)          0           ['dropout_285[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_71 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_142[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_143[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_286 (Dropout)          (None, 90)           0           ['concatenate_71[0][0]']         \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 128)          11648       ['dropout_286[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_287 (Dropout)          (None, 128)          0           ['dense_142[0][0]']              \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 1)            129         ['dropout_287[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1661 - accuracy: 0.9414 - val_loss: 0.0302 - val_accuracy: 0.9914\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1003 - accuracy: 0.9757 - val_loss: 0.0312 - val_accuracy: 0.9914\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0954 - accuracy: 0.9772 - val_loss: 0.0368 - val_accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0901 - accuracy: 0.9763 - val_loss: 0.0334 - val_accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0881 - accuracy: 0.9776 - val_loss: 0.0378 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0862 - accuracy: 0.9779 - val_loss: 0.0287 - val_accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0824 - accuracy: 0.9780 - val_loss: 0.0304 - val_accuracy: 0.9924\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0807 - accuracy: 0.9793 - val_loss: 0.0223 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0769 - accuracy: 0.9789 - val_loss: 0.0354 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0744 - accuracy: 0.9801 - val_loss: 0.0416 - val_accuracy: 0.9919\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_72\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_145 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_146 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_144 (TFOp  (None, 8, 45)       0           ['input_145[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_145 (TFOp  (None, 11, 45)      0           ['input_146[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_144 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_144[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_144[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_145 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_145[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_145[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_144 (Layer  (None, 8, 45)       90          ['multi_head_attention_144[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_145 (Layer  (None, 11, 45)      90          ['multi_head_attention_145[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_288 (Dropout)          (None, 8, 45)        0           ['layer_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " dropout_289 (Dropout)          (None, 11, 45)       0           ['layer_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_144 (  (None, 45)          0           ['dropout_288[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_145 (  (None, 45)          0           ['dropout_289[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_72 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_144[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_145[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_290 (Dropout)          (None, 90)           0           ['concatenate_72[0][0]']         \n",
      "                                                                                                  \n",
      " dense_144 (Dense)              (None, 128)          11648       ['dropout_290[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_291 (Dropout)          (None, 128)          0           ['dense_144[0][0]']              \n",
      "                                                                                                  \n",
      " dense_145 (Dense)              (None, 1)            129         ['dropout_291[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2693 - accuracy: 0.8859 - val_loss: 0.1557 - val_accuracy: 0.9228\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1330 - accuracy: 0.9520 - val_loss: 0.0751 - val_accuracy: 0.9706\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1063 - accuracy: 0.9642 - val_loss: 0.0663 - val_accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0955 - accuracy: 0.9690 - val_loss: 0.0912 - val_accuracy: 0.9701\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0874 - accuracy: 0.9712 - val_loss: 0.0705 - val_accuracy: 0.9718\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0819 - accuracy: 0.9724 - val_loss: 0.0700 - val_accuracy: 0.9732\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0786 - accuracy: 0.9751 - val_loss: 0.0671 - val_accuracy: 0.9740\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0761 - accuracy: 0.9740 - val_loss: 0.0669 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0740 - accuracy: 0.9765 - val_loss: 0.0738 - val_accuracy: 0.9763\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0702 - accuracy: 0.9772 - val_loss: 0.0623 - val_accuracy: 0.9754\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 9 19931\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_73\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_147 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_148 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_146 (TFOp  (None, 8, 45)       0           ['input_147[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_147 (TFOp  (None, 11, 45)      0           ['input_148[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_146 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_146[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_146[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_147 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_147[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_147[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_146 (Layer  (None, 8, 45)       90          ['multi_head_attention_146[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_147 (Layer  (None, 11, 45)      90          ['multi_head_attention_147[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_292 (Dropout)          (None, 8, 45)        0           ['layer_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " dropout_293 (Dropout)          (None, 11, 45)       0           ['layer_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_146 (  (None, 45)          0           ['dropout_292[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_147 (  (None, 45)          0           ['dropout_293[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_73 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_146[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_147[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_294 (Dropout)          (None, 90)           0           ['concatenate_73[0][0]']         \n",
      "                                                                                                  \n",
      " dense_146 (Dense)              (None, 128)          11648       ['dropout_294[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_295 (Dropout)          (None, 128)          0           ['dense_146[0][0]']              \n",
      "                                                                                                  \n",
      " dense_147 (Dense)              (None, 1)            129         ['dropout_295[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2291 - accuracy: 0.9001 - val_loss: 0.0670 - val_accuracy: 0.9790\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0750 - accuracy: 0.9750 - val_loss: 0.0544 - val_accuracy: 0.9811\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0521 - accuracy: 0.9822 - val_loss: 0.0243 - val_accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0450 - accuracy: 0.9850 - val_loss: 0.0323 - val_accuracy: 0.9871\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.0163 - val_accuracy: 0.9947\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0258 - val_accuracy: 0.9895\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.0304 - val_accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0135 - val_accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0404 - val_accuracy: 0.9830\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 0.0211 - val_accuracy: 0.9940\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_74\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_149 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_150 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_148 (TFOp  (None, 8, 45)       0           ['input_149[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_149 (TFOp  (None, 11, 45)      0           ['input_150[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_148 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_148[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_148[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_149 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_149[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_149[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_148 (Layer  (None, 8, 45)       90          ['multi_head_attention_148[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_149 (Layer  (None, 11, 45)      90          ['multi_head_attention_149[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_296 (Dropout)          (None, 8, 45)        0           ['layer_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " dropout_297 (Dropout)          (None, 11, 45)       0           ['layer_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_148 (  (None, 45)          0           ['dropout_296[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_149 (  (None, 45)          0           ['dropout_297[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_74 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_148[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_149[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_298 (Dropout)          (None, 90)           0           ['concatenate_74[0][0]']         \n",
      "                                                                                                  \n",
      " dense_148 (Dense)              (None, 128)          11648       ['dropout_298[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_299 (Dropout)          (None, 128)          0           ['dense_148[0][0]']              \n",
      "                                                                                                  \n",
      " dense_149 (Dense)              (None, 1)            129         ['dropout_299[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2657 - accuracy: 0.8734 - val_loss: 0.0698 - val_accuracy: 0.9694\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1341 - accuracy: 0.9431 - val_loss: 0.0806 - val_accuracy: 0.9677\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1199 - accuracy: 0.9501 - val_loss: 0.0747 - val_accuracy: 0.9730\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1060 - accuracy: 0.9562 - val_loss: 0.0781 - val_accuracy: 0.9687\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0996 - accuracy: 0.9587 - val_loss: 0.0565 - val_accuracy: 0.9792\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0954 - accuracy: 0.9615 - val_loss: 0.0744 - val_accuracy: 0.9697\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0869 - accuracy: 0.9639 - val_loss: 0.0281 - val_accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0866 - accuracy: 0.9637 - val_loss: 0.0656 - val_accuracy: 0.9778\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0818 - accuracy: 0.9672 - val_loss: 0.0625 - val_accuracy: 0.9730\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0786 - accuracy: 0.9681 - val_loss: 0.0934 - val_accuracy: 0.9630\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_75\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_151 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_152 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_150 (TFOp  (None, 8, 45)       0           ['input_151[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_151 (TFOp  (None, 11, 45)      0           ['input_152[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_150 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_150[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_150[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_151 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_151[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_151[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_150 (Layer  (None, 8, 45)       90          ['multi_head_attention_150[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_151 (Layer  (None, 11, 45)      90          ['multi_head_attention_151[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_300 (Dropout)          (None, 8, 45)        0           ['layer_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " dropout_301 (Dropout)          (None, 11, 45)       0           ['layer_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_150 (  (None, 45)          0           ['dropout_300[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_151 (  (None, 45)          0           ['dropout_301[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_75 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_150[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_151[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_302 (Dropout)          (None, 90)           0           ['concatenate_75[0][0]']         \n",
      "                                                                                                  \n",
      " dense_150 (Dense)              (None, 128)          11648       ['dropout_302[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_303 (Dropout)          (None, 128)          0           ['dense_150[0][0]']              \n",
      "                                                                                                  \n",
      " dense_151 (Dense)              (None, 1)            129         ['dropout_303[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2101 - accuracy: 0.9218 - val_loss: 0.0698 - val_accuracy: 0.9830\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1181 - accuracy: 0.9696 - val_loss: 0.0257 - val_accuracy: 0.9962\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1084 - accuracy: 0.9720 - val_loss: 0.0447 - val_accuracy: 0.9964\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1033 - accuracy: 0.9721 - val_loss: 0.1041 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0989 - accuracy: 0.9724 - val_loss: 0.0334 - val_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0937 - accuracy: 0.9734 - val_loss: 0.0696 - val_accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0914 - accuracy: 0.9735 - val_loss: 0.0217 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0906 - accuracy: 0.9737 - val_loss: 0.0358 - val_accuracy: 0.9969\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0871 - accuracy: 0.9740 - val_loss: 0.0334 - val_accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0855 - accuracy: 0.9734 - val_loss: 0.0460 - val_accuracy: 0.9962\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_76\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_153 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_154 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_152 (TFOp  (None, 8, 45)       0           ['input_153[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_153 (TFOp  (None, 11, 45)      0           ['input_154[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_152 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_152[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_152[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_153 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_153[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_153[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_152 (Layer  (None, 8, 45)       90          ['multi_head_attention_152[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_153 (Layer  (None, 11, 45)      90          ['multi_head_attention_153[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_304 (Dropout)          (None, 8, 45)        0           ['layer_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " dropout_305 (Dropout)          (None, 11, 45)       0           ['layer_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_152 (  (None, 45)          0           ['dropout_304[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_153 (  (None, 45)          0           ['dropout_305[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_76 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_152[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_153[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_306 (Dropout)          (None, 90)           0           ['concatenate_76[0][0]']         \n",
      "                                                                                                  \n",
      " dense_152 (Dense)              (None, 128)          11648       ['dropout_306[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_307 (Dropout)          (None, 128)          0           ['dense_152[0][0]']              \n",
      "                                                                                                  \n",
      " dense_153 (Dense)              (None, 1)            129         ['dropout_307[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1665 - accuracy: 0.9281 - val_loss: 0.0651 - val_accuracy: 0.9713\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0614 - accuracy: 0.9823 - val_loss: 0.0649 - val_accuracy: 0.9797\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.0429 - val_accuracy: 0.9876\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.0571 - val_accuracy: 0.9845\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.0474 - val_accuracy: 0.9869\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.1149 - val_accuracy: 0.9723\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.0478 - val_accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 0.0468 - val_accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 0.0322 - val_accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0265 - accuracy: 0.9907 - val_loss: 0.0411 - val_accuracy: 0.9895\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_77\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_155 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_156 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_154 (TFOp  (None, 8, 45)       0           ['input_155[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_155 (TFOp  (None, 11, 45)      0           ['input_156[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_154 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_154[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_154[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_155 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_155[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_155[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_154 (Layer  (None, 8, 45)       90          ['multi_head_attention_154[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_155 (Layer  (None, 11, 45)      90          ['multi_head_attention_155[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_308 (Dropout)          (None, 8, 45)        0           ['layer_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " dropout_309 (Dropout)          (None, 11, 45)       0           ['layer_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_154 (  (None, 45)          0           ['dropout_308[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_155 (  (None, 45)          0           ['dropout_309[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_77 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_154[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_155[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_310 (Dropout)          (None, 90)           0           ['concatenate_77[0][0]']         \n",
      "                                                                                                  \n",
      " dense_154 (Dense)              (None, 128)          11648       ['dropout_310[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_311 (Dropout)          (None, 128)          0           ['dense_154[0][0]']              \n",
      "                                                                                                  \n",
      " dense_155 (Dense)              (None, 1)            129         ['dropout_311[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0894 - accuracy: 0.9643 - val_loss: 0.0322 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0139 - accuracy: 0.9966 - val_loss: 0.0070 - val_accuracy: 0.9978\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0126 - val_accuracy: 0.9974\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.0123 - val_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0102 - val_accuracy: 0.9986\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0109 - accuracy: 0.9976 - val_loss: 0.0081 - val_accuracy: 0.9986\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.0057 - val_accuracy: 0.9986\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0036 - val_accuracy: 0.9986\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0069 - val_accuracy: 0.9986\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0141 - val_accuracy: 0.9983\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_78\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_157 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_158 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_156 (TFOp  (None, 8, 45)       0           ['input_157[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_157 (TFOp  (None, 11, 45)      0           ['input_158[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_156 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_156[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_156[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_157 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_157[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_157[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_156 (Layer  (None, 8, 45)       90          ['multi_head_attention_156[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_157 (Layer  (None, 11, 45)      90          ['multi_head_attention_157[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_312 (Dropout)          (None, 8, 45)        0           ['layer_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " dropout_313 (Dropout)          (None, 11, 45)       0           ['layer_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_156 (  (None, 45)          0           ['dropout_312[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_157 (  (None, 45)          0           ['dropout_313[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_78 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_156[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_157[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_314 (Dropout)          (None, 90)           0           ['concatenate_78[0][0]']         \n",
      "                                                                                                  \n",
      " dense_156 (Dense)              (None, 128)          11648       ['dropout_314[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_315 (Dropout)          (None, 128)          0           ['dense_156[0][0]']              \n",
      "                                                                                                  \n",
      " dense_157 (Dense)              (None, 1)            129         ['dropout_315[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0955 - accuracy: 0.9639 - val_loss: 0.0165 - val_accuracy: 0.9938\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0216 - accuracy: 0.9962 - val_loss: 0.0029 - val_accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0184 - accuracy: 0.9959 - val_loss: 0.0042 - val_accuracy: 0.9986\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0161 - accuracy: 0.9967 - val_loss: 0.0033 - val_accuracy: 0.9986\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.0054 - val_accuracy: 0.9978\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0121 - accuracy: 0.9976 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.0032 - val_accuracy: 0.9986\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.0094 - val_accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0019 - val_accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0064 - val_accuracy: 0.9990\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_79\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_159 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_160 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_158 (TFOp  (None, 8, 45)       0           ['input_159[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_159 (TFOp  (None, 11, 45)      0           ['input_160[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_158 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_158[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_158[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_159 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_159[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_159[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_158 (Layer  (None, 8, 45)       90          ['multi_head_attention_158[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_159 (Layer  (None, 11, 45)      90          ['multi_head_attention_159[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_316 (Dropout)          (None, 8, 45)        0           ['layer_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " dropout_317 (Dropout)          (None, 11, 45)       0           ['layer_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_158 (  (None, 45)          0           ['dropout_316[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_159 (  (None, 45)          0           ['dropout_317[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_79 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_158[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_159[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_318 (Dropout)          (None, 90)           0           ['concatenate_79[0][0]']         \n",
      "                                                                                                  \n",
      " dense_158 (Dense)              (None, 128)          11648       ['dropout_318[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_319 (Dropout)          (None, 128)          0           ['dense_158[0][0]']              \n",
      "                                                                                                  \n",
      " dense_159 (Dense)              (None, 1)            129         ['dropout_319[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1662 - accuracy: 0.9435 - val_loss: 0.0377 - val_accuracy: 0.9890\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1062 - accuracy: 0.9737 - val_loss: 0.0313 - val_accuracy: 0.9919\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1012 - accuracy: 0.9742 - val_loss: 0.0376 - val_accuracy: 0.9912\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0937 - accuracy: 0.9754 - val_loss: 0.0184 - val_accuracy: 0.9962\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0938 - accuracy: 0.9749 - val_loss: 0.0204 - val_accuracy: 0.9974\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0918 - accuracy: 0.9756 - val_loss: 0.0284 - val_accuracy: 0.9962\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0883 - accuracy: 0.9761 - val_loss: 0.0287 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0873 - accuracy: 0.9766 - val_loss: 0.0175 - val_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0845 - accuracy: 0.9767 - val_loss: 0.0212 - val_accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0796 - accuracy: 0.9779 - val_loss: 0.0201 - val_accuracy: 0.9976\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_80\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_161 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_162 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_160 (TFOp  (None, 8, 45)       0           ['input_161[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_161 (TFOp  (None, 11, 45)      0           ['input_162[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_160 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_160[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_160[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_161 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_161[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_161[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_160 (Layer  (None, 8, 45)       90          ['multi_head_attention_160[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_161 (Layer  (None, 11, 45)      90          ['multi_head_attention_161[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_320 (Dropout)          (None, 8, 45)        0           ['layer_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " dropout_321 (Dropout)          (None, 11, 45)       0           ['layer_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_160 (  (None, 45)          0           ['dropout_320[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_161 (  (None, 45)          0           ['dropout_321[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_80 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_160[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_161[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_322 (Dropout)          (None, 90)           0           ['concatenate_80[0][0]']         \n",
      "                                                                                                  \n",
      " dense_160 (Dense)              (None, 128)          11648       ['dropout_322[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_323 (Dropout)          (None, 128)          0           ['dense_160[0][0]']              \n",
      "                                                                                                  \n",
      " dense_161 (Dense)              (None, 1)            129         ['dropout_323[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 11ms/step - loss: 0.2549 - accuracy: 0.8966 - val_loss: 0.0943 - val_accuracy: 0.9362\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1347 - accuracy: 0.9525 - val_loss: 0.0869 - val_accuracy: 0.9642\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.1074 - accuracy: 0.9628 - val_loss: 0.0717 - val_accuracy: 0.9704\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0988 - accuracy: 0.9668 - val_loss: 0.0766 - val_accuracy: 0.9720\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0882 - accuracy: 0.9697 - val_loss: 0.0716 - val_accuracy: 0.9713\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0837 - accuracy: 0.9729 - val_loss: 0.0558 - val_accuracy: 0.9816\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0802 - accuracy: 0.9738 - val_loss: 0.0493 - val_accuracy: 0.9816\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0767 - accuracy: 0.9742 - val_loss: 0.0748 - val_accuracy: 0.9716\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0736 - accuracy: 0.9757 - val_loss: 0.0531 - val_accuracy: 0.9797\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0681 - accuracy: 0.9771 - val_loss: 0.0799 - val_accuracy: 0.9740\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 10 19932\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_81\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_163 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_164 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_162 (TFOp  (None, 8, 45)       0           ['input_163[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_163 (TFOp  (None, 11, 45)      0           ['input_164[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_162 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_162[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_162[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_163 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_163[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_163[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_162 (Layer  (None, 8, 45)       90          ['multi_head_attention_162[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_163 (Layer  (None, 11, 45)      90          ['multi_head_attention_163[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_324 (Dropout)          (None, 8, 45)        0           ['layer_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " dropout_325 (Dropout)          (None, 11, 45)       0           ['layer_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_162 (  (None, 45)          0           ['dropout_324[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_163 (  (None, 45)          0           ['dropout_325[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_81 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_162[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_163[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_326 (Dropout)          (None, 90)           0           ['concatenate_81[0][0]']         \n",
      "                                                                                                  \n",
      " dense_162 (Dense)              (None, 128)          11648       ['dropout_326[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_327 (Dropout)          (None, 128)          0           ['dense_162[0][0]']              \n",
      "                                                                                                  \n",
      " dense_163 (Dense)              (None, 1)            129         ['dropout_327[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1895 - accuracy: 0.9174 - val_loss: 0.0662 - val_accuracy: 0.9838\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0675 - accuracy: 0.9789 - val_loss: 0.0517 - val_accuracy: 0.9842\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0471 - accuracy: 0.9842 - val_loss: 0.0493 - val_accuracy: 0.9818\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.0285 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.0444 - val_accuracy: 0.9823\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.0345 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 0.0415 - val_accuracy: 0.9859\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0170 - val_accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0284 - accuracy: 0.9901 - val_loss: 0.0235 - val_accuracy: 0.9921\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.0282 - val_accuracy: 0.9897\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_165 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_166 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_164 (TFOp  (None, 8, 45)       0           ['input_165[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_165 (TFOp  (None, 11, 45)      0           ['input_166[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_164 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_164[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_164[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_165 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_165[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_165[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_164 (Layer  (None, 8, 45)       90          ['multi_head_attention_164[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_165 (Layer  (None, 11, 45)      90          ['multi_head_attention_165[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_328 (Dropout)          (None, 8, 45)        0           ['layer_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " dropout_329 (Dropout)          (None, 11, 45)       0           ['layer_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_164 (  (None, 45)          0           ['dropout_328[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_165 (  (None, 45)          0           ['dropout_329[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_82 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_164[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_165[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_330 (Dropout)          (None, 90)           0           ['concatenate_82[0][0]']         \n",
      "                                                                                                  \n",
      " dense_164 (Dense)              (None, 128)          11648       ['dropout_330[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_331 (Dropout)          (None, 128)          0           ['dense_164[0][0]']              \n",
      "                                                                                                  \n",
      " dense_165 (Dense)              (None, 1)            129         ['dropout_331[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2685 - accuracy: 0.8708 - val_loss: 0.1145 - val_accuracy: 0.9381\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1348 - accuracy: 0.9392 - val_loss: 0.0719 - val_accuracy: 0.9811\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1107 - accuracy: 0.9516 - val_loss: 0.0765 - val_accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1031 - accuracy: 0.9570 - val_loss: 0.0670 - val_accuracy: 0.9792\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0936 - accuracy: 0.9615 - val_loss: 0.1033 - val_accuracy: 0.9462\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0915 - accuracy: 0.9627 - val_loss: 0.0706 - val_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0870 - accuracy: 0.9641 - val_loss: 0.0525 - val_accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0830 - accuracy: 0.9657 - val_loss: 0.0722 - val_accuracy: 0.9725\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0771 - accuracy: 0.9682 - val_loss: 0.0580 - val_accuracy: 0.9811\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0765 - accuracy: 0.9696 - val_loss: 0.0917 - val_accuracy: 0.9618\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_83\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_167 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_168 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_166 (TFOp  (None, 8, 45)       0           ['input_167[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_167 (TFOp  (None, 11, 45)      0           ['input_168[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_166 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_166[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_166[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_167 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_167[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_167[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_166 (Layer  (None, 8, 45)       90          ['multi_head_attention_166[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_167 (Layer  (None, 11, 45)      90          ['multi_head_attention_167[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_332 (Dropout)          (None, 8, 45)        0           ['layer_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " dropout_333 (Dropout)          (None, 11, 45)       0           ['layer_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_166 (  (None, 45)          0           ['dropout_332[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_167 (  (None, 45)          0           ['dropout_333[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_83 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_166[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_167[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_334 (Dropout)          (None, 90)           0           ['concatenate_83[0][0]']         \n",
      "                                                                                                  \n",
      " dense_166 (Dense)              (None, 128)          11648       ['dropout_334[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_335 (Dropout)          (None, 128)          0           ['dense_166[0][0]']              \n",
      "                                                                                                  \n",
      " dense_167 (Dense)              (None, 1)            129         ['dropout_335[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2001 - accuracy: 0.9310 - val_loss: 0.0257 - val_accuracy: 0.9976\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1172 - accuracy: 0.9708 - val_loss: 0.0437 - val_accuracy: 0.9988\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.1095 - accuracy: 0.9718 - val_loss: 0.0258 - val_accuracy: 0.9986\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1076 - accuracy: 0.9719 - val_loss: 0.0450 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1020 - accuracy: 0.9733 - val_loss: 0.0247 - val_accuracy: 0.9976\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0974 - accuracy: 0.9732 - val_loss: 0.0357 - val_accuracy: 0.9971\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0964 - accuracy: 0.9733 - val_loss: 0.0346 - val_accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0892 - accuracy: 0.9737 - val_loss: 0.0383 - val_accuracy: 0.9981\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0822 - accuracy: 0.9731 - val_loss: 0.0239 - val_accuracy: 0.9967\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0745 - accuracy: 0.9750 - val_loss: 0.0209 - val_accuracy: 0.9974\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_84\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_169 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_170 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_168 (TFOp  (None, 8, 45)       0           ['input_169[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_169 (TFOp  (None, 11, 45)      0           ['input_170[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_168 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_168[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_168[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_169 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_169[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_169[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_168 (Layer  (None, 8, 45)       90          ['multi_head_attention_168[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_169 (Layer  (None, 11, 45)      90          ['multi_head_attention_169[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_336 (Dropout)          (None, 8, 45)        0           ['layer_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " dropout_337 (Dropout)          (None, 11, 45)       0           ['layer_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_168 (  (None, 45)          0           ['dropout_336[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_169 (  (None, 45)          0           ['dropout_337[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_84 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_168[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_169[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_338 (Dropout)          (None, 90)           0           ['concatenate_84[0][0]']         \n",
      "                                                                                                  \n",
      " dense_168 (Dense)              (None, 128)          11648       ['dropout_338[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_339 (Dropout)          (None, 128)          0           ['dense_168[0][0]']              \n",
      "                                                                                                  \n",
      " dense_169 (Dense)              (None, 1)            129         ['dropout_339[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1958 - accuracy: 0.9141 - val_loss: 0.0518 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0658 - accuracy: 0.9790 - val_loss: 0.0272 - val_accuracy: 0.9933\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0553 - accuracy: 0.9830 - val_loss: 0.0296 - val_accuracy: 0.9921\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0465 - accuracy: 0.9845 - val_loss: 0.0296 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0433 - accuracy: 0.9853 - val_loss: 0.0118 - val_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.0152 - val_accuracy: 0.9947\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0335 - accuracy: 0.9895 - val_loss: 0.0184 - val_accuracy: 0.9924\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0337 - accuracy: 0.9899 - val_loss: 0.0393 - val_accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.0211 - val_accuracy: 0.9924\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0303 - accuracy: 0.9901 - val_loss: 0.0210 - val_accuracy: 0.9890\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_85\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_171 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_172 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_170 (TFOp  (None, 8, 45)       0           ['input_171[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_171 (TFOp  (None, 11, 45)      0           ['input_172[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_170 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_170[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_170[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_171 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_171[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_171[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_170 (Layer  (None, 8, 45)       90          ['multi_head_attention_170[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_171 (Layer  (None, 11, 45)      90          ['multi_head_attention_171[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_340 (Dropout)          (None, 8, 45)        0           ['layer_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " dropout_341 (Dropout)          (None, 11, 45)       0           ['layer_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_170 (  (None, 45)          0           ['dropout_340[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_171 (  (None, 45)          0           ['dropout_341[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_85 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_170[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_171[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_342 (Dropout)          (None, 90)           0           ['concatenate_85[0][0]']         \n",
      "                                                                                                  \n",
      " dense_170 (Dense)              (None, 128)          11648       ['dropout_342[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_343 (Dropout)          (None, 128)          0           ['dense_170[0][0]']              \n",
      "                                                                                                  \n",
      " dense_171 (Dense)              (None, 1)            129         ['dropout_343[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0777 - accuracy: 0.9682 - val_loss: 0.0470 - val_accuracy: 0.9892\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.0583 - val_accuracy: 0.9912\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0678 - val_accuracy: 0.9935\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.0816 - val_accuracy: 0.9938\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0937 - val_accuracy: 0.9940\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.0637 - val_accuracy: 0.9940\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.2127 - val_accuracy: 0.9689\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0722 - val_accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0815 - val_accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0772 - val_accuracy: 0.9950\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_86\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_173 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_174 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_172 (TFOp  (None, 8, 45)       0           ['input_173[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_173 (TFOp  (None, 11, 45)      0           ['input_174[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_172 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_172[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_172[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_173 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_173[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_173[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_172 (Layer  (None, 8, 45)       90          ['multi_head_attention_172[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_173 (Layer  (None, 11, 45)      90          ['multi_head_attention_173[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_344 (Dropout)          (None, 8, 45)        0           ['layer_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " dropout_345 (Dropout)          (None, 11, 45)       0           ['layer_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_172 (  (None, 45)          0           ['dropout_344[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_173 (  (None, 45)          0           ['dropout_345[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_86 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_172[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_173[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_346 (Dropout)          (None, 90)           0           ['concatenate_86[0][0]']         \n",
      "                                                                                                  \n",
      " dense_172 (Dense)              (None, 128)          11648       ['dropout_346[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_347 (Dropout)          (None, 128)          0           ['dense_172[0][0]']              \n",
      "                                                                                                  \n",
      " dense_173 (Dense)              (None, 1)            129         ['dropout_347[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0990 - accuracy: 0.9630 - val_loss: 0.0222 - val_accuracy: 0.9935\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0210 - accuracy: 0.9955 - val_loss: 0.0223 - val_accuracy: 0.9947\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0185 - accuracy: 0.9961 - val_loss: 0.0135 - val_accuracy: 0.9967\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.0124 - val_accuracy: 0.9952\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.0080 - val_accuracy: 0.9971\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0131 - accuracy: 0.9977 - val_loss: 4.0452e-04 - val_accuracy: 0.9998\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.0218 - val_accuracy: 0.9938\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.0206 - val_accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.0038 - val_accuracy: 0.9978\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_87\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_175 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_176 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_174 (TFOp  (None, 8, 45)       0           ['input_175[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_175 (TFOp  (None, 11, 45)      0           ['input_176[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_174 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_174[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_174[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_175 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_175[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_175[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_174 (Layer  (None, 8, 45)       90          ['multi_head_attention_174[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_175 (Layer  (None, 11, 45)      90          ['multi_head_attention_175[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_348 (Dropout)          (None, 8, 45)        0           ['layer_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " dropout_349 (Dropout)          (None, 11, 45)       0           ['layer_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_174 (  (None, 45)          0           ['dropout_348[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_175 (  (None, 45)          0           ['dropout_349[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_87 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_174[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_175[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_350 (Dropout)          (None, 90)           0           ['concatenate_87[0][0]']         \n",
      "                                                                                                  \n",
      " dense_174 (Dense)              (None, 128)          11648       ['dropout_350[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_351 (Dropout)          (None, 128)          0           ['dense_174[0][0]']              \n",
      "                                                                                                  \n",
      " dense_175 (Dense)              (None, 1)            129         ['dropout_351[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1690 - accuracy: 0.9381 - val_loss: 0.0489 - val_accuracy: 0.9852\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1011 - accuracy: 0.9747 - val_loss: 0.0484 - val_accuracy: 0.9869\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0960 - accuracy: 0.9762 - val_loss: 0.0522 - val_accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0917 - accuracy: 0.9767 - val_loss: 0.0528 - val_accuracy: 0.9864\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0867 - accuracy: 0.9769 - val_loss: 0.0457 - val_accuracy: 0.9878\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0806 - accuracy: 0.9779 - val_loss: 0.0421 - val_accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0774 - accuracy: 0.9783 - val_loss: 0.0561 - val_accuracy: 0.9833\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0761 - accuracy: 0.9781 - val_loss: 0.0440 - val_accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0701 - accuracy: 0.9788 - val_loss: 0.0508 - val_accuracy: 0.9888\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0688 - accuracy: 0.9795 - val_loss: 0.0546 - val_accuracy: 0.9881\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_88\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_177 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_178 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_176 (TFOp  (None, 8, 45)       0           ['input_177[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_177 (TFOp  (None, 11, 45)      0           ['input_178[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_176 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_176[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_176[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_177 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_177[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_177[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_176 (Layer  (None, 8, 45)       90          ['multi_head_attention_176[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_177 (Layer  (None, 11, 45)      90          ['multi_head_attention_177[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_352 (Dropout)          (None, 8, 45)        0           ['layer_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " dropout_353 (Dropout)          (None, 11, 45)       0           ['layer_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_176 (  (None, 45)          0           ['dropout_352[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_177 (  (None, 45)          0           ['dropout_353[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_88 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_176[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_177[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_354 (Dropout)          (None, 90)           0           ['concatenate_88[0][0]']         \n",
      "                                                                                                  \n",
      " dense_176 (Dense)              (None, 128)          11648       ['dropout_354[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_355 (Dropout)          (None, 128)          0           ['dense_176[0][0]']              \n",
      "                                                                                                  \n",
      " dense_177 (Dense)              (None, 1)            129         ['dropout_355[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2623 - accuracy: 0.8897 - val_loss: 0.1348 - val_accuracy: 0.9197\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1305 - accuracy: 0.9529 - val_loss: 0.1128 - val_accuracy: 0.9517\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1048 - accuracy: 0.9639 - val_loss: 0.0786 - val_accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0915 - accuracy: 0.9688 - val_loss: 0.1017 - val_accuracy: 0.9649\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0887 - accuracy: 0.9706 - val_loss: 0.0971 - val_accuracy: 0.9682\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0804 - accuracy: 0.9725 - val_loss: 0.0778 - val_accuracy: 0.9699\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0801 - accuracy: 0.9730 - val_loss: 0.0638 - val_accuracy: 0.9723\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0740 - accuracy: 0.9750 - val_loss: 0.0715 - val_accuracy: 0.9713\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0707 - accuracy: 0.9770 - val_loss: 0.0879 - val_accuracy: 0.9680\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0679 - accuracy: 0.9775 - val_loss: 0.0861 - val_accuracy: 0.9713\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "\t 11 19933\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN toileting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_89\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_179 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_180 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_178 (TFOp  (None, 8, 45)       0           ['input_179[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_179 (TFOp  (None, 11, 45)      0           ['input_180[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_178 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_178[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_178[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_179 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_179[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_179[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_178 (Layer  (None, 8, 45)       90          ['multi_head_attention_178[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_179 (Layer  (None, 11, 45)      90          ['multi_head_attention_179[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_356 (Dropout)          (None, 8, 45)        0           ['layer_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " dropout_357 (Dropout)          (None, 11, 45)       0           ['layer_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_178 (  (None, 45)          0           ['dropout_356[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_179 (  (None, 45)          0           ['dropout_357[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_89 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_178[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_179[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_358 (Dropout)          (None, 90)           0           ['concatenate_89[0][0]']         \n",
      "                                                                                                  \n",
      " dense_178 (Dense)              (None, 128)          11648       ['dropout_358[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_359 (Dropout)          (None, 128)          0           ['dense_178[0][0]']              \n",
      "                                                                                                  \n",
      " dense_179 (Dense)              (None, 1)            129         ['dropout_359[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 12ms/step - loss: 0.2076 - accuracy: 0.9089 - val_loss: 0.0572 - val_accuracy: 0.9833\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0690 - accuracy: 0.9759 - val_loss: 0.0409 - val_accuracy: 0.9842\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0503 - accuracy: 0.9829 - val_loss: 0.0325 - val_accuracy: 0.9859\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0373 - accuracy: 0.9876 - val_loss: 0.0260 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0374 - accuracy: 0.9880 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0319 - accuracy: 0.9888 - val_loss: 0.0174 - val_accuracy: 0.9940\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.0421 - val_accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.0380 - val_accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.0411 - val_accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 0.0238 - val_accuracy: 0.9892\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN resting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_90\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_181 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_182 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_180 (TFOp  (None, 8, 45)       0           ['input_181[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_181 (TFOp  (None, 11, 45)      0           ['input_182[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_180 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_180[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_180[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_181 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_181[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_181[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_180 (Layer  (None, 8, 45)       90          ['multi_head_attention_180[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_181 (Layer  (None, 11, 45)      90          ['multi_head_attention_181[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_360 (Dropout)          (None, 8, 45)        0           ['layer_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " dropout_361 (Dropout)          (None, 11, 45)       0           ['layer_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_180 (  (None, 45)          0           ['dropout_360[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_181 (  (None, 45)          0           ['dropout_361[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_90 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_180[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_181[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_362 (Dropout)          (None, 90)           0           ['concatenate_90[0][0]']         \n",
      "                                                                                                  \n",
      " dense_180 (Dense)              (None, 128)          11648       ['dropout_362[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_363 (Dropout)          (None, 128)          0           ['dense_180[0][0]']              \n",
      "                                                                                                  \n",
      " dense_181 (Dense)              (None, 1)            129         ['dropout_363[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2586 - accuracy: 0.8803 - val_loss: 0.1551 - val_accuracy: 0.9080\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1379 - accuracy: 0.9431 - val_loss: 0.1764 - val_accuracy: 0.8855\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1230 - accuracy: 0.9498 - val_loss: 0.1335 - val_accuracy: 0.9240\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1103 - accuracy: 0.9538 - val_loss: 0.1127 - val_accuracy: 0.9563\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1015 - accuracy: 0.9583 - val_loss: 0.1077 - val_accuracy: 0.9575\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0947 - accuracy: 0.9623 - val_loss: 0.1240 - val_accuracy: 0.9556\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0913 - accuracy: 0.9625 - val_loss: 0.1373 - val_accuracy: 0.9302\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0860 - accuracy: 0.9660 - val_loss: 0.0871 - val_accuracy: 0.9795\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0816 - accuracy: 0.9673 - val_loss: 0.0886 - val_accuracy: 0.9775\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0776 - accuracy: 0.9686 - val_loss: 0.0802 - val_accuracy: 0.9775\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN exit 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_91\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_183 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_184 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_182 (TFOp  (None, 8, 45)       0           ['input_183[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_183 (TFOp  (None, 11, 45)      0           ['input_184[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_182 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_182[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_182[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_183 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_183[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_183[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_182 (Layer  (None, 8, 45)       90          ['multi_head_attention_182[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_183 (Layer  (None, 11, 45)      90          ['multi_head_attention_183[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_364 (Dropout)          (None, 8, 45)        0           ['layer_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " dropout_365 (Dropout)          (None, 11, 45)       0           ['layer_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_182 (  (None, 45)          0           ['dropout_364[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_183 (  (None, 45)          0           ['dropout_365[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_91 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_182[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_183[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_366 (Dropout)          (None, 90)           0           ['concatenate_91[0][0]']         \n",
      "                                                                                                  \n",
      " dense_182 (Dense)              (None, 128)          11648       ['dropout_366[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_367 (Dropout)          (None, 128)          0           ['dense_182[0][0]']              \n",
      "                                                                                                  \n",
      " dense_183 (Dense)              (None, 1)            129         ['dropout_367[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2016 - accuracy: 0.9276 - val_loss: 0.0791 - val_accuracy: 0.9885\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.1151 - accuracy: 0.9719 - val_loss: 0.0595 - val_accuracy: 0.9897\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1065 - accuracy: 0.9732 - val_loss: 0.0698 - val_accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1001 - accuracy: 0.9746 - val_loss: 0.0606 - val_accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.0941 - accuracy: 0.9753 - val_loss: 0.0598 - val_accuracy: 0.9890\n",
      "Epoch 6/10\n",
      "247/938 [======>.......................] - ETA: 6s - loss: 0.0963 - accuracy: 0.9729\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN sleep 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_95\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_191 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_192 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_190 (TFOp  (None, 8, 45)       0           ['input_191[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_191 (TFOp  (None, 11, 45)      0           ['input_192[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_190 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_190[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_190[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_191 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_191[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_191[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_190 (Layer  (None, 8, 45)       90          ['multi_head_attention_190[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_191 (Layer  (None, 11, 45)      90          ['multi_head_attention_191[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_380 (Dropout)          (None, 8, 45)        0           ['layer_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " dropout_381 (Dropout)          (None, 11, 45)       0           ['layer_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_190 (  (None, 45)          0           ['dropout_380[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_191 (  (None, 45)          0           ['dropout_381[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_95 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_190[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_191[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_382 (Dropout)          (None, 90)           0           ['concatenate_95[0][0]']         \n",
      "                                                                                                  \n",
      " dense_190 (Dense)              (None, 128)          11648       ['dropout_382[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_383 (Dropout)          (None, 128)          0           ['dense_190[0][0]']              \n",
      "                                                                                                  \n",
      " dense_191 (Dense)              (None, 1)            129         ['dropout_383[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1745 - accuracy: 0.9369 - val_loss: 0.0418 - val_accuracy: 0.9885\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1023 - accuracy: 0.9738 - val_loss: 0.0376 - val_accuracy: 0.9876\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0974 - accuracy: 0.9740 - val_loss: 0.0225 - val_accuracy: 0.9935\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0920 - accuracy: 0.9755 - val_loss: 0.0201 - val_accuracy: 0.9955\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0863 - accuracy: 0.9763 - val_loss: 0.0228 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0814 - accuracy: 0.9775 - val_loss: 0.0345 - val_accuracy: 0.9955\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0787 - accuracy: 0.9771 - val_loss: 0.0276 - val_accuracy: 0.9950\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0805 - accuracy: 0.9765 - val_loss: 0.0202 - val_accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0759 - accuracy: 0.9780 - val_loss: 0.0147 - val_accuracy: 0.9957\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0734 - accuracy: 0.9782 - val_loss: 0.0131 - val_accuracy: 0.9971\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_96\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_193 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_194 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_192 (TFOp  (None, 8, 45)       0           ['input_193[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_193 (TFOp  (None, 11, 45)      0           ['input_194[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_192 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_192[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_192[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_193 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_193[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_193[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_192 (Layer  (None, 8, 45)       90          ['multi_head_attention_192[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_193 (Layer  (None, 11, 45)      90          ['multi_head_attention_193[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_384 (Dropout)          (None, 8, 45)        0           ['layer_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " dropout_385 (Dropout)          (None, 11, 45)       0           ['layer_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_192 (  (None, 45)          0           ['dropout_384[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_193 (  (None, 45)          0           ['dropout_385[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_96 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_192[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_193[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_386 (Dropout)          (None, 90)           0           ['concatenate_96[0][0]']         \n",
      "                                                                                                  \n",
      " dense_192 (Dense)              (None, 128)          11648       ['dropout_386[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_387 (Dropout)          (None, 128)          0           ['dense_192[0][0]']              \n",
      "                                                                                                  \n",
      " dense_193 (Dense)              (None, 1)            129         ['dropout_387[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 12ms/step - loss: 0.2692 - accuracy: 0.8848 - val_loss: 0.0992 - val_accuracy: 0.9474\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1327 - accuracy: 0.9503 - val_loss: 0.0654 - val_accuracy: 0.9730\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1084 - accuracy: 0.9610 - val_loss: 0.0818 - val_accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0978 - accuracy: 0.9656 - val_loss: 0.0791 - val_accuracy: 0.9670\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0923 - accuracy: 0.9684 - val_loss: 0.0774 - val_accuracy: 0.9687\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0853 - accuracy: 0.9718 - val_loss: 0.0707 - val_accuracy: 0.9730\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0816 - accuracy: 0.9741 - val_loss: 0.0563 - val_accuracy: 0.9802\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0757 - accuracy: 0.9749 - val_loss: 0.0674 - val_accuracy: 0.9761\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0696 - accuracy: 0.9763 - val_loss: 0.0750 - val_accuracy: 0.9730\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0688 - accuracy: 0.9772 - val_loss: 0.0662 - val_accuracy: 0.9778\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 12 19934\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN toileting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_97\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_195 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_196 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_194 (TFOp  (None, 8, 45)       0           ['input_195[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_195 (TFOp  (None, 11, 45)      0           ['input_196[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_194 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_194[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_194[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_195 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_195[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_195[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_194 (Layer  (None, 8, 45)       90          ['multi_head_attention_194[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_195 (Layer  (None, 11, 45)      90          ['multi_head_attention_195[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_388 (Dropout)          (None, 8, 45)        0           ['layer_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " dropout_389 (Dropout)          (None, 11, 45)       0           ['layer_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_194 (  (None, 45)          0           ['dropout_388[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_195 (  (None, 45)          0           ['dropout_389[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_97 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_194[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_195[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_390 (Dropout)          (None, 90)           0           ['concatenate_97[0][0]']         \n",
      "                                                                                                  \n",
      " dense_194 (Dense)              (None, 128)          11648       ['dropout_390[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_391 (Dropout)          (None, 128)          0           ['dense_194[0][0]']              \n",
      "                                                                                                  \n",
      " dense_195 (Dense)              (None, 1)            129         ['dropout_391[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 12ms/step - loss: 0.2011 - accuracy: 0.9112 - val_loss: 0.1081 - val_accuracy: 0.9692\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0692 - accuracy: 0.9776 - val_loss: 0.0251 - val_accuracy: 0.9928\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0506 - accuracy: 0.9830 - val_loss: 0.0450 - val_accuracy: 0.9840\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0520 - val_accuracy: 0.9835\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0381 - accuracy: 0.9874 - val_loss: 0.0240 - val_accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0298 - accuracy: 0.9892 - val_loss: 0.0371 - val_accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.0224 - val_accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.0247 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.0197 - val_accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0213 - accuracy: 0.9923 - val_loss: 0.0267 - val_accuracy: 0.9947\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN resting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_98\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_197 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_198 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_196 (TFOp  (None, 8, 45)       0           ['input_197[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_197 (TFOp  (None, 11, 45)      0           ['input_198[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_196 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_196[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_196[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_197 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_197[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_197[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_196 (Layer  (None, 8, 45)       90          ['multi_head_attention_196[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_197 (Layer  (None, 11, 45)      90          ['multi_head_attention_197[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_392 (Dropout)          (None, 8, 45)        0           ['layer_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " dropout_393 (Dropout)          (None, 11, 45)       0           ['layer_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_196 (  (None, 45)          0           ['dropout_392[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_197 (  (None, 45)          0           ['dropout_393[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_98 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_196[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_197[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_394 (Dropout)          (None, 90)           0           ['concatenate_98[0][0]']         \n",
      "                                                                                                  \n",
      " dense_196 (Dense)              (None, 128)          11648       ['dropout_394[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_395 (Dropout)          (None, 128)          0           ['dense_196[0][0]']              \n",
      "                                                                                                  \n",
      " dense_197 (Dense)              (None, 1)            129         ['dropout_395[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2978 - accuracy: 0.8535 - val_loss: 0.1004 - val_accuracy: 0.9713\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1380 - accuracy: 0.9421 - val_loss: 0.0785 - val_accuracy: 0.9761\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1176 - accuracy: 0.9527 - val_loss: 0.0740 - val_accuracy: 0.9775\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1084 - accuracy: 0.9580 - val_loss: 0.1321 - val_accuracy: 0.9192\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1013 - accuracy: 0.9585 - val_loss: 0.0779 - val_accuracy: 0.9821\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0948 - accuracy: 0.9633 - val_loss: 0.0586 - val_accuracy: 0.9833\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0916 - accuracy: 0.9626 - val_loss: 0.0639 - val_accuracy: 0.9823\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0898 - accuracy: 0.9647 - val_loss: 0.0673 - val_accuracy: 0.9792\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0863 - accuracy: 0.9659 - val_loss: 0.0691 - val_accuracy: 0.9792\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0832 - accuracy: 0.9666 - val_loss: 0.0826 - val_accuracy: 0.9751\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN exit 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_99\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_199 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_200 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_198 (TFOp  (None, 8, 45)       0           ['input_199[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_199 (TFOp  (None, 11, 45)      0           ['input_200[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_198 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_198[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_198[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_199 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_199[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_199[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_198 (Layer  (None, 8, 45)       90          ['multi_head_attention_198[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_199 (Layer  (None, 11, 45)      90          ['multi_head_attention_199[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_396 (Dropout)          (None, 8, 45)        0           ['layer_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " dropout_397 (Dropout)          (None, 11, 45)       0           ['layer_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_198 (  (None, 45)          0           ['dropout_396[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_199 (  (None, 45)          0           ['dropout_397[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_99 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_198[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_199[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_398 (Dropout)          (None, 90)           0           ['concatenate_99[0][0]']         \n",
      "                                                                                                  \n",
      " dense_198 (Dense)              (None, 128)          11648       ['dropout_398[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_399 (Dropout)          (None, 128)          0           ['dense_198[0][0]']              \n",
      "                                                                                                  \n",
      " dense_199 (Dense)              (None, 1)            129         ['dropout_399[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2151 - accuracy: 0.9222 - val_loss: 0.0577 - val_accuracy: 0.9971\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 10ms/step - loss: 0.1254 - accuracy: 0.9702 - val_loss: 0.0524 - val_accuracy: 0.9967\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1115 - accuracy: 0.9716 - val_loss: 0.0447 - val_accuracy: 0.9935\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1018 - accuracy: 0.9737 - val_loss: 0.0252 - val_accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0998 - accuracy: 0.9734 - val_loss: 0.0226 - val_accuracy: 0.9962\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0925 - accuracy: 0.9748 - val_loss: 0.0333 - val_accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0887 - accuracy: 0.9751 - val_loss: 0.0387 - val_accuracy: 0.9959\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0872 - accuracy: 0.9743 - val_loss: 0.0270 - val_accuracy: 0.9990\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0769 - accuracy: 0.9750 - val_loss: 0.0176 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0735 - accuracy: 0.9757 - val_loss: 0.0187 - val_accuracy: 0.9964\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN cooking 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_100\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_201 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_202 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_200 (TFOp  (None, 8, 45)       0           ['input_201[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_201 (TFOp  (None, 11, 45)      0           ['input_202[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_200 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_200[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_200[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_201 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_201[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_201[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_200 (Layer  (None, 8, 45)       90          ['multi_head_attention_200[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_201 (Layer  (None, 11, 45)      90          ['multi_head_attention_201[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_400 (Dropout)          (None, 8, 45)        0           ['layer_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " dropout_401 (Dropout)          (None, 11, 45)       0           ['layer_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_200 (  (None, 45)          0           ['dropout_400[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_201 (  (None, 45)          0           ['dropout_401[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_100 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_200[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_201[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_402 (Dropout)          (None, 90)           0           ['concatenate_100[0][0]']        \n",
      "                                                                                                  \n",
      " dense_200 (Dense)              (None, 128)          11648       ['dropout_402[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_403 (Dropout)          (None, 128)          0           ['dense_200[0][0]']              \n",
      "                                                                                                  \n",
      " dense_201 (Dense)              (None, 1)            129         ['dropout_403[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 12ms/step - loss: 0.1732 - accuracy: 0.9274 - val_loss: 0.0387 - val_accuracy: 0.9866\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.0347 - val_accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0493 - accuracy: 0.9857 - val_loss: 0.0216 - val_accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.0234 - val_accuracy: 0.9931\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0416 - accuracy: 0.9879 - val_loss: 0.0233 - val_accuracy: 0.9916\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.0333 - val_accuracy: 0.9909\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.0293 - val_accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.0012 - val_accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 6.4281e-04 - val_accuracy: 0.9998\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN sleep 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_103\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_207 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_208 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_206 (TFOp  (None, 8, 45)       0           ['input_207[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_207 (TFOp  (None, 11, 45)      0           ['input_208[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_206 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_206[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_206[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_207 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_207[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_207[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_206 (Layer  (None, 8, 45)       90          ['multi_head_attention_206[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_207 (Layer  (None, 11, 45)      90          ['multi_head_attention_207[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_412 (Dropout)          (None, 8, 45)        0           ['layer_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " dropout_413 (Dropout)          (None, 11, 45)       0           ['layer_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_206 (  (None, 45)          0           ['dropout_412[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_207 (  (None, 45)          0           ['dropout_413[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_103 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_206[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_207[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_414 (Dropout)          (None, 90)           0           ['concatenate_103[0][0]']        \n",
      "                                                                                                  \n",
      " dense_206 (Dense)              (None, 128)          11648       ['dropout_414[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_415 (Dropout)          (None, 128)          0           ['dense_206[0][0]']              \n",
      "                                                                                                  \n",
      " dense_207 (Dense)              (None, 1)            129         ['dropout_415[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 14s 11ms/step - loss: 0.1717 - accuracy: 0.9371 - val_loss: 0.0400 - val_accuracy: 0.9945\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.1006 - accuracy: 0.9749 - val_loss: 0.0243 - val_accuracy: 0.9945\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0948 - accuracy: 0.9762 - val_loss: 0.0229 - val_accuracy: 0.9952\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0897 - accuracy: 0.9779 - val_loss: 0.0283 - val_accuracy: 0.9943\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0869 - accuracy: 0.9789 - val_loss: 0.0270 - val_accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0848 - accuracy: 0.9776 - val_loss: 0.0236 - val_accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "765/938 [=======================>......] - ETA: 1s - loss: 0.0844 - accuracy: 0.9787\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN kitchen 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_104\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_209 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_210 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_208 (TFOp  (None, 8, 45)       0           ['input_209[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_209 (TFOp  (None, 11, 45)      0           ['input_210[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_208 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_208[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_208[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_209 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_209[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_209[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_208 (Layer  (None, 8, 45)       90          ['multi_head_attention_208[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_209 (Layer  (None, 11, 45)      90          ['multi_head_attention_209[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_416 (Dropout)          (None, 8, 45)        0           ['layer_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " dropout_417 (Dropout)          (None, 11, 45)       0           ['layer_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_208 (  (None, 45)          0           ['dropout_416[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_209 (  (None, 45)          0           ['dropout_417[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_208[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_209[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_418 (Dropout)          (None, 90)           0           ['concatenate_104[0][0]']        \n",
      "                                                                                                  \n",
      " dense_208 (Dense)              (None, 128)          11648       ['dropout_418[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_419 (Dropout)          (None, 128)          0           ['dense_208[0][0]']              \n",
      "                                                                                                  \n",
      " dense_209 (Dense)              (None, 1)            129         ['dropout_419[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2660 - accuracy: 0.8891 - val_loss: 0.0900 - val_accuracy: 0.9546\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1322 - accuracy: 0.9518 - val_loss: 0.0791 - val_accuracy: 0.9651\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1079 - accuracy: 0.9629 - val_loss: 0.1279 - val_accuracy: 0.9570\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0991 - accuracy: 0.9663 - val_loss: 0.1338 - val_accuracy: 0.9405\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0919 - accuracy: 0.9688 - val_loss: 0.0649 - val_accuracy: 0.9742\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0850 - accuracy: 0.9705 - val_loss: 0.1111 - val_accuracy: 0.9673\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0786 - accuracy: 0.9741 - val_loss: 0.1166 - val_accuracy: 0.9613\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0754 - accuracy: 0.9744 - val_loss: 0.0942 - val_accuracy: 0.9756\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1917 - accuracy: 0.9207 - val_loss: 0.2029 - val_accuracy: 0.9467\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0736 - accuracy: 0.9754 - val_loss: 0.0638 - val_accuracy: 0.9795\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 0.0220 - val_accuracy: 0.9907\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.0329 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.0171 - val_accuracy: 0.9914\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 0.0306 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 0.0464 - val_accuracy: 0.9838\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 0.0359 - val_accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1014 - accuracy: 0.9588 - val_loss: 0.0844 - val_accuracy: 0.9751\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0927 - accuracy: 0.9622 - val_loss: 0.1030 - val_accuracy: 0.9587\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0895 - accuracy: 0.9642 - val_loss: 0.1294 - val_accuracy: 0.9524\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0860 - accuracy: 0.9666 - val_loss: 0.0923 - val_accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0836 - accuracy: 0.9673 - val_loss: 0.0817 - val_accuracy: 0.9725\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0799 - accuracy: 0.9685 - val_loss: 0.0993 - val_accuracy: 0.9615\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN exit 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_107\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_215 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_216 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_214 (TFOp  (None, 8, 45)       0           ['input_215[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_215 (TFOp  (None, 11, 45)      0           ['input_216[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_214 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_214[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_214[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_215 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_215[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_215[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_214 (Layer  (None, 8, 45)       90          ['multi_head_attention_214[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_215 (Layer  (None, 11, 45)      90          ['multi_head_attention_215[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_428 (Dropout)          (None, 8, 45)        0           ['layer_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " dropout_429 (Dropout)          (None, 11, 45)       0           ['layer_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_214 (  (None, 45)          0           ['dropout_428[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_215 (  (None, 45)          0           ['dropout_429[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_107 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_214[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_215[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_430 (Dropout)          (None, 90)           0           ['concatenate_107[0][0]']        \n",
      "                                                                                                  \n",
      " dense_214 (Dense)              (None, 128)          11648       ['dropout_430[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_431 (Dropout)          (None, 128)          0           ['dense_214[0][0]']              \n",
      "                                                                                                  \n",
      " dense_215 (Dense)              (None, 1)            129         ['dropout_431[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2011 - accuracy: 0.9294 - val_loss: 0.0792 - val_accuracy: 0.9840\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1151 - accuracy: 0.9736 - val_loss: 0.0856 - val_accuracy: 0.9823\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1030 - accuracy: 0.9751 - val_loss: 0.0557 - val_accuracy: 0.9895\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0970 - accuracy: 0.9754 - val_loss: 0.0575 - val_accuracy: 0.9835\n",
      "Epoch 5/10\n",
      " 88/938 [=>............................] - ETA: 8s - loss: 0.1022 - accuracy: 0.9751\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN cooking 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_108\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_217 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_218 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_216 (TFOp  (None, 8, 45)       0           ['input_217[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_217 (TFOp  (None, 11, 45)      0           ['input_218[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_216 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_216[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_216[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_217 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_217[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_217[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_216 (Layer  (None, 8, 45)       90          ['multi_head_attention_216[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_217 (Layer  (None, 11, 45)      90          ['multi_head_attention_217[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_432 (Dropout)          (None, 8, 45)        0           ['layer_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " dropout_433 (Dropout)          (None, 11, 45)       0           ['layer_normalization_217[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_216 (  (None, 45)          0           ['dropout_432[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_217 (  (None, 45)          0           ['dropout_433[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_108 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_216[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_217[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_434 (Dropout)          (None, 90)           0           ['concatenate_108[0][0]']        \n",
      "                                                                                                  \n",
      " dense_216 (Dense)              (None, 128)          11648       ['dropout_434[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_435 (Dropout)          (None, 128)          0           ['dense_216[0][0]']              \n",
      "                                                                                                  \n",
      " dense_217 (Dense)              (None, 1)            129         ['dropout_435[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1661 - accuracy: 0.9306 - val_loss: 0.1026 - val_accuracy: 0.9730\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0632 - accuracy: 0.9827 - val_loss: 0.0577 - val_accuracy: 0.9840\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0517 - accuracy: 0.9851 - val_loss: 0.0563 - val_accuracy: 0.9840\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0435 - accuracy: 0.9869 - val_loss: 0.0545 - val_accuracy: 0.9840\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.0454 - val_accuracy: 0.9883\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 0.0397 - val_accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0329 - accuracy: 0.9905 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0336 - accuracy: 0.9898 - val_loss: 0.0268 - val_accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0285 - accuracy: 0.9916 - val_loss: 0.0452 - val_accuracy: 0.9902\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0673 - val_accuracy: 0.9852\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "TRAIN shower 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_109\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_219 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_220 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_218 (TFOp  (None, 8, 45)       0           ['input_219[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_219 (TFOp  (None, 11, 45)      0           ['input_220[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_218 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_218[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_218[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_219 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_219[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_219[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_218 (Layer  (None, 8, 45)       90          ['multi_head_attention_218[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_219 (Layer  (None, 11, 45)      90          ['multi_head_attention_219[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_436 (Dropout)          (None, 8, 45)        0           ['layer_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " dropout_437 (Dropout)          (None, 11, 45)       0           ['layer_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_218 (  (None, 45)          0           ['dropout_436[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_219 (  (None, 45)          0           ['dropout_437[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_109 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_218[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_219[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_438 (Dropout)          (None, 90)           0           ['concatenate_109[0][0]']        \n",
      "                                                                                                  \n",
      " dense_218 (Dense)              (None, 128)          11648       ['dropout_438[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_439 (Dropout)          (None, 128)          0           ['dense_218[0][0]']              \n",
      "                                                                                                  \n",
      " dense_219 (Dense)              (None, 1)            129         ['dropout_439[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.0864 - accuracy: 0.9672 - val_loss: 0.0474 - val_accuracy: 0.9909\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.0336 - val_accuracy: 0.9916\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 11s 12ms/step - loss: 0.0155 - accuracy: 0.9967 - val_loss: 0.0410 - val_accuracy: 0.9926\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.0213 - val_accuracy: 0.9950\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.0263 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0172 - val_accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.0151 - val_accuracy: 0.9967\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0238 - val_accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 3.7100e-04 - val_accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0091 - accuracy: 0.9982 - val_loss: 0.0029 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 2.7487e-04 - val_accuracy: 1.0000\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN sleep 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_111\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_223 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_224 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_222 (TFOp  (None, 8, 45)       0           ['input_223[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_223 (TFOp  (None, 11, 45)      0           ['input_224[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_222 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_222[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_222[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_223 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_223[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_223[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_222 (Layer  (None, 8, 45)       90          ['multi_head_attention_222[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_223 (Layer  (None, 11, 45)      90          ['multi_head_attention_223[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_444 (Dropout)          (None, 8, 45)        0           ['layer_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " dropout_445 (Dropout)          (None, 11, 45)       0           ['layer_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_222 (  (None, 45)          0           ['dropout_444[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_223 (  (None, 45)          0           ['dropout_445[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_111 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_222[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_223[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_446 (Dropout)          (None, 90)           0           ['concatenate_111[0][0]']        \n",
      "                                                                                                  \n",
      " dense_222 (Dense)              (None, 128)          11648       ['dropout_446[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_447 (Dropout)          (None, 128)          0           ['dense_222[0][0]']              \n",
      "                                                                                                  \n",
      " dense_223 (Dense)              (None, 1)            129         ['dropout_447[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.1744 - accuracy: 0.9385 - val_loss: 0.0356 - val_accuracy: 0.9921\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.1014 - accuracy: 0.9750 - val_loss: 0.0349 - val_accuracy: 0.9928\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0957 - accuracy: 0.9762 - val_loss: 0.0282 - val_accuracy: 0.9952\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0949 - accuracy: 0.9760 - val_loss: 0.0422 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 11s 11ms/step - loss: 0.0886 - accuracy: 0.9769 - val_loss: 0.0283 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 10s 11ms/step - loss: 0.0804 - accuracy: 0.9780 - val_loss: 0.0339 - val_accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "387/938 [===========>..................] - ETA: 5s - loss: 0.0830 - accuracy: 0.9771\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN kitchen 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_112\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_225 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_226 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_224 (TFOp  (None, 8, 45)       0           ['input_225[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_225 (TFOp  (None, 11, 45)      0           ['input_226[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_224 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_224[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_224[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_225 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_225[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_225[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_224 (Layer  (None, 8, 45)       90          ['multi_head_attention_224[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_225 (Layer  (None, 11, 45)      90          ['multi_head_attention_225[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_448 (Dropout)          (None, 8, 45)        0           ['layer_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " dropout_449 (Dropout)          (None, 11, 45)       0           ['layer_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_224 (  (None, 45)          0           ['dropout_448[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_225 (  (None, 45)          0           ['dropout_449[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_112 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_224[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_225[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_450 (Dropout)          (None, 90)           0           ['concatenate_112[0][0]']        \n",
      "                                                                                                  \n",
      " dense_224 (Dense)              (None, 128)          11648       ['dropout_450[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_451 (Dropout)          (None, 128)          0           ['dense_224[0][0]']              \n",
      "                                                                                                  \n",
      " dense_225 (Dense)              (None, 1)            129         ['dropout_451[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 11ms/step - loss: 0.2684 - accuracy: 0.8876 - val_loss: 0.1340 - val_accuracy: 0.9326\n",
      "Epoch 2/10\n",
      "303/938 [========>.....................] - ETA: 6s - loss: 0.1732 - accuracy: 0.9378"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "SizeTrainOk=4000\n",
    "SizeTrainKo=6000\n",
    "\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    print(\"\\t\",dx,day)\n",
    "    other_dx= [other for other in range(0,len(days)) if other != dx]\n",
    "\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    \n",
    "    for ax,activity in enumerate(activities):\n",
    "            print(ax,activity)\n",
    "            \n",
    "            ##TRAING DATA\n",
    "            L1=[]\n",
    "            L2=[]\n",
    "            S=[]\n",
    "            Y=[]\n",
    "            for ux,user in enumerate(users):\n",
    "                    print(\"\\t\\t\",ux,user)\n",
    "                    other_ux= [other for other in range(0,len(users)) if other != ux]\n",
    "                    print(day,user,other_dx,other_ux)\n",
    "\n",
    "                    #OK act\n",
    "                    for ix in range(0,SizeTrainOk):\n",
    "                        #print(\"SizeTrainOk\",ix,\"vs\",SizeTrainOk)\n",
    "                        filtered_elements = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 1)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            #print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                            X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        Ss=[]\n",
    "                        for sx, sensor in enumerate(sensors):\n",
    "                            Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                        L1.append(X1s)\n",
    "                        L2.append(X2s)\n",
    "                        S.append(Ss)\n",
    "                        Y.append(user_activity[index])\n",
    "                        \n",
    "                    #KO act\n",
    "                    ix=0\n",
    "                    while ix < SizeTrainKo:\n",
    "                        #print(\"SizeTrainKo\",ix,\"vs\",SizeTrainKo)\n",
    "                        filtered_elements_specific = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 0)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        none=True\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            #if(ax2==ax):\n",
    "                                r=np.random.rand()\n",
    "                                #print(\" removing loc?:\",loc_user[ax2][iu][idy][tt],r)\n",
    "                                if(r<loc_user[ax2][iu][idy][tt]+0.05):\n",
    "                                    #print(\"NOT  removing loc:\",loc_user[ax2][iu][idy][tt])\n",
    "                                    none=False\n",
    "                                    \n",
    "                                X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                                X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        if not none:\n",
    "                            L1.append(X1s)\n",
    "                            L2.append(X2s)\n",
    "                            Ss=[]\n",
    "                            for sx, sensor in enumerate(sensors):\n",
    "                                Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                            S.append(Ss)\n",
    "                            Y.append(user_activity[index])       \n",
    "                            ix=ix+1\n",
    "\n",
    "            L1=np.array(L1)        \n",
    "            L2=np.array(L2)        \n",
    "            S=np.array(S)\n",
    "            Y=np.array(Y)\n",
    "            print(\"TRAIN\",activity,day,L1.shape,L2.shape,S.shape,Y.shape)\n",
    "            \n",
    "            \n",
    "            model=getModelHAR()\n",
    "            model.summary()\n",
    "            \n",
    "            ##TEST DATA\n",
    "            TL1=[]\n",
    "            TL2=[]\n",
    "            TS=[]\n",
    "            TY=[]\n",
    "            \n",
    "            \n",
    "            (t0,tN)=t0N_days[day]\n",
    "            ts=list(range(TWA,sizeT(t0,tN)-TWB))\n",
    "            \n",
    "            for ux2,user2 in enumerate(users):\n",
    "                other_ux2= [other for other in range(0,len(users)) if other != ux2]\n",
    "\n",
    "                for tx in ts:\n",
    "\n",
    "                    Ss=[]\n",
    "                    for sx, sensor in enumerate(sensors):\n",
    "                        Ss.append(act_sensors[sx][dx][tx-TWA:tx+TWB])\n",
    "                    \n",
    "                    X1s=[]\n",
    "                    X2s=[]\n",
    "                    for ax2,activity2 in enumerate(activities):\n",
    "                        X1s.append(loc_user[ax2][ux2][dx][tx-TWA:tx+TWB])\n",
    "                        X2s.append(np.amax(loc_user[ax2,other_ux2,dx,tx-TWA:tx+TWB],axis=0))\n",
    "\n",
    "\n",
    "                    TL1.append(X1s)\n",
    "                    TL2.append(X2s)\n",
    "                    TS.append(Ss)\n",
    "                    TY.append(user_activity[ax, ux2, dx, tx])\n",
    "                        \n",
    "            TL1=np.array(TL1)        \n",
    "            TL2=np.array(TL2)        \n",
    "            TS=np.array(TS)\n",
    "            TY=np.array(TY)\n",
    "            print(\"EVAL\",activity,day,TL1.shape,TL2.shape,TS.shape,TY.shape)\n",
    "            \n",
    "            history = model.fit([L1,S] , Y, shuffle=True, batch_size=32,epochs=10, validation_data = ([TL1,TS], TY))\n",
    "            YT_prediction = model.predict([TL1,TS])\n",
    "            print(YT_prediction.shape)\n",
    "            \n",
    "            ix=0\n",
    "            for ux2,user2 in enumerate(users):\n",
    "                with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/PREDICTION-Transformer-position-encoding-no-other-30+15.\"+user2+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                    for tx in (ts):\n",
    "                        tt=tx*time_step2+t0\n",
    "                        #print(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0]))\n",
    "                        file.write(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0])+\"\\n\")\n",
    "                        \n",
    "                        ix=ix+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fc952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
