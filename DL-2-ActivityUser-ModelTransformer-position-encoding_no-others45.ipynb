{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934b764b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2024-07-05': ['0001', '3d57', 'ed9c'], '2024-07-06': ['0001', '3d57', 'ed9c'], '2024-07-07': ['0001', '3d57', 'ed9c'], '2024-07-18': ['16fe', 'f02e', 'ed9c'], '2024-07-19': ['16fe', 'f02e', 'ed9c'], '2024-07-20': ['16fe', 'f02e', 'ed9c'], '2024-07-24': ['16fe', '5b66', 'ed9c'], '2024-07-25': ['16fe', '5b66', 'ed9c'], '2024-07-26': ['16fe', '5b66', 'ed9c'], '2024-07-27': ['16fe', '5b66', 'ed9c'], '2024-07-28': ['16fe', '5b66', 'ed9c'], '2024-07-29': ['16fe', '5b66', 'ed9c'], '2024-07-30': ['16fe', '5b66', 'ed9c'], '2024-07-31': ['16fe', '5b66', 'ed9c']}\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('agg-config.txt')\n",
    "\n",
    "\n",
    "time_step = int(config.get('Configuration', 'time_step'))\n",
    "time_step2 = int(config.get('Configuration', 'time_step2'))\n",
    "\n",
    "window_size = int(config.get('Configuration', 'window_size'))\n",
    "processed_data_folder = config.get('Configuration', 'processed_data_folder')\n",
    "raw_data_folder = config.get('Configuration', 'raw_data_folder')\n",
    "\n",
    "ini_date = config.get('Configuration', 'ini_date')\n",
    "end_date = config.get('Configuration', 'end_date')\n",
    "\n",
    "\n",
    "activities=config.get('Configuration', 'learn_activities')\n",
    "activities = [(item.strip()) for item in activities.split(',')]\n",
    "\n",
    "cross_days=config.get('Configuration', 'cross_days')\n",
    "cross_days = [(item.strip()) for item in cross_days.split(',')]\n",
    "\n",
    "sensors=config.get('Configuration', 'sensors')\n",
    "sensors = [(item.strip()) for item in sensors.split(',')]\n",
    "\n",
    "w = int(config.get('Configuration', 'w'))\n",
    "h = int(config.get('Configuration', 'h'))\n",
    "\n",
    "users_day={}\n",
    "for cross_day in cross_days:\n",
    "    users_day[cross_day]=config.get('Configuration', cross_day)\n",
    "    users_day[cross_day] = [(item.strip()) for item in users_day[cross_day].split(',')]\n",
    "print(users_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44ea50ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv    \n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "off_zone=60*60*2\n",
    "\n",
    "def day_time(t0,tN,ti):\n",
    "    return int((int)((ti+off_zone)/(60*60*24)))\n",
    "\n",
    "\n",
    "def time2str(t0,tN,tt):\n",
    "    return datetime.fromtimestamp(tt).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def day_time0(t0,tN,ti):\n",
    "    return day_time(ti)-day_time(t0)+1\n",
    "\n",
    "def relT(t0,tN,ti):\n",
    "    return (int)((ti-t0)/time_step2)\n",
    "\n",
    "def sizeT(t0,tN):\n",
    "    return relT(t0,tN,tN)+1\n",
    "\n",
    "\n",
    "def initTime(ini_date,end_date):\n",
    "    tN = (int)(datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "\n",
    "    t0 = (int)(datetime.strptime(ini_date, '%Y-%m-%d %H:%M:%S').timestamp())\n",
    "    print (ini_date,\"Init date is\", t0, \"day:\",day_time(t0,tN,t0), time2str(t0,tN,t0))\n",
    "    print (end_date,\"End date is\", tN, \"day:\",day_time(t0,tN,tN), time2str(t0,tN,tN))\n",
    "\n",
    "    day=list(range(day_time(t0,tN,t0),day_time(t0,tN,tN)+1))[0]\n",
    "    return day,t0,tN\n",
    "    \n",
    "initTime(ini_date,end_date)\n",
    "\n",
    "\n",
    "def getStrDatefrom(day_number):\n",
    "    # Reference date (1970-01-01)\n",
    "    reference_date = datetime(1970, 1, 1)\n",
    "    \n",
    "    # Compute the date corresponding to the day number\n",
    "    resulting_date = reference_date + timedelta(days=day_number)\n",
    "    \n",
    "    return resulting_date.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeeab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe748a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ed8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8787ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-05\n",
      "New ini_date: 2024-07-05 02:00:00\n",
      "New end_date: 2024-07-06 01:59:59\n",
      "2024-07-05 02:00:00 Init date is 1720137600 day: 19909 2024-07-05 02:00:00\n",
      "2024-07-06 01:59:59 End date is 1720223999 day: 19910 2024-07-06 01:59:59\n",
      "2024-07-06\n",
      "New ini_date: 2024-07-06 02:00:00\n",
      "New end_date: 2024-07-07 01:59:59\n",
      "2024-07-06 02:00:00 Init date is 1720224000 day: 19910 2024-07-06 02:00:00\n",
      "2024-07-07 01:59:59 End date is 1720310399 day: 19911 2024-07-07 01:59:59\n",
      "2024-07-07\n",
      "New ini_date: 2024-07-07 02:00:00\n",
      "New end_date: 2024-07-08 01:59:59\n",
      "2024-07-07 02:00:00 Init date is 1720310400 day: 19911 2024-07-07 02:00:00\n",
      "2024-07-08 01:59:59 End date is 1720396799 day: 19912 2024-07-08 01:59:59\n",
      "2024-07-18\n",
      "New ini_date: 2024-07-18 02:00:00\n",
      "New end_date: 2024-07-19 01:59:59\n",
      "2024-07-18 02:00:00 Init date is 1721260800 day: 19922 2024-07-18 02:00:00\n",
      "2024-07-19 01:59:59 End date is 1721347199 day: 19923 2024-07-19 01:59:59\n",
      "2024-07-19\n",
      "New ini_date: 2024-07-19 02:00:00\n",
      "New end_date: 2024-07-20 01:59:59\n",
      "2024-07-19 02:00:00 Init date is 1721347200 day: 19923 2024-07-19 02:00:00\n",
      "2024-07-20 01:59:59 End date is 1721433599 day: 19924 2024-07-20 01:59:59\n",
      "2024-07-20\n",
      "New ini_date: 2024-07-20 02:00:00\n",
      "New end_date: 2024-07-21 01:59:59\n",
      "2024-07-20 02:00:00 Init date is 1721433600 day: 19924 2024-07-20 02:00:00\n",
      "2024-07-21 01:59:59 End date is 1721519999 day: 19925 2024-07-21 01:59:59\n",
      "2024-07-24\n",
      "New ini_date: 2024-07-24 02:00:00\n",
      "New end_date: 2024-07-25 01:59:59\n",
      "2024-07-24 02:00:00 Init date is 1721779200 day: 19928 2024-07-24 02:00:00\n",
      "2024-07-25 01:59:59 End date is 1721865599 day: 19929 2024-07-25 01:59:59\n",
      "2024-07-25\n",
      "New ini_date: 2024-07-25 02:00:00\n",
      "New end_date: 2024-07-26 01:59:59\n",
      "2024-07-25 02:00:00 Init date is 1721865600 day: 19929 2024-07-25 02:00:00\n",
      "2024-07-26 01:59:59 End date is 1721951999 day: 19930 2024-07-26 01:59:59\n",
      "2024-07-26\n",
      "New ini_date: 2024-07-26 02:00:00\n",
      "New end_date: 2024-07-27 01:59:59\n",
      "2024-07-26 02:00:00 Init date is 1721952000 day: 19930 2024-07-26 02:00:00\n",
      "2024-07-27 01:59:59 End date is 1722038399 day: 19931 2024-07-27 01:59:59\n",
      "2024-07-27\n",
      "New ini_date: 2024-07-27 02:00:00\n",
      "New end_date: 2024-07-28 01:59:59\n",
      "2024-07-27 02:00:00 Init date is 1722038400 day: 19931 2024-07-27 02:00:00\n",
      "2024-07-28 01:59:59 End date is 1722124799 day: 19932 2024-07-28 01:59:59\n",
      "2024-07-28\n",
      "New ini_date: 2024-07-28 02:00:00\n",
      "New end_date: 2024-07-29 01:59:59\n",
      "2024-07-28 02:00:00 Init date is 1722124800 day: 19932 2024-07-28 02:00:00\n",
      "2024-07-29 01:59:59 End date is 1722211199 day: 19933 2024-07-29 01:59:59\n",
      "2024-07-29\n",
      "New ini_date: 2024-07-29 02:00:00\n",
      "New end_date: 2024-07-30 01:59:59\n",
      "2024-07-29 02:00:00 Init date is 1722211200 day: 19933 2024-07-29 02:00:00\n",
      "2024-07-30 01:59:59 End date is 1722297599 day: 19934 2024-07-30 01:59:59\n",
      "2024-07-30\n",
      "New ini_date: 2024-07-30 02:00:00\n",
      "New end_date: 2024-07-31 01:59:59\n",
      "2024-07-30 02:00:00 Init date is 1722297600 day: 19934 2024-07-30 02:00:00\n",
      "2024-07-31 01:59:59 End date is 1722383999 day: 19935 2024-07-31 01:59:59\n",
      "2024-07-31\n",
      "New ini_date: 2024-07-31 02:00:00\n",
      "New end_date: 2024-08-01 01:59:59\n",
      "2024-07-31 02:00:00 Init date is 1722384000 day: 19935 2024-07-31 02:00:00\n",
      "2024-08-01 01:59:59 End date is 1722470399 day: 19936 2024-08-01 01:59:59\n",
      "[19909, 19910, 19911, 19922, 19923, 19924, 19928, 19929, 19930, 19931, 19932, 19933, 19934, 19935]\n",
      "{19909: (1720137600, 1720223999), 19910: (1720224000, 1720310399), 19911: (1720310400, 1720396799), 19922: (1721260800, 1721347199), 19923: (1721347200, 1721433599), 19924: (1721433600, 1721519999), 19928: (1721779200, 1721865599), 19929: (1721865600, 1721951999), 19930: (1721952000, 1722038399), 19931: (1722038400, 1722124799), 19932: (1722124800, 1722211199), 19933: (1722211200, 1722297599), 19934: (1722297600, 1722383999), 19935: (1722384000, 1722470399)}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "days=[]\n",
    "t0N_days={}\n",
    "\n",
    "for cross_day in cross_days:\n",
    "    print(cross_day)\n",
    "    # Convertir las fechas a objetos datetime\n",
    "    ini_date_dt = datetime.strptime(ini_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    end_date_dt = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    cross_day_dt = datetime.strptime(cross_day, \"%Y-%m-%d\")\n",
    "\n",
    "    # Reemplazar el día manteniendo la hora original\n",
    "    new_ini_date = cross_day_dt.replace(hour=ini_date_dt.hour, minute=ini_date_dt.minute, second=ini_date_dt.second)\n",
    "    new_end_date = cross_day_dt.replace(hour=end_date_dt.hour, minute=end_date_dt.minute, second=end_date_dt.second) + timedelta(days=1)\n",
    "\n",
    "    # Convertir las fechas de nuevo a cadena si es necesario\n",
    "    new_ini_date_str = new_ini_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    new_end_date_str = new_end_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    print(f\"New ini_date: {new_ini_date_str}\")\n",
    "    print(f\"New end_date: {new_end_date_str}\")\n",
    "    day,t0,tN=initTime(new_ini_date_str,new_end_date_str)\n",
    "    days.append(day)\n",
    "    t0N_days[day]=(t0,tN)\n",
    "    \n",
    "\n",
    "print(days)\n",
    "print(t0N_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f2ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3, 14, 1440)\n",
      "\t toileting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.toileting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.toileting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.toileting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.toileting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.toileting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.toileting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.toileting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.toileting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.toileting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.toileting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.toileting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.toileting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.toileting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.toileting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.toileting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.toileting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.toileting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.toileting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.toileting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.toileting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.toileting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.toileting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.toileting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.toileting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.toileting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.toileting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.toileting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.toileting.tsv\n",
      "19935 (1440,)\n",
      "\t resting\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.resting.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.resting.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.resting.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.resting.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.resting.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.resting.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.resting.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.resting.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.resting.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.resting.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.resting.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.resting.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.resting.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.resting.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.resting.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.resting.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.resting.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.resting.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.resting.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.resting.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.resting.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.resting.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.resting.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.resting.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.resting.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.resting.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.resting.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.resting.tsv\n",
      "19935 (1440,)\n",
      "\t exit\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.exit.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.exit.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.exit.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.exit.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.exit.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.exit.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.exit.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.exit.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.exit.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.exit.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.exit.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.exit.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.exit.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.exit.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.exit.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.exit.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.exit.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.exit.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.exit.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.exit.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.exit.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.exit.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.exit.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.exit.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.exit.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.exit.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.exit.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.exit.tsv\n",
      "19935 (1440,)\n",
      "\t cooking\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.cooking.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.cooking.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.cooking.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.cooking.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.cooking.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.cooking.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.cooking.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.cooking.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.cooking.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.cooking.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.cooking.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.cooking.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.cooking.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.cooking.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.cooking.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.cooking.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.cooking.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.cooking.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.cooking.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.cooking.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.cooking.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.cooking.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.cooking.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.cooking.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.cooking.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.cooking.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.cooking.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.cooking.tsv\n",
      "19935 (1440,)\n",
      "\t shower\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.shower.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.shower.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.shower.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.shower.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.shower.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.shower.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.shower.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.shower.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.shower.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.shower.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.shower.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.shower.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.shower.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.shower.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.shower.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.shower.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.shower.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.shower.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.shower.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.shower.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.shower.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.shower.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.shower.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.shower.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.shower.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.shower.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.shower.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.shower.tsv\n",
      "19935 (1440,)\n",
      "\t pc\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.pc.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.pc.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.pc.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.pc.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.pc.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.pc.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.pc.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.pc.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.pc.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.pc.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.pc.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.pc.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.pc.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.pc.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.pc.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.pc.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.pc.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.pc.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.pc.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.pc.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.pc.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.pc.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.pc.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.pc.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.pc.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.pc.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.pc.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.pc.tsv\n",
      "19935 (1440,)\n",
      "\t sleep\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.sleep.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.sleep.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.sleep.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.sleep.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.sleep.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.sleep.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.sleep.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.sleep.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.sleep.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.sleep.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.sleep.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.sleep.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.sleep.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.sleep.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.sleep.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.sleep.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.sleep.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.sleep.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.sleep.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.sleep.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.sleep.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.sleep.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.sleep.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.sleep.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.sleep.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.sleep.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.sleep.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.sleep.tsv\n",
      "19935 (1440,)\n",
      "\t kitchen\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19909/act/loc.0001.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.3d57.kitchen.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19909/act/loc.ed9c.kitchen.tsv\n",
      "19909 (1440,)\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19910/act/loc.0001.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.3d57.kitchen.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19910/act/loc.ed9c.kitchen.tsv\n",
      "19910 (1440,)\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "./data-har//DAY_19911/act/loc.0001.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.3d57.kitchen.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19911/act/loc.ed9c.kitchen.tsv\n",
      "19911 (1440,)\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19922/act/loc.16fe.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.f02e.kitchen.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19922/act/loc.ed9c.kitchen.tsv\n",
      "19922 (1440,)\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19923/act/loc.16fe.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.f02e.kitchen.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19923/act/loc.ed9c.kitchen.tsv\n",
      "19923 (1440,)\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "./data-har//DAY_19924/act/loc.16fe.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.f02e.kitchen.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19924/act/loc.ed9c.kitchen.tsv\n",
      "19924 (1440,)\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19928/act/loc.16fe.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.5b66.kitchen.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19928/act/loc.ed9c.kitchen.tsv\n",
      "19928 (1440,)\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19929/act/loc.16fe.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.5b66.kitchen.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19929/act/loc.ed9c.kitchen.tsv\n",
      "19929 (1440,)\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19930/act/loc.16fe.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.5b66.kitchen.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19930/act/loc.ed9c.kitchen.tsv\n",
      "19930 (1440,)\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19931/act/loc.16fe.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.5b66.kitchen.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19931/act/loc.ed9c.kitchen.tsv\n",
      "19931 (1440,)\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19932/act/loc.16fe.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.5b66.kitchen.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19932/act/loc.ed9c.kitchen.tsv\n",
      "19932 (1440,)\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19933/act/loc.16fe.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.5b66.kitchen.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19933/act/loc.ed9c.kitchen.tsv\n",
      "19933 (1440,)\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19934/act/loc.16fe.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.5b66.kitchen.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19934/act/loc.ed9c.kitchen.tsv\n",
      "19934 (1440,)\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "./data-har//DAY_19935/act/loc.16fe.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.5b66.kitchen.tsv\n",
      "19935 (1440,)\n",
      "./data-har//DAY_19935/act/loc.ed9c.kitchen.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "len_users=3\n",
    "loc_user=np.zeros((len(activities),len_users,len(days),sizeT(t0,tN)))\n",
    "print(loc_user.shape)\n",
    "for ax,activity in enumerate(activities):\n",
    "    print(\"\\t\",activity)\n",
    "    for dx,day in enumerate(days):\n",
    "        day_str=getStrDatefrom(day)\n",
    "        users=users_day[day_str]\n",
    "        print(day,users)\n",
    "        for ux,user in enumerate(users):\n",
    "            print(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\")\n",
    "            series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/loc.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"loc\"])\n",
    "            series=series[\"loc\"].values\n",
    "            print(day,series.shape)\n",
    "            loc_user[ax][ux][dx]=series\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9631e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 14, 1440)\n",
      "\t fridge_13\n",
      "./data-har//DAY_19909/object_sensor/fridge_13.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/fridge_13.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/fridge_13.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/fridge_13.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/fridge_13.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/fridge_13.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/fridge_13.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/fridge_13.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/fridge_13.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/fridge_13.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/fridge_13.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/fridge_13.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/fridge_13.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/fridge_13.tsv\n",
      "19935 (1440,)\n",
      "\t tap_22\n",
      "./data-har//DAY_19909/object_sensor/tap_22.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/tap_22.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/tap_22.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/tap_22.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/tap_22.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/tap_22.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/tap_22.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/tap_22.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/tap_22.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/tap_22.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/tap_22.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/tap_22.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/tap_22.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/tap_22.tsv\n",
      "19935 (1440,)\n",
      "\t micro_5\n",
      "./data-har//DAY_19909/object_sensor/micro_5.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/micro_5.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/micro_5.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/micro_5.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/micro_5.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/micro_5.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/micro_5.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/micro_5.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/micro_5.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/micro_5.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/micro_5.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/micro_5.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/micro_5.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/micro_5.tsv\n",
      "19935 (1440,)\n",
      "\t pans_8\n",
      "./data-har//DAY_19909/object_sensor/pans_8.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pans_8.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pans_8.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pans_8.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pans_8.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pans_8.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pans_8.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pans_8.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pans_8.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pans_8.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pans_8.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pans_8.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pans_8.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pans_8.tsv\n",
      "19935 (1440,)\n",
      "\t dishes_9\n",
      "./data-har//DAY_19909/object_sensor/dishes_9.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/dishes_9.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/dishes_9.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/dishes_9.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/dishes_9.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/dishes_9.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/dishes_9.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/dishes_9.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/dishes_9.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/dishes_9.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/dishes_9.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/dishes_9.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/dishes_9.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/dishes_9.tsv\n",
      "19935 (1440,)\n",
      "\t shower_24_apertura\n",
      "./data-har//DAY_19909/object_sensor/shower_24_apertura.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_24_apertura.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_24_apertura.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_24_apertura.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_24_apertura.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_24_apertura.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_24_apertura.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_24_apertura.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_24_apertura.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_24_apertura.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_24_apertura.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_24_apertura.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_24_apertura.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_24_apertura.tsv\n",
      "19935 (1440,)\n",
      "\t hum_shower_25\n",
      "./data-har//DAY_19909/object_sensor/hum_shower_25.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/hum_shower_25.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/hum_shower_25.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/hum_shower_25.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/hum_shower_25.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/hum_shower_25.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/hum_shower_25.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/hum_shower_25.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/hum_shower_25.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/hum_shower_25.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/hum_shower_25.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/hum_shower_25.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/hum_shower_25.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/hum_shower_25.tsv\n",
      "19935 (1440,)\n",
      "\t shower_31\n",
      "./data-har//DAY_19909/object_sensor/shower_31.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/shower_31.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/shower_31.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/shower_31.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/shower_31.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/shower_31.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/shower_31.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/shower_31.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/shower_31.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/shower_31.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/shower_31.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/shower_31.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/shower_31.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/shower_31.tsv\n",
      "19935 (1440,)\n",
      "\t wc_17\n",
      "./data-har//DAY_19909/object_sensor/wc_17.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/wc_17.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/wc_17.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/wc_17.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/wc_17.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/wc_17.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/wc_17.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/wc_17.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/wc_17.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/wc_17.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/wc_17.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/wc_17.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/wc_17.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/wc_17.tsv\n",
      "19935 (1440,)\n",
      "\t sink_21\n",
      "./data-har//DAY_19909/object_sensor/sink_21.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/sink_21.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/sink_21.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/sink_21.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/sink_21.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/sink_21.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/sink_21.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/sink_21.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/sink_21.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/sink_21.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/sink_21.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/sink_21.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/sink_21.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/sink_21.tsv\n",
      "19935 (1440,)\n",
      "\t pc_1_current_consumption\n",
      "./data-har//DAY_19909/object_sensor/pc_1_current_consumption.tsv\n",
      "19909 (1440,)\n",
      "./data-har//DAY_19910/object_sensor/pc_1_current_consumption.tsv\n",
      "19910 (1440,)\n",
      "./data-har//DAY_19911/object_sensor/pc_1_current_consumption.tsv\n",
      "19911 (1440,)\n",
      "./data-har//DAY_19922/object_sensor/pc_1_current_consumption.tsv\n",
      "19922 (1440,)\n",
      "./data-har//DAY_19923/object_sensor/pc_1_current_consumption.tsv\n",
      "19923 (1440,)\n",
      "./data-har//DAY_19924/object_sensor/pc_1_current_consumption.tsv\n",
      "19924 (1440,)\n",
      "./data-har//DAY_19928/object_sensor/pc_1_current_consumption.tsv\n",
      "19928 (1440,)\n",
      "./data-har//DAY_19929/object_sensor/pc_1_current_consumption.tsv\n",
      "19929 (1440,)\n",
      "./data-har//DAY_19930/object_sensor/pc_1_current_consumption.tsv\n",
      "19930 (1440,)\n",
      "./data-har//DAY_19931/object_sensor/pc_1_current_consumption.tsv\n",
      "19931 (1440,)\n",
      "./data-har//DAY_19932/object_sensor/pc_1_current_consumption.tsv\n",
      "19932 (1440,)\n",
      "./data-har//DAY_19933/object_sensor/pc_1_current_consumption.tsv\n",
      "19933 (1440,)\n",
      "./data-har//DAY_19934/object_sensor/pc_1_current_consumption.tsv\n",
      "19934 (1440,)\n",
      "./data-har//DAY_19935/object_sensor/pc_1_current_consumption.tsv\n",
      "19935 (1440,)\n"
     ]
    }
   ],
   "source": [
    "act_sensors=np.zeros((len(sensors),len(days),sizeT(t0,tN)))\n",
    "print(act_sensors.shape)\n",
    "for sx,sensor in enumerate(sensors):\n",
    "    print(\"\\t\",sensor)\n",
    "    for dx,day in enumerate(days):\n",
    "        print(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\")\n",
    "        series=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/object_sensor/\"+sensor+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"time\",\"status\"])\n",
    "        series=series[\"status\"].values\n",
    "        print(day,series.shape)\n",
    "        act_sensors[sx][dx]=series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "19934 ['16fe', '5b66', 'ed9c']\n",
      "19935 ['16fe', '5b66', 'ed9c']\n"
     ]
    }
   ],
   "source": [
    "user_activity=np.zeros((len(activities),len(users),len(days),sizeT(t0,tN)))\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            df_total=read_csv(processed_data_folder+\"/DAY_\"+str(day)+\"/act/INTERVAL.\"+user+\".\"+activity+\".tsv\", sep=\"\\t\",parse_dates=True, header=None, names=[\"ix\",\"d0\",\"dN\"])\n",
    "            #print(df_total)\n",
    "            #print(pd.to_datetime(df_total['d0']))\n",
    "            df_total['d0'] = pd.to_datetime(df_total['d0'])\n",
    "            df_total['dN'] = pd.to_datetime(df_total['dN'])\n",
    "            #print(df_total)\n",
    "\n",
    "            for tx,tt in enumerate(ts):\n",
    "                ttt=pd.to_datetime(time2str(t0,tN,tt))\n",
    "#                print(ttt)\n",
    "                row = df_total[(df_total['d0'] <= ttt) & (df_total['dN'] >= ttt)]\n",
    "#                print(\"df_in#tervalo\",row)\n",
    "                if(row.size>0):\n",
    "                    user_activity[ax][ux][dx][tx]=1\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    (t0,tN)=t0N_days[day]\n",
    "    ts=list(range(t0,tN,time_step2))\n",
    "            \n",
    "    for ax,activity in enumerate(activities):\n",
    "        for ux,user in enumerate(users):\n",
    "            with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/LABEL3.\"+user+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                for tx,tt in enumerate(ts):\n",
    "                    file.write(time2str(t0,tN,tt)+\"\\t\"+str(user_activity[ax][ux][dx][tx])+\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b92a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 00:46:56.173182: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-12 00:46:57.212694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 00:46:59.738965: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.048447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.048511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.051075: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.051123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.051157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.271615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.271690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.271700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-12-12 00:47:00.271741: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-12 00:47:00.271771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:26:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 8, 45)       0           ['input_1[0][0]']                \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 11, 45)      0           ['input_2[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 8, 45)       65925       ['tf.__operators__.add[0][0]',   \n",
      " dAttention)                                                      'tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_1[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 8, 45)       90          ['multi_head_attention[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8, 45)        0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 11, 45)       0           ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 45)          0           ['dropout[0][0]']                \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 45)          0           ['dropout_1[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 90)           0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'global_average_pooling1d_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 90)           0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          11648       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            129         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, MultiHeadAttention, LayerNormalization, Dropout, Concatenate, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "N1 = len(activities)\n",
    "N2 = len(activities)\n",
    "N3 = len(sensors)\n",
    "\n",
    "TWA = 45\n",
    "TWB = 0\n",
    "T = TWA + TWB\n",
    "\n",
    "print(N1,N2,N3)\n",
    "\n",
    "# Positional Encoding function\n",
    "def getPositionEncoding(seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Computes positional encoding for a given sequence length and embedding dimension.\n",
    "    \"\"\"\n",
    "    position = np.arange(seq_len)[:, np.newaxis]  # (seq_len, 1)\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "\n",
    "    pos_enc = np.zeros((seq_len, d_model))  # Inicializar matriz de codificación posicional\n",
    "\n",
    "    # Llenar columnas pares con seno\n",
    "    pos_enc[:, 0::2] = np.sin(position * div_term)\n",
    "\n",
    "    # Llenar columnas impares con coseno\n",
    "    pos_enc[:, 1::2] = np.cos(position * div_term[:len(pos_enc[0, 1::2])])\n",
    "\n",
    "    # Expandir dimensiones para coincidir con batch size\n",
    "    pos_enc = np.expand_dims(pos_enc, axis=0)  # (1, seq_len, d_model)\n",
    "\n",
    "    return tf.cast(pos_enc, dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modelo con Positional Encoding\n",
    "def getModelHAR():\n",
    "    # Define inputs\n",
    "    input1 = Input(shape=(8, 45))  # Forma de L1: (batch_size, 8, 45)\n",
    "    input3 = Input(shape=(11, 45))  # Forma de S: (batch_size, 11, 45)\n",
    "\n",
    "    # Codificación posicional\n",
    "    pos_enc1 = getPositionEncoding(8, 45)\n",
    "    pos_enc3 = getPositionEncoding(11, 45)\n",
    "\n",
    "    # Añadir Positional Encoding a las entradas\n",
    "    encoded1 = input1 + pos_enc1\n",
    "    encoded3 = input3 + pos_enc3\n",
    "\n",
    "    # Encoder para la primera secuencia\n",
    "    encoder1 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded1, encoded1)\n",
    "    encoder1 = LayerNormalization()(encoder1)\n",
    "    encoder1 = Dropout(0.5)(encoder1)\n",
    "\n",
    "\n",
    "    # Encoder para la tercera secuencia\n",
    "    encoder3 = MultiHeadAttention(num_heads=8, key_dim=45)(encoded3, encoded3)\n",
    "    encoder3 = LayerNormalization()(encoder3)\n",
    "    encoder3 = Dropout(0.5)(encoder3)\n",
    "\n",
    "    # Reducir las dimensiones de las secuencias\n",
    "    reduced1 = GlobalAveragePooling1D()(encoder1)\n",
    "    reduced3 = GlobalAveragePooling1D()(encoder3)\n",
    "\n",
    "    # Concatenar las secuencias reducidas\n",
    "    merged_encoded = Concatenate(axis=-1)([reduced1, reduced3])\n",
    "\n",
    "    # Capa Bottleneck\n",
    "    bottleneck = Dropout(0.5)(merged_encoded)\n",
    "\n",
    "    # Capas densas para clasificación\n",
    "    dense = Dense(128, activation='relu')(bottleneck)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = Model(inputs=[input1, input3], outputs=output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = getModelHAR()\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "386cb41e-bb1e-4043-b002-ea2c550f5dbd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a216fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 0 19909\n",
      "19909 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 8, 45)       0           ['input_3[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 11, 45)      0           ['input_4[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_2[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_3[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_3[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 8, 45)        0           ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 11, 45)       0           ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 45)          0           ['dropout_4[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 45)          0           ['dropout_5[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 90)           0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          11648       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            129         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 00:48:15.834946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-12-12 00:48:15.960373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-12-12 00:48:16.100555: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7eff00a0d7b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-12 00:48:16.100590: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "2024-12-12 00:48:16.149191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-12 00:48:16.419872: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2024-12-12 00:48:16.419901: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-12-12 00:48:16.419948: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:344] Couldn't read CUDA driver version.\n",
      "2024-12-12 00:48:16.460221: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 18s 15ms/step - loss: 0.4306 - accuracy: 0.8045 - val_loss: 0.2069 - val_accuracy: 0.9192\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2801 - accuracy: 0.8963 - val_loss: 0.2079 - val_accuracy: 0.9176\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2474 - accuracy: 0.9076 - val_loss: 0.2092 - val_accuracy: 0.9111\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2264 - accuracy: 0.9179 - val_loss: 0.2421 - val_accuracy: 0.8984\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2174 - accuracy: 0.9202 - val_loss: 0.0927 - val_accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2037 - accuracy: 0.9250 - val_loss: 0.1776 - val_accuracy: 0.9293\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1974 - accuracy: 0.9282 - val_loss: 0.2250 - val_accuracy: 0.9111\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1880 - accuracy: 0.9332 - val_loss: 0.1977 - val_accuracy: 0.9243\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1828 - accuracy: 0.9338 - val_loss: 0.1793 - val_accuracy: 0.9391\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1786 - accuracy: 0.9366 - val_loss: 0.1690 - val_accuracy: 0.9355\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 8, 45)       0           ['input_5[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 11, 45)      0           ['input_6[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_4[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_4[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_5[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_5[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_4[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_5[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 8, 45)        0           ['layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 11, 45)       0           ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 45)          0           ['dropout_8[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 45)          0           ['dropout_9[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 90)           0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          11648       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 128)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            129         ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 14ms/step - loss: 0.2951 - accuracy: 0.8589 - val_loss: 0.3608 - val_accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1380 - accuracy: 0.9516 - val_loss: 0.3394 - val_accuracy: 0.8860\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1195 - accuracy: 0.9573 - val_loss: 0.3081 - val_accuracy: 0.8855\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1105 - accuracy: 0.9618 - val_loss: 0.3199 - val_accuracy: 0.8836\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1055 - accuracy: 0.9636 - val_loss: 0.5105 - val_accuracy: 0.8841\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0967 - accuracy: 0.9683 - val_loss: 0.6719 - val_accuracy: 0.8863\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.4452 - val_accuracy: 0.8836\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0854 - accuracy: 0.9712 - val_loss: 0.5290 - val_accuracy: 0.8872\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0883 - accuracy: 0.9708 - val_loss: 0.4757 - val_accuracy: 0.8800\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0810 - accuracy: 0.9735 - val_loss: 0.6046 - val_accuracy: 0.8855\n",
      "131/131 [==============================] - 1s 3ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 8, 45)       0           ['input_7[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None, 11, 45)      0           ['input_8[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_6[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_6[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_7[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_7[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_6[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_7[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 8, 45)        0           ['layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 11, 45)       0           ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 45)          0           ['dropout_12[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 45)          0           ['dropout_13[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 90)           0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          11648       ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 128)          0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            129         ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.2295 - accuracy: 0.9184 - val_loss: 0.0804 - val_accuracy: 0.9876\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1353 - accuracy: 0.9664 - val_loss: 0.0613 - val_accuracy: 0.9895\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1283 - accuracy: 0.9678 - val_loss: 0.0610 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1242 - accuracy: 0.9679 - val_loss: 0.0638 - val_accuracy: 0.9876\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1192 - accuracy: 0.9677 - val_loss: 0.0846 - val_accuracy: 0.9873\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1120 - accuracy: 0.9690 - val_loss: 0.0671 - val_accuracy: 0.9878\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1061 - accuracy: 0.9684 - val_loss: 0.0967 - val_accuracy: 0.9816\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1015 - accuracy: 0.9692 - val_loss: 0.0696 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0989 - accuracy: 0.9697 - val_loss: 0.0737 - val_accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0976 - accuracy: 0.9701 - val_loss: 0.0634 - val_accuracy: 0.9885\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 8, 45)       0           ['input_9[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 11, 45)      0           ['input_10[0][0]']               \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (MultiH  (None, 8, 45)       65925       ['tf.__operators__.add_8[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (MultiH  (None, 11, 45)      65925       ['tf.__operators__.add_9[0][0]', \n",
      " eadAttention)                                                    'tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 8, 45)       90          ['multi_head_attention_8[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 11, 45)      90          ['multi_head_attention_9[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 8, 45)        0           ['layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 11, 45)       0           ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 45)          0           ['dropout_16[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 45)          0           ['dropout_17[0][0]']             \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 90)           0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          11648       ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 128)          0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            129         ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.3566 - accuracy: 0.8531 - val_loss: 0.2557 - val_accuracy: 0.9171\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2535 - accuracy: 0.9087 - val_loss: 0.2179 - val_accuracy: 0.9271\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2294 - accuracy: 0.9160 - val_loss: 0.2121 - val_accuracy: 0.9288\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2133 - accuracy: 0.9211 - val_loss: 0.1306 - val_accuracy: 0.9589\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2035 - accuracy: 0.9247 - val_loss: 0.1595 - val_accuracy: 0.9458\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1924 - accuracy: 0.9295 - val_loss: 0.1746 - val_accuracy: 0.9453\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1855 - accuracy: 0.9318 - val_loss: 0.1392 - val_accuracy: 0.9493\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1777 - accuracy: 0.9345 - val_loss: 0.1251 - val_accuracy: 0.9520\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1756 - accuracy: 0.9345 - val_loss: 0.1439 - val_accuracy: 0.9484\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1645 - accuracy: 0.9385 - val_loss: 0.2172 - val_accuracy: 0.9240\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 8, 45)       0           ['input_11[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 11, 45)      0           ['input_12[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_10[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_11 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_11[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 8, 45)       90          ['multi_head_attention_10[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 11, 45)      90          ['multi_head_attention_11[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 8, 45)        0           ['layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 11, 45)       0           ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_10 (G  (None, 45)          0           ['dropout_20[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_11 (G  (None, 45)          0           ['dropout_21[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_10[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 90)           0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 128)          11648       ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 128)          0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 1)            129         ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.1248 - accuracy: 0.9513 - val_loss: 0.0360 - val_accuracy: 0.9852\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0400 - accuracy: 0.9898 - val_loss: 0.0869 - val_accuracy: 0.9656\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.0123 - val_accuracy: 0.9962\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.0209 - val_accuracy: 0.9935\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0390 - val_accuracy: 0.9902\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0192 - val_accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0120 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0171 - val_accuracy: 0.9943\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0170 - val_accuracy: 0.9943\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.0096 - val_accuracy: 0.9981\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 8, 45)       0           ['input_13[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 11, 45)      0           ['input_14[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_12[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_13[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 8, 45)       90          ['multi_head_attention_12[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 11, 45)      90          ['multi_head_attention_13[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 8, 45)        0           ['layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 11, 45)       0           ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_12 (G  (None, 45)          0           ['dropout_24[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_13 (G  (None, 45)          0           ['dropout_25[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_12[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_13[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 90)           0           ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 128)          11648       ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 128)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 1)            129         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.1363 - accuracy: 0.9467 - val_loss: 0.0147 - val_accuracy: 0.9955\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0272 - accuracy: 0.9945 - val_loss: 0.0165 - val_accuracy: 0.9964\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0258 - accuracy: 0.9946 - val_loss: 0.0180 - val_accuracy: 0.9950\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0334 - accuracy: 0.9914 - val_loss: 0.0259 - val_accuracy: 0.9926\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0200 - accuracy: 0.9960 - val_loss: 0.0188 - val_accuracy: 0.9931\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0181 - accuracy: 0.9965 - val_loss: 0.0157 - val_accuracy: 0.9964\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.0153 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.0151 - val_accuracy: 0.9959\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 0.0138 - val_accuracy: 0.9945\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0205 - accuracy: 0.9955 - val_loss: 0.0152 - val_accuracy: 0.9940\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 8, 45)       0           ['input_15[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 11, 45)      0           ['input_16[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_14[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_15[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 8, 45)       90          ['multi_head_attention_14[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 11, 45)      90          ['multi_head_attention_15[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 8, 45)        0           ['layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 11, 45)       0           ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_14 (G  (None, 45)          0           ['dropout_28[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_15 (G  (None, 45)          0           ['dropout_29[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_14[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_15[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 90)           0           ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          11648       ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 128)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            129         ['dropout_31[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.1838 - accuracy: 0.9349 - val_loss: 0.0400 - val_accuracy: 0.9916\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1132 - accuracy: 0.9705 - val_loss: 0.0438 - val_accuracy: 0.9919\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1073 - accuracy: 0.9716 - val_loss: 0.0384 - val_accuracy: 0.9895\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1025 - accuracy: 0.9727 - val_loss: 0.0346 - val_accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1014 - accuracy: 0.9728 - val_loss: 0.0378 - val_accuracy: 0.9921\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0960 - accuracy: 0.9739 - val_loss: 0.0415 - val_accuracy: 0.9924\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0933 - accuracy: 0.9740 - val_loss: 0.0415 - val_accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0890 - accuracy: 0.9755 - val_loss: 0.0328 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0886 - accuracy: 0.9755 - val_loss: 0.0369 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0872 - accuracy: 0.9758 - val_loss: 0.0381 - val_accuracy: 0.9900\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19909 0001 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19909 3d57 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19909 ed9c [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19909 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (TFOpL  (None, 8, 45)       0           ['input_17[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (TFOpL  (None, 11, 45)      0           ['input_18[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_16[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_16[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_17[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_17[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 8, 45)       90          ['multi_head_attention_16[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_17 (LayerN  (None, 11, 45)      90          ['multi_head_attention_17[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 8, 45)        0           ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 11, 45)       0           ['layer_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_16 (G  (None, 45)          0           ['dropout_32[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_17 (G  (None, 45)          0           ['dropout_33[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_16[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 90)           0           ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          11648       ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1)            129         ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19909 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.2990 - accuracy: 0.8799 - val_loss: 0.1894 - val_accuracy: 0.9042\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2118 - accuracy: 0.9240 - val_loss: 0.1529 - val_accuracy: 0.9231\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1913 - accuracy: 0.9316 - val_loss: 0.1617 - val_accuracy: 0.9128\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1817 - accuracy: 0.9334 - val_loss: 0.1732 - val_accuracy: 0.9180\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1701 - accuracy: 0.9373 - val_loss: 0.1463 - val_accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1622 - accuracy: 0.9413 - val_loss: 0.1639 - val_accuracy: 0.9140\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1542 - accuracy: 0.9433 - val_loss: 0.1619 - val_accuracy: 0.9281\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1469 - accuracy: 0.9462 - val_loss: 0.1521 - val_accuracy: 0.9211\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1424 - accuracy: 0.9460 - val_loss: 0.1641 - val_accuracy: 0.9278\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1384 - accuracy: 0.9480 - val_loss: 0.1730 - val_accuracy: 0.9121\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 1 19910\n",
      "19910 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (TFOpL  (None, 8, 45)       0           ['input_19[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (TFOpL  (None, 11, 45)      0           ['input_20[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_18[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_18[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_19[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_19[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_18 (LayerN  (None, 8, 45)       90          ['multi_head_attention_18[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_19 (LayerN  (None, 11, 45)      90          ['multi_head_attention_19[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 8, 45)        0           ['layer_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 11, 45)       0           ['layer_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_18 (G  (None, 45)          0           ['dropout_36[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_19 (G  (None, 45)          0           ['dropout_37[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 90)           0           ['global_average_pooling1d_18[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_19[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 90)           0           ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 128)          11648       ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 128)          0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1)            129         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.4296 - accuracy: 0.8067 - val_loss: 0.2145 - val_accuracy: 0.9407\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2837 - accuracy: 0.8924 - val_loss: 0.1274 - val_accuracy: 0.9527\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2540 - accuracy: 0.9038 - val_loss: 0.0867 - val_accuracy: 0.9630\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2406 - accuracy: 0.9096 - val_loss: 0.0988 - val_accuracy: 0.9591\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2238 - accuracy: 0.9152 - val_loss: 0.1689 - val_accuracy: 0.9496\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2162 - accuracy: 0.9186 - val_loss: 0.1353 - val_accuracy: 0.9558\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2046 - accuracy: 0.9213 - val_loss: 0.1214 - val_accuracy: 0.9584\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1980 - accuracy: 0.9272 - val_loss: 0.0655 - val_accuracy: 0.9728\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1899 - accuracy: 0.9309 - val_loss: 0.0946 - val_accuracy: 0.9658\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1838 - accuracy: 0.9330 - val_loss: 0.1269 - val_accuracy: 0.9606\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (TFOpL  (None, 8, 45)       0           ['input_21[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (TFOpL  (None, 11, 45)      0           ['input_22[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_20[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_20[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_21[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_21[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_20 (LayerN  (None, 8, 45)       90          ['multi_head_attention_20[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_21 (LayerN  (None, 11, 45)      90          ['multi_head_attention_21[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 8, 45)        0           ['layer_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 11, 45)       0           ['layer_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_20 (G  (None, 45)          0           ['dropout_40[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_21 (G  (None, 45)          0           ['dropout_41[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_20[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_21[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 90)           0           ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 128)          11648       ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 128)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            129         ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.3051 - accuracy: 0.8521 - val_loss: 0.0517 - val_accuracy: 0.9804\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1697 - accuracy: 0.9338 - val_loss: 0.0675 - val_accuracy: 0.9728\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1505 - accuracy: 0.9418 - val_loss: 0.0452 - val_accuracy: 0.9869\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1362 - accuracy: 0.9495 - val_loss: 0.0559 - val_accuracy: 0.9830\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1306 - accuracy: 0.9510 - val_loss: 0.0341 - val_accuracy: 0.9935\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1279 - accuracy: 0.9519 - val_loss: 0.0426 - val_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1241 - accuracy: 0.9528 - val_loss: 0.0506 - val_accuracy: 0.9873\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1204 - accuracy: 0.9558 - val_loss: 0.0447 - val_accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1113 - accuracy: 0.9587 - val_loss: 0.0392 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1092 - accuracy: 0.9595 - val_loss: 0.0565 - val_accuracy: 0.9845\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (TFOpL  (None, 8, 45)       0           ['input_23[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (TFOpL  (None, 11, 45)      0           ['input_24[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_22[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_22[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_23[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_23[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_22 (LayerN  (None, 8, 45)       90          ['multi_head_attention_22[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_23 (LayerN  (None, 11, 45)      90          ['multi_head_attention_23[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 8, 45)        0           ['layer_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 11, 45)       0           ['layer_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_22 (G  (None, 45)          0           ['dropout_44[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_23 (G  (None, 45)          0           ['dropout_45[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_22[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_23[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 90)           0           ['concatenate_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 128)          11648       ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 128)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            129         ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.2166 - accuracy: 0.9250 - val_loss: 0.4696 - val_accuracy: 0.8772\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1180 - accuracy: 0.9731 - val_loss: 0.4310 - val_accuracy: 0.8777\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1128 - accuracy: 0.9732 - val_loss: 0.3907 - val_accuracy: 0.8784\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1073 - accuracy: 0.9749 - val_loss: 0.4124 - val_accuracy: 0.8784\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1039 - accuracy: 0.9745 - val_loss: 0.3633 - val_accuracy: 0.8789\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0995 - accuracy: 0.9750 - val_loss: 0.5179 - val_accuracy: 0.8772\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0953 - accuracy: 0.9751 - val_loss: 0.3389 - val_accuracy: 0.8734\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0911 - accuracy: 0.9749 - val_loss: 0.5277 - val_accuracy: 0.8784\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0820 - accuracy: 0.9753 - val_loss: 0.3129 - val_accuracy: 0.8781\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0736 - accuracy: 0.9762 - val_loss: 0.7100 - val_accuracy: 0.8755\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 8, 45)       0           ['input_25[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 11, 45)      0           ['input_26[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_24[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_25[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 8, 45)       90          ['multi_head_attention_24[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 11, 45)      90          ['multi_head_attention_25[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 8, 45)        0           ['layer_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 11, 45)       0           ['layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_24 (G  (None, 45)          0           ['dropout_48[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_25 (G  (None, 45)          0           ['dropout_49[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_24[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_25[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 90)           0           ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 128)          11648       ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 128)          0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1)            129         ['dropout_51[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.3763 - accuracy: 0.8416 - val_loss: 0.1967 - val_accuracy: 0.9642\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2515 - accuracy: 0.9088 - val_loss: 0.2527 - val_accuracy: 0.9465\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2290 - accuracy: 0.9153 - val_loss: 0.1340 - val_accuracy: 0.9577\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2158 - accuracy: 0.9180 - val_loss: 0.1159 - val_accuracy: 0.9651\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2038 - accuracy: 0.9213 - val_loss: 0.1040 - val_accuracy: 0.9670\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1925 - accuracy: 0.9272 - val_loss: 0.0833 - val_accuracy: 0.9740\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1848 - accuracy: 0.9291 - val_loss: 0.0998 - val_accuracy: 0.9613\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1790 - accuracy: 0.9324 - val_loss: 0.0827 - val_accuracy: 0.9742\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1714 - accuracy: 0.9355 - val_loss: 0.1008 - val_accuracy: 0.9646\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1701 - accuracy: 0.9381 - val_loss: 0.1174 - val_accuracy: 0.9601\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 8, 45)       0           ['input_27[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 11, 45)      0           ['input_28[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_26[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_27[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 8, 45)       90          ['multi_head_attention_26[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 11, 45)      90          ['multi_head_attention_27[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 8, 45)        0           ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 11, 45)       0           ['layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_26 (G  (None, 45)          0           ['dropout_52[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_27 (G  (None, 45)          0           ['dropout_53[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_26[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_27[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 90)           0           ['concatenate_13[0][0]']         \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 128)          11648       ['dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 128)          0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 1)            129         ['dropout_55[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.1410 - accuracy: 0.9443 - val_loss: 0.0424 - val_accuracy: 0.9847\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0360 - accuracy: 0.9911 - val_loss: 0.0273 - val_accuracy: 0.9933\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0275 - accuracy: 0.9927 - val_loss: 0.0157 - val_accuracy: 0.9945\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0144 - val_accuracy: 0.9952\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.0166 - val_accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.0132 - val_accuracy: 0.9967\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.0095 - val_accuracy: 0.9957\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0170 - val_accuracy: 0.9957\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0087 - val_accuracy: 0.9981\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.0184 - val_accuracy: 0.9955\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_29 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 8, 45)       0           ['input_29[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 11, 45)      0           ['input_30[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_28 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_28[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_29 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_29[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 8, 45)       90          ['multi_head_attention_28[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 11, 45)      90          ['multi_head_attention_29[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 8, 45)        0           ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 11, 45)       0           ['layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_28 (G  (None, 45)          0           ['dropout_56[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_29 (G  (None, 45)          0           ['dropout_57[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_28[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_29[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 90)           0           ['concatenate_14[0][0]']         \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          11648       ['dropout_58[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 128)          0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 1)            129         ['dropout_59[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1350 - accuracy: 0.9481 - val_loss: 0.0521 - val_accuracy: 0.9883\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0304 - accuracy: 0.9941 - val_loss: 0.0530 - val_accuracy: 0.9869\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0272 - accuracy: 0.9949 - val_loss: 0.0501 - val_accuracy: 0.9842\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0242 - accuracy: 0.9953 - val_loss: 0.0395 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 0.0447 - val_accuracy: 0.9890\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0204 - accuracy: 0.9961 - val_loss: 0.0489 - val_accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0205 - accuracy: 0.9961 - val_loss: 0.0438 - val_accuracy: 0.9895\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0182 - accuracy: 0.9965 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0213 - accuracy: 0.9958 - val_loss: 0.0824 - val_accuracy: 0.9830\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0208 - accuracy: 0.9961 - val_loss: 0.0580 - val_accuracy: 0.9878\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_31 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 8, 45)       0           ['input_31[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 11, 45)      0           ['input_32[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_30 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_30[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_31 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_31[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_31[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 8, 45)       90          ['multi_head_attention_30[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 11, 45)      90          ['multi_head_attention_31[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 8, 45)        0           ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 11, 45)       0           ['layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_30 (G  (None, 45)          0           ['dropout_60[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_31 (G  (None, 45)          0           ['dropout_61[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_30[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_31[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 90)           0           ['concatenate_15[0][0]']         \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 128)          11648       ['dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 128)          0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            129         ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.1757 - accuracy: 0.9343 - val_loss: 0.4048 - val_accuracy: 0.8705\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0941 - accuracy: 0.9772 - val_loss: 0.3900 - val_accuracy: 0.8731\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0871 - accuracy: 0.9780 - val_loss: 0.5536 - val_accuracy: 0.8621\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0815 - accuracy: 0.9788 - val_loss: 0.3863 - val_accuracy: 0.8714\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0747 - accuracy: 0.9793 - val_loss: 0.5365 - val_accuracy: 0.8722\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0694 - accuracy: 0.9798 - val_loss: 0.6979 - val_accuracy: 0.8691\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0763 - accuracy: 0.9797 - val_loss: 0.5103 - val_accuracy: 0.8700\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0750 - accuracy: 0.9803 - val_loss: 0.4593 - val_accuracy: 0.8712\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0730 - accuracy: 0.9812 - val_loss: 0.4769 - val_accuracy: 0.8691\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0716 - accuracy: 0.9809 - val_loss: 0.6004 - val_accuracy: 0.8691\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19910 0001 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19910 3d57 [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19910 ed9c [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19910 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_33 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 8, 45)       0           ['input_33[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 11, 45)      0           ['input_34[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_32 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_32[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_33 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_33[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 8, 45)       90          ['multi_head_attention_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 11, 45)      90          ['multi_head_attention_33[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 8, 45)        0           ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)           (None, 11, 45)       0           ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_32 (G  (None, 45)          0           ['dropout_64[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_33 (G  (None, 45)          0           ['dropout_65[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_32[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_33[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 90)           0           ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 128)          11648       ['dropout_66[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 128)          0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 1)            129         ['dropout_67[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19910 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.3129 - accuracy: 0.8641 - val_loss: 0.0887 - val_accuracy: 0.9541\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2017 - accuracy: 0.9272 - val_loss: 0.1018 - val_accuracy: 0.9556\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1817 - accuracy: 0.9351 - val_loss: 0.0797 - val_accuracy: 0.9603\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1688 - accuracy: 0.9376 - val_loss: 0.0813 - val_accuracy: 0.9646\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1625 - accuracy: 0.9396 - val_loss: 0.0705 - val_accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1551 - accuracy: 0.9406 - val_loss: 0.1027 - val_accuracy: 0.9577\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1480 - accuracy: 0.9433 - val_loss: 0.0892 - val_accuracy: 0.9596\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1415 - accuracy: 0.9463 - val_loss: 0.0830 - val_accuracy: 0.9563\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1353 - accuracy: 0.9489 - val_loss: 0.0914 - val_accuracy: 0.9611\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1350 - accuracy: 0.9489 - val_loss: 0.0839 - val_accuracy: 0.9632\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 2 19911\n",
      "19911 ['0001', '3d57', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_35 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 8, 45)       0           ['input_35[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 11, 45)      0           ['input_36[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_34 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_34[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_35 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_35[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 8, 45)       90          ['multi_head_attention_34[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 11, 45)      90          ['multi_head_attention_35[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_68 (Dropout)           (None, 8, 45)        0           ['layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 11, 45)       0           ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_34 (G  (None, 45)          0           ['dropout_68[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_35 (G  (None, 45)          0           ['dropout_69[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_34[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_35[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_70 (Dropout)           (None, 90)           0           ['concatenate_17[0][0]']         \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 128)          11648       ['dropout_70[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 128)          0           ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 1)            129         ['dropout_71[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.4226 - accuracy: 0.8064 - val_loss: 0.2034 - val_accuracy: 0.9515\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2771 - accuracy: 0.8939 - val_loss: 0.2168 - val_accuracy: 0.9269\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2397 - accuracy: 0.9116 - val_loss: 0.2741 - val_accuracy: 0.9011\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2218 - accuracy: 0.9186 - val_loss: 0.1898 - val_accuracy: 0.9355\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2121 - accuracy: 0.9235 - val_loss: 0.2373 - val_accuracy: 0.9109\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1987 - accuracy: 0.9271 - val_loss: 0.2797 - val_accuracy: 0.8987\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1933 - accuracy: 0.9303 - val_loss: 0.2510 - val_accuracy: 0.9106\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1855 - accuracy: 0.9346 - val_loss: 0.1819 - val_accuracy: 0.9350\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1833 - accuracy: 0.9350 - val_loss: 0.1205 - val_accuracy: 0.9570\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1773 - accuracy: 0.9371 - val_loss: 0.2259 - val_accuracy: 0.9266\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_38 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (TFOpL  (None, 8, 45)       0           ['input_37[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (TFOpL  (None, 11, 45)      0           ['input_38[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_36 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_36[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_36[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_37 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_37[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_37[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 8, 45)       90          ['multi_head_attention_36[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 11, 45)      90          ['multi_head_attention_37[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 8, 45)        0           ['layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 11, 45)       0           ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_36 (G  (None, 45)          0           ['dropout_72[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_37 (G  (None, 45)          0           ['dropout_73[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_36[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_37[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 90)           0           ['concatenate_18[0][0]']         \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 128)          11648       ['dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 128)          0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 1)            129         ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3843 - accuracy: 0.8042 - val_loss: 0.1853 - val_accuracy: 0.9192\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1690 - accuracy: 0.9313 - val_loss: 0.1731 - val_accuracy: 0.9405\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1569 - accuracy: 0.9353 - val_loss: 0.1252 - val_accuracy: 0.9634\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1418 - accuracy: 0.9412 - val_loss: 0.1827 - val_accuracy: 0.9505\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1405 - accuracy: 0.9430 - val_loss: 0.1547 - val_accuracy: 0.9515\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1314 - accuracy: 0.9465 - val_loss: 0.1806 - val_accuracy: 0.9448\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1238 - accuracy: 0.9518 - val_loss: 0.1619 - val_accuracy: 0.9615\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1190 - accuracy: 0.9544 - val_loss: 0.1753 - val_accuracy: 0.9589\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1131 - accuracy: 0.9556 - val_loss: 0.1437 - val_accuracy: 0.9498\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1073 - accuracy: 0.9586 - val_loss: 0.1801 - val_accuracy: 0.9565\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_39 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_40 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (TFOpL  (None, 8, 45)       0           ['input_39[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (TFOpL  (None, 11, 45)      0           ['input_40[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_38 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_38[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_38[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_39 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_39[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_39[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 8, 45)       90          ['multi_head_attention_38[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 11, 45)      90          ['multi_head_attention_39[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)           (None, 8, 45)        0           ['layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 11, 45)       0           ['layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_38 (G  (None, 45)          0           ['dropout_76[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_39 (G  (None, 45)          0           ['dropout_77[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_38[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_39[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 90)           0           ['concatenate_19[0][0]']         \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 128)          11648       ['dropout_78[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_79 (Dropout)           (None, 128)          0           ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 1)            129         ['dropout_79[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.2044 - accuracy: 0.9249 - val_loss: 0.6055 - val_accuracy: 0.8363\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1069 - accuracy: 0.9785 - val_loss: 0.6847 - val_accuracy: 0.8368\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0984 - accuracy: 0.9796 - val_loss: 0.7450 - val_accuracy: 0.8311\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0961 - accuracy: 0.9800 - val_loss: 0.6301 - val_accuracy: 0.8356\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0907 - accuracy: 0.9802 - val_loss: 0.5695 - val_accuracy: 0.8368\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0894 - accuracy: 0.9799 - val_loss: 0.5447 - val_accuracy: 0.8382\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0879 - accuracy: 0.9805 - val_loss: 0.5683 - val_accuracy: 0.8368\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0817 - accuracy: 0.9815 - val_loss: 0.7257 - val_accuracy: 0.8323\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0800 - accuracy: 0.9815 - val_loss: 0.7177 - val_accuracy: 0.8361\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0816 - accuracy: 0.9806 - val_loss: 0.5137 - val_accuracy: 0.8366\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_41 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_42 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (TFOpL  (None, 8, 45)       0           ['input_41[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (TFOpL  (None, 11, 45)      0           ['input_42[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_40 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_40[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_40[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_41 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_41[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_41[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 8, 45)       90          ['multi_head_attention_40[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 11, 45)      90          ['multi_head_attention_41[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 8, 45)        0           ['layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_81 (Dropout)           (None, 11, 45)       0           ['layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_40 (G  (None, 45)          0           ['dropout_80[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_41 (G  (None, 45)          0           ['dropout_81[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_40[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_41[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_82 (Dropout)           (None, 90)           0           ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 128)          11648       ['dropout_82[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_83 (Dropout)           (None, 128)          0           ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 1)            129         ['dropout_83[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3714 - accuracy: 0.8425 - val_loss: 0.2148 - val_accuracy: 0.9360\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2633 - accuracy: 0.9043 - val_loss: 0.2113 - val_accuracy: 0.9305\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2425 - accuracy: 0.9111 - val_loss: 0.1248 - val_accuracy: 0.9505\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2285 - accuracy: 0.9149 - val_loss: 0.2769 - val_accuracy: 0.9223\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2184 - accuracy: 0.9186 - val_loss: 0.2646 - val_accuracy: 0.9070\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2085 - accuracy: 0.9231 - val_loss: 0.2062 - val_accuracy: 0.9331\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2023 - accuracy: 0.9260 - val_loss: 0.1230 - val_accuracy: 0.9599\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1915 - accuracy: 0.9279 - val_loss: 0.1584 - val_accuracy: 0.9510\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1871 - accuracy: 0.9313 - val_loss: 0.1255 - val_accuracy: 0.9565\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1823 - accuracy: 0.9323 - val_loss: 0.1258 - val_accuracy: 0.9606\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_43 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_44 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (TFOpL  (None, 8, 45)       0           ['input_43[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (TFOpL  (None, 11, 45)      0           ['input_44[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_42 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_42[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_42[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_43 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_43[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_43[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 8, 45)       90          ['multi_head_attention_42[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 11, 45)      90          ['multi_head_attention_43[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_84 (Dropout)           (None, 8, 45)        0           ['layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_85 (Dropout)           (None, 11, 45)       0           ['layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_42 (G  (None, 45)          0           ['dropout_84[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_43 (G  (None, 45)          0           ['dropout_85[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_42[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_43[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_86 (Dropout)           (None, 90)           0           ['concatenate_21[0][0]']         \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 128)          11648       ['dropout_86[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_87 (Dropout)           (None, 128)          0           ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 1)            129         ['dropout_87[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1354 - accuracy: 0.9442 - val_loss: 0.0291 - val_accuracy: 0.9909\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 0.0342 - val_accuracy: 0.9926\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0389 - val_accuracy: 0.9940\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0184 - accuracy: 0.9956 - val_loss: 0.0456 - val_accuracy: 0.9938\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 0.0527 - val_accuracy: 0.9928\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0468 - val_accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.0634 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0601 - val_accuracy: 0.9971\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0577 - val_accuracy: 0.9964\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.0710 - val_accuracy: 0.9933\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_45 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_46 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  (None, 8, 45)       0           ['input_45[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (TFOpL  (None, 11, 45)      0           ['input_46[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_44 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_44[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_45 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_45[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_45[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 8, 45)       90          ['multi_head_attention_44[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 11, 45)      90          ['multi_head_attention_45[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 8, 45)        0           ['layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 11, 45)       0           ['layer_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_44 (G  (None, 45)          0           ['dropout_88[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_45 (G  (None, 45)          0           ['dropout_89[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_44[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_45[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_90 (Dropout)           (None, 90)           0           ['concatenate_22[0][0]']         \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 128)          11648       ['dropout_90[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)           (None, 128)          0           ['dense_44[0][0]']               \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 1)            129         ['dropout_91[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 18ms/step - loss: 0.1314 - accuracy: 0.9511 - val_loss: 0.0269 - val_accuracy: 0.9902\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0362 - accuracy: 0.9925 - val_loss: 0.0237 - val_accuracy: 0.9938\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0309 - accuracy: 0.9935 - val_loss: 0.0163 - val_accuracy: 0.9959\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0266 - accuracy: 0.9946 - val_loss: 0.0100 - val_accuracy: 0.9978\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0231 - accuracy: 0.9954 - val_loss: 0.0141 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 0.0360 - val_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0255 - accuracy: 0.9949 - val_loss: 0.0189 - val_accuracy: 0.9940\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0252 - accuracy: 0.9947 - val_loss: 0.0159 - val_accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0214 - accuracy: 0.9961 - val_loss: 0.0186 - val_accuracy: 0.9945\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0251 - accuracy: 0.9950 - val_loss: 0.0192 - val_accuracy: 0.9931\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_47 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_48 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_46 (TFOpL  (None, 8, 45)       0           ['input_47[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (TFOpL  (None, 11, 45)      0           ['input_48[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_46 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_46[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_46[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_47 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_47[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_47[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 8, 45)       90          ['multi_head_attention_46[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 11, 45)      90          ['multi_head_attention_47[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)           (None, 8, 45)        0           ['layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)           (None, 11, 45)       0           ['layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_46 (G  (None, 45)          0           ['dropout_92[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_47 (G  (None, 45)          0           ['dropout_93[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_46[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)           (None, 90)           0           ['concatenate_23[0][0]']         \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 128)          11648       ['dropout_94[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)           (None, 128)          0           ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 1)            129         ['dropout_95[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1633 - accuracy: 0.9439 - val_loss: 0.3934 - val_accuracy: 0.8691\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0947 - accuracy: 0.9777 - val_loss: 0.4165 - val_accuracy: 0.8562\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0886 - accuracy: 0.9789 - val_loss: 0.4305 - val_accuracy: 0.8583\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0840 - accuracy: 0.9795 - val_loss: 0.3874 - val_accuracy: 0.8578\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0847 - accuracy: 0.9790 - val_loss: 0.4612 - val_accuracy: 0.8595\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0797 - accuracy: 0.9808 - val_loss: 0.5233 - val_accuracy: 0.8600\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0753 - accuracy: 0.9815 - val_loss: 0.4828 - val_accuracy: 0.8602\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0782 - accuracy: 0.9808 - val_loss: 0.4966 - val_accuracy: 0.8597\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0765 - accuracy: 0.9811 - val_loss: 0.5457 - val_accuracy: 0.8605\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0742 - accuracy: 0.9817 - val_loss: 0.5435 - val_accuracy: 0.8607\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 0001\n",
      "19911 0001 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 3d57\n",
      "19911 3d57 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19911 ed9c [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19911 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_49 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_50 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_48 (TFOpL  (None, 8, 45)       0           ['input_49[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_49 (TFOpL  (None, 11, 45)      0           ['input_50[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_48 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_48[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_48[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_49 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_49[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_49[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_48 (LayerN  (None, 8, 45)       90          ['multi_head_attention_48[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 11, 45)      90          ['multi_head_attention_49[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_96 (Dropout)           (None, 8, 45)        0           ['layer_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_97 (Dropout)           (None, 11, 45)       0           ['layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_48 (G  (None, 45)          0           ['dropout_96[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_49 (G  (None, 45)          0           ['dropout_97[0][0]']             \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_48[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_49[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_98 (Dropout)           (None, 90)           0           ['concatenate_24[0][0]']         \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 128)          11648       ['dropout_98[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_99 (Dropout)           (None, 128)          0           ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 1)            129         ['dropout_99[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19911 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3046 - accuracy: 0.8729 - val_loss: 0.1468 - val_accuracy: 0.9027\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2130 - accuracy: 0.9241 - val_loss: 0.1805 - val_accuracy: 0.8918\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1898 - accuracy: 0.9312 - val_loss: 0.1619 - val_accuracy: 0.9085\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1766 - accuracy: 0.9360 - val_loss: 0.1408 - val_accuracy: 0.9395\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1668 - accuracy: 0.9399 - val_loss: 0.1307 - val_accuracy: 0.9484\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1557 - accuracy: 0.9435 - val_loss: 0.1461 - val_accuracy: 0.9336\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1475 - accuracy: 0.9462 - val_loss: 0.1741 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1409 - accuracy: 0.9473 - val_loss: 0.1763 - val_accuracy: 0.9262\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1379 - accuracy: 0.9498 - val_loss: 0.2249 - val_accuracy: 0.9211\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1349 - accuracy: 0.9499 - val_loss: 0.1477 - val_accuracy: 0.9362\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 3 19922\n",
      "19922 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_51 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_52 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_50 (TFOpL  (None, 8, 45)       0           ['input_51[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_51 (TFOpL  (None, 11, 45)      0           ['input_52[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_50 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_50[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_50[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_51 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_51[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_51[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 8, 45)       90          ['multi_head_attention_50[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 11, 45)      90          ['multi_head_attention_51[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_100 (Dropout)          (None, 8, 45)        0           ['layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_101 (Dropout)          (None, 11, 45)       0           ['layer_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_50 (G  (None, 45)          0           ['dropout_100[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_51 (G  (None, 45)          0           ['dropout_101[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_50[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_51[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_102 (Dropout)          (None, 90)           0           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 128)          11648       ['dropout_102[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_103 (Dropout)          (None, 128)          0           ['dense_50[0][0]']               \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 1)            129         ['dropout_103[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.4202 - accuracy: 0.8040 - val_loss: 0.1845 - val_accuracy: 0.9262\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2741 - accuracy: 0.8986 - val_loss: 0.2782 - val_accuracy: 0.8989\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.2480 - accuracy: 0.9059 - val_loss: 0.1917 - val_accuracy: 0.9257\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2294 - accuracy: 0.9149 - val_loss: 0.1753 - val_accuracy: 0.9410\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2137 - accuracy: 0.9203 - val_loss: 0.2264 - val_accuracy: 0.9211\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2094 - accuracy: 0.9223 - val_loss: 0.2472 - val_accuracy: 0.9092\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1991 - accuracy: 0.9248 - val_loss: 0.1781 - val_accuracy: 0.9345\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1899 - accuracy: 0.9301 - val_loss: 0.1520 - val_accuracy: 0.9496\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1849 - accuracy: 0.9326 - val_loss: 0.1462 - val_accuracy: 0.9486\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1780 - accuracy: 0.9348 - val_loss: 0.1856 - val_accuracy: 0.9441\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_53 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_54 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_52 (TFOpL  (None, 8, 45)       0           ['input_53[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_53 (TFOpL  (None, 11, 45)      0           ['input_54[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_52 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_52[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_52[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_53 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_53[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_53[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 8, 45)       90          ['multi_head_attention_52[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 11, 45)      90          ['multi_head_attention_53[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_104 (Dropout)          (None, 8, 45)        0           ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_105 (Dropout)          (None, 11, 45)       0           ['layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_52 (G  (None, 45)          0           ['dropout_104[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_53 (G  (None, 45)          0           ['dropout_105[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_52[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_53[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_106 (Dropout)          (None, 90)           0           ['concatenate_26[0][0]']         \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 128)          11648       ['dropout_106[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_107 (Dropout)          (None, 128)          0           ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 1)            129         ['dropout_107[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3527 - accuracy: 0.8280 - val_loss: 0.2971 - val_accuracy: 0.8363\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1718 - accuracy: 0.9311 - val_loss: 0.2551 - val_accuracy: 0.8867\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1538 - accuracy: 0.9396 - val_loss: 0.2227 - val_accuracy: 0.8970\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1329 - accuracy: 0.9488 - val_loss: 0.2180 - val_accuracy: 0.8927\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1221 - accuracy: 0.9542 - val_loss: 0.2162 - val_accuracy: 0.8958\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1193 - accuracy: 0.9557 - val_loss: 0.2599 - val_accuracy: 0.8724\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1142 - accuracy: 0.9570 - val_loss: 0.2151 - val_accuracy: 0.8930\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1086 - accuracy: 0.9598 - val_loss: 0.2280 - val_accuracy: 0.8958\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1045 - accuracy: 0.9605 - val_loss: 0.3327 - val_accuracy: 0.8671\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1012 - accuracy: 0.9620 - val_loss: 0.2232 - val_accuracy: 0.8906\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_55 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_56 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_54 (TFOpL  (None, 8, 45)       0           ['input_55[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_55 (TFOpL  (None, 11, 45)      0           ['input_56[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_54 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_54[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_54[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_55 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_55[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_55[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 8, 45)       90          ['multi_head_attention_54[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 11, 45)      90          ['multi_head_attention_55[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_108 (Dropout)          (None, 8, 45)        0           ['layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_109 (Dropout)          (None, 11, 45)       0           ['layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_54 (G  (None, 45)          0           ['dropout_108[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_55 (G  (None, 45)          0           ['dropout_109[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_54[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_55[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_110 (Dropout)          (None, 90)           0           ['concatenate_27[0][0]']         \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 128)          11648       ['dropout_110[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_111 (Dropout)          (None, 128)          0           ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 1)            129         ['dropout_111[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.2294 - accuracy: 0.9234 - val_loss: 0.0792 - val_accuracy: 0.9895\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1426 - accuracy: 0.9667 - val_loss: 0.1000 - val_accuracy: 0.9873\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1330 - accuracy: 0.9683 - val_loss: 0.1065 - val_accuracy: 0.9826\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1289 - accuracy: 0.9685 - val_loss: 0.0851 - val_accuracy: 0.9890\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1272 - accuracy: 0.9685 - val_loss: 0.0648 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1281 - accuracy: 0.9683 - val_loss: 0.0749 - val_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1221 - accuracy: 0.9692 - val_loss: 0.0773 - val_accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1216 - accuracy: 0.9690 - val_loss: 0.0796 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1202 - accuracy: 0.9692 - val_loss: 0.0566 - val_accuracy: 0.9904\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1162 - accuracy: 0.9694 - val_loss: 0.0647 - val_accuracy: 0.9900\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_57 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_58 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_56 (TFOpL  (None, 8, 45)       0           ['input_57[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_57 (TFOpL  (None, 11, 45)      0           ['input_58[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_56 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_56[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_56[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_57 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_57[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_57[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 8, 45)       90          ['multi_head_attention_56[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 11, 45)      90          ['multi_head_attention_57[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_112 (Dropout)          (None, 8, 45)        0           ['layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_113 (Dropout)          (None, 11, 45)       0           ['layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_56 (G  (None, 45)          0           ['dropout_112[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_57 (G  (None, 45)          0           ['dropout_113[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_56[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_57[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_114 (Dropout)          (None, 90)           0           ['concatenate_28[0][0]']         \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 128)          11648       ['dropout_114[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_115 (Dropout)          (None, 128)          0           ['dense_56[0][0]']               \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 1)            129         ['dropout_115[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3707 - accuracy: 0.8450 - val_loss: 0.1786 - val_accuracy: 0.9357\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2528 - accuracy: 0.9066 - val_loss: 0.3785 - val_accuracy: 0.8789\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2317 - accuracy: 0.9133 - val_loss: 0.1716 - val_accuracy: 0.9297\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2130 - accuracy: 0.9167 - val_loss: 0.1512 - val_accuracy: 0.9436\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2032 - accuracy: 0.9230 - val_loss: 0.2677 - val_accuracy: 0.8724\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1894 - accuracy: 0.9267 - val_loss: 0.2310 - val_accuracy: 0.9157\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1860 - accuracy: 0.9294 - val_loss: 0.2380 - val_accuracy: 0.9202\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1772 - accuracy: 0.9329 - val_loss: 0.2539 - val_accuracy: 0.8798\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1698 - accuracy: 0.9367 - val_loss: 0.2241 - val_accuracy: 0.9087\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1705 - accuracy: 0.9356 - val_loss: 0.1632 - val_accuracy: 0.9369\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_59 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_60 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_58 (TFOpL  (None, 8, 45)       0           ['input_59[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_59 (TFOpL  (None, 11, 45)      0           ['input_60[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_58 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_58[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_58[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_59 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_59[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_59[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_58 (LayerN  (None, 8, 45)       90          ['multi_head_attention_58[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_59 (LayerN  (None, 11, 45)      90          ['multi_head_attention_59[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_116 (Dropout)          (None, 8, 45)        0           ['layer_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_117 (Dropout)          (None, 11, 45)       0           ['layer_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_58 (G  (None, 45)          0           ['dropout_116[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_59 (G  (None, 45)          0           ['dropout_117[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_58[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_59[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_118 (Dropout)          (None, 90)           0           ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 128)          11648       ['dropout_118[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_119 (Dropout)          (None, 128)          0           ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 1)            129         ['dropout_119[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.1308 - accuracy: 0.9487 - val_loss: 0.0907 - val_accuracy: 0.9787\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0336 - accuracy: 0.9916 - val_loss: 0.0886 - val_accuracy: 0.9809\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0253 - accuracy: 0.9940 - val_loss: 0.0643 - val_accuracy: 0.9866\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0647 - val_accuracy: 0.9883\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.0697 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0864 - val_accuracy: 0.9857\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0427 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.0716 - val_accuracy: 0.9904\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0598 - val_accuracy: 0.9904\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.0410 - val_accuracy: 0.9916\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_61 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_62 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_60 (TFOpL  (None, 8, 45)       0           ['input_61[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_61 (TFOpL  (None, 11, 45)      0           ['input_62[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_60 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_60[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_60[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_61 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_61[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_61[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_60 (LayerN  (None, 8, 45)       90          ['multi_head_attention_60[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_61 (LayerN  (None, 11, 45)      90          ['multi_head_attention_61[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_120 (Dropout)          (None, 8, 45)        0           ['layer_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_121 (Dropout)          (None, 11, 45)       0           ['layer_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_60 (G  (None, 45)          0           ['dropout_120[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_61 (G  (None, 45)          0           ['dropout_121[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_60[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_61[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_122 (Dropout)          (None, 90)           0           ['concatenate_30[0][0]']         \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 128)          11648       ['dropout_122[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_123 (Dropout)          (None, 128)          0           ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 1)            129         ['dropout_123[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1143 - accuracy: 0.9560 - val_loss: 0.0812 - val_accuracy: 0.9785\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0312 - accuracy: 0.9938 - val_loss: 0.0953 - val_accuracy: 0.9787\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0291 - accuracy: 0.9942 - val_loss: 0.0886 - val_accuracy: 0.9823\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0245 - accuracy: 0.9952 - val_loss: 0.0874 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0235 - accuracy: 0.9955 - val_loss: 0.0823 - val_accuracy: 0.9845\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0263 - accuracy: 0.9941 - val_loss: 0.0829 - val_accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0218 - accuracy: 0.9956 - val_loss: 0.0731 - val_accuracy: 0.9845\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0214 - accuracy: 0.9958 - val_loss: 0.0871 - val_accuracy: 0.9816\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 0.0882 - val_accuracy: 0.9792\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0207 - accuracy: 0.9961 - val_loss: 0.0782 - val_accuracy: 0.9845\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_63 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_64 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_62 (TFOpL  (None, 8, 45)       0           ['input_63[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_63 (TFOpL  (None, 11, 45)      0           ['input_64[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_62 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_62[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_62[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_63 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_63[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_63[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_62 (LayerN  (None, 8, 45)       90          ['multi_head_attention_62[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_63 (LayerN  (None, 11, 45)      90          ['multi_head_attention_63[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_124 (Dropout)          (None, 8, 45)        0           ['layer_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_125 (Dropout)          (None, 11, 45)       0           ['layer_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_62 (G  (None, 45)          0           ['dropout_124[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_63 (G  (None, 45)          0           ['dropout_125[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_62[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_63[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_126 (Dropout)          (None, 90)           0           ['concatenate_31[0][0]']         \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 128)          11648       ['dropout_126[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_127 (Dropout)          (None, 128)          0           ['dense_62[0][0]']               \n",
      "                                                                                                  \n",
      " dense_63 (Dense)               (None, 1)            129         ['dropout_127[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.2041 - accuracy: 0.9209 - val_loss: 0.0430 - val_accuracy: 0.9897\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1121 - accuracy: 0.9713 - val_loss: 0.0366 - val_accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1050 - accuracy: 0.9725 - val_loss: 0.0432 - val_accuracy: 0.9943\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1011 - accuracy: 0.9733 - val_loss: 0.0310 - val_accuracy: 0.9916\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0973 - accuracy: 0.9743 - val_loss: 0.0343 - val_accuracy: 0.9890\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0968 - accuracy: 0.9736 - val_loss: 0.0311 - val_accuracy: 0.9904\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0921 - accuracy: 0.9749 - val_loss: 0.0444 - val_accuracy: 0.9897\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0895 - accuracy: 0.9750 - val_loss: 0.0543 - val_accuracy: 0.9881\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0856 - accuracy: 0.9756 - val_loss: 0.0595 - val_accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0827 - accuracy: 0.9762 - val_loss: 0.0510 - val_accuracy: 0.9895\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19922 16fe [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19922 f02e [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19922 ed9c [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19922 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_65 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_66 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_64 (TFOpL  (None, 8, 45)       0           ['input_65[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_65 (TFOpL  (None, 11, 45)      0           ['input_66[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_64 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_64[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_64[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_65 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_65[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_65[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_64 (LayerN  (None, 8, 45)       90          ['multi_head_attention_64[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_65 (LayerN  (None, 11, 45)      90          ['multi_head_attention_65[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_128 (Dropout)          (None, 8, 45)        0           ['layer_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_129 (Dropout)          (None, 11, 45)       0           ['layer_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_64 (G  (None, 45)          0           ['dropout_128[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_65 (G  (None, 45)          0           ['dropout_129[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_64[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_65[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_130 (Dropout)          (None, 90)           0           ['concatenate_32[0][0]']         \n",
      "                                                                                                  \n",
      " dense_64 (Dense)               (None, 128)          11648       ['dropout_130[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, 128)          0           ['dense_64[0][0]']               \n",
      "                                                                                                  \n",
      " dense_65 (Dense)               (None, 1)            129         ['dropout_131[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19922 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3201 - accuracy: 0.8662 - val_loss: 0.2560 - val_accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2057 - accuracy: 0.9295 - val_loss: 0.3197 - val_accuracy: 0.8308\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1839 - accuracy: 0.9333 - val_loss: 0.4248 - val_accuracy: 0.8103\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1699 - accuracy: 0.9356 - val_loss: 0.3480 - val_accuracy: 0.8492\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1564 - accuracy: 0.9408 - val_loss: 0.4692 - val_accuracy: 0.8335\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1518 - accuracy: 0.9422 - val_loss: 0.2322 - val_accuracy: 0.8736\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1445 - accuracy: 0.9431 - val_loss: 0.2741 - val_accuracy: 0.8679\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1365 - accuracy: 0.9471 - val_loss: 0.3558 - val_accuracy: 0.8476\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1333 - accuracy: 0.9494 - val_loss: 0.2792 - val_accuracy: 0.8719\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1298 - accuracy: 0.9495 - val_loss: 0.2507 - val_accuracy: 0.8616\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 4 19923\n",
      "19923 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_67 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_68 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_66 (TFOpL  (None, 8, 45)       0           ['input_67[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_67 (TFOpL  (None, 11, 45)      0           ['input_68[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_66 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_66[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_66[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_67 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_67[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_67[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_66 (LayerN  (None, 8, 45)       90          ['multi_head_attention_66[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_67 (LayerN  (None, 11, 45)      90          ['multi_head_attention_67[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_132 (Dropout)          (None, 8, 45)        0           ['layer_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_133 (Dropout)          (None, 11, 45)       0           ['layer_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_66 (G  (None, 45)          0           ['dropout_132[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_67 (G  (None, 45)          0           ['dropout_133[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_66[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_67[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_134 (Dropout)          (None, 90)           0           ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 128)          11648       ['dropout_134[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_135 (Dropout)          (None, 128)          0           ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 1)            129         ['dropout_135[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.4205 - accuracy: 0.8050 - val_loss: 0.1896 - val_accuracy: 0.9245\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2688 - accuracy: 0.8995 - val_loss: 0.2357 - val_accuracy: 0.9243\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2450 - accuracy: 0.9086 - val_loss: 0.1743 - val_accuracy: 0.9491\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2221 - accuracy: 0.9183 - val_loss: 0.1776 - val_accuracy: 0.9403\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2090 - accuracy: 0.9231 - val_loss: 0.2661 - val_accuracy: 0.9276\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1987 - accuracy: 0.9262 - val_loss: 0.1599 - val_accuracy: 0.9441\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1916 - accuracy: 0.9301 - val_loss: 0.1839 - val_accuracy: 0.9367\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1836 - accuracy: 0.9325 - val_loss: 0.2633 - val_accuracy: 0.9152\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1775 - accuracy: 0.9346 - val_loss: 0.1507 - val_accuracy: 0.9486\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1747 - accuracy: 0.9360 - val_loss: 0.1240 - val_accuracy: 0.9572\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_69 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_70 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (TFOpL  (None, 8, 45)       0           ['input_69[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (TFOpL  (None, 11, 45)      0           ['input_70[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_68 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_68[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_69 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_69[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_68 (LayerN  (None, 8, 45)       90          ['multi_head_attention_68[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_69 (LayerN  (None, 11, 45)      90          ['multi_head_attention_69[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 8, 45)        0           ['layer_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 11, 45)       0           ['layer_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_68 (G  (None, 45)          0           ['dropout_136[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_69 (G  (None, 45)          0           ['dropout_137[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_68[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_69[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 90)           0           ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 128)          11648       ['dropout_138[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 128)          0           ['dense_68[0][0]']               \n",
      "                                                                                                  \n",
      " dense_69 (Dense)               (None, 1)            129         ['dropout_139[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3601 - accuracy: 0.8165 - val_loss: 0.1542 - val_accuracy: 0.9508\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1659 - accuracy: 0.9328 - val_loss: 0.1961 - val_accuracy: 0.9254\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1439 - accuracy: 0.9427 - val_loss: 0.1393 - val_accuracy: 0.9532\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1319 - accuracy: 0.9483 - val_loss: 0.1895 - val_accuracy: 0.9367\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1219 - accuracy: 0.9534 - val_loss: 0.2347 - val_accuracy: 0.9085\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1161 - accuracy: 0.9564 - val_loss: 0.1451 - val_accuracy: 0.9501\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1125 - accuracy: 0.9577 - val_loss: 0.1588 - val_accuracy: 0.9381\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1074 - accuracy: 0.9590 - val_loss: 0.2024 - val_accuracy: 0.9341\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1040 - accuracy: 0.9612 - val_loss: 0.2396 - val_accuracy: 0.9147\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1025 - accuracy: 0.9624 - val_loss: 0.1569 - val_accuracy: 0.9470\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_71 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_72 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 8, 45)       0           ['input_71[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 11, 45)      0           ['input_72[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_70 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_70[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_71 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_71[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_71[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_70 (LayerN  (None, 8, 45)       90          ['multi_head_attention_70[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_71 (LayerN  (None, 11, 45)      90          ['multi_head_attention_71[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 8, 45)        0           ['layer_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 11, 45)       0           ['layer_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_70 (G  (None, 45)          0           ['dropout_140[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_71 (G  (None, 45)          0           ['dropout_141[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_70[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_71[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 90)           0           ['concatenate_35[0][0]']         \n",
      "                                                                                                  \n",
      " dense_70 (Dense)               (None, 128)          11648       ['dropout_142[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 128)          0           ['dense_70[0][0]']               \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 1)            129         ['dropout_143[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.2391 - accuracy: 0.9157 - val_loss: 0.0861 - val_accuracy: 0.9866\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1432 - accuracy: 0.9687 - val_loss: 0.0851 - val_accuracy: 0.9838\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1300 - accuracy: 0.9702 - val_loss: 0.1049 - val_accuracy: 0.9873\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1241 - accuracy: 0.9705 - val_loss: 0.0752 - val_accuracy: 0.9876\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1191 - accuracy: 0.9704 - val_loss: 0.1015 - val_accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1169 - accuracy: 0.9711 - val_loss: 0.0892 - val_accuracy: 0.9876\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1144 - accuracy: 0.9711 - val_loss: 0.0776 - val_accuracy: 0.9888\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1097 - accuracy: 0.9712 - val_loss: 0.0816 - val_accuracy: 0.9864\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1008 - accuracy: 0.9718 - val_loss: 0.0890 - val_accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0993 - accuracy: 0.9713 - val_loss: 0.0774 - val_accuracy: 0.9885\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_73 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_74 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_72 (TFOpL  (None, 8, 45)       0           ['input_73[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_73 (TFOpL  (None, 11, 45)      0           ['input_74[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_72 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_72[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_72[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_73 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_73[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_73[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_72 (LayerN  (None, 8, 45)       90          ['multi_head_attention_72[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_73 (LayerN  (None, 11, 45)      90          ['multi_head_attention_73[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_144 (Dropout)          (None, 8, 45)        0           ['layer_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_145 (Dropout)          (None, 11, 45)       0           ['layer_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_72 (G  (None, 45)          0           ['dropout_144[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_73 (G  (None, 45)          0           ['dropout_145[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_72[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_73[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 90)           0           ['concatenate_36[0][0]']         \n",
      "                                                                                                  \n",
      " dense_72 (Dense)               (None, 128)          11648       ['dropout_146[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 128)          0           ['dense_72[0][0]']               \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 1)            129         ['dropout_147[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3551 - accuracy: 0.8517 - val_loss: 0.1515 - val_accuracy: 0.9474\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2481 - accuracy: 0.9107 - val_loss: 0.1485 - val_accuracy: 0.9364\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2267 - accuracy: 0.9164 - val_loss: 0.1935 - val_accuracy: 0.9171\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2129 - accuracy: 0.9196 - val_loss: 0.1518 - val_accuracy: 0.9331\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2015 - accuracy: 0.9239 - val_loss: 0.1988 - val_accuracy: 0.9307\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1921 - accuracy: 0.9283 - val_loss: 0.2055 - val_accuracy: 0.9142\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1850 - accuracy: 0.9322 - val_loss: 0.1475 - val_accuracy: 0.9486\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1797 - accuracy: 0.9345 - val_loss: 0.1582 - val_accuracy: 0.9481\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1729 - accuracy: 0.9376 - val_loss: 0.1909 - val_accuracy: 0.9223\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1672 - accuracy: 0.9393 - val_loss: 0.1628 - val_accuracy: 0.9470\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_75 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_76 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_74 (TFOpL  (None, 8, 45)       0           ['input_75[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_75 (TFOpL  (None, 11, 45)      0           ['input_76[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_74 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_74[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_74[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_75 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_75[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_75[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_74 (LayerN  (None, 8, 45)       90          ['multi_head_attention_74[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_75 (LayerN  (None, 11, 45)      90          ['multi_head_attention_75[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_148 (Dropout)          (None, 8, 45)        0           ['layer_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_149 (Dropout)          (None, 11, 45)       0           ['layer_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_74 (G  (None, 45)          0           ['dropout_148[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_75 (G  (None, 45)          0           ['dropout_149[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_74[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_75[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_150 (Dropout)          (None, 90)           0           ['concatenate_37[0][0]']         \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 128)          11648       ['dropout_150[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_151 (Dropout)          (None, 128)          0           ['dense_74[0][0]']               \n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 1)            129         ['dropout_151[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1367 - accuracy: 0.9471 - val_loss: 0.0429 - val_accuracy: 0.9892\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0374 - accuracy: 0.9901 - val_loss: 0.0262 - val_accuracy: 0.9912\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0565 - val_accuracy: 0.9881\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.0159 - val_accuracy: 0.9971\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.0489 - val_accuracy: 0.9907\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0321 - val_accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.0227 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.0340 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0444 - val_accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0321 - val_accuracy: 0.9947\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_77 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_78 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_76 (TFOpL  (None, 8, 45)       0           ['input_77[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_77 (TFOpL  (None, 11, 45)      0           ['input_78[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_76 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_76[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_76[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_77 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_77[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_77[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_76 (LayerN  (None, 8, 45)       90          ['multi_head_attention_76[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_77 (LayerN  (None, 11, 45)      90          ['multi_head_attention_77[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_152 (Dropout)          (None, 8, 45)        0           ['layer_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_153 (Dropout)          (None, 11, 45)       0           ['layer_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_76 (G  (None, 45)          0           ['dropout_152[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_77 (G  (None, 45)          0           ['dropout_153[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_76[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_77[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_154 (Dropout)          (None, 90)           0           ['concatenate_38[0][0]']         \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 128)          11648       ['dropout_154[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_155 (Dropout)          (None, 128)          0           ['dense_76[0][0]']               \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 1)            129         ['dropout_155[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1268 - accuracy: 0.9502 - val_loss: 0.1122 - val_accuracy: 0.9785\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0271 - accuracy: 0.9940 - val_loss: 0.0600 - val_accuracy: 0.9857\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0246 - accuracy: 0.9946 - val_loss: 0.1253 - val_accuracy: 0.9799\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.0927 - val_accuracy: 0.9809\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0201 - accuracy: 0.9962 - val_loss: 0.1157 - val_accuracy: 0.9818\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.0942 - val_accuracy: 0.9845\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0176 - accuracy: 0.9966 - val_loss: 0.0969 - val_accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0169 - accuracy: 0.9967 - val_loss: 0.1286 - val_accuracy: 0.9806\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0169 - accuracy: 0.9964 - val_loss: 0.0910 - val_accuracy: 0.9838\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0171 - accuracy: 0.9964 - val_loss: 0.0894 - val_accuracy: 0.9838\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_79 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_80 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_78 (TFOpL  (None, 8, 45)       0           ['input_79[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_79 (TFOpL  (None, 11, 45)      0           ['input_80[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_78 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_78[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_78[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_79 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_79[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_79[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_78 (LayerN  (None, 8, 45)       90          ['multi_head_attention_78[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_79 (LayerN  (None, 11, 45)      90          ['multi_head_attention_79[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_156 (Dropout)          (None, 8, 45)        0           ['layer_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_157 (Dropout)          (None, 11, 45)       0           ['layer_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_78 (G  (None, 45)          0           ['dropout_156[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_79 (G  (None, 45)          0           ['dropout_157[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_78[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_79[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_158 (Dropout)          (None, 90)           0           ['concatenate_39[0][0]']         \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 128)          11648       ['dropout_158[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_159 (Dropout)          (None, 128)          0           ['dense_78[0][0]']               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 1)            129         ['dropout_159[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1935 - accuracy: 0.9290 - val_loss: 0.0491 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1206 - accuracy: 0.9676 - val_loss: 0.0348 - val_accuracy: 0.9924\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1141 - accuracy: 0.9693 - val_loss: 0.0464 - val_accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1075 - accuracy: 0.9699 - val_loss: 0.0384 - val_accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1048 - accuracy: 0.9706 - val_loss: 0.0466 - val_accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1013 - accuracy: 0.9714 - val_loss: 0.0346 - val_accuracy: 0.9924\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0989 - accuracy: 0.9721 - val_loss: 0.0457 - val_accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0961 - accuracy: 0.9726 - val_loss: 0.0465 - val_accuracy: 0.9916\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0955 - accuracy: 0.9732 - val_loss: 0.0401 - val_accuracy: 0.9945\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0945 - accuracy: 0.9729 - val_loss: 0.0489 - val_accuracy: 0.9938\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19923 16fe [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19923 f02e [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19923 ed9c [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19923 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_81 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_82 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_80 (TFOpL  (None, 8, 45)       0           ['input_81[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_81 (TFOpL  (None, 11, 45)      0           ['input_82[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_80 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_80[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_80[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_81 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_81[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_81[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_80 (LayerN  (None, 8, 45)       90          ['multi_head_attention_80[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_81 (LayerN  (None, 11, 45)      90          ['multi_head_attention_81[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_160 (Dropout)          (None, 8, 45)        0           ['layer_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_161 (Dropout)          (None, 11, 45)       0           ['layer_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_80 (G  (None, 45)          0           ['dropout_160[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_81 (G  (None, 45)          0           ['dropout_161[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_80[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_81[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_162 (Dropout)          (None, 90)           0           ['concatenate_40[0][0]']         \n",
      "                                                                                                  \n",
      " dense_80 (Dense)               (None, 128)          11648       ['dropout_162[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_163 (Dropout)          (None, 128)          0           ['dense_80[0][0]']               \n",
      "                                                                                                  \n",
      " dense_81 (Dense)               (None, 1)            129         ['dropout_163[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19923 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.3163 - accuracy: 0.8677 - val_loss: 0.2134 - val_accuracy: 0.8786\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2042 - accuracy: 0.9246 - val_loss: 0.2411 - val_accuracy: 0.8722\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1803 - accuracy: 0.9329 - val_loss: 0.1629 - val_accuracy: 0.9209\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1709 - accuracy: 0.9359 - val_loss: 0.1881 - val_accuracy: 0.9090\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1606 - accuracy: 0.9388 - val_loss: 0.1204 - val_accuracy: 0.9446\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1511 - accuracy: 0.9409 - val_loss: 0.1471 - val_accuracy: 0.9264\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1449 - accuracy: 0.9439 - val_loss: 0.1467 - val_accuracy: 0.9059\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1484 - accuracy: 0.9442 - val_loss: 0.1706 - val_accuracy: 0.9037\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1374 - accuracy: 0.9480 - val_loss: 0.1352 - val_accuracy: 0.9173\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1329 - accuracy: 0.9488 - val_loss: 0.1644 - val_accuracy: 0.9168\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 5 19924\n",
      "19924 ['16fe', 'f02e', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_83 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_84 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_82 (TFOpL  (None, 8, 45)       0           ['input_83[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_83 (TFOpL  (None, 11, 45)      0           ['input_84[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_82 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_82[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_82[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_83 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_83[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_83[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_82 (LayerN  (None, 8, 45)       90          ['multi_head_attention_82[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_83 (LayerN  (None, 11, 45)      90          ['multi_head_attention_83[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_164 (Dropout)          (None, 8, 45)        0           ['layer_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_165 (Dropout)          (None, 11, 45)       0           ['layer_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_82 (G  (None, 45)          0           ['dropout_164[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_83 (G  (None, 45)          0           ['dropout_165[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_82[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_83[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_166 (Dropout)          (None, 90)           0           ['concatenate_41[0][0]']         \n",
      "                                                                                                  \n",
      " dense_82 (Dense)               (None, 128)          11648       ['dropout_166[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_167 (Dropout)          (None, 128)          0           ['dense_82[0][0]']               \n",
      "                                                                                                  \n",
      " dense_83 (Dense)               (None, 1)            129         ['dropout_167[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.4443 - accuracy: 0.7926 - val_loss: 0.2110 - val_accuracy: 0.9286\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2823 - accuracy: 0.8948 - val_loss: 0.1647 - val_accuracy: 0.9505\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2493 - accuracy: 0.9078 - val_loss: 0.2026 - val_accuracy: 0.9247\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2290 - accuracy: 0.9157 - val_loss: 0.2073 - val_accuracy: 0.9362\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2169 - accuracy: 0.9207 - val_loss: 0.1242 - val_accuracy: 0.9606\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2080 - accuracy: 0.9240 - val_loss: 0.1375 - val_accuracy: 0.9536\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1964 - accuracy: 0.9295 - val_loss: 0.1301 - val_accuracy: 0.9553\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1871 - accuracy: 0.9324 - val_loss: 0.1204 - val_accuracy: 0.9584\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1830 - accuracy: 0.9332 - val_loss: 0.1603 - val_accuracy: 0.9484\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1772 - accuracy: 0.9355 - val_loss: 0.1427 - val_accuracy: 0.9532\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_85 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_86 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_84 (TFOpL  (None, 8, 45)       0           ['input_85[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_85 (TFOpL  (None, 11, 45)      0           ['input_86[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_84 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_84[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_84[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_85 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_85[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_85[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_84 (LayerN  (None, 8, 45)       90          ['multi_head_attention_84[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_85 (LayerN  (None, 11, 45)      90          ['multi_head_attention_85[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_168 (Dropout)          (None, 8, 45)        0           ['layer_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_169 (Dropout)          (None, 11, 45)       0           ['layer_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_84 (G  (None, 45)          0           ['dropout_168[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_85 (G  (None, 45)          0           ['dropout_169[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_84[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_85[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_170 (Dropout)          (None, 90)           0           ['concatenate_42[0][0]']         \n",
      "                                                                                                  \n",
      " dense_84 (Dense)               (None, 128)          11648       ['dropout_170[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_171 (Dropout)          (None, 128)          0           ['dense_84[0][0]']               \n",
      "                                                                                                  \n",
      " dense_85 (Dense)               (None, 1)            129         ['dropout_171[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.3119 - accuracy: 0.8477 - val_loss: 0.1797 - val_accuracy: 0.9092\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1686 - accuracy: 0.9331 - val_loss: 0.2217 - val_accuracy: 0.8915\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1460 - accuracy: 0.9411 - val_loss: 0.1555 - val_accuracy: 0.9568\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1336 - accuracy: 0.9474 - val_loss: 0.1388 - val_accuracy: 0.9622\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1292 - accuracy: 0.9478 - val_loss: 0.1956 - val_accuracy: 0.9061\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1335 - accuracy: 0.9467 - val_loss: 0.1801 - val_accuracy: 0.8843\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1235 - accuracy: 0.9505 - val_loss: 0.1580 - val_accuracy: 0.9438\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1144 - accuracy: 0.9543 - val_loss: 0.2175 - val_accuracy: 0.9276\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1116 - accuracy: 0.9543 - val_loss: 0.1946 - val_accuracy: 0.9465\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1073 - accuracy: 0.9557 - val_loss: 0.1492 - val_accuracy: 0.9644\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_87 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_88 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_86 (TFOpL  (None, 8, 45)       0           ['input_87[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_87 (TFOpL  (None, 11, 45)      0           ['input_88[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_86 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_86[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_86[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_87 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_87[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_87[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_86 (LayerN  (None, 8, 45)       90          ['multi_head_attention_86[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_87 (LayerN  (None, 11, 45)      90          ['multi_head_attention_87[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_172 (Dropout)          (None, 8, 45)        0           ['layer_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_173 (Dropout)          (None, 11, 45)       0           ['layer_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_86 (G  (None, 45)          0           ['dropout_172[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_87 (G  (None, 45)          0           ['dropout_173[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_86[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_87[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_174 (Dropout)          (None, 90)           0           ['concatenate_43[0][0]']         \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 128)          11648       ['dropout_174[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_175 (Dropout)          (None, 128)          0           ['dense_86[0][0]']               \n",
      "                                                                                                  \n",
      " dense_87 (Dense)               (None, 1)            129         ['dropout_175[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.2303 - accuracy: 0.9191 - val_loss: 0.0856 - val_accuracy: 0.9849\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1351 - accuracy: 0.9684 - val_loss: 0.0819 - val_accuracy: 0.9835\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1286 - accuracy: 0.9692 - val_loss: 0.0702 - val_accuracy: 0.9864\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1230 - accuracy: 0.9709 - val_loss: 0.0958 - val_accuracy: 0.9842\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1177 - accuracy: 0.9713 - val_loss: 0.0982 - val_accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1164 - accuracy: 0.9717 - val_loss: 0.0673 - val_accuracy: 0.9852\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1176 - accuracy: 0.9703 - val_loss: 0.0765 - val_accuracy: 0.9818\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1099 - accuracy: 0.9721 - val_loss: 0.0687 - val_accuracy: 0.9854\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1037 - accuracy: 0.9719 - val_loss: 0.1234 - val_accuracy: 0.9842\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1009 - accuracy: 0.9717 - val_loss: 0.0692 - val_accuracy: 0.9861\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_89 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_90 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_88 (TFOpL  (None, 8, 45)       0           ['input_89[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_89 (TFOpL  (None, 11, 45)      0           ['input_90[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_88 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_88[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_88[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_89 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_89[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_89[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_88 (LayerN  (None, 8, 45)       90          ['multi_head_attention_88[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_89 (LayerN  (None, 11, 45)      90          ['multi_head_attention_89[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_176 (Dropout)          (None, 8, 45)        0           ['layer_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_177 (Dropout)          (None, 11, 45)       0           ['layer_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_88 (G  (None, 45)          0           ['dropout_176[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_89 (G  (None, 45)          0           ['dropout_177[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_88[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_89[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_178 (Dropout)          (None, 90)           0           ['concatenate_44[0][0]']         \n",
      "                                                                                                  \n",
      " dense_88 (Dense)               (None, 128)          11648       ['dropout_178[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_179 (Dropout)          (None, 128)          0           ['dense_88[0][0]']               \n",
      "                                                                                                  \n",
      " dense_89 (Dense)               (None, 1)            129         ['dropout_179[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3467 - accuracy: 0.8552 - val_loss: 0.1979 - val_accuracy: 0.9324\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2503 - accuracy: 0.9088 - val_loss: 0.1327 - val_accuracy: 0.9517\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2331 - accuracy: 0.9155 - val_loss: 0.1531 - val_accuracy: 0.9489\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2191 - accuracy: 0.9194 - val_loss: 0.1312 - val_accuracy: 0.9484\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2108 - accuracy: 0.9238 - val_loss: 0.1277 - val_accuracy: 0.9503\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2016 - accuracy: 0.9266 - val_loss: 0.1122 - val_accuracy: 0.9553\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1966 - accuracy: 0.9290 - val_loss: 0.1375 - val_accuracy: 0.9503\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1894 - accuracy: 0.9311 - val_loss: 0.1599 - val_accuracy: 0.9462\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1854 - accuracy: 0.9339 - val_loss: 0.1750 - val_accuracy: 0.9429\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1829 - accuracy: 0.9340 - val_loss: 0.1838 - val_accuracy: 0.9467\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_91 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_92 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_90 (TFOpL  (None, 8, 45)       0           ['input_91[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_91 (TFOpL  (None, 11, 45)      0           ['input_92[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_90 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_90[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_90[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_91 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_91[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_91[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_90 (LayerN  (None, 8, 45)       90          ['multi_head_attention_90[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_91 (LayerN  (None, 11, 45)      90          ['multi_head_attention_91[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_180 (Dropout)          (None, 8, 45)        0           ['layer_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_181 (Dropout)          (None, 11, 45)       0           ['layer_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_90 (G  (None, 45)          0           ['dropout_180[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_91 (G  (None, 45)          0           ['dropout_181[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_45 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_90[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_91[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_182 (Dropout)          (None, 90)           0           ['concatenate_45[0][0]']         \n",
      "                                                                                                  \n",
      " dense_90 (Dense)               (None, 128)          11648       ['dropout_182[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_183 (Dropout)          (None, 128)          0           ['dense_90[0][0]']               \n",
      "                                                                                                  \n",
      " dense_91 (Dense)               (None, 1)            129         ['dropout_183[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1356 - accuracy: 0.9461 - val_loss: 0.0302 - val_accuracy: 0.9907\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0303 - accuracy: 0.9921 - val_loss: 0.0341 - val_accuracy: 0.9895\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.0285 - val_accuracy: 0.9935\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.0224 - val_accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0234 - val_accuracy: 0.9945\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0227 - val_accuracy: 0.9955\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.0335 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.0388 - val_accuracy: 0.9909\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0640 - val_accuracy: 0.9861\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.0661 - val_accuracy: 0.9861\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_93 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_94 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_92 (TFOpL  (None, 8, 45)       0           ['input_93[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_93 (TFOpL  (None, 11, 45)      0           ['input_94[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_92 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_92[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_92[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_93 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_93[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_93[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_92 (LayerN  (None, 8, 45)       90          ['multi_head_attention_92[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_93 (LayerN  (None, 11, 45)      90          ['multi_head_attention_93[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_184 (Dropout)          (None, 8, 45)        0           ['layer_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_185 (Dropout)          (None, 11, 45)       0           ['layer_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_92 (G  (None, 45)          0           ['dropout_184[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_93 (G  (None, 45)          0           ['dropout_185[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_46 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_92[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_93[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_186 (Dropout)          (None, 90)           0           ['concatenate_46[0][0]']         \n",
      "                                                                                                  \n",
      " dense_92 (Dense)               (None, 128)          11648       ['dropout_186[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_187 (Dropout)          (None, 128)          0           ['dense_92[0][0]']               \n",
      "                                                                                                  \n",
      " dense_93 (Dense)               (None, 1)            129         ['dropout_187[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.1366 - accuracy: 0.9456 - val_loss: 0.0086 - val_accuracy: 0.9978\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0343 - accuracy: 0.9926 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0262 - accuracy: 0.9947 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0240 - accuracy: 0.9952 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0270 - accuracy: 0.9940 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0242 - accuracy: 0.9952 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0198 - accuracy: 0.9959 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0190 - accuracy: 0.9962 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.0079 - val_accuracy: 0.9976\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_95 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_96 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_94 (TFOpL  (None, 8, 45)       0           ['input_95[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_95 (TFOpL  (None, 11, 45)      0           ['input_96[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_94 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_94[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_94[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_95 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_95[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_95[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_94 (LayerN  (None, 8, 45)       90          ['multi_head_attention_94[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_95 (LayerN  (None, 11, 45)      90          ['multi_head_attention_95[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_188 (Dropout)          (None, 8, 45)        0           ['layer_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_189 (Dropout)          (None, 11, 45)       0           ['layer_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_94 (G  (None, 45)          0           ['dropout_188[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_95 (G  (None, 45)          0           ['dropout_189[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_94[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_95[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_190 (Dropout)          (None, 90)           0           ['concatenate_47[0][0]']         \n",
      "                                                                                                  \n",
      " dense_94 (Dense)               (None, 128)          11648       ['dropout_190[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_191 (Dropout)          (None, 128)          0           ['dense_94[0][0]']               \n",
      "                                                                                                  \n",
      " dense_95 (Dense)               (None, 1)            129         ['dropout_191[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1867 - accuracy: 0.9306 - val_loss: 0.1361 - val_accuracy: 0.9785\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1127 - accuracy: 0.9700 - val_loss: 0.1511 - val_accuracy: 0.9785\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1072 - accuracy: 0.9711 - val_loss: 0.1752 - val_accuracy: 0.9816\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1009 - accuracy: 0.9724 - val_loss: 0.1875 - val_accuracy: 0.9818\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0969 - accuracy: 0.9724 - val_loss: 0.1657 - val_accuracy: 0.9809\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0917 - accuracy: 0.9737 - val_loss: 0.1413 - val_accuracy: 0.9816\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0881 - accuracy: 0.9747 - val_loss: 0.1429 - val_accuracy: 0.9830\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0875 - accuracy: 0.9743 - val_loss: 0.2337 - val_accuracy: 0.9622\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0846 - accuracy: 0.9754 - val_loss: 0.1641 - val_accuracy: 0.9821\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0808 - accuracy: 0.9766 - val_loss: 0.1825 - val_accuracy: 0.9797\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19924 16fe [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 f02e\n",
      "19924 f02e [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19924 ed9c [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19924 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_97 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_98 (InputLayer)          [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_96 (TFOpL  (None, 8, 45)       0           ['input_97[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_97 (TFOpL  (None, 11, 45)      0           ['input_98[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_96 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_96[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_96[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_97 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_97[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_97[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_96 (LayerN  (None, 8, 45)       90          ['multi_head_attention_96[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_97 (LayerN  (None, 11, 45)      90          ['multi_head_attention_97[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_192 (Dropout)          (None, 8, 45)        0           ['layer_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_193 (Dropout)          (None, 11, 45)       0           ['layer_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_96 (G  (None, 45)          0           ['dropout_192[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_97 (G  (None, 45)          0           ['dropout_193[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_96[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_97[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_194 (Dropout)          (None, 90)           0           ['concatenate_48[0][0]']         \n",
      "                                                                                                  \n",
      " dense_96 (Dense)               (None, 128)          11648       ['dropout_194[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_195 (Dropout)          (None, 128)          0           ['dense_96[0][0]']               \n",
      "                                                                                                  \n",
      " dense_97 (Dense)               (None, 1)            129         ['dropout_195[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19924 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 17ms/step - loss: 0.3128 - accuracy: 0.8710 - val_loss: 0.1943 - val_accuracy: 0.9121\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.2129 - accuracy: 0.9277 - val_loss: 0.1474 - val_accuracy: 0.9157\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1964 - accuracy: 0.9307 - val_loss: 0.1801 - val_accuracy: 0.8968\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1806 - accuracy: 0.9338 - val_loss: 0.2145 - val_accuracy: 0.8886\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1710 - accuracy: 0.9348 - val_loss: 0.1508 - val_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1574 - accuracy: 0.9385 - val_loss: 0.1826 - val_accuracy: 0.9023\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1535 - accuracy: 0.9408 - val_loss: 0.1596 - val_accuracy: 0.9309\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1492 - accuracy: 0.9411 - val_loss: 0.1255 - val_accuracy: 0.9388\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1441 - accuracy: 0.9427 - val_loss: 0.1336 - val_accuracy: 0.9345\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1416 - accuracy: 0.9441 - val_loss: 0.1337 - val_accuracy: 0.9286\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 6 19928\n",
      "19928 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_99 (InputLayer)          [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_100 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_98 (TFOpL  (None, 8, 45)       0           ['input_99[0][0]']               \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_99 (TFOpL  (None, 11, 45)      0           ['input_100[0][0]']              \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " multi_head_attention_98 (Multi  (None, 8, 45)       65925       ['tf.__operators__.add_98[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_98[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_99 (Multi  (None, 11, 45)      65925       ['tf.__operators__.add_99[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_99[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_98 (LayerN  (None, 8, 45)       90          ['multi_head_attention_98[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " layer_normalization_99 (LayerN  (None, 11, 45)      90          ['multi_head_attention_99[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_196 (Dropout)          (None, 8, 45)        0           ['layer_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_197 (Dropout)          (None, 11, 45)       0           ['layer_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling1d_98 (G  (None, 45)          0           ['dropout_196[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " global_average_pooling1d_99 (G  (None, 45)          0           ['dropout_197[0][0]']            \n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_98[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'global_average_pooling1d_99[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_198 (Dropout)          (None, 90)           0           ['concatenate_49[0][0]']         \n",
      "                                                                                                  \n",
      " dense_98 (Dense)               (None, 128)          11648       ['dropout_198[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_199 (Dropout)          (None, 128)          0           ['dense_98[0][0]']               \n",
      "                                                                                                  \n",
      " dense_99 (Dense)               (None, 1)            129         ['dropout_199[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.1894 - val_accuracy: 0.9333\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2834 - accuracy: 0.8948 - val_loss: 0.2294 - val_accuracy: 0.9080\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2552 - accuracy: 0.9048 - val_loss: 0.1881 - val_accuracy: 0.9326\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2280 - accuracy: 0.9156 - val_loss: 0.1343 - val_accuracy: 0.9493\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2179 - accuracy: 0.9193 - val_loss: 0.1544 - val_accuracy: 0.9438\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2021 - accuracy: 0.9272 - val_loss: 0.1617 - val_accuracy: 0.9410\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1963 - accuracy: 0.9279 - val_loss: 0.1571 - val_accuracy: 0.9427\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1828 - accuracy: 0.9325 - val_loss: 0.1586 - val_accuracy: 0.9479\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1832 - accuracy: 0.9326 - val_loss: 0.1867 - val_accuracy: 0.9350\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1753 - accuracy: 0.9360 - val_loss: 0.1535 - val_accuracy: 0.9462\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_101 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_102 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_100 (TFOp  (None, 8, 45)       0           ['input_101[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_101 (TFOp  (None, 11, 45)      0           ['input_102[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_100 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_100[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_100[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_101 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_101[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_101[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_100 (Layer  (None, 8, 45)       90          ['multi_head_attention_100[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_101 (Layer  (None, 11, 45)      90          ['multi_head_attention_101[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_200 (Dropout)          (None, 8, 45)        0           ['layer_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " dropout_201 (Dropout)          (None, 11, 45)       0           ['layer_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_100 (  (None, 45)          0           ['dropout_200[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_101 (  (None, 45)          0           ['dropout_201[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_50 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_100[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_101[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_202 (Dropout)          (None, 90)           0           ['concatenate_50[0][0]']         \n",
      "                                                                                                  \n",
      " dense_100 (Dense)              (None, 128)          11648       ['dropout_202[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_203 (Dropout)          (None, 128)          0           ['dense_100[0][0]']              \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 1)            129         ['dropout_203[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.3034 - accuracy: 0.8585 - val_loss: 0.1302 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1770 - accuracy: 0.9281 - val_loss: 0.1277 - val_accuracy: 0.9515\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1614 - accuracy: 0.9349 - val_loss: 0.1698 - val_accuracy: 0.9465\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1452 - accuracy: 0.9416 - val_loss: 0.1253 - val_accuracy: 0.9625\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1337 - accuracy: 0.9467 - val_loss: 0.1288 - val_accuracy: 0.9606\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1332 - accuracy: 0.9463 - val_loss: 0.1090 - val_accuracy: 0.9730\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1268 - accuracy: 0.9507 - val_loss: 0.1158 - val_accuracy: 0.9663\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1209 - accuracy: 0.9537 - val_loss: 0.1151 - val_accuracy: 0.9611\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1168 - accuracy: 0.9555 - val_loss: 0.1430 - val_accuracy: 0.9470\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1130 - accuracy: 0.9564 - val_loss: 0.0794 - val_accuracy: 0.9797\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_103 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_104 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_102 (TFOp  (None, 8, 45)       0           ['input_103[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_103 (TFOp  (None, 11, 45)      0           ['input_104[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_102 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_102[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_102[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_103 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_103[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_103[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_102 (Layer  (None, 8, 45)       90          ['multi_head_attention_102[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_103 (Layer  (None, 11, 45)      90          ['multi_head_attention_103[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_204 (Dropout)          (None, 8, 45)        0           ['layer_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " dropout_205 (Dropout)          (None, 11, 45)       0           ['layer_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_102 (  (None, 45)          0           ['dropout_204[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_103 (  (None, 45)          0           ['dropout_205[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_51 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_102[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_103[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_206 (Dropout)          (None, 90)           0           ['concatenate_51[0][0]']         \n",
      "                                                                                                  \n",
      " dense_102 (Dense)              (None, 128)          11648       ['dropout_206[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_207 (Dropout)          (None, 128)          0           ['dense_102[0][0]']              \n",
      "                                                                                                  \n",
      " dense_103 (Dense)              (None, 1)            129         ['dropout_207[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.2285 - accuracy: 0.9209 - val_loss: 0.0820 - val_accuracy: 0.9866\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1336 - accuracy: 0.9678 - val_loss: 0.0960 - val_accuracy: 0.9909\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1298 - accuracy: 0.9682 - val_loss: 0.0713 - val_accuracy: 0.9935\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1263 - accuracy: 0.9691 - val_loss: 0.0812 - val_accuracy: 0.9885\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1239 - accuracy: 0.9688 - val_loss: 0.0675 - val_accuracy: 0.9935\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1207 - accuracy: 0.9693 - val_loss: 0.0476 - val_accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1122 - accuracy: 0.9693 - val_loss: 0.0674 - val_accuracy: 0.9938\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1071 - accuracy: 0.9694 - val_loss: 0.0525 - val_accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1047 - accuracy: 0.9695 - val_loss: 0.0556 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1005 - accuracy: 0.9701 - val_loss: 0.0658 - val_accuracy: 0.9928\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_105 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_106 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_104 (TFOp  (None, 8, 45)       0           ['input_105[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_105 (TFOp  (None, 11, 45)      0           ['input_106[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_104 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_104[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_104[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_105 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_105[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_105[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_104 (Layer  (None, 8, 45)       90          ['multi_head_attention_104[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_105 (Layer  (None, 11, 45)      90          ['multi_head_attention_105[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_208 (Dropout)          (None, 8, 45)        0           ['layer_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " dropout_209 (Dropout)          (None, 11, 45)       0           ['layer_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_104 (  (None, 45)          0           ['dropout_208[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_105 (  (None, 45)          0           ['dropout_209[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_52 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_104[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_105[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_210 (Dropout)          (None, 90)           0           ['concatenate_52[0][0]']         \n",
      "                                                                                                  \n",
      " dense_104 (Dense)              (None, 128)          11648       ['dropout_210[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_211 (Dropout)          (None, 128)          0           ['dense_104[0][0]']              \n",
      "                                                                                                  \n",
      " dense_105 (Dense)              (None, 1)            129         ['dropout_211[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3732 - accuracy: 0.8411 - val_loss: 0.1629 - val_accuracy: 0.9372\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2496 - accuracy: 0.9101 - val_loss: 0.1775 - val_accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2264 - accuracy: 0.9167 - val_loss: 0.1830 - val_accuracy: 0.9300\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2108 - accuracy: 0.9218 - val_loss: 0.1516 - val_accuracy: 0.9293\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1948 - accuracy: 0.9280 - val_loss: 0.1539 - val_accuracy: 0.9407\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1872 - accuracy: 0.9297 - val_loss: 0.1905 - val_accuracy: 0.9293\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1804 - accuracy: 0.9329 - val_loss: 0.2090 - val_accuracy: 0.9247\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1738 - accuracy: 0.9365 - val_loss: 0.1255 - val_accuracy: 0.9486\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1682 - accuracy: 0.9373 - val_loss: 0.2072 - val_accuracy: 0.9228\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1644 - accuracy: 0.9391 - val_loss: 0.1813 - val_accuracy: 0.9324\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_107 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_108 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_106 (TFOp  (None, 8, 45)       0           ['input_107[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_107 (TFOp  (None, 11, 45)      0           ['input_108[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_106 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_106[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_106[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_107 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_107[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_107[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_106 (Layer  (None, 8, 45)       90          ['multi_head_attention_106[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_107 (Layer  (None, 11, 45)      90          ['multi_head_attention_107[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_212 (Dropout)          (None, 8, 45)        0           ['layer_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " dropout_213 (Dropout)          (None, 11, 45)       0           ['layer_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_106 (  (None, 45)          0           ['dropout_212[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_107 (  (None, 45)          0           ['dropout_213[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_53 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_106[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_107[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_214 (Dropout)          (None, 90)           0           ['concatenate_53[0][0]']         \n",
      "                                                                                                  \n",
      " dense_106 (Dense)              (None, 128)          11648       ['dropout_214[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_215 (Dropout)          (None, 128)          0           ['dense_106[0][0]']              \n",
      "                                                                                                  \n",
      " dense_107 (Dense)              (None, 1)            129         ['dropout_215[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1298 - accuracy: 0.9458 - val_loss: 0.0671 - val_accuracy: 0.9809\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0381 - accuracy: 0.9901 - val_loss: 0.0357 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 0.0342 - val_accuracy: 0.9909\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.0282 - val_accuracy: 0.9931\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.0186 - val_accuracy: 0.9950\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0181 - accuracy: 0.9956 - val_loss: 0.0189 - val_accuracy: 0.9943\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 0.0310 - val_accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0254 - val_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 0.0417 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0115 - accuracy: 0.9976 - val_loss: 0.0408 - val_accuracy: 0.9945\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_109 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_110 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_108 (TFOp  (None, 8, 45)       0           ['input_109[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_109 (TFOp  (None, 11, 45)      0           ['input_110[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_108 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_108[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_108[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_109 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_109[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_109[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_108 (Layer  (None, 8, 45)       90          ['multi_head_attention_108[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_109 (Layer  (None, 11, 45)      90          ['multi_head_attention_109[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_216 (Dropout)          (None, 8, 45)        0           ['layer_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " dropout_217 (Dropout)          (None, 11, 45)       0           ['layer_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_108 (  (None, 45)          0           ['dropout_216[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_109 (  (None, 45)          0           ['dropout_217[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_54 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_108[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_109[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_218 (Dropout)          (None, 90)           0           ['concatenate_54[0][0]']         \n",
      "                                                                                                  \n",
      " dense_108 (Dense)              (None, 128)          11648       ['dropout_218[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_219 (Dropout)          (None, 128)          0           ['dense_108[0][0]']              \n",
      "                                                                                                  \n",
      " dense_109 (Dense)              (None, 1)            129         ['dropout_219[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1419 - accuracy: 0.9452 - val_loss: 0.0403 - val_accuracy: 0.9883\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0305 - accuracy: 0.9939 - val_loss: 0.0364 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0284 - accuracy: 0.9942 - val_loss: 0.0376 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0259 - accuracy: 0.9949 - val_loss: 0.0296 - val_accuracy: 0.9895\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0307 - accuracy: 0.9933 - val_loss: 0.0291 - val_accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0240 - accuracy: 0.9955 - val_loss: 0.0350 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0231 - accuracy: 0.9958 - val_loss: 0.0257 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0223 - accuracy: 0.9960 - val_loss: 0.0290 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0234 - accuracy: 0.9956 - val_loss: 0.0366 - val_accuracy: 0.9921\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 0.0382 - val_accuracy: 0.9926\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_55\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_111 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_112 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_110 (TFOp  (None, 8, 45)       0           ['input_111[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_111 (TFOp  (None, 11, 45)      0           ['input_112[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_110 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_110[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_110[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_111 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_111[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_111[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_110 (Layer  (None, 8, 45)       90          ['multi_head_attention_110[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_111 (Layer  (None, 11, 45)      90          ['multi_head_attention_111[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_220 (Dropout)          (None, 8, 45)        0           ['layer_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " dropout_221 (Dropout)          (None, 11, 45)       0           ['layer_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_110 (  (None, 45)          0           ['dropout_220[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_111 (  (None, 45)          0           ['dropout_221[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_55 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_110[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_111[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_222 (Dropout)          (None, 90)           0           ['concatenate_55[0][0]']         \n",
      "                                                                                                  \n",
      " dense_110 (Dense)              (None, 128)          11648       ['dropout_222[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_223 (Dropout)          (None, 128)          0           ['dense_110[0][0]']              \n",
      "                                                                                                  \n",
      " dense_111 (Dense)              (None, 1)            129         ['dropout_223[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1800 - accuracy: 0.9375 - val_loss: 0.0342 - val_accuracy: 0.9931\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1128 - accuracy: 0.9709 - val_loss: 0.0385 - val_accuracy: 0.9909\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1066 - accuracy: 0.9721 - val_loss: 0.0372 - val_accuracy: 0.9902\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0996 - accuracy: 0.9727 - val_loss: 0.0316 - val_accuracy: 0.9933\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0972 - accuracy: 0.9734 - val_loss: 0.0340 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0931 - accuracy: 0.9743 - val_loss: 0.0372 - val_accuracy: 0.9931\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0931 - accuracy: 0.9745 - val_loss: 0.0311 - val_accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0893 - accuracy: 0.9751 - val_loss: 0.0505 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0882 - accuracy: 0.9745 - val_loss: 0.0323 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0875 - accuracy: 0.9759 - val_loss: 0.0293 - val_accuracy: 0.9928\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19928 16fe [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19928 5b66 [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19928 ed9c [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19928 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_113 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_114 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_112 (TFOp  (None, 8, 45)       0           ['input_113[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_113 (TFOp  (None, 11, 45)      0           ['input_114[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_112 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_112[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_112[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_113 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_113[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_113[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_112 (Layer  (None, 8, 45)       90          ['multi_head_attention_112[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_113 (Layer  (None, 11, 45)      90          ['multi_head_attention_113[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_224 (Dropout)          (None, 8, 45)        0           ['layer_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " dropout_225 (Dropout)          (None, 11, 45)       0           ['layer_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_112 (  (None, 45)          0           ['dropout_224[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_113 (  (None, 45)          0           ['dropout_225[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_56 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_112[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_113[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_226 (Dropout)          (None, 90)           0           ['concatenate_56[0][0]']         \n",
      "                                                                                                  \n",
      " dense_112 (Dense)              (None, 128)          11648       ['dropout_226[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_227 (Dropout)          (None, 128)          0           ['dense_112[0][0]']              \n",
      "                                                                                                  \n",
      " dense_113 (Dense)              (None, 1)            129         ['dropout_227[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19928 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.3288 - accuracy: 0.8582 - val_loss: 0.2302 - val_accuracy: 0.8867\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2127 - accuracy: 0.9229 - val_loss: 0.1326 - val_accuracy: 0.9286\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1965 - accuracy: 0.9284 - val_loss: 0.1792 - val_accuracy: 0.9099\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1820 - accuracy: 0.9318 - val_loss: 0.1406 - val_accuracy: 0.9223\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1720 - accuracy: 0.9339 - val_loss: 0.1476 - val_accuracy: 0.9238\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1670 - accuracy: 0.9365 - val_loss: 0.1492 - val_accuracy: 0.9168\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1579 - accuracy: 0.9384 - val_loss: 0.1225 - val_accuracy: 0.9391\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1516 - accuracy: 0.9412 - val_loss: 0.1153 - val_accuracy: 0.9348\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1450 - accuracy: 0.9428 - val_loss: 0.1068 - val_accuracy: 0.9462\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1407 - accuracy: 0.9459 - val_loss: 0.1436 - val_accuracy: 0.9307\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 7 19929\n",
      "19929 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_115 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_116 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_114 (TFOp  (None, 8, 45)       0           ['input_115[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_115 (TFOp  (None, 11, 45)      0           ['input_116[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_114 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_114[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_114[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_115 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_115[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_115[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_114 (Layer  (None, 8, 45)       90          ['multi_head_attention_114[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_115 (Layer  (None, 11, 45)      90          ['multi_head_attention_115[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_228 (Dropout)          (None, 8, 45)        0           ['layer_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " dropout_229 (Dropout)          (None, 11, 45)       0           ['layer_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_114 (  (None, 45)          0           ['dropout_228[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_115 (  (None, 45)          0           ['dropout_229[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_57 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_114[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_115[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_230 (Dropout)          (None, 90)           0           ['concatenate_57[0][0]']         \n",
      "                                                                                                  \n",
      " dense_114 (Dense)              (None, 128)          11648       ['dropout_230[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_231 (Dropout)          (None, 128)          0           ['dense_114[0][0]']              \n",
      "                                                                                                  \n",
      " dense_115 (Dense)              (None, 1)            129         ['dropout_231[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.4203 - accuracy: 0.8109 - val_loss: 0.2308 - val_accuracy: 0.9133\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2816 - accuracy: 0.8957 - val_loss: 0.1888 - val_accuracy: 0.9276\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2560 - accuracy: 0.9063 - val_loss: 0.1494 - val_accuracy: 0.9455\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2329 - accuracy: 0.9133 - val_loss: 0.2673 - val_accuracy: 0.9087\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2163 - accuracy: 0.9207 - val_loss: 0.1839 - val_accuracy: 0.9391\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2023 - accuracy: 0.9267 - val_loss: 0.1375 - val_accuracy: 0.9455\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1948 - accuracy: 0.9280 - val_loss: 0.1284 - val_accuracy: 0.9532\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1890 - accuracy: 0.9316 - val_loss: 0.1327 - val_accuracy: 0.9455\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1829 - accuracy: 0.9345 - val_loss: 0.1362 - val_accuracy: 0.9517\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1764 - accuracy: 0.9370 - val_loss: 0.1331 - val_accuracy: 0.9563\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_117 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_118 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_116 (TFOp  (None, 8, 45)       0           ['input_117[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_117 (TFOp  (None, 11, 45)      0           ['input_118[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_116 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_116[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_116[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_117 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_117[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_117[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_116 (Layer  (None, 8, 45)       90          ['multi_head_attention_116[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_117 (Layer  (None, 11, 45)      90          ['multi_head_attention_117[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_232 (Dropout)          (None, 8, 45)        0           ['layer_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " dropout_233 (Dropout)          (None, 11, 45)       0           ['layer_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_116 (  (None, 45)          0           ['dropout_232[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_117 (  (None, 45)          0           ['dropout_233[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_58 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_116[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_117[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_234 (Dropout)          (None, 90)           0           ['concatenate_58[0][0]']         \n",
      "                                                                                                  \n",
      " dense_116 (Dense)              (None, 128)          11648       ['dropout_234[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_235 (Dropout)          (None, 128)          0           ['dense_116[0][0]']              \n",
      "                                                                                                  \n",
      " dense_117 (Dense)              (None, 1)            129         ['dropout_235[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3120 - accuracy: 0.8401 - val_loss: 0.1679 - val_accuracy: 0.9551\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1655 - accuracy: 0.9251 - val_loss: 0.1318 - val_accuracy: 0.9634\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1467 - accuracy: 0.9366 - val_loss: 0.1675 - val_accuracy: 0.9192\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1413 - accuracy: 0.9403 - val_loss: 0.1470 - val_accuracy: 0.9484\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1375 - accuracy: 0.9424 - val_loss: 0.1215 - val_accuracy: 0.9587\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1336 - accuracy: 0.9452 - val_loss: 0.1357 - val_accuracy: 0.9527\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1267 - accuracy: 0.9485 - val_loss: 0.1145 - val_accuracy: 0.9673\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1211 - accuracy: 0.9522 - val_loss: 0.1063 - val_accuracy: 0.9677\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1153 - accuracy: 0.9558 - val_loss: 0.1299 - val_accuracy: 0.9493\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1121 - accuracy: 0.9572 - val_loss: 0.1155 - val_accuracy: 0.9618\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_119 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_120 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_118 (TFOp  (None, 8, 45)       0           ['input_119[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_119 (TFOp  (None, 11, 45)      0           ['input_120[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_118 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_118[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_118[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_119 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_119[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_119[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_118 (Layer  (None, 8, 45)       90          ['multi_head_attention_118[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_119 (Layer  (None, 11, 45)      90          ['multi_head_attention_119[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_236 (Dropout)          (None, 8, 45)        0           ['layer_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " dropout_237 (Dropout)          (None, 11, 45)       0           ['layer_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_118 (  (None, 45)          0           ['dropout_236[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_119 (  (None, 45)          0           ['dropout_237[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_59 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_118[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_119[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_238 (Dropout)          (None, 90)           0           ['concatenate_59[0][0]']         \n",
      "                                                                                                  \n",
      " dense_118 (Dense)              (None, 128)          11648       ['dropout_238[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_239 (Dropout)          (None, 128)          0           ['dense_118[0][0]']              \n",
      "                                                                                                  \n",
      " dense_119 (Dense)              (None, 1)            129         ['dropout_239[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.2331 - accuracy: 0.9192 - val_loss: 0.0852 - val_accuracy: 0.9883\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1434 - accuracy: 0.9643 - val_loss: 0.0621 - val_accuracy: 0.9935\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1346 - accuracy: 0.9660 - val_loss: 0.0591 - val_accuracy: 0.9940\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1330 - accuracy: 0.9660 - val_loss: 0.0542 - val_accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1301 - accuracy: 0.9661 - val_loss: 0.0946 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1280 - accuracy: 0.9663 - val_loss: 0.0769 - val_accuracy: 0.9940\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1193 - accuracy: 0.9665 - val_loss: 0.0408 - val_accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1090 - accuracy: 0.9664 - val_loss: 0.0344 - val_accuracy: 0.9935\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1074 - accuracy: 0.9672 - val_loss: 0.0443 - val_accuracy: 0.9921\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1035 - accuracy: 0.9671 - val_loss: 0.0458 - val_accuracy: 0.9938\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_121 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_122 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_120 (TFOp  (None, 8, 45)       0           ['input_121[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_121 (TFOp  (None, 11, 45)      0           ['input_122[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_120 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_120[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_120[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_121 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_121[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_121[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_120 (Layer  (None, 8, 45)       90          ['multi_head_attention_120[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_121 (Layer  (None, 11, 45)      90          ['multi_head_attention_121[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_240 (Dropout)          (None, 8, 45)        0           ['layer_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " dropout_241 (Dropout)          (None, 11, 45)       0           ['layer_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_120 (  (None, 45)          0           ['dropout_240[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_121 (  (None, 45)          0           ['dropout_241[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_60 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_120[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_121[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_242 (Dropout)          (None, 90)           0           ['concatenate_60[0][0]']         \n",
      "                                                                                                  \n",
      " dense_120 (Dense)              (None, 128)          11648       ['dropout_242[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_243 (Dropout)          (None, 128)          0           ['dense_120[0][0]']              \n",
      "                                                                                                  \n",
      " dense_121 (Dense)              (None, 1)            129         ['dropout_243[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.3522 - accuracy: 0.8511 - val_loss: 0.1908 - val_accuracy: 0.9216\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2428 - accuracy: 0.9107 - val_loss: 0.1843 - val_accuracy: 0.9168\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2222 - accuracy: 0.9164 - val_loss: 0.1571 - val_accuracy: 0.9348\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2066 - accuracy: 0.9207 - val_loss: 0.1425 - val_accuracy: 0.9450\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1922 - accuracy: 0.9284 - val_loss: 0.1543 - val_accuracy: 0.9281\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1851 - accuracy: 0.9323 - val_loss: 0.1845 - val_accuracy: 0.9135\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1773 - accuracy: 0.9339 - val_loss: 0.1959 - val_accuracy: 0.9247\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1720 - accuracy: 0.9358 - val_loss: 0.1801 - val_accuracy: 0.9166\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1642 - accuracy: 0.9384 - val_loss: 0.1383 - val_accuracy: 0.9331\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1636 - accuracy: 0.9403 - val_loss: 0.1627 - val_accuracy: 0.9283\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_61\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_123 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_124 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_122 (TFOp  (None, 8, 45)       0           ['input_123[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_123 (TFOp  (None, 11, 45)      0           ['input_124[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_122 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_122[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_122[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_123 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_123[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_123[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_122 (Layer  (None, 8, 45)       90          ['multi_head_attention_122[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_123 (Layer  (None, 11, 45)      90          ['multi_head_attention_123[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_244 (Dropout)          (None, 8, 45)        0           ['layer_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " dropout_245 (Dropout)          (None, 11, 45)       0           ['layer_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_122 (  (None, 45)          0           ['dropout_244[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_123 (  (None, 45)          0           ['dropout_245[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_61 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_122[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_123[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_246 (Dropout)          (None, 90)           0           ['concatenate_61[0][0]']         \n",
      "                                                                                                  \n",
      " dense_122 (Dense)              (None, 128)          11648       ['dropout_246[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_247 (Dropout)          (None, 128)          0           ['dense_122[0][0]']              \n",
      "                                                                                                  \n",
      " dense_123 (Dense)              (None, 1)            129         ['dropout_247[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1228 - accuracy: 0.9551 - val_loss: 0.0501 - val_accuracy: 0.9811\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 0.0608 - val_accuracy: 0.9835\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0273 - accuracy: 0.9930 - val_loss: 0.0186 - val_accuracy: 0.9926\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.0161 - val_accuracy: 0.9969\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0179 - accuracy: 0.9955 - val_loss: 0.0284 - val_accuracy: 0.9940\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.0306 - val_accuracy: 0.9938\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 0.0252 - val_accuracy: 0.9952\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0336 - val_accuracy: 0.9938\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.0227 - val_accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0218 - val_accuracy: 0.9959\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_125 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_126 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_124 (TFOp  (None, 8, 45)       0           ['input_125[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_125 (TFOp  (None, 11, 45)      0           ['input_126[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_124 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_124[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_124[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_125 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_125[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_125[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_124 (Layer  (None, 8, 45)       90          ['multi_head_attention_124[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_125 (Layer  (None, 11, 45)      90          ['multi_head_attention_125[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_248 (Dropout)          (None, 8, 45)        0           ['layer_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " dropout_249 (Dropout)          (None, 11, 45)       0           ['layer_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_124 (  (None, 45)          0           ['dropout_248[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_125 (  (None, 45)          0           ['dropout_249[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_62 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_124[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_125[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_250 (Dropout)          (None, 90)           0           ['concatenate_62[0][0]']         \n",
      "                                                                                                  \n",
      " dense_124 (Dense)              (None, 128)          11648       ['dropout_250[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_251 (Dropout)          (None, 128)          0           ['dense_124[0][0]']              \n",
      "                                                                                                  \n",
      " dense_125 (Dense)              (None, 1)            129         ['dropout_251[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1170 - accuracy: 0.9545 - val_loss: 0.0303 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0273 - accuracy: 0.9949 - val_loss: 0.0241 - val_accuracy: 0.9957\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0252 - accuracy: 0.9949 - val_loss: 0.0206 - val_accuracy: 0.9952\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0223 - accuracy: 0.9958 - val_loss: 0.0122 - val_accuracy: 0.9969\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0228 - accuracy: 0.9955 - val_loss: 0.0215 - val_accuracy: 0.9938\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0235 - accuracy: 0.9953 - val_loss: 0.0172 - val_accuracy: 0.9962\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0193 - accuracy: 0.9965 - val_loss: 0.0189 - val_accuracy: 0.9950\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0200 - accuracy: 0.9963 - val_loss: 0.0169 - val_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0099 - val_accuracy: 0.9971\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.0099 - val_accuracy: 0.9983\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_63\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_127 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_128 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_126 (TFOp  (None, 8, 45)       0           ['input_127[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_127 (TFOp  (None, 11, 45)      0           ['input_128[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_126 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_126[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_126[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_127 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_127[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_127[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_126 (Layer  (None, 8, 45)       90          ['multi_head_attention_126[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_127 (Layer  (None, 11, 45)      90          ['multi_head_attention_127[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_252 (Dropout)          (None, 8, 45)        0           ['layer_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " dropout_253 (Dropout)          (None, 11, 45)       0           ['layer_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_126 (  (None, 45)          0           ['dropout_252[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_127 (  (None, 45)          0           ['dropout_253[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_63 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_126[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_127[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_254 (Dropout)          (None, 90)           0           ['concatenate_63[0][0]']         \n",
      "                                                                                                  \n",
      " dense_126 (Dense)              (None, 128)          11648       ['dropout_254[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_255 (Dropout)          (None, 128)          0           ['dense_126[0][0]']              \n",
      "                                                                                                  \n",
      " dense_127 (Dense)              (None, 1)            129         ['dropout_255[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.1964 - accuracy: 0.9281 - val_loss: 0.0992 - val_accuracy: 0.9744\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1181 - accuracy: 0.9689 - val_loss: 0.0916 - val_accuracy: 0.9768\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1130 - accuracy: 0.9690 - val_loss: 0.0898 - val_accuracy: 0.9761\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1083 - accuracy: 0.9716 - val_loss: 0.0734 - val_accuracy: 0.9816\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1033 - accuracy: 0.9717 - val_loss: 0.0709 - val_accuracy: 0.9818\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0987 - accuracy: 0.9726 - val_loss: 0.0826 - val_accuracy: 0.9806\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0961 - accuracy: 0.9731 - val_loss: 0.0755 - val_accuracy: 0.9790\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0946 - accuracy: 0.9721 - val_loss: 0.0605 - val_accuracy: 0.9852\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0928 - accuracy: 0.9728 - val_loss: 0.0803 - val_accuracy: 0.9809\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0914 - accuracy: 0.9728 - val_loss: 0.0771 - val_accuracy: 0.9830\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19929 16fe [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19929 5b66 [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19929 ed9c [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19929 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_64\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_129 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_130 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_128 (TFOp  (None, 8, 45)       0           ['input_129[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_129 (TFOp  (None, 11, 45)      0           ['input_130[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_128 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_128[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_128[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_129 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_129[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_129[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_128 (Layer  (None, 8, 45)       90          ['multi_head_attention_128[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_129 (Layer  (None, 11, 45)      90          ['multi_head_attention_129[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_256 (Dropout)          (None, 8, 45)        0           ['layer_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " dropout_257 (Dropout)          (None, 11, 45)       0           ['layer_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_128 (  (None, 45)          0           ['dropout_256[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_129 (  (None, 45)          0           ['dropout_257[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_64 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_128[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_129[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_258 (Dropout)          (None, 90)           0           ['concatenate_64[0][0]']         \n",
      "                                                                                                  \n",
      " dense_128 (Dense)              (None, 128)          11648       ['dropout_258[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_259 (Dropout)          (None, 128)          0           ['dense_128[0][0]']              \n",
      "                                                                                                  \n",
      " dense_129 (Dense)              (None, 1)            129         ['dropout_259[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19929 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3103 - accuracy: 0.8734 - val_loss: 0.1588 - val_accuracy: 0.9178\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2174 - accuracy: 0.9239 - val_loss: 0.1358 - val_accuracy: 0.9259\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1927 - accuracy: 0.9276 - val_loss: 0.1601 - val_accuracy: 0.9214\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1785 - accuracy: 0.9322 - val_loss: 0.1215 - val_accuracy: 0.9362\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1685 - accuracy: 0.9339 - val_loss: 0.1320 - val_accuracy: 0.9245\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1552 - accuracy: 0.9385 - val_loss: 0.1476 - val_accuracy: 0.9278\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1460 - accuracy: 0.9413 - val_loss: 0.1243 - val_accuracy: 0.9415\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1451 - accuracy: 0.9408 - val_loss: 0.1808 - val_accuracy: 0.9259\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1432 - accuracy: 0.9419 - val_loss: 0.1215 - val_accuracy: 0.9388\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1388 - accuracy: 0.9437 - val_loss: 0.1207 - val_accuracy: 0.9364\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 8 19930\n",
      "19930 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_65\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_131 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_132 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_130 (TFOp  (None, 8, 45)       0           ['input_131[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_131 (TFOp  (None, 11, 45)      0           ['input_132[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_130 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_130[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_130[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_131 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_131[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_131[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_130 (Layer  (None, 8, 45)       90          ['multi_head_attention_130[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_131 (Layer  (None, 11, 45)      90          ['multi_head_attention_131[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_260 (Dropout)          (None, 8, 45)        0           ['layer_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " dropout_261 (Dropout)          (None, 11, 45)       0           ['layer_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_130 (  (None, 45)          0           ['dropout_260[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_131 (  (None, 45)          0           ['dropout_261[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_65 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_130[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_131[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_262 (Dropout)          (None, 90)           0           ['concatenate_65[0][0]']         \n",
      "                                                                                                  \n",
      " dense_130 (Dense)              (None, 128)          11648       ['dropout_262[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_263 (Dropout)          (None, 128)          0           ['dense_130[0][0]']              \n",
      "                                                                                                  \n",
      " dense_131 (Dense)              (None, 1)            129         ['dropout_263[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.4212 - accuracy: 0.8056 - val_loss: 0.2329 - val_accuracy: 0.9489\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2872 - accuracy: 0.8947 - val_loss: 0.1879 - val_accuracy: 0.9300\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2524 - accuracy: 0.9080 - val_loss: 0.1498 - val_accuracy: 0.9417\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2279 - accuracy: 0.9162 - val_loss: 0.1478 - val_accuracy: 0.9410\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2115 - accuracy: 0.9226 - val_loss: 0.1945 - val_accuracy: 0.9286\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2025 - accuracy: 0.9268 - val_loss: 0.1668 - val_accuracy: 0.9422\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1917 - accuracy: 0.9305 - val_loss: 0.1913 - val_accuracy: 0.9276\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1854 - accuracy: 0.9329 - val_loss: 0.1583 - val_accuracy: 0.9436\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1786 - accuracy: 0.9356 - val_loss: 0.1045 - val_accuracy: 0.9589\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1778 - accuracy: 0.9373 - val_loss: 0.1252 - val_accuracy: 0.9541\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_66\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_133 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_134 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_132 (TFOp  (None, 8, 45)       0           ['input_133[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_133 (TFOp  (None, 11, 45)      0           ['input_134[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_132 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_132[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_132[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_133 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_133[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_133[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_132 (Layer  (None, 8, 45)       90          ['multi_head_attention_132[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_133 (Layer  (None, 11, 45)      90          ['multi_head_attention_133[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_264 (Dropout)          (None, 8, 45)        0           ['layer_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " dropout_265 (Dropout)          (None, 11, 45)       0           ['layer_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_132 (  (None, 45)          0           ['dropout_264[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_133 (  (None, 45)          0           ['dropout_265[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_66 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_132[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_133[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_266 (Dropout)          (None, 90)           0           ['concatenate_66[0][0]']         \n",
      "                                                                                                  \n",
      " dense_132 (Dense)              (None, 128)          11648       ['dropout_266[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_267 (Dropout)          (None, 128)          0           ['dense_132[0][0]']              \n",
      "                                                                                                  \n",
      " dense_133 (Dense)              (None, 1)            129         ['dropout_267[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.2850 - accuracy: 0.8618 - val_loss: 0.2119 - val_accuracy: 0.8774\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1535 - accuracy: 0.9372 - val_loss: 0.1110 - val_accuracy: 0.9706\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1400 - accuracy: 0.9443 - val_loss: 0.1536 - val_accuracy: 0.9412\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1321 - accuracy: 0.9488 - val_loss: 0.1103 - val_accuracy: 0.9711\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1258 - accuracy: 0.9505 - val_loss: 0.0994 - val_accuracy: 0.9742\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1212 - accuracy: 0.9527 - val_loss: 0.1282 - val_accuracy: 0.9591\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1158 - accuracy: 0.9564 - val_loss: 0.1081 - val_accuracy: 0.9665\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1153 - accuracy: 0.9567 - val_loss: 0.0910 - val_accuracy: 0.9790\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1093 - accuracy: 0.9593 - val_loss: 0.0882 - val_accuracy: 0.9766\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1039 - accuracy: 0.9613 - val_loss: 0.0970 - val_accuracy: 0.9723\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_67\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_135 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_136 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_134 (TFOp  (None, 8, 45)       0           ['input_135[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_135 (TFOp  (None, 11, 45)      0           ['input_136[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_134 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_134[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_134[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_135 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_135[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_135[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_134 (Layer  (None, 8, 45)       90          ['multi_head_attention_134[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_135 (Layer  (None, 11, 45)      90          ['multi_head_attention_135[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_268 (Dropout)          (None, 8, 45)        0           ['layer_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " dropout_269 (Dropout)          (None, 11, 45)       0           ['layer_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_134 (  (None, 45)          0           ['dropout_268[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_135 (  (None, 45)          0           ['dropout_269[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_67 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_134[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_135[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_270 (Dropout)          (None, 90)           0           ['concatenate_67[0][0]']         \n",
      "                                                                                                  \n",
      " dense_134 (Dense)              (None, 128)          11648       ['dropout_270[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_271 (Dropout)          (None, 128)          0           ['dense_134[0][0]']              \n",
      "                                                                                                  \n",
      " dense_135 (Dense)              (None, 1)            129         ['dropout_271[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.2520 - accuracy: 0.9099 - val_loss: 0.0794 - val_accuracy: 0.9902\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1568 - accuracy: 0.9655 - val_loss: 0.0739 - val_accuracy: 0.9892\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1450 - accuracy: 0.9669 - val_loss: 0.0548 - val_accuracy: 0.9900\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1353 - accuracy: 0.9667 - val_loss: 0.0761 - val_accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1279 - accuracy: 0.9679 - val_loss: 0.0627 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1256 - accuracy: 0.9676 - val_loss: 0.0499 - val_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1234 - accuracy: 0.9675 - val_loss: 0.0696 - val_accuracy: 0.9919\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1280 - accuracy: 0.9658 - val_loss: 0.0851 - val_accuracy: 0.9909\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1212 - accuracy: 0.9680 - val_loss: 0.0685 - val_accuracy: 0.9914\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1147 - accuracy: 0.9685 - val_loss: 0.0590 - val_accuracy: 0.9924\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_68\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_137 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_138 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_136 (TFOp  (None, 8, 45)       0           ['input_137[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_137 (TFOp  (None, 11, 45)      0           ['input_138[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_136 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_136[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_136[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_137 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_137[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_137[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_136 (Layer  (None, 8, 45)       90          ['multi_head_attention_136[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_137 (Layer  (None, 11, 45)      90          ['multi_head_attention_137[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_272 (Dropout)          (None, 8, 45)        0           ['layer_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " dropout_273 (Dropout)          (None, 11, 45)       0           ['layer_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_136 (  (None, 45)          0           ['dropout_272[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_137 (  (None, 45)          0           ['dropout_273[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_68 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_136[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_137[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_274 (Dropout)          (None, 90)           0           ['concatenate_68[0][0]']         \n",
      "                                                                                                  \n",
      " dense_136 (Dense)              (None, 128)          11648       ['dropout_274[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_275 (Dropout)          (None, 128)          0           ['dense_136[0][0]']              \n",
      "                                                                                                  \n",
      " dense_137 (Dense)              (None, 1)            129         ['dropout_275[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.3536 - accuracy: 0.8521 - val_loss: 0.3077 - val_accuracy: 0.9044\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2441 - accuracy: 0.9106 - val_loss: 0.2791 - val_accuracy: 0.8791\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2239 - accuracy: 0.9147 - val_loss: 0.1275 - val_accuracy: 0.9527\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2047 - accuracy: 0.9218 - val_loss: 0.2848 - val_accuracy: 0.8679\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1976 - accuracy: 0.9240 - val_loss: 0.2348 - val_accuracy: 0.9211\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1897 - accuracy: 0.9277 - val_loss: 0.2200 - val_accuracy: 0.9121\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1806 - accuracy: 0.9324 - val_loss: 0.1269 - val_accuracy: 0.9591\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1776 - accuracy: 0.9318 - val_loss: 0.1851 - val_accuracy: 0.9362\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1712 - accuracy: 0.9330 - val_loss: 0.2502 - val_accuracy: 0.8812\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1673 - accuracy: 0.9341 - val_loss: 0.2311 - val_accuracy: 0.9128\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_69\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_139 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_140 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_138 (TFOp  (None, 8, 45)       0           ['input_139[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_139 (TFOp  (None, 11, 45)      0           ['input_140[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_138 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_138[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_138[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_139 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_139[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_139[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_138 (Layer  (None, 8, 45)       90          ['multi_head_attention_138[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_139 (Layer  (None, 11, 45)      90          ['multi_head_attention_139[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_276 (Dropout)          (None, 8, 45)        0           ['layer_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " dropout_277 (Dropout)          (None, 11, 45)       0           ['layer_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_138 (  (None, 45)          0           ['dropout_276[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_139 (  (None, 45)          0           ['dropout_277[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_69 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_138[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_139[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_278 (Dropout)          (None, 90)           0           ['concatenate_69[0][0]']         \n",
      "                                                                                                  \n",
      " dense_138 (Dense)              (None, 128)          11648       ['dropout_278[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_279 (Dropout)          (None, 128)          0           ['dense_138[0][0]']              \n",
      "                                                                                                  \n",
      " dense_139 (Dense)              (None, 1)            129         ['dropout_279[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1249 - accuracy: 0.9499 - val_loss: 0.0488 - val_accuracy: 0.9845\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0362 - accuracy: 0.9909 - val_loss: 0.0195 - val_accuracy: 0.9935\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0374 - val_accuracy: 0.9912\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.0200 - val_accuracy: 0.9950\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 0.0410 - val_accuracy: 0.9909\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0263 - val_accuracy: 0.9945\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.0263 - val_accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0121 - accuracy: 0.9973 - val_loss: 0.0211 - val_accuracy: 0.9955\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.0299 - val_accuracy: 0.9950\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0208 - val_accuracy: 0.9957\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_70\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_141 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_142 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_140 (TFOp  (None, 8, 45)       0           ['input_141[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_141 (TFOp  (None, 11, 45)      0           ['input_142[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_140 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_140[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_140[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_141 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_141[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_141[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_140 (Layer  (None, 8, 45)       90          ['multi_head_attention_140[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_141 (Layer  (None, 11, 45)      90          ['multi_head_attention_141[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_280 (Dropout)          (None, 8, 45)        0           ['layer_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " dropout_281 (Dropout)          (None, 11, 45)       0           ['layer_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_140 (  (None, 45)          0           ['dropout_280[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_141 (  (None, 45)          0           ['dropout_281[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_70 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_140[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_141[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_282 (Dropout)          (None, 90)           0           ['concatenate_70[0][0]']         \n",
      "                                                                                                  \n",
      " dense_140 (Dense)              (None, 128)          11648       ['dropout_282[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_283 (Dropout)          (None, 128)          0           ['dense_140[0][0]']              \n",
      "                                                                                                  \n",
      " dense_141 (Dense)              (None, 1)            129         ['dropout_283[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1412 - accuracy: 0.9410 - val_loss: 0.0462 - val_accuracy: 0.9878\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0254 - accuracy: 0.9943 - val_loss: 0.0776 - val_accuracy: 0.9852\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 0.0437 - val_accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.0432 - val_accuracy: 0.9900\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.1241 - val_accuracy: 0.9699\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 0.0597 - val_accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 0.0580 - val_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0187 - accuracy: 0.9962 - val_loss: 0.0443 - val_accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0140 - accuracy: 0.9969 - val_loss: 0.0554 - val_accuracy: 0.9912\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_71\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_143 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_144 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_142 (TFOp  (None, 8, 45)       0           ['input_143[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_143 (TFOp  (None, 11, 45)      0           ['input_144[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_142 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_142[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_142[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_143 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_143[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_143[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_142 (Layer  (None, 8, 45)       90          ['multi_head_attention_142[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_143 (Layer  (None, 11, 45)      90          ['multi_head_attention_143[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_284 (Dropout)          (None, 8, 45)        0           ['layer_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " dropout_285 (Dropout)          (None, 11, 45)       0           ['layer_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_142 (  (None, 45)          0           ['dropout_284[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_143 (  (None, 45)          0           ['dropout_285[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_71 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_142[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_143[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_286 (Dropout)          (None, 90)           0           ['concatenate_71[0][0]']         \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 128)          11648       ['dropout_286[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_287 (Dropout)          (None, 128)          0           ['dense_142[0][0]']              \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 1)            129         ['dropout_287[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.1899 - accuracy: 0.9287 - val_loss: 0.0612 - val_accuracy: 0.9828\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1136 - accuracy: 0.9711 - val_loss: 0.0528 - val_accuracy: 0.9838\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1041 - accuracy: 0.9713 - val_loss: 0.0541 - val_accuracy: 0.9871\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0988 - accuracy: 0.9729 - val_loss: 0.0500 - val_accuracy: 0.9864\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0949 - accuracy: 0.9737 - val_loss: 0.0515 - val_accuracy: 0.9878\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0911 - accuracy: 0.9744 - val_loss: 0.0634 - val_accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0907 - accuracy: 0.9751 - val_loss: 0.0457 - val_accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0881 - accuracy: 0.9750 - val_loss: 0.0429 - val_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0878 - accuracy: 0.9752 - val_loss: 0.0635 - val_accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0855 - accuracy: 0.9755 - val_loss: 0.0571 - val_accuracy: 0.9847\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19930 16fe [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19930 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19930 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19930 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_72\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_145 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_146 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_144 (TFOp  (None, 8, 45)       0           ['input_145[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_145 (TFOp  (None, 11, 45)      0           ['input_146[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_144 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_144[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_144[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_145 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_145[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_145[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_144 (Layer  (None, 8, 45)       90          ['multi_head_attention_144[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_145 (Layer  (None, 11, 45)      90          ['multi_head_attention_145[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_288 (Dropout)          (None, 8, 45)        0           ['layer_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " dropout_289 (Dropout)          (None, 11, 45)       0           ['layer_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_144 (  (None, 45)          0           ['dropout_288[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_145 (  (None, 45)          0           ['dropout_289[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_72 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_144[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_145[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_290 (Dropout)          (None, 90)           0           ['concatenate_72[0][0]']         \n",
      "                                                                                                  \n",
      " dense_144 (Dense)              (None, 128)          11648       ['dropout_290[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_291 (Dropout)          (None, 128)          0           ['dense_144[0][0]']              \n",
      "                                                                                                  \n",
      " dense_145 (Dense)              (None, 1)            129         ['dropout_291[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19930 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.3089 - accuracy: 0.8699 - val_loss: 0.1831 - val_accuracy: 0.9142\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2092 - accuracy: 0.9255 - val_loss: 0.1359 - val_accuracy: 0.9321\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1865 - accuracy: 0.9304 - val_loss: 0.1349 - val_accuracy: 0.9376\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1769 - accuracy: 0.9344 - val_loss: 0.1524 - val_accuracy: 0.9355\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1703 - accuracy: 0.9346 - val_loss: 0.1347 - val_accuracy: 0.9429\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1589 - accuracy: 0.9387 - val_loss: 0.1782 - val_accuracy: 0.9314\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1511 - accuracy: 0.9408 - val_loss: 0.1844 - val_accuracy: 0.9297\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1462 - accuracy: 0.9426 - val_loss: 0.1534 - val_accuracy: 0.9300\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1400 - accuracy: 0.9437 - val_loss: 0.1990 - val_accuracy: 0.9214\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1381 - accuracy: 0.9462 - val_loss: 0.2403 - val_accuracy: 0.9020\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 9 19931\n",
      "19931 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_73\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_147 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_148 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_146 (TFOp  (None, 8, 45)       0           ['input_147[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_147 (TFOp  (None, 11, 45)      0           ['input_148[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_146 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_146[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_146[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_147 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_147[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_147[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_146 (Layer  (None, 8, 45)       90          ['multi_head_attention_146[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_147 (Layer  (None, 11, 45)      90          ['multi_head_attention_147[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_292 (Dropout)          (None, 8, 45)        0           ['layer_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " dropout_293 (Dropout)          (None, 11, 45)       0           ['layer_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_146 (  (None, 45)          0           ['dropout_292[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_147 (  (None, 45)          0           ['dropout_293[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_73 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_146[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_147[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_294 (Dropout)          (None, 90)           0           ['concatenate_73[0][0]']         \n",
      "                                                                                                  \n",
      " dense_146 (Dense)              (None, 128)          11648       ['dropout_294[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_295 (Dropout)          (None, 128)          0           ['dense_146[0][0]']              \n",
      "                                                                                                  \n",
      " dense_147 (Dense)              (None, 1)            129         ['dropout_295[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.4333 - accuracy: 0.8001 - val_loss: 0.2854 - val_accuracy: 0.9013\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2763 - accuracy: 0.8976 - val_loss: 0.2292 - val_accuracy: 0.9109\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2463 - accuracy: 0.9079 - val_loss: 0.1879 - val_accuracy: 0.9264\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2283 - accuracy: 0.9137 - val_loss: 0.1210 - val_accuracy: 0.9527\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2124 - accuracy: 0.9207 - val_loss: 0.1417 - val_accuracy: 0.9427\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2012 - accuracy: 0.9258 - val_loss: 0.1543 - val_accuracy: 0.9391\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1944 - accuracy: 0.9291 - val_loss: 0.3112 - val_accuracy: 0.8762\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1907 - accuracy: 0.9308 - val_loss: 0.1473 - val_accuracy: 0.9431\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1810 - accuracy: 0.9336 - val_loss: 0.1174 - val_accuracy: 0.9553\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1787 - accuracy: 0.9355 - val_loss: 0.1468 - val_accuracy: 0.9462\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_74\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_149 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_150 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_148 (TFOp  (None, 8, 45)       0           ['input_149[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_149 (TFOp  (None, 11, 45)      0           ['input_150[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_148 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_148[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_148[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_149 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_149[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_149[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_148 (Layer  (None, 8, 45)       90          ['multi_head_attention_148[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_149 (Layer  (None, 11, 45)      90          ['multi_head_attention_149[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_296 (Dropout)          (None, 8, 45)        0           ['layer_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " dropout_297 (Dropout)          (None, 11, 45)       0           ['layer_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_148 (  (None, 45)          0           ['dropout_296[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_149 (  (None, 45)          0           ['dropout_297[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_74 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_148[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_149[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_298 (Dropout)          (None, 90)           0           ['concatenate_74[0][0]']         \n",
      "                                                                                                  \n",
      " dense_148 (Dense)              (None, 128)          11648       ['dropout_298[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_299 (Dropout)          (None, 128)          0           ['dense_148[0][0]']              \n",
      "                                                                                                  \n",
      " dense_149 (Dense)              (None, 1)            129         ['dropout_299[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 17ms/step - loss: 0.3350 - accuracy: 0.8345 - val_loss: 0.1165 - val_accuracy: 0.9692\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1733 - accuracy: 0.9255 - val_loss: 0.1149 - val_accuracy: 0.9742\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1560 - accuracy: 0.9330 - val_loss: 0.1046 - val_accuracy: 0.9680\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1480 - accuracy: 0.9394 - val_loss: 0.0863 - val_accuracy: 0.9799\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1407 - accuracy: 0.9417 - val_loss: 0.0909 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1320 - accuracy: 0.9450 - val_loss: 0.0794 - val_accuracy: 0.9809\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1302 - accuracy: 0.9493 - val_loss: 0.0962 - val_accuracy: 0.9706\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1215 - accuracy: 0.9536 - val_loss: 0.0832 - val_accuracy: 0.9787\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1167 - accuracy: 0.9557 - val_loss: 0.1053 - val_accuracy: 0.9704\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1140 - accuracy: 0.9568 - val_loss: 0.0658 - val_accuracy: 0.9852\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_75\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_151 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_152 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_150 (TFOp  (None, 8, 45)       0           ['input_151[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_151 (TFOp  (None, 11, 45)      0           ['input_152[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_150 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_150[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_150[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_151 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_151[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_151[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_150 (Layer  (None, 8, 45)       90          ['multi_head_attention_150[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_151 (Layer  (None, 11, 45)      90          ['multi_head_attention_151[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_300 (Dropout)          (None, 8, 45)        0           ['layer_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " dropout_301 (Dropout)          (None, 11, 45)       0           ['layer_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_150 (  (None, 45)          0           ['dropout_300[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_151 (  (None, 45)          0           ['dropout_301[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_75 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_150[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_151[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_302 (Dropout)          (None, 90)           0           ['concatenate_75[0][0]']         \n",
      "                                                                                                  \n",
      " dense_150 (Dense)              (None, 128)          11648       ['dropout_302[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_303 (Dropout)          (None, 128)          0           ['dense_150[0][0]']              \n",
      "                                                                                                  \n",
      " dense_151 (Dense)              (None, 1)            129         ['dropout_303[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 17ms/step - loss: 0.2392 - accuracy: 0.9208 - val_loss: 0.0559 - val_accuracy: 0.9909\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1477 - accuracy: 0.9651 - val_loss: 0.0647 - val_accuracy: 0.9912\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1366 - accuracy: 0.9663 - val_loss: 0.0670 - val_accuracy: 0.9916\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1343 - accuracy: 0.9661 - val_loss: 0.0603 - val_accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1294 - accuracy: 0.9665 - val_loss: 0.0635 - val_accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.1262 - accuracy: 0.9670 - val_loss: 0.0633 - val_accuracy: 0.9924\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 17ms/step - loss: 0.1216 - accuracy: 0.9669 - val_loss: 0.0662 - val_accuracy: 0.9881\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1159 - accuracy: 0.9670 - val_loss: 0.1066 - val_accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1111 - accuracy: 0.9664 - val_loss: 0.0662 - val_accuracy: 0.9909\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1040 - accuracy: 0.9666 - val_loss: 0.0680 - val_accuracy: 0.9902\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_76\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_153 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_154 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_152 (TFOp  (None, 8, 45)       0           ['input_153[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_153 (TFOp  (None, 11, 45)      0           ['input_154[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_152 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_152[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_152[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_153 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_153[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_153[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_152 (Layer  (None, 8, 45)       90          ['multi_head_attention_152[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_153 (Layer  (None, 11, 45)      90          ['multi_head_attention_153[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_304 (Dropout)          (None, 8, 45)        0           ['layer_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " dropout_305 (Dropout)          (None, 11, 45)       0           ['layer_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_152 (  (None, 45)          0           ['dropout_304[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_153 (  (None, 45)          0           ['dropout_305[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_76 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_152[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_153[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_306 (Dropout)          (None, 90)           0           ['concatenate_76[0][0]']         \n",
      "                                                                                                  \n",
      " dense_152 (Dense)              (None, 128)          11648       ['dropout_306[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_307 (Dropout)          (None, 128)          0           ['dense_152[0][0]']              \n",
      "                                                                                                  \n",
      " dense_153 (Dense)              (None, 1)            129         ['dropout_307[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 19s 17ms/step - loss: 0.3552 - accuracy: 0.8525 - val_loss: 0.1866 - val_accuracy: 0.9317\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2526 - accuracy: 0.9066 - val_loss: 0.2027 - val_accuracy: 0.9233\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2318 - accuracy: 0.9133 - val_loss: 0.1297 - val_accuracy: 0.9498\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2120 - accuracy: 0.9170 - val_loss: 0.1584 - val_accuracy: 0.9376\n",
      "Epoch 5/10\n",
      " 36/938 [>.............................] - ETA: 13s - loss: 0.2296 - accuracy: 0.9089\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN pc 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_78\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_157 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_158 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_156 (TFOp  (None, 8, 45)       0           ['input_157[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_157 (TFOp  (None, 11, 45)      0           ['input_158[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_156 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_156[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_156[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_157 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_157[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_157[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_156 (Layer  (None, 8, 45)       90          ['multi_head_attention_156[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_157 (Layer  (None, 11, 45)      90          ['multi_head_attention_157[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_312 (Dropout)          (None, 8, 45)        0           ['layer_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " dropout_313 (Dropout)          (None, 11, 45)       0           ['layer_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_156 (  (None, 45)          0           ['dropout_312[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_157 (  (None, 45)          0           ['dropout_313[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_78 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_156[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_157[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_314 (Dropout)          (None, 90)           0           ['concatenate_78[0][0]']         \n",
      "                                                                                                  \n",
      " dense_156 (Dense)              (None, 128)          11648       ['dropout_314[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_315 (Dropout)          (None, 128)          0           ['dense_156[0][0]']              \n",
      "                                                                                                  \n",
      " dense_157 (Dense)              (None, 1)            129         ['dropout_315[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1343 - accuracy: 0.9469 - val_loss: 0.0198 - val_accuracy: 0.9950\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0340 - accuracy: 0.9925 - val_loss: 0.0135 - val_accuracy: 0.9967\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0293 - accuracy: 0.9941 - val_loss: 0.0173 - val_accuracy: 0.9957\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0270 - accuracy: 0.9943 - val_loss: 0.0160 - val_accuracy: 0.9967\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0223 - accuracy: 0.9952 - val_loss: 0.0156 - val_accuracy: 0.9959\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.0197 - val_accuracy: 0.9945\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN sleep 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_79\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_159 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_160 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_158 (TFOp  (None, 8, 45)       0           ['input_159[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_159 (TFOp  (None, 11, 45)      0           ['input_160[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_158 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_158[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_158[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_159 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_159[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_159[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_158 (Layer  (None, 8, 45)       90          ['multi_head_attention_158[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_159 (Layer  (None, 11, 45)      90          ['multi_head_attention_159[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_316 (Dropout)          (None, 8, 45)        0           ['layer_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " dropout_317 (Dropout)          (None, 11, 45)       0           ['layer_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_158 (  (None, 45)          0           ['dropout_316[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_159 (  (None, 45)          0           ['dropout_317[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_79 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_158[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_159[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_318 (Dropout)          (None, 90)           0           ['concatenate_79[0][0]']         \n",
      "                                                                                                  \n",
      " dense_158 (Dense)              (None, 128)          11648       ['dropout_318[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_319 (Dropout)          (None, 128)          0           ['dense_158[0][0]']              \n",
      "                                                                                                  \n",
      " dense_159 (Dense)              (None, 1)            129         ['dropout_319[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 17ms/step - loss: 0.1888 - accuracy: 0.9292 - val_loss: 0.0612 - val_accuracy: 0.9885\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1153 - accuracy: 0.9702 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1075 - accuracy: 0.9715 - val_loss: 0.0472 - val_accuracy: 0.9881\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1032 - accuracy: 0.9725 - val_loss: 0.0461 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1011 - accuracy: 0.9722 - val_loss: 0.0517 - val_accuracy: 0.9907\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0963 - accuracy: 0.9739 - val_loss: 0.0425 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0954 - accuracy: 0.9739 - val_loss: 0.0424 - val_accuracy: 0.9897\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0934 - accuracy: 0.9745 - val_loss: 0.0489 - val_accuracy: 0.9871\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0930 - accuracy: 0.9743 - val_loss: 0.0475 - val_accuracy: 0.9892\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0891 - accuracy: 0.9747 - val_loss: 0.0451 - val_accuracy: 0.9871\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19931 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19931 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19931 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13] [0, 1]\n",
      "TRAIN kitchen 19931 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_80\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_161 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_162 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_160 (TFOp  (None, 8, 45)       0           ['input_161[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_161 (TFOp  (None, 11, 45)      0           ['input_162[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_160 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_160[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_160[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_161 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_161[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_161[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_160 (Layer  (None, 8, 45)       90          ['multi_head_attention_160[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_161 (Layer  (None, 11, 45)      90          ['multi_head_attention_161[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_320 (Dropout)          (None, 8, 45)        0           ['layer_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " dropout_321 (Dropout)          (None, 11, 45)       0           ['layer_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_160 (  (None, 45)          0           ['dropout_320[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_161 (  (None, 45)          0           ['dropout_321[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_80 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_160[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_161[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_322 (Dropout)          (None, 90)           0           ['concatenate_80[0][0]']         \n",
      "                                                                                                  \n",
      " dense_160 (Dense)              (None, 128)          11648       ['dropout_322[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_323 (Dropout)          (None, 128)          0           ['dense_160[0][0]']              \n",
      "                                                                                                  \n",
      " dense_161 (Dense)              (None, 1)            129         ['dropout_323[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19931 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3124 - accuracy: 0.8709 - val_loss: 0.1504 - val_accuracy: 0.9192\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2125 - accuracy: 0.9260 - val_loss: 0.1707 - val_accuracy: 0.9161\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1891 - accuracy: 0.9319 - val_loss: 0.1160 - val_accuracy: 0.9312\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1788 - accuracy: 0.9334 - val_loss: 0.1212 - val_accuracy: 0.9195\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1616 - accuracy: 0.9369 - val_loss: 0.0967 - val_accuracy: 0.9522\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1551 - accuracy: 0.9386 - val_loss: 0.1069 - val_accuracy: 0.9563\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1467 - accuracy: 0.9446 - val_loss: 0.1122 - val_accuracy: 0.9486\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1411 - accuracy: 0.9447 - val_loss: 0.1144 - val_accuracy: 0.9532\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1366 - accuracy: 0.9470 - val_loss: 0.1139 - val_accuracy: 0.9534\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1348 - accuracy: 0.9486 - val_loss: 0.1339 - val_accuracy: 0.9493\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 10 19932\n",
      "19932 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN toileting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_81\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_163 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_164 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_162 (TFOp  (None, 8, 45)       0           ['input_163[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_163 (TFOp  (None, 11, 45)      0           ['input_164[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_162 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_162[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_162[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_163 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_163[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_163[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_162 (Layer  (None, 8, 45)       90          ['multi_head_attention_162[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_163 (Layer  (None, 11, 45)      90          ['multi_head_attention_163[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_324 (Dropout)          (None, 8, 45)        0           ['layer_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " dropout_325 (Dropout)          (None, 11, 45)       0           ['layer_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_162 (  (None, 45)          0           ['dropout_324[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_163 (  (None, 45)          0           ['dropout_325[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_81 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_162[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_163[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_326 (Dropout)          (None, 90)           0           ['concatenate_81[0][0]']         \n",
      "                                                                                                  \n",
      " dense_162 (Dense)              (None, 128)          11648       ['dropout_326[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_327 (Dropout)          (None, 128)          0           ['dense_162[0][0]']              \n",
      "                                                                                                  \n",
      " dense_163 (Dense)              (None, 1)            129         ['dropout_327[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.4235 - accuracy: 0.8057 - val_loss: 0.1306 - val_accuracy: 0.9637\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2821 - accuracy: 0.8976 - val_loss: 0.1367 - val_accuracy: 0.9505\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2453 - accuracy: 0.9084 - val_loss: 0.1488 - val_accuracy: 0.9458\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2285 - accuracy: 0.9150 - val_loss: 0.0951 - val_accuracy: 0.9644\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2153 - accuracy: 0.9202 - val_loss: 0.1387 - val_accuracy: 0.9544\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2052 - accuracy: 0.9240 - val_loss: 0.1448 - val_accuracy: 0.9455\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1983 - accuracy: 0.9271 - val_loss: 0.1942 - val_accuracy: 0.9321\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1915 - accuracy: 0.9308 - val_loss: 0.1525 - val_accuracy: 0.9348\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1826 - accuracy: 0.9323 - val_loss: 0.1225 - val_accuracy: 0.9579\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1807 - accuracy: 0.9338 - val_loss: 0.1610 - val_accuracy: 0.9348\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN resting 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_165 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_166 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_164 (TFOp  (None, 8, 45)       0           ['input_165[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_165 (TFOp  (None, 11, 45)      0           ['input_166[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_164 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_164[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_164[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_165 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_165[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_165[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_164 (Layer  (None, 8, 45)       90          ['multi_head_attention_164[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_165 (Layer  (None, 11, 45)      90          ['multi_head_attention_165[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_328 (Dropout)          (None, 8, 45)        0           ['layer_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " dropout_329 (Dropout)          (None, 11, 45)       0           ['layer_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_164 (  (None, 45)          0           ['dropout_328[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_165 (  (None, 45)          0           ['dropout_329[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_82 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_164[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_165[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_330 (Dropout)          (None, 90)           0           ['concatenate_82[0][0]']         \n",
      "                                                                                                  \n",
      " dense_164 (Dense)              (None, 128)          11648       ['dropout_330[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_331 (Dropout)          (None, 128)          0           ['dense_164[0][0]']              \n",
      "                                                                                                  \n",
      " dense_165 (Dense)              (None, 1)            129         ['dropout_331[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.3175 - accuracy: 0.8526 - val_loss: 0.1198 - val_accuracy: 0.9654\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1692 - accuracy: 0.9330 - val_loss: 0.1150 - val_accuracy: 0.9458\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1478 - accuracy: 0.9416 - val_loss: 0.1269 - val_accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1416 - accuracy: 0.9436 - val_loss: 0.1016 - val_accuracy: 0.9665\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1317 - accuracy: 0.9473 - val_loss: 0.1029 - val_accuracy: 0.9646\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1246 - accuracy: 0.9514 - val_loss: 0.1167 - val_accuracy: 0.9618\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1223 - accuracy: 0.9530 - val_loss: 0.0939 - val_accuracy: 0.9716\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1141 - accuracy: 0.9555 - val_loss: 0.1121 - val_accuracy: 0.9591\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1098 - accuracy: 0.9567 - val_loss: 0.1093 - val_accuracy: 0.9620\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1084 - accuracy: 0.9561 - val_loss: 0.0883 - val_accuracy: 0.9708\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN exit 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_83\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_167 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_168 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_166 (TFOp  (None, 8, 45)       0           ['input_167[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_167 (TFOp  (None, 11, 45)      0           ['input_168[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_166 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_166[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_166[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_167 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_167[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_167[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_166 (Layer  (None, 8, 45)       90          ['multi_head_attention_166[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_167 (Layer  (None, 11, 45)      90          ['multi_head_attention_167[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_332 (Dropout)          (None, 8, 45)        0           ['layer_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " dropout_333 (Dropout)          (None, 11, 45)       0           ['layer_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_166 (  (None, 45)          0           ['dropout_332[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_167 (  (None, 45)          0           ['dropout_333[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_83 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_166[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_167[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_334 (Dropout)          (None, 90)           0           ['concatenate_83[0][0]']         \n",
      "                                                                                                  \n",
      " dense_166 (Dense)              (None, 128)          11648       ['dropout_334[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_335 (Dropout)          (None, 128)          0           ['dense_166[0][0]']              \n",
      "                                                                                                  \n",
      " dense_167 (Dense)              (None, 1)            129         ['dropout_335[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.2415 - accuracy: 0.9167 - val_loss: 0.0698 - val_accuracy: 0.9890\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1404 - accuracy: 0.9669 - val_loss: 0.0686 - val_accuracy: 0.9885\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1339 - accuracy: 0.9677 - val_loss: 0.0696 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1271 - accuracy: 0.9680 - val_loss: 0.0476 - val_accuracy: 0.9909\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1254 - accuracy: 0.9689 - val_loss: 0.0693 - val_accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1243 - accuracy: 0.9683 - val_loss: 0.0743 - val_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1184 - accuracy: 0.9684 - val_loss: 0.0717 - val_accuracy: 0.9895\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1084 - accuracy: 0.9690 - val_loss: 0.0777 - val_accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1075 - accuracy: 0.9684 - val_loss: 0.0781 - val_accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1022 - accuracy: 0.9689 - val_loss: 0.0910 - val_accuracy: 0.9897\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN cooking 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_84\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_169 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_170 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_168 (TFOp  (None, 8, 45)       0           ['input_169[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_169 (TFOp  (None, 11, 45)      0           ['input_170[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_168 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_168[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_168[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_169 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_169[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_169[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_168 (Layer  (None, 8, 45)       90          ['multi_head_attention_168[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_169 (Layer  (None, 11, 45)      90          ['multi_head_attention_169[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_336 (Dropout)          (None, 8, 45)        0           ['layer_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " dropout_337 (Dropout)          (None, 11, 45)       0           ['layer_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_168 (  (None, 45)          0           ['dropout_336[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_169 (  (None, 45)          0           ['dropout_337[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_84 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_168[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_169[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_338 (Dropout)          (None, 90)           0           ['concatenate_84[0][0]']         \n",
      "                                                                                                  \n",
      " dense_168 (Dense)              (None, 128)          11648       ['dropout_338[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_339 (Dropout)          (None, 128)          0           ['dense_168[0][0]']              \n",
      "                                                                                                  \n",
      " dense_169 (Dense)              (None, 1)            129         ['dropout_339[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3747 - accuracy: 0.8394 - val_loss: 0.1943 - val_accuracy: 0.9183\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2453 - accuracy: 0.9093 - val_loss: 0.1265 - val_accuracy: 0.9661\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2291 - accuracy: 0.9152 - val_loss: 0.0877 - val_accuracy: 0.9637\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2164 - accuracy: 0.9187 - val_loss: 0.1187 - val_accuracy: 0.9670\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2051 - accuracy: 0.9237 - val_loss: 0.1257 - val_accuracy: 0.9352\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2023 - accuracy: 0.9233 - val_loss: 0.1200 - val_accuracy: 0.9763\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1889 - accuracy: 0.9294 - val_loss: 0.1199 - val_accuracy: 0.9474\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1846 - accuracy: 0.9330 - val_loss: 0.1352 - val_accuracy: 0.9388\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1803 - accuracy: 0.9330 - val_loss: 0.1343 - val_accuracy: 0.9551\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1741 - accuracy: 0.9355 - val_loss: 0.1204 - val_accuracy: 0.9520\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "TRAIN shower 19932 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_85\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_171 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_172 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_170 (TFOp  (None, 8, 45)       0           ['input_171[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_171 (TFOp  (None, 11, 45)      0           ['input_172[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_170 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_170[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_170[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_171 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_171[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_171[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_170 (Layer  (None, 8, 45)       90          ['multi_head_attention_170[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_171 (Layer  (None, 11, 45)      90          ['multi_head_attention_171[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_340 (Dropout)          (None, 8, 45)        0           ['layer_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " dropout_341 (Dropout)          (None, 11, 45)       0           ['layer_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_170 (  (None, 45)          0           ['dropout_340[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_171 (  (None, 45)          0           ['dropout_341[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_85 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_170[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_171[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_342 (Dropout)          (None, 90)           0           ['concatenate_85[0][0]']         \n",
      "                                                                                                  \n",
      " dense_170 (Dense)              (None, 128)          11648       ['dropout_342[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_343 (Dropout)          (None, 128)          0           ['dense_170[0][0]']              \n",
      "                                                                                                  \n",
      " dense_171 (Dense)              (None, 1)            129         ['dropout_343[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19932 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.1241 - accuracy: 0.9505 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0342 - accuracy: 0.9909 - val_loss: 0.0735 - val_accuracy: 0.9840\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 0.0833 - val_accuracy: 0.9895\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.0734 - val_accuracy: 0.9921\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.0939 - val_accuracy: 0.9919\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0146 - accuracy: 0.9965 - val_loss: 0.1052 - val_accuracy: 0.9919\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0973 - accuracy: 0.9733 - val_loss: 0.0761 - val_accuracy: 0.9795\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0948 - accuracy: 0.9736 - val_loss: 0.0791 - val_accuracy: 0.9773\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0898 - accuracy: 0.9743 - val_loss: 0.0912 - val_accuracy: 0.9723\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0908 - accuracy: 0.9745 - val_loss: 0.0864 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0851 - accuracy: 0.9755 - val_loss: 0.1049 - val_accuracy: 0.9756\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0816 - accuracy: 0.9755 - val_loss: 0.0955 - val_accuracy: 0.9771\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "7 kitchen\n",
      "\t\t 0 16fe\n",
      "19932 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19932 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19932 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13] [0, 1]\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1771 - accuracy: 0.9325 - val_loss: 0.1557 - val_accuracy: 0.9228\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1659 - accuracy: 0.9374 - val_loss: 0.1515 - val_accuracy: 0.9202\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1540 - accuracy: 0.9390 - val_loss: 0.1530 - val_accuracy: 0.9333\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1516 - accuracy: 0.9415 - val_loss: 0.1626 - val_accuracy: 0.9321\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1417 - accuracy: 0.9448 - val_loss: 0.1355 - val_accuracy: 0.9376\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1400 - accuracy: 0.9457 - val_loss: 0.1747 - val_accuracy: 0.9278\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1363 - accuracy: 0.9459 - val_loss: 0.1535 - val_accuracy: 0.9264\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 11 19933\n",
      "19933 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19933 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [1, 2]\n",
      "TRAIN toileting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_89\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_179 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_180 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_178 (TFOp  (None, 8, 45)       0           ['input_179[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_179 (TFOp  (None, 11, 45)      0           ['input_180[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_178 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_178[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_178[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_179 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_179[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_179[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_178 (Layer  (None, 8, 45)       90          ['multi_head_attention_178[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_179 (Layer  (None, 11, 45)      90          ['multi_head_attention_179[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_356 (Dropout)          (None, 8, 45)        0           ['layer_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " dropout_357 (Dropout)          (None, 11, 45)       0           ['layer_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_178 (  (None, 45)          0           ['dropout_356[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_179 (  (None, 45)          0           ['dropout_357[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_89 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_178[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_179[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_358 (Dropout)          (None, 90)           0           ['concatenate_89[0][0]']         \n",
      "                                                                                                  \n",
      " dense_178 (Dense)              (None, 128)          11648       ['dropout_358[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_359 (Dropout)          (None, 128)          0           ['dense_178[0][0]']              \n",
      "                                                                                                  \n",
      " dense_179 (Dense)              (None, 1)            129         ['dropout_359[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.4436 - accuracy: 0.7907 - val_loss: 0.2036 - val_accuracy: 0.9276\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2671 - accuracy: 0.9023 - val_loss: 0.1572 - val_accuracy: 0.9395\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2343 - accuracy: 0.9141 - val_loss: 0.1865 - val_accuracy: 0.9314\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2164 - accuracy: 0.9188 - val_loss: 0.1931 - val_accuracy: 0.9312\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2012 - accuracy: 0.9242 - val_loss: 0.1534 - val_accuracy: 0.9410\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1939 - accuracy: 0.9279 - val_loss: 0.1601 - val_accuracy: 0.9388\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1843 - accuracy: 0.9321 - val_loss: 0.1216 - val_accuracy: 0.9520\n",
      "Epoch 8/10\n",
      " 45/938 [>.............................] - ETA: 12s - loss: 0.1546 - accuracy: 0.9354\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN resting 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_90\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_181 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_182 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_180 (TFOp  (None, 8, 45)       0           ['input_181[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_181 (TFOp  (None, 11, 45)      0           ['input_182[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_180 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_180[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_180[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_181 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_181[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_181[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_180 (Layer  (None, 8, 45)       90          ['multi_head_attention_180[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_181 (Layer  (None, 11, 45)      90          ['multi_head_attention_181[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_360 (Dropout)          (None, 8, 45)        0           ['layer_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " dropout_361 (Dropout)          (None, 11, 45)       0           ['layer_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_180 (  (None, 45)          0           ['dropout_360[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_181 (  (None, 45)          0           ['dropout_361[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_90 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_180[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_181[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_362 (Dropout)          (None, 90)           0           ['concatenate_90[0][0]']         \n",
      "                                                                                                  \n",
      " dense_180 (Dense)              (None, 128)          11648       ['dropout_362[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_363 (Dropout)          (None, 128)          0           ['dense_180[0][0]']              \n",
      "                                                                                                  \n",
      " dense_181 (Dense)              (None, 1)            129         ['dropout_363[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 16s 15ms/step - loss: 0.3072 - accuracy: 0.8540 - val_loss: 0.2002 - val_accuracy: 0.8973\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1707 - accuracy: 0.9297 - val_loss: 0.1589 - val_accuracy: 0.9529\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1485 - accuracy: 0.9391 - val_loss: 0.1150 - val_accuracy: 0.9744\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1388 - accuracy: 0.9457 - val_loss: 0.1230 - val_accuracy: 0.9706\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1342 - accuracy: 0.9478 - val_loss: 0.1520 - val_accuracy: 0.9558\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1300 - accuracy: 0.9508 - val_loss: 0.1369 - val_accuracy: 0.9651\n",
      "Epoch 7/10\n",
      "808/938 [========================>.....] - ETA: 1s - loss: 0.1229 - accuracy: 0.9526\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN exit 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_91\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_183 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_184 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_182 (TFOp  (None, 8, 45)       0           ['input_183[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_183 (TFOp  (None, 11, 45)      0           ['input_184[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_182 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_182[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_182[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_183 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_183[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_183[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_182 (Layer  (None, 8, 45)       90          ['multi_head_attention_182[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_183 (Layer  (None, 11, 45)      90          ['multi_head_attention_183[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_364 (Dropout)          (None, 8, 45)        0           ['layer_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " dropout_365 (Dropout)          (None, 11, 45)       0           ['layer_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_182 (  (None, 45)          0           ['dropout_364[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_183 (  (None, 45)          0           ['dropout_365[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_91 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_182[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_183[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_366 (Dropout)          (None, 90)           0           ['concatenate_91[0][0]']         \n",
      "                                                                                                  \n",
      " dense_182 (Dense)              (None, 128)          11648       ['dropout_366[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_367 (Dropout)          (None, 128)          0           ['dense_182[0][0]']              \n",
      "                                                                                                  \n",
      " dense_183 (Dense)              (None, 1)            129         ['dropout_367[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.2374 - accuracy: 0.9154 - val_loss: 0.0773 - val_accuracy: 0.9845\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1334 - accuracy: 0.9687 - val_loss: 0.0799 - val_accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1228 - accuracy: 0.9698 - val_loss: 0.0773 - val_accuracy: 0.9861\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1218 - accuracy: 0.9695 - val_loss: 0.0942 - val_accuracy: 0.9833\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1141 - accuracy: 0.9712 - val_loss: 0.0762 - val_accuracy: 0.9876\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1114 - accuracy: 0.9709 - val_loss: 0.0729 - val_accuracy: 0.9869\n",
      "Epoch 7/10\n",
      "813/938 [=========================>....] - ETA: 1s - loss: 0.1074 - accuracy: 0.9709\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN cooking 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_92\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_185 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_186 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_184 (TFOp  (None, 8, 45)       0           ['input_185[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_185 (TFOp  (None, 11, 45)      0           ['input_186[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_184 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_184[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_184[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_185 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_185[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_185[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_184 (Layer  (None, 8, 45)       90          ['multi_head_attention_184[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_185 (Layer  (None, 11, 45)      90          ['multi_head_attention_185[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_368 (Dropout)          (None, 8, 45)        0           ['layer_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " dropout_369 (Dropout)          (None, 11, 45)       0           ['layer_normalization_185[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_184 (  (None, 45)          0           ['dropout_368[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_185 (  (None, 45)          0           ['dropout_369[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_92 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_184[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_185[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_370 (Dropout)          (None, 90)           0           ['concatenate_92[0][0]']         \n",
      "                                                                                                  \n",
      " dense_184 (Dense)              (None, 128)          11648       ['dropout_370[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_371 (Dropout)          (None, 128)          0           ['dense_184[0][0]']              \n",
      "                                                                                                  \n",
      " dense_185 (Dense)              (None, 1)            129         ['dropout_371[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 20s 18ms/step - loss: 0.3552 - accuracy: 0.8503 - val_loss: 0.2397 - val_accuracy: 0.8970\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 0.2519 - accuracy: 0.9087 - val_loss: 0.1677 - val_accuracy: 0.9223\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 16s 18ms/step - loss: 0.2309 - accuracy: 0.9152 - val_loss: 0.1668 - val_accuracy: 0.9264\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2125 - accuracy: 0.9195 - val_loss: 0.2102 - val_accuracy: 0.9259\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2047 - accuracy: 0.9222 - val_loss: 0.1674 - val_accuracy: 0.9281\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1916 - accuracy: 0.9270 - val_loss: 0.3451 - val_accuracy: 0.8736\n",
      "Epoch 7/10\n",
      "647/938 [===================>..........] - ETA: 4s - loss: 0.1835 - accuracy: 0.9303\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN shower 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_93\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_187 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_188 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_186 (TFOp  (None, 8, 45)       0           ['input_187[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_187 (TFOp  (None, 11, 45)      0           ['input_188[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_186 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_186[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_186[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_187 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_187[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_187[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_186 (Layer  (None, 8, 45)       90          ['multi_head_attention_186[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_187 (Layer  (None, 11, 45)      90          ['multi_head_attention_187[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_372 (Dropout)          (None, 8, 45)        0           ['layer_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " dropout_373 (Dropout)          (None, 11, 45)       0           ['layer_normalization_187[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_186 (  (None, 45)          0           ['dropout_372[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_187 (  (None, 45)          0           ['dropout_373[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_93 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_186[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_187[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_374 (Dropout)          (None, 90)           0           ['concatenate_93[0][0]']         \n",
      "                                                                                                  \n",
      " dense_186 (Dense)              (None, 128)          11648       ['dropout_374[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_375 (Dropout)          (None, 128)          0           ['dense_186[0][0]']              \n",
      "                                                                                                  \n",
      " dense_187 (Dense)              (None, 1)            129         ['dropout_375[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1475 - accuracy: 0.9390 - val_loss: 0.0333 - val_accuracy: 0.9840\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0397 - accuracy: 0.9883 - val_loss: 0.0259 - val_accuracy: 0.9921\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 0.0262 - val_accuracy: 0.9904\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 0.0305 - val_accuracy: 0.9940\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.0246 - val_accuracy: 0.9955\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.0259 - val_accuracy: 0.9959\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0262 - val_accuracy: 0.9964\n",
      "Epoch 8/10\n",
      "349/938 [==========>...................] - ETA: 8s - loss: 0.0137 - accuracy: 0.9970\t\t 1 5b66\n",
      "19933 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN pc 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_94\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_189 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_190 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_188 (TFOp  (None, 8, 45)       0           ['input_189[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_189 (TFOp  (None, 11, 45)      0           ['input_190[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_188 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_188[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_188[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_189 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_189[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_189[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_188 (Layer  (None, 8, 45)       90          ['multi_head_attention_188[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_189 (Layer  (None, 11, 45)      90          ['multi_head_attention_189[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_376 (Dropout)          (None, 8, 45)        0           ['layer_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " dropout_377 (Dropout)          (None, 11, 45)       0           ['layer_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_188 (  (None, 45)          0           ['dropout_376[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_189 (  (None, 45)          0           ['dropout_377[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_94 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_188[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_189[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_378 (Dropout)          (None, 90)           0           ['concatenate_94[0][0]']         \n",
      "                                                                                                  \n",
      " dense_188 (Dense)              (None, 128)          11648       ['dropout_378[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_379 (Dropout)          (None, 128)          0           ['dense_188[0][0]']              \n",
      "                                                                                                  \n",
      " dense_189 (Dense)              (None, 1)            129         ['dropout_379[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1281 - accuracy: 0.9518 - val_loss: 0.0450 - val_accuracy: 0.9890\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0326 - accuracy: 0.9928 - val_loss: 0.0425 - val_accuracy: 0.9897\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0325 - accuracy: 0.9928 - val_loss: 0.0743 - val_accuracy: 0.9790\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0309 - accuracy: 0.9930 - val_loss: 0.0644 - val_accuracy: 0.9878\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0237 - accuracy: 0.9952 - val_loss: 0.0534 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0218 - accuracy: 0.9951 - val_loss: 0.0433 - val_accuracy: 0.9916\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0210 - accuracy: 0.9957 - val_loss: 0.0367 - val_accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 0.0475 - val_accuracy: 0.9916\n",
      "Epoch 9/10\n",
      "453/938 [=============>................] - ETA: 7s - loss: 0.0294 - accuracy: 0.9937\t\t 2 ed9c\n",
      "19933 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13] [0, 1]\n",
      "TRAIN sleep 19933 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_95\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_191 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_192 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_190 (TFOp  (None, 8, 45)       0           ['input_191[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_191 (TFOp  (None, 11, 45)      0           ['input_192[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_190 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_190[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_190[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_191 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_191[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_191[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_190 (Layer  (None, 8, 45)       90          ['multi_head_attention_190[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_191 (Layer  (None, 11, 45)      90          ['multi_head_attention_191[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_380 (Dropout)          (None, 8, 45)        0           ['layer_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " dropout_381 (Dropout)          (None, 11, 45)       0           ['layer_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_190 (  (None, 45)          0           ['dropout_380[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_191 (  (None, 45)          0           ['dropout_381[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_95 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_190[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_191[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_382 (Dropout)          (None, 90)           0           ['concatenate_95[0][0]']         \n",
      "                                                                                                  \n",
      " dense_190 (Dense)              (None, 128)          11648       ['dropout_382[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_383 (Dropout)          (None, 128)          0           ['dense_190[0][0]']              \n",
      "                                                                                                  \n",
      " dense_191 (Dense)              (None, 1)            129         ['dropout_383[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19933 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.1954 - accuracy: 0.9251 - val_loss: 0.0457 - val_accuracy: 0.9931\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1122 - accuracy: 0.9704 - val_loss: 0.0366 - val_accuracy: 0.9909\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1062 - accuracy: 0.9712 - val_loss: 0.0330 - val_accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1016 - accuracy: 0.9722 - val_loss: 0.0309 - val_accuracy: 0.9943\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1006 - accuracy: 0.9732 - val_loss: 0.0370 - val_accuracy: 0.9945\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0979 - accuracy: 0.9742 - val_loss: 0.0387 - val_accuracy: 0.9912\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0950 - accuracy: 0.9748 - val_loss: 0.0345 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2114 - accuracy: 0.9228 - val_loss: 0.1455 - val_accuracy: 0.9245\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1916 - accuracy: 0.9270 - val_loss: 0.1368 - val_accuracy: 0.9341\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1785 - accuracy: 0.9293 - val_loss: 0.1377 - val_accuracy: 0.9388\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1662 - accuracy: 0.9335 - val_loss: 0.1689 - val_accuracy: 0.9216\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1578 - accuracy: 0.9373 - val_loss: 0.1395 - val_accuracy: 0.9438\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1536 - accuracy: 0.9396 - val_loss: 0.1181 - val_accuracy: 0.9450\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1481 - accuracy: 0.9410 - val_loss: 0.1554 - val_accuracy: 0.9379\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.2456 - accuracy: 0.9092 - val_loss: 0.1223 - val_accuracy: 0.9572\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2281 - accuracy: 0.9171 - val_loss: 0.1463 - val_accuracy: 0.9407\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2102 - accuracy: 0.9237 - val_loss: 0.1239 - val_accuracy: 0.9522\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2012 - accuracy: 0.9283 - val_loss: 0.1765 - val_accuracy: 0.9326\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.1942 - accuracy: 0.9312 - val_loss: 0.1698 - val_accuracy: 0.9352\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1859 - accuracy: 0.9333 - val_loss: 0.1229 - val_accuracy: 0.9575\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1803 - accuracy: 0.9343 - val_loss: 0.1004 - val_accuracy: 0.9615\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1733 - accuracy: 0.9374 - val_loss: 0.3453 - val_accuracy: 0.8915\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN resting 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_98\"\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1410 - accuracy: 0.9423 - val_loss: 0.1127 - val_accuracy: 0.9732\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1308 - accuracy: 0.9471 - val_loss: 0.1229 - val_accuracy: 0.9615\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1234 - accuracy: 0.9504 - val_loss: 0.1080 - val_accuracy: 0.9699\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1270 - accuracy: 0.9489 - val_loss: 0.0958 - val_accuracy: 0.9763\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1165 - accuracy: 0.9536 - val_loss: 0.1116 - val_accuracy: 0.9723\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1134 - accuracy: 0.9559 - val_loss: 0.1355 - val_accuracy: 0.9443\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1107 - accuracy: 0.9560 - val_loss: 0.1011 - val_accuracy: 0.9754\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN exit 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_99\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_199 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_200 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_198 (TFOp  (None, 8, 45)       0           ['input_199[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_199 (TFOp  (None, 11, 45)      0           ['input_200[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_198 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_198[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_198[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_199 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_199[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_199[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_198 (Layer  (None, 8, 45)       90          ['multi_head_attention_198[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_199 (Layer  (None, 11, 45)      90          ['multi_head_attention_199[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_396 (Dropout)          (None, 8, 45)        0           ['layer_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " dropout_397 (Dropout)          (None, 11, 45)       0           ['layer_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_198 (  (None, 45)          0           ['dropout_396[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_199 (  (None, 45)          0           ['dropout_397[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_99 (Concatenate)   (None, 90)           0           ['global_average_pooling1d_198[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_199[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_398 (Dropout)          (None, 90)           0           ['concatenate_99[0][0]']         \n",
      "                                                                                                  \n",
      " dense_198 (Dense)              (None, 128)          11648       ['dropout_398[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_399 (Dropout)          (None, 128)          0           ['dense_198[0][0]']              \n",
      "                                                                                                  \n",
      " dense_199 (Dense)              (None, 1)            129         ['dropout_399[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 15ms/step - loss: 0.2464 - accuracy: 0.9160 - val_loss: 0.0831 - val_accuracy: 0.9924\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1284 - accuracy: 0.9680 - val_loss: 0.0588 - val_accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1246 - accuracy: 0.9680 - val_loss: 0.0775 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1149 - accuracy: 0.9684 - val_loss: 0.0627 - val_accuracy: 0.9926\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1096 - accuracy: 0.9682 - val_loss: 0.0689 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1091 - accuracy: 0.9687 - val_loss: 0.0521 - val_accuracy: 0.9919\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "3 cooking\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN cooking 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_100\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_201 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_202 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_200 (TFOp  (None, 8, 45)       0           ['input_201[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_201 (TFOp  (None, 11, 45)      0           ['input_202[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_200 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_200[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_200[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_201 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_201[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_201[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_200 (Layer  (None, 8, 45)       90          ['multi_head_attention_200[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_201 (Layer  (None, 11, 45)      90          ['multi_head_attention_201[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_400 (Dropout)          (None, 8, 45)        0           ['layer_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " dropout_401 (Dropout)          (None, 11, 45)       0           ['layer_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_200 (  (None, 45)          0           ['dropout_400[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_201 (  (None, 45)          0           ['dropout_401[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_100 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_200[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_201[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_402 (Dropout)          (None, 90)           0           ['concatenate_100[0][0]']        \n",
      "                                                                                                  \n",
      " dense_200 (Dense)              (None, 128)          11648       ['dropout_402[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_403 (Dropout)          (None, 128)          0           ['dense_200[0][0]']              \n",
      "                                                                                                  \n",
      " dense_201 (Dense)              (None, 1)            129         ['dropout_403[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL cooking 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3651 - accuracy: 0.8430 - val_loss: 0.1054 - val_accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2525 - accuracy: 0.9078 - val_loss: 0.1740 - val_accuracy: 0.9429\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1835 - accuracy: 0.9297 - val_loss: 0.1293 - val_accuracy: 0.9489\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1759 - accuracy: 0.9319 - val_loss: 0.2115 - val_accuracy: 0.9329\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1745 - accuracy: 0.9339 - val_loss: 0.1364 - val_accuracy: 0.9465\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "4 shower\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN shower 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_101\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_203 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_204 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_202 (TFOp  (None, 8, 45)       0           ['input_203[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_203 (TFOp  (None, 11, 45)      0           ['input_204[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_202 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_202[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_202[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_203 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_203[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_203[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_202 (Layer  (None, 8, 45)       90          ['multi_head_attention_202[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_203 (Layer  (None, 11, 45)      90          ['multi_head_attention_203[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_404 (Dropout)          (None, 8, 45)        0           ['layer_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " dropout_405 (Dropout)          (None, 11, 45)       0           ['layer_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_202 (  (None, 45)          0           ['dropout_404[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_203 (  (None, 45)          0           ['dropout_405[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_101 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_202[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_203[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_406 (Dropout)          (None, 90)           0           ['concatenate_101[0][0]']        \n",
      "                                                                                                  \n",
      " dense_202 (Dense)              (None, 128)          11648       ['dropout_406[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_407 (Dropout)          (None, 128)          0           ['dense_202[0][0]']              \n",
      "                                                                                                  \n",
      " dense_203 (Dense)              (None, 1)            129         ['dropout_407[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL shower 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 18s 16ms/step - loss: 0.1372 - accuracy: 0.9413 - val_loss: 0.0332 - val_accuracy: 0.9888\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0353 - accuracy: 0.9896 - val_loss: 0.0258 - val_accuracy: 0.9926\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0251 - accuracy: 0.9937 - val_loss: 0.0222 - val_accuracy: 0.9919\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0222 - val_accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 0.0115 - val_accuracy: 0.9971\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN pc 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_102\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_205 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_206 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_204 (TFOp  (None, 8, 45)       0           ['input_205[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_205 (TFOp  (None, 11, 45)      0           ['input_206[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_204 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_204[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_204[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_205 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_205[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_205[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_204 (Layer  (None, 8, 45)       90          ['multi_head_attention_204[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_205 (Layer  (None, 11, 45)      90          ['multi_head_attention_205[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_408 (Dropout)          (None, 8, 45)        0           ['layer_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " dropout_409 (Dropout)          (None, 11, 45)       0           ['layer_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_204 (  (None, 45)          0           ['dropout_408[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_205 (  (None, 45)          0           ['dropout_409[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_102 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_204[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_205[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_410 (Dropout)          (None, 90)           0           ['concatenate_102[0][0]']        \n",
      "                                                                                                  \n",
      " dense_204 (Dense)              (None, 128)          11648       ['dropout_410[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_411 (Dropout)          (None, 128)          0           ['dense_204[0][0]']              \n",
      "                                                                                                  \n",
      " dense_205 (Dense)              (None, 1)            129         ['dropout_411[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.1280 - accuracy: 0.9507 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0361 - accuracy: 0.9921 - val_loss: 0.0036 - val_accuracy: 0.9990\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 15ms/step - loss: 0.0280 - accuracy: 0.9945 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0309 - accuracy: 0.9929 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0242 - accuracy: 0.9952 - val_loss: 0.0057 - val_accuracy: 0.9983\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0215 - accuracy: 0.9959 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "6 sleep\n",
      "\t\t 0 16fe\n",
      "19934 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN sleep 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_103\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_207 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_208 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_206 (TFOp  (None, 8, 45)       0           ['input_207[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_207 (TFOp  (None, 11, 45)      0           ['input_208[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_206 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_206[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_206[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_207 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_207[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_207[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_206 (Layer  (None, 8, 45)       90          ['multi_head_attention_206[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_207 (Layer  (None, 11, 45)      90          ['multi_head_attention_207[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_412 (Dropout)          (None, 8, 45)        0           ['layer_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " dropout_413 (Dropout)          (None, 11, 45)       0           ['layer_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_206 (  (None, 45)          0           ['dropout_412[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_207 (  (None, 45)          0           ['dropout_413[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_103 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_206[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_207[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_414 (Dropout)          (None, 90)           0           ['concatenate_103[0][0]']        \n",
      "                                                                                                  \n",
      " dense_206 (Dense)              (None, 128)          11648       ['dropout_414[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_415 (Dropout)          (None, 128)          0           ['dense_206[0][0]']              \n",
      "                                                                                                  \n",
      " dense_207 (Dense)              (None, 1)            129         ['dropout_415[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.1960 - accuracy: 0.9272 - val_loss: 0.0556 - val_accuracy: 0.9892\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1171 - accuracy: 0.9693 - val_loss: 0.0503 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1109 - accuracy: 0.9710 - val_loss: 0.0423 - val_accuracy: 0.9897\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1068 - accuracy: 0.9715 - val_loss: 0.0409 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1043 - accuracy: 0.9712 - val_loss: 0.0464 - val_accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "636/938 [===================>..........] - ETA: 4s - loss: 0.1039 - accuracy: 0.9719\t\t 1 5b66\n",
      "19934 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19934 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13] [0, 1]\n",
      "TRAIN kitchen 19934 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_104\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_209 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_210 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_208 (TFOp  (None, 8, 45)       0           ['input_209[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_209 (TFOp  (None, 11, 45)      0           ['input_210[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_208 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_208[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_208[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_209 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_209[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_209[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_208 (Layer  (None, 8, 45)       90          ['multi_head_attention_208[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_209 (Layer  (None, 11, 45)      90          ['multi_head_attention_209[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_416 (Dropout)          (None, 8, 45)        0           ['layer_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " dropout_417 (Dropout)          (None, 11, 45)       0           ['layer_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_208 (  (None, 45)          0           ['dropout_416[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_209 (  (None, 45)          0           ['dropout_417[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_208[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_209[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_418 (Dropout)          (None, 90)           0           ['concatenate_104[0][0]']        \n",
      "                                                                                                  \n",
      " dense_208 (Dense)              (None, 128)          11648       ['dropout_418[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_419 (Dropout)          (None, 128)          0           ['dense_208[0][0]']              \n",
      "                                                                                                  \n",
      " dense_209 (Dense)              (None, 1)            129         ['dropout_419[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19934 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3108 - accuracy: 0.8706 - val_loss: 0.1526 - val_accuracy: 0.9214\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.2146 - accuracy: 0.9261 - val_loss: 0.1552 - val_accuracy: 0.9216\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1937 - accuracy: 0.9306 - val_loss: 0.1578 - val_accuracy: 0.9276\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1788 - accuracy: 0.9328 - val_loss: 0.1545 - val_accuracy: 0.9338\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1368 - accuracy: 0.9473 - val_loss: 0.1390 - val_accuracy: 0.9477\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "\t 13 19935\n",
      "19935 ['16fe', '5b66', 'ed9c']\n",
      "0 toileting\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN toileting 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_105\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_211 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_212 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_210 (TFOp  (None, 8, 45)       0           ['input_211[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_211 (TFOp  (None, 11, 45)      0           ['input_212[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_210 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_210[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_210[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_211 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_211[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_211[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_210 (Layer  (None, 8, 45)       90          ['multi_head_attention_210[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_211 (Layer  (None, 11, 45)      90          ['multi_head_attention_211[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_420 (Dropout)          (None, 8, 45)        0           ['layer_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " dropout_421 (Dropout)          (None, 11, 45)       0           ['layer_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_210 (  (None, 45)          0           ['dropout_420[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_211 (  (None, 45)          0           ['dropout_421[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_105 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_210[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_211[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_422 (Dropout)          (None, 90)           0           ['concatenate_105[0][0]']        \n",
      "                                                                                                  \n",
      " dense_210 (Dense)              (None, 128)          11648       ['dropout_422[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_423 (Dropout)          (None, 128)          0           ['dense_210[0][0]']              \n",
      "                                                                                                  \n",
      " dense_211 (Dense)              (None, 1)            129         ['dropout_423[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL toileting 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.4253 - accuracy: 0.8006 - val_loss: 0.2738 - val_accuracy: 0.8875\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2687 - accuracy: 0.9015 - val_loss: 0.1565 - val_accuracy: 0.9474\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2461 - accuracy: 0.9101 - val_loss: 0.1961 - val_accuracy: 0.9266\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.2244 - accuracy: 0.9188 - val_loss: 0.3129 - val_accuracy: 0.8922\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2120 - accuracy: 0.9234 - val_loss: 0.2427 - val_accuracy: 0.9042\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2005 - accuracy: 0.9288 - val_loss: 0.1921 - val_accuracy: 0.9231\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1922 - accuracy: 0.9321 - val_loss: 0.1507 - val_accuracy: 0.9436\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1840 - accuracy: 0.9342 - val_loss: 0.2631 - val_accuracy: 0.9092\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1804 - accuracy: 0.9350 - val_loss: 0.1314 - val_accuracy: 0.9508\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1689 - accuracy: 0.9397 - val_loss: 0.1582 - val_accuracy: 0.9384\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "1 resting\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN resting 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_106\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_213 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_214 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_212 (TFOp  (None, 8, 45)       0           ['input_213[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_213 (TFOp  (None, 11, 45)      0           ['input_214[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_212 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_212[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_212[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_213 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_213[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_213[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_212 (Layer  (None, 8, 45)       90          ['multi_head_attention_212[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_213 (Layer  (None, 11, 45)      90          ['multi_head_attention_213[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_424 (Dropout)          (None, 8, 45)        0           ['layer_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " dropout_425 (Dropout)          (None, 11, 45)       0           ['layer_normalization_213[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_212 (  (None, 45)          0           ['dropout_424[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_213 (  (None, 45)          0           ['dropout_425[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_106 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_212[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_213[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_426 (Dropout)          (None, 90)           0           ['concatenate_106[0][0]']        \n",
      "                                                                                                  \n",
      " dense_212 (Dense)              (None, 128)          11648       ['dropout_426[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_427 (Dropout)          (None, 128)          0           ['dense_212[0][0]']              \n",
      "                                                                                                  \n",
      " dense_213 (Dense)              (None, 1)            129         ['dropout_427[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL resting 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.2910 - accuracy: 0.8650 - val_loss: 0.0901 - val_accuracy: 0.9716\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1505 - accuracy: 0.9419 - val_loss: 0.2282 - val_accuracy: 0.8915\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1378 - accuracy: 0.9470 - val_loss: 0.1028 - val_accuracy: 0.9701\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1265 - accuracy: 0.9520 - val_loss: 0.1109 - val_accuracy: 0.9675\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1227 - accuracy: 0.9527 - val_loss: 0.0985 - val_accuracy: 0.9697\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1128 - accuracy: 0.9581 - val_loss: 0.0975 - val_accuracy: 0.9656\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1093 - accuracy: 0.9588 - val_loss: 0.1318 - val_accuracy: 0.9536\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1059 - accuracy: 0.9603 - val_loss: 0.1039 - val_accuracy: 0.9680\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1009 - accuracy: 0.9611 - val_loss: 0.1016 - val_accuracy: 0.9663\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0968 - accuracy: 0.9643 - val_loss: 0.1494 - val_accuracy: 0.9386\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "2 exit\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN exit 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_107\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_215 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_216 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_214 (TFOp  (None, 8, 45)       0           ['input_215[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_215 (TFOp  (None, 11, 45)      0           ['input_216[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_214 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_214[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_214[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_215 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_215[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_215[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_214 (Layer  (None, 8, 45)       90          ['multi_head_attention_214[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_215 (Layer  (None, 11, 45)      90          ['multi_head_attention_215[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_428 (Dropout)          (None, 8, 45)        0           ['layer_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " dropout_429 (Dropout)          (None, 11, 45)       0           ['layer_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_214 (  (None, 45)          0           ['dropout_428[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_215 (  (None, 45)          0           ['dropout_429[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_107 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_214[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_215[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_430 (Dropout)          (None, 90)           0           ['concatenate_107[0][0]']        \n",
      "                                                                                                  \n",
      " dense_214 (Dense)              (None, 128)          11648       ['dropout_430[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_431 (Dropout)          (None, 128)          0           ['dense_214[0][0]']              \n",
      "                                                                                                  \n",
      " dense_215 (Dense)              (None, 1)            129         ['dropout_431[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL exit 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.2371 - accuracy: 0.9205 - val_loss: 0.0947 - val_accuracy: 0.9790\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1398 - accuracy: 0.9671 - val_loss: 0.0967 - val_accuracy: 0.9816\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1308 - accuracy: 0.9683 - val_loss: 0.0835 - val_accuracy: 0.9828\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1240 - accuracy: 0.9692 - val_loss: 0.1014 - val_accuracy: 0.9821\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1175 - accuracy: 0.9686 - val_loss: 0.0984 - val_accuracy: 0.9816\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1083 - accuracy: 0.9689 - val_loss: 0.0995 - val_accuracy: 0.9821\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1033 - accuracy: 0.9690 - val_loss: 0.0952 - val_accuracy: 0.9804\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1026 - accuracy: 0.9691 - val_loss: 0.0978 - val_accuracy: 0.9821\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.1004 - accuracy: 0.9695 - val_loss: 0.0949 - val_accuracy: 0.9828\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0977 - accuracy: 0.9702 - val_loss: 0.1075 - val_accuracy: 0.9811\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.0254 - val_accuracy: 0.9928\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 0.0344 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.0213 - val_accuracy: 0.9938\n",
      "131/131 [==============================] - 1s 4ms/step\n",
      "(4185, 1)\n",
      "5 pc\n",
      "\t\t 0 16fe\n",
      "19935 16fe [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [1, 2]\n",
      "\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN pc 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_110\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_221 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_222 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_220 (TFOp  (None, 8, 45)       0           ['input_221[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_221 (TFOp  (None, 11, 45)      0           ['input_222[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_220 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_220[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_220[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_221 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_221[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_221[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_220 (Layer  (None, 8, 45)       90          ['multi_head_attention_220[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_221 (Layer  (None, 11, 45)      90          ['multi_head_attention_221[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_440 (Dropout)          (None, 8, 45)        0           ['layer_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " dropout_441 (Dropout)          (None, 11, 45)       0           ['layer_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_220 (  (None, 45)          0           ['dropout_440[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_221 (  (None, 45)          0           ['dropout_441[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_110 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_220[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_221[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_442 (Dropout)          (None, 90)           0           ['concatenate_110[0][0]']        \n",
      "                                                                                                  \n",
      " dense_220 (Dense)              (None, 128)          11648       ['dropout_442[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_443 (Dropout)          (None, 128)          0           ['dense_220[0][0]']              \n",
      "                                                                                                  \n",
      " dense_221 (Dense)              (None, 1)            129         ['dropout_443[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL pc 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 13s 14ms/step - loss: 0.0206 - accuracy: 0.9959 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0197 - accuracy: 0.9962 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0205 - accuracy: 0.9959 - val_loss: 0.0048 - val_accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 0.0027 - val_accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "669/938 [====================>.........] - ETA: 3s - loss: 0.0184 - accuracy: 0.9959TRAIN sleep 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_111\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_223 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_224 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_222 (TFOp  (None, 8, 45)       0           ['input_223[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_223 (TFOp  (None, 11, 45)      0           ['input_224[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_222 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_222[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_222[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_223 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_223[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_223[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_222 (Layer  (None, 8, 45)       90          ['multi_head_attention_222[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_223 (Layer  (None, 11, 45)      90          ['multi_head_attention_223[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_444 (Dropout)          (None, 8, 45)        0           ['layer_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " dropout_445 (Dropout)          (None, 11, 45)       0           ['layer_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_222 (  (None, 45)          0           ['dropout_444[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_223 (  (None, 45)          0           ['dropout_445[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_111 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_222[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_223[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_446 (Dropout)          (None, 90)           0           ['concatenate_111[0][0]']        \n",
      "                                                                                                  \n",
      " dense_222 (Dense)              (None, 128)          11648       ['dropout_446[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_447 (Dropout)          (None, 128)          0           ['dense_222[0][0]']              \n",
      "                                                                                                  \n",
      " dense_223 (Dense)              (None, 1)            129         ['dropout_447[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL sleep 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.1915 - accuracy: 0.9303 - val_loss: 0.0454 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1121 - accuracy: 0.9695 - val_loss: 0.0468 - val_accuracy: 0.9871\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 14s 14ms/step - loss: 0.1088 - accuracy: 0.9706 - val_loss: 0.0505 - val_accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1006 - accuracy: 0.9720 - val_loss: 0.0436 - val_accuracy: 0.9890\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0983 - accuracy: 0.9736 - val_loss: 0.0525 - val_accuracy: 0.9883\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.0453 - val_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "109/938 [==>...........................] - ETA: 12s - loss: 0.0904 - accuracy: 0.9745\t\t 1 5b66\n",
      "19935 5b66 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 2]\n",
      "\t\t 2 ed9c\n",
      "19935 ed9c [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] [0, 1]\n",
      "TRAIN kitchen 19935 (30000, 8, 45) (30000, 8, 45) (30000, 11, 45) (30000,)\n",
      "Model: \"model_112\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_225 (InputLayer)         [(None, 8, 45)]      0           []                               \n",
      "                                                                                                  \n",
      " input_226 (InputLayer)         [(None, 11, 45)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_224 (TFOp  (None, 8, 45)       0           ['input_225[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_225 (TFOp  (None, 11, 45)      0           ['input_226[0][0]']              \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " multi_head_attention_224 (Mult  (None, 8, 45)       65925       ['tf.__operators__.add_224[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_224[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " multi_head_attention_225 (Mult  (None, 11, 45)      65925       ['tf.__operators__.add_225[0][0]'\n",
      " iHeadAttention)                                                 , 'tf.__operators__.add_225[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " layer_normalization_224 (Layer  (None, 8, 45)       90          ['multi_head_attention_224[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " layer_normalization_225 (Layer  (None, 11, 45)      90          ['multi_head_attention_225[0][0]'\n",
      " Normalization)                                                  ]                                \n",
      "                                                                                                  \n",
      " dropout_448 (Dropout)          (None, 8, 45)        0           ['layer_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " dropout_449 (Dropout)          (None, 11, 45)       0           ['layer_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_224 (  (None, 45)          0           ['dropout_448[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " global_average_pooling1d_225 (  (None, 45)          0           ['dropout_449[0][0]']            \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " concatenate_112 (Concatenate)  (None, 90)           0           ['global_average_pooling1d_224[0]\n",
      "                                                                 [0]',                            \n",
      "                                                                  'global_average_pooling1d_225[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " dropout_450 (Dropout)          (None, 90)           0           ['concatenate_112[0][0]']        \n",
      "                                                                                                  \n",
      " dense_224 (Dense)              (None, 128)          11648       ['dropout_450[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_451 (Dropout)          (None, 128)          0           ['dense_224[0][0]']              \n",
      "                                                                                                  \n",
      " dense_225 (Dense)              (None, 1)            129         ['dropout_451[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,807\n",
      "Trainable params: 143,807\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "EVAL kitchen 19935 (4185, 8, 45) (4185, 8, 45) (4185, 11, 45) (4185,)\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 17s 16ms/step - loss: 0.3142 - accuracy: 0.8679 - val_loss: 0.1710 - val_accuracy: 0.9099\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.2101 - accuracy: 0.9259 - val_loss: 0.1562 - val_accuracy: 0.9173\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1902 - accuracy: 0.9285 - val_loss: 0.1644 - val_accuracy: 0.9159\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1747 - accuracy: 0.9316 - val_loss: 0.1709 - val_accuracy: 0.9211\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.1711 - accuracy: 0.9337 - val_loss: 0.1370 - val_accuracy: 0.9331\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.1641 - accuracy: 0.9362 - val_loss: 0.1115 - val_accuracy: 0.9472\n",
      "Epoch 7/10\n",
      "403/938 [===========>..................] - ETA: 5s - loss: 0.1540 - accuracy: 0.9420"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "SizeTrainOk=4000\n",
    "SizeTrainKo=6000\n",
    "\n",
    "\n",
    "for dx,day in enumerate(days):\n",
    "    print(\"\\t\",dx,day)\n",
    "    other_dx= [other for other in range(0,len(days)) if other != dx]\n",
    "\n",
    "    day_str=getStrDatefrom(day)\n",
    "    users=users_day[day_str]\n",
    "    print(day,users)\n",
    "    \n",
    "    for ax,activity in enumerate(activities):\n",
    "            print(ax,activity)\n",
    "            \n",
    "            ##TRAING DATA\n",
    "            L1=[]\n",
    "            L2=[]\n",
    "            S=[]\n",
    "            Y=[]\n",
    "            for ux,user in enumerate(users):\n",
    "                    print(\"\\t\\t\",ux,user)\n",
    "                    other_ux= [other for other in range(0,len(users)) if other != ux]\n",
    "                    print(day,user,other_dx,other_ux)\n",
    "\n",
    "                    #OK act\n",
    "                    for ix in range(0,SizeTrainOk):\n",
    "                        #print(\"SizeTrainOk\",ix,\"vs\",SizeTrainOk)\n",
    "                        filtered_elements = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 1)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            #print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                            X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        Ss=[]\n",
    "                        for sx, sensor in enumerate(sensors):\n",
    "                            Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                        L1.append(X1s)\n",
    "                        L2.append(X2s)\n",
    "                        S.append(Ss)\n",
    "                        Y.append(user_activity[index])\n",
    "                        \n",
    "                    #KO act\n",
    "                    ix=0\n",
    "                    while ix < SizeTrainKo:\n",
    "                        #print(\"SizeTrainKo\",ix,\"vs\",SizeTrainKo)\n",
    "                        filtered_elements_specific = user_activity[ax, ux, other_dx, :]\n",
    "\n",
    "                        # Encontramos los elementos que son 1\n",
    "                        indices = np.argwhere(filtered_elements == 0)\n",
    "\n",
    "                        if(len(indices)==0):\n",
    "                            print(\"\\t\\t\\t\",\"Non activity for user \")\n",
    "                            break\n",
    "                        \n",
    "                        # Para obtener las posiciones relativas a las dimensiones originales\n",
    "                        indexs = [(ax, ux, other_dx[idx[0]], idx[1]) for idx in indices]\n",
    "                        index = random.choice(indexs)\n",
    "                        #print(\"\\t\\t\\t\",index,user_activity[index])\n",
    "                        \n",
    "                        (ia,iu,idy,tt)=index\n",
    "                        \n",
    "                        if(tt<TWA):\n",
    "                            tt=TWA\n",
    "                        if(tt>=sizeT(t0,tN)-TWB):\n",
    "                            tt=sizeT(t0,tN)-TWB\n",
    "                        \n",
    "                        \n",
    "                        X1s=[]\n",
    "                        X2s=[]\n",
    "                        none=True\n",
    "                        for ax2,activity2 in enumerate(activities):\n",
    "                            #if(ax2==ax):\n",
    "                                r=np.random.rand()\n",
    "                                #print(\" removing loc?:\",loc_user[ax2][iu][idy][tt],r)\n",
    "                                if(r<loc_user[ax2][iu][idy][tt]+0.05):\n",
    "                                    #print(\"NOT  removing loc:\",loc_user[ax2][iu][idy][tt])\n",
    "                                    none=False\n",
    "                                    \n",
    "                                X1s.append(loc_user[ax2][iu][idy][tt-TWA:tt+TWB])\n",
    "                                X2s.append(np.amax(loc_user[ax2,other_ux,idy,tt-TWA:tt+TWB],axis=0))\n",
    "                            \n",
    "                            \n",
    "                        if not none:\n",
    "                            L1.append(X1s)\n",
    "                            L2.append(X2s)\n",
    "                            Ss=[]\n",
    "                            for sx, sensor in enumerate(sensors):\n",
    "                                Ss.append(act_sensors[sx][idy][tt-TWA:tt+TWB])\n",
    "                            S.append(Ss)\n",
    "                            Y.append(user_activity[index])       \n",
    "                            ix=ix+1\n",
    "\n",
    "            L1=np.array(L1)        \n",
    "            L2=np.array(L2)        \n",
    "            S=np.array(S)\n",
    "            Y=np.array(Y)\n",
    "            print(\"TRAIN\",activity,day,L1.shape,L2.shape,S.shape,Y.shape)\n",
    "            \n",
    "            \n",
    "            model=getModelHAR()\n",
    "            model.summary()\n",
    "            \n",
    "            ##TEST DATA\n",
    "            TL1=[]\n",
    "            TL2=[]\n",
    "            TS=[]\n",
    "            TY=[]\n",
    "            \n",
    "            \n",
    "            (t0,tN)=t0N_days[day]\n",
    "            ts=list(range(TWA,sizeT(t0,tN)-TWB))\n",
    "            \n",
    "            for ux2,user2 in enumerate(users):\n",
    "                other_ux2= [other for other in range(0,len(users)) if other != ux2]\n",
    "\n",
    "                for tx in ts:\n",
    "\n",
    "                    Ss=[]\n",
    "                    for sx, sensor in enumerate(sensors):\n",
    "                        Ss.append(act_sensors[sx][dx][tx-TWA:tx+TWB])\n",
    "                    \n",
    "                    X1s=[]\n",
    "                    X2s=[]\n",
    "                    for ax2,activity2 in enumerate(activities):\n",
    "                        X1s.append(loc_user[ax2][ux2][dx][tx-TWA:tx+TWB])\n",
    "                        X2s.append(np.amax(loc_user[ax2,other_ux2,dx,tx-TWA:tx+TWB],axis=0))\n",
    "\n",
    "\n",
    "                    TL1.append(X1s)\n",
    "                    TL2.append(X2s)\n",
    "                    TS.append(Ss)\n",
    "                    TY.append(user_activity[ax, ux2, dx, tx])\n",
    "                        \n",
    "            TL1=np.array(TL1)        \n",
    "            TL2=np.array(TL2)        \n",
    "            TS=np.array(TS)\n",
    "            TY=np.array(TY)\n",
    "            print(\"EVAL\",activity,day,TL1.shape,TL2.shape,TS.shape,TY.shape)\n",
    "            \n",
    "            history = model.fit([L1,S] , Y, shuffle=True, batch_size=32,epochs=10, validation_data = ([TL1,TS], TY))\n",
    "            YT_prediction = model.predict([TL1,TS])\n",
    "            print(YT_prediction.shape)\n",
    "            \n",
    "            ix=0\n",
    "            for ux2,user2 in enumerate(users):\n",
    "                with open(processed_data_folder+\"/DAY_\"+str(day)+\"/act/PREDICTION-Transformer-position-encoding-no-others-45+0.\"+user2+\".\"+activity+\".tsv\", \"w\") as file:\n",
    "                    for tx in (ts):\n",
    "                        tt=tx*time_step2+t0\n",
    "                        #print(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0]))\n",
    "                        file.write(\"\\t\"+time2str(t0,tN,tt)+\"\\t\"+str(TY[ix])+\"\\t\"+str(YT_prediction[ix][0])+\"\\n\")\n",
    "                        \n",
    "                        ix=ix+1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fc952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
